{"doc": "Commercial recommender systems use various data mining techniques to make appropriate recommendations to users during online , real-time sessions . Published algorithms focus more on the discrete user ratings instead of binary results , which hampers their predictive capabilities when usage data is sparse . The system proposed in this paper , e-VZpro , is an association mining-based recommender tool designed to overcome these problems through a two-phase approach . In the first phase , batches of customer historical data are analyzed through association mining in order to determine the association rules for the second phase . During the second phase , a scoring algorithm is used to rank the recommendations online for the customer . The second phase differs from the traditional approach and an empirical comparison between the methods used in e-VZpro and other collaborative filtering methods including dependency networks , item-based , and association mining is provided in this paper . This comparison evaluates the algorithms used in each of the above methods using two internal customer datasets and a benchmark dataset . The results of this comparison clearly show that e-VZpro performs well compared to dependency networks and association mining . In general , item-based algorithms with cosine similarity measures have the best performance . Introduction Customers on the web are often overwhelmed with options and flooded with promotional messages for products or services they neither need nor want . When users cannot find what they are searching for , the e-commerce site struggles to maintain good customer relations. Employing a recommender system as part of a site's Customer Relationship Management (CRM) activities can overcome the problems associated with providing users with too little information , or too much of the wrong information . Recommender systems are able to assist customers during catalog browsing and are an e#ective way to cross-sell and improve customer loyalty. In this paper , we will compare several recommender systems being used as an essential component of CRM tools under development at Verizon . Our solutions are purposely for the current customers and current products - recommendations for new customers and new products are out of the scope of this paper. According to Breese et al. , 1998 , there are two main approaches used in recommender systems: memory and model-based systems . Memory-based recommender systems , such as correlation analysis and vector similarity , search the customer database for customer profiles that are similar to the profile of the active customer . For this type of recommender system , it is important that the customer database remain in system memory during the algorithm's runtime . Model-based methods , such as Bayesian networks and Clustering models , approach the problem from a probabilistic perspective to find the best product for a given customer profile Breese et al. , 1998 and need only keep the resulting model in memory while the algorithm runs . The above methods will be described in the following sections. Because memory-based approaches make predictions based on the local neighborhood of the active user and the model-based approach bases its", "label": ["customer relationship management", "collaborative filtering", "association mining", "recommender systems", "e-commerce", "dependency networks"], "stemmed_label": ["custom relationship manag", "collabor filter", "associ mine", "recommend system", "e-commerc", "depend network"]}
{"doc": "We give a formal semantics for a highly expressive language for representing temporal relationships and events . This language , which we call Versatile Event Logic (VEL) , provides a general temporal ontology and semantics encompassing many other representations . The system incorporates a number of features that have not been widely employed in AI formalisms . It has the ability to describe alternative histories using a modal operator . It provides a semantics for individuals that explicitly models their identity through time and across alternative possible histories; and enables one to distinguish between necessary and extensional identity of individuals . In virtue of its treatment of individuals and count nouns , the formalism offers a solution to certain puzzles of identity , which arise when individuals are described in different ways . We propose that VEL can be used as a foundational interlingua for comparing and interfacing different AI languages and illustrate this by considering how Situation Calculus and Event Calculus can be represented within VEL . Introduction Many researchers in the eld of AI have recognised the need for formal representation languages capable of expressing high-level information in a naturalistic form | e.g . (Hayes 1979 , Davis 1990) . Of central importance to such a representation is a precise analysis of the semantics of actions , events and temporal relations . Among the most in uential of the large number of formalisms proposed to deal with these are: the Situation Calculus (McCarthy and Hayes 1969) , Allen's theory of action and time (Allen 1984) and the Event Calculus (Kowalski and Sergot 1986 , Shanahan 1999) . Philosophers have also examined various logical aspects of events and we aim to take into account in particular the analyses given by Davidson (1980) and Galton (1984) . We present unifying language that we call Versatile Event Logic (VEL) embodying a range of insights into the logic of time and events. Representations of time within formal languages can be readily divided into three main approaches: Explicit reference to time points and a temporal ordering relation. Explicit reference to temporal intervals and the temporal relationships between them (which implicitly constrain the ordering of the end-points of the intervals). Use of propositional tenses to convey temporal relationships among facts (without explict reference to any temporal entities). Whereas most temporal logics incorporate only one of these ways of refering to temporal structure , in our formalism all three of them happily coexist . A single VEL formula can contain time point and interval variables as well as tenses (though it truns out , unsurprisingly , that all of these constructs are in fact reducible to logically equivalent expressions involving just time points and the temporal ordering relation). Our formalism incorporates each of the following analyses: Events as Transitions: A view of events that can be found in some of the earliest AI systems is that an event is a transition between states . This idea is the basis of STRIPS (Fikes and Nilsson 1971) and also the Situation Calculus (McCarthy and Hayes 1969) . The transition", "label": ["semantics", "temporal logic"], "stemmed_label": ["semant", "tempor logic"]}
{"doc": "The work described in this report is motivated by the desire to test the expressive possibilities of action language C+ . The Causal Calculator (CCALC) is a system that answers queries about action domains described in a fragment of that language . The Zoo World and the Traffic World have been proposed by Erik Sandewall in his Logic Modelling Workshop--an environment for communicating axiomatizations of action domains of nontrivial size.The Zoo World consists of several cages and the exterior , gates between them , and animals of several species , including humans . Actions in this domain include moving within and between cages , opening and closing gates , and mounting and riding animals . The Traffic World includes vehicles moving continuously between road crossings subject to a number of restrictions , such as speed limits and keeping a fixed safety distance away from other vehicles on the road . We show how to represent the two domains in the input language of CCALC , and how to use CCALC to test these representations . Introduction The work described in this report is motivated by the desire to test the expressive possibilities of action language C+ introduced in the companion paper . Specically , we are interested in the expres- Preprint submitted to Elsevier Science siveness of the \\denite\" fragment of C+ that is implemented in the Causal Calculator (CCalc). Language C+ is a recent addition to the family of formal languages for describing actions , which started with STRIPS Fikes and Nilsson , 1971 and . It is an extension of action language C dened in Giunchiglia and Lifschitz , 1998 . The Causal Calculator uses propositional sat- isability solvers to answer queries about action domains described in C+. Its original version was written by Norman McCain as part of his dissertation now it is being maintained by Texas Action Group at Austin . 1 It can be downloaded from its home page http://www.cs.utexas.edu/users/tag/ccalc/ . CCalc has been applied to several challenge problems in the theory of commonsense knowledge Lifschitz , 2000 and to the formalization of norm-governed computational systems . The two test domains discussed in this paper , the Zoo World and the Tra-c World , have been proposed by Erik Sandewall in his Logic Modelling Workshop environment for communicating axiomatizations of action domains of nontrivial size . The Zoo World consists of several cages and the ex- terior , gates between them , and animals of several species , including humans. Actions in this domain include moving within and between cages , opening and closing gates , and mounting and riding animals . The Tra-c World includes vehicles moving continuously between road crossings subject to a number of restrictions , such as speed limits and keeping a xed safety distance away from other vehicles on the road . More details can be found in the next section , which contains extensive quotes from the LMW descriptions of both domains. In accordance with our goal , we have attempted to translate these descriptions into the input language of CCalc", "label": ["action languages", "knowledge representation", "reasoning about actions", "commonsense reasoning"], "stemmed_label": ["action languag", "knowledg represent", "reason about action", "commonsens reason"]}
{"doc": "We describe a logic-based AI architecture based on Brooks' subsumption architecture . In this architecture , we axiomatize different layers of control in First-Order Logic (FOL) and use independent theorem provers to derive each layer's outputs given its inputs . We implement the subsumption of lower layers by higher layers using nonmonotonic reasoning principles . In particular , we use circumscription to make default assumptions in lower layers , and nonmonotonically retract those assumptions when higher layers draw new conclusions . We also give formal semantics to our approach . Finally , we describe layers designed for the task of robot control and a system that we have implemented that uses this architecture for the control of a Nomad 200 mobile robot.Our system combines the virtues of using the represent-and-reason paradigm and the behavioral-decomposition paradigm . It allows multiple goals to be serviced simultaneously and reactively . It also allows high-level tasks and is tolerant to different changes and elaborations of its knowledge in runtime . Finally , it allows us to give more commonsense knowledge to robots . We report on several experiments that empirically show the feasibility of using fully expressive FOL theorem provers for robot control with our architecture and the benefits claimed above . Introduction In (Brooks 1986) , Rodney Brooks provided a decomposition of the problem of robot control into layers corresponding to levels of behavior , rather than according to a sequential , functional form . Within this setting , he introduced the idea of subsumption , that is , that more complex layers could not only depend on lower , more reactive layers , but could also influence their behavior. The resulting architecture was one that could service simultaneously multiple , potentially conflicting goals in a reactive fashion , giving precedence to high priority goals. Because of its realization in hardware , the architecture lacks declarativeness , making it difficult to implement higher-level reasoning and making its semantics unclear . Furthermore , the increasing hardware complexity with new layers introduces scaling problems . Fi- nally , relying on hardware specifications , the architecture is specifically oriented towards robot control and is not applicable to software agents or other software-based intelligent agents . The problem of extending similar architectures to more complex tasks and goals and to agents that are not necessarily physical , has already been raised and discussed in general lines by (Minsky 1985) and (Stein 1997) , but , to our knowledge , no practical AI architecture has been developed along these lines. In this paper we describe an architecture modeled in the spirit of Brooks' Subsumption Architecture but which relies on a logical framework and which has wider applicability and extendability in the manner described above . Our Logic-Based Subsumption Architecture includes a set of logical theories , each corresponding to a layer in the sense of Brooks' archi- tecture . Each layer is supplied with a separate theorem prover , allowing the system of layers to operate concur- rently . We use an approximation of nonmonotonic reasoning to model the connections", "label": ["cognitive robotics", "subsumption architecture", "logical representations"], "stemmed_label": ["cognit robot", "subsumpt architectur", "logic represent"]}
{"doc": "This article proves the conjecture of Thomas that , for every graph G , there is an integer k such that every graph with no minor isomorphic to G has a 2-coloring of either its vertices or its edges where each color induces a graph of tree-widlh at most k . Some generalizations are also proved . Introduction A vertex partition of a graph G , into n parts , is a set P 1 , - , P n of induced subgraphs of G such that # n An edge partition of a graph G , into n parts , is a set Q 1 , - , Q n of subgraphs of G such that # n partition into n parts , can be associated with a coloring (of edges or vertices , as appropriate) with n colors in the obvious way. The edge partition Q 1 , - , Q n of a graph G is balanced , as witnessed by a vertex partition P 1 , j . This is a technical condition needed later . In terms of colorings , with a set of colors C , the edge coloring, witnessed by a vertex coloring , c for every edge e with endpoints u , v, it holds that c E Given a graph G , a T -decomposition of G is a pair (T , X) , where T is a graph, and for each vertex t of T , there is a bag X t # V (G) such that and the following are satisfied. (2) For every edge xy of G , there is a t # V (T ) such that x , y # X t . (3) For every x # V (G) , the subgraph of T induced by t # V connected. The width of (T , X) is Date: May 1 , 2001. 1991 Mathematics Subject Classification . Primary: 05C15; Secondary: 05C55. Key words and phrases . tree-width , vertex partitions , edge partitions , small components. This author's research was partially supported by National Science Foundation under Grant DMS-9400946. This author's research was partially supported by the National Security Agency , grant number MDA904-94-H-2057. 3 This author's research was supported by the O#ce of Naval Research , grant number N00014- 92-J-1965. 4 Research of these authors was partially supported by the Louisiana Education Quality Support Fund , grant LEQSF(1995-98)-RD-A-08. If T is a tree , then (T , X) is a tree-decomposition . The tree-width of a graph G, denoted tw(G) , is the smallest integer w such that G has a tree-decomposition of width w . A graph is a partial k-tree if it has tree-width at most k . Tree-width is important not only for its theoretical application in the graph minors project , but also for its algorithmic qualities: many problems which are NP-hard for the class of all graphs are solvable in linear time for the class of graphs of tree-width at most k for every fixed k. Given graphs G and H", "label": ["vertex partitions", "tree-width", "edge partitions", "small components"], "stemmed_label": ["vertex partit", "tree-width", "edg partit", "small compon"]}
{"doc": "The performance of IP networks depends on a wide variety of dynamic conditions . Traffic shifts , equipment failures , planned maintenance , and topology changes in other parts of the Internet can all degrade performance . To maintain good performance , network operators must continually reconfigure the routing protocols . Operators configure BGP to control how traffic flows to neighboring Autonomous Systems (ASes) , as well as how traffic traverses their networks . However , because BGP route selection is distributed , indirectly controlled by configurable policies , and influenced by complex interactions with intradomain routing protocols , operators cannot predict how a particular BGP configuration would behave in practice . To avoid inadvertently degrading network performance , operators need to evaluate the effects of configuration changes before deploying them on a live network . We propose an algorithm that computes the outcome of the BGP route selection process for each router in a single AS , given only a static snapshot of the network state , without simulating the complex details of BGP message passing . We describe a BGP emulator based on this algorithm; the emulator exploits the unique characteristics of routing data to reduce computational overhead . Using data from a large ISP , we show that the emulator correctly computes BGP routing decisions and has a running time that is acceptable for many tasks , such as traffic engineering and capacity planning . INTRODUCTION The delivery of IP packets through the Internet depends on a large collection of routers that compute end-to-end paths in a dis- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. tributed fashion , using standardized routing protocols . Providing low latency , high throughput , and high reliability requires network operators to adjust routing protocol configuration when performance problems arise or network conditions change . For example , an operator might adjust the configuration to respond to network congestion or equipment failures or to prepare for planned maintenance. However , the complexity of the protocols , the large number of tunable parameters , and the size of the network make it extremely difficult for operators to reason about the effects of their actions. The common approach of \"tweak and pray\" is no longer acceptable in an environment where users have high expectations for performance and reliability 1 . To avoid costly debugging time and catastrophic mistakes , operators must be able to make predictions quickly based on an accurate model of the routing protocols. Previous work in this area has focused on Interior Gateway Protocols (IGPs) , such as Open Shortest Path First (OSPF) and Intermediate System-Intermediate System (IS-IS) , that operate within a single Autonomous", "label": ["routing", "modeling", "bgp", "traffic engineering"], "stemmed_label": ["rout", "model", "bgp", "traffic engin"]}
{"doc": "We present a collective approach to learning a Bayesian network from distributed heterogeneous data . In this approach , we first learn a local Bayesian network at each site using the local data . Then each site identifies the observations that are most likely to be evidence of coupling between local and non-local variables and transmits a subset of these observations to a central site . Another Bayesian network is learnt at the central site using the data transmitted from the local site . The local and central Bayesian networks are combined to obtain a collective Bayesian network , which models the entire data . Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented . Table 1 . Homogeneous case: Site A with a table for credit card transaction records. Account Amount Location Previous Unusual Number record transaction Table 2 . Homogeneous case: Site B with a table for credit card transaction records. Account Amount Location Previous Unusual Number record transaction commercial domains (e.g . the Internet and corporate intranets) introduces a new dimension to this process | a large number of distributed sources of data that can be used for discovering knowledge . Cost of data communication between the distributed databases is a signicant factor in an increasingly mobile and connected world with a large number of distributed data sources . This cost consists of several components like (a) limited network bandwidth , (b) data security, and (c) existing organizational structure of the applications environment . The eld of Distributed Knowledge Discovery and Data Mining (DDM) studies algo- rithms , systems , and human-computer interaction issues for knowledge discovery applications in distributed environments for minimizing this cost. In this paper , we consider a Bayesian network (BN) model to represent uncertain knowledge . Specically , we address the problem of learning a BN from heterogenous distributed data . It uses a collective data mining (CDM) approach introduced earlier by Kargupta et . al . (Kargupta , Huang , Sivakumar and Johnson , 2001; Kargupta , Park , Hershberger and Johnson , 2000; Hershberger and Kargupta , 2001; Park and Kargupta , 2002) . Section 2 provides some background and reviews existing literature in this area . Section 3 presents the collective Bayesian learning technique . Experimental results for three datasets | one simulated and two real world | are presented in Section 4 . A preliminary version of these results have been presented in (Chen , Sivakumar and Kargupta , 2001a; Chen , Sivakumar and Kargupta , 2001b) . Finally , Section 5 provides some concluding remarks and directions for future work. 2 . Background , Motivation , and Related Work In this section , we provide and background and motivation to the problem by means of an example . We then review the existing literature in this area. Distributed data mining (DDM) must deal with dierent possibilities of data distribution . Dierent sites may contain data for a common set of features of the Collective Mining of Bayesian Networks from Distributed Heterogeneous Data 3 problem", "label": ["distributed data mining", "bayesian network", "heterogeneous data", "web log mining", "collective data mining"], "stemmed_label": ["distribut data mine", "bayesian network", "heterogen data", "web log mine", "collect data mine"]}
{"doc": "Measuring the information retrieval effectiveness of World Wide Web search engines is costly because of human relevance judgments involved . However , both for business enterprises and people it is important to know the most effective Web search engines , since such search engines help their users find higher number of relevant Web pages with less effort . Furthermore , this information can be used for several practical purposes . In this study we introduce automatic Web search engine evaluation method as an efficient and effective assessment tool of such systems . The experiments based on eight Web search engines , 25 queries , and binary user relevance judgments show that our method provides results consistent with human-based evaluations . It is shown that the observed consistencies are statistically significant . This indicates that the new method can be successfully used in the evaluation of Web search engines . Table Desirable features of Web search evaluation according to Gordon and Pathak (1999): features 1?7 and Hawking et al. features 8?11 1 . The searches should be motivated by genuine information-needs of Web users 2 . If a search intermediary is employed , the primary searchers information-need should be captured as fully as and with as much context possible and transmitted to the intermediary 3 . A su?ciently large number of searches must be conducted to obtain meaningful evaluations of search engine e?ectiveness 4 . Most major search engines should be considered 5 . The most e?ective combination of speci?c features of each search engine should be exploited (i.e . the queries submitted to the engines may be di?erent) 6 . The user who needs the information must make relevance judgments (Hawking et al . (2001) assumes that independent judges can do it) 7 . Experiments should (a) prevent bias towards search engines (e.g. , by blinding or randomizing search outputs), (b) use accepted information retrieval measures , (c) employ statistical tests to measure performance di?erences of search engines 8 . The search topics should represent the range of information-needs over which it is desired to draw conclusions 9 . Result judging should be appropriate to the type of query submitted (e.g. , some queries may need a one-line answer) 10 . Document presentation should be like that of a Web browser (images should be viewable , if necessary it should be possible to follow links) 11 . Dead links should count as useless answers in addition to the seven items speci?ed in Gordon and Pathak (1999) study (they are also provided in Table 1) . Note that , our approach is di?erent than these two studies , since we aim to automate the evaluation process. In this study , we satisfy all the features given in Table 1 except features 2 and 5 . Feature 2 does not apply to us; furthermore , contrary to the suggestion of the authors , in such studies we believe that genuine user queries should be used . By this way the true everyday behavior of the search engines will be measured . Feature 5 requires", "label": ["information retrieval", "world wide web", "search engine", "performance"], "stemmed_label": ["inform retriev", "world wide web", "search engin", "perform"]}
{"doc": "We present two algorithms for the problem of finding a minimum transversal in a hypergraph of rank 3 , also known as the 3-Hitting Set problem . This problem is a natural extension of the vertex cover problem for ordinary graphs . The first algorithm runs in time O(1.6538n) for a hypergraph with n vertices , and needs polynomial space . The second algorithm uses exponential space and runs in time O(1.6316n) . INTRODUCTION Hypergraphs are a generalization of graphs , where the edges (called hyperedges) may consist of 1 , 2 , or more vertices . A hypergraph is of rank k if the largest hyperedge contains k vertices . A transversal , also known as a hitting set or a vertex cover , is a subset T ' V of the vertices that includes at least one vertex from every hyperedge. Minimum Transversal , the problem of finding a transversal of minimum cardinality for a hypergraph , is NP-complete , both in the general case and for hypergraphs of maximum rank k ? 1 6 . In this article , we will only consider the problem when the hypergraph is of rank 3 . Finding a transversal of minimum cardinality is equivalent to finding an independent set of maximum cardinality , but transversals are much more widely studied for hypergraphs than independent sets. Finding hypergraph transversals has applications in many areas , for example artificial intelligence and database theory 4 . The particular situation of finding a small transversal in a large rank-3 hypergraph is encountered in computational biology , when computing evolutionary phylogenies 3 . There is a close connection between computing the set of all minimal transversals T r(H) of a hypergraph H and the data mining problem of This research is partially supported by CUGS - National Graduate School in Computer Science , Sweden. finding maximally specific sentences that are interesting in a database 8 . Furthermore , the Minimum Transversal problem is a natural generalization of the Vertex Cover problem for ordinary graphs. Our algorithm is the first exact algorithm that we are aware of that solves this problem in a time which is provably lower than O(2 n ) . Some algorithms for related problems could be used to solve Minimum Transver- sal , but they do not provide any such guarantee . In particular , Niedermeier and Rossmanith 13 have constructed an algorithm for the parameterized version of our problem , where one tries to find a transversal smaller than a given parameter k , which runs in time O(2:270 k +n) . We will take a closer look at the applicability of this and other previous algorithms in Section 3. As for other related results , beyond the ones mentioned in Section 3, there is an approximation algorithm for Minimum Transversal in 10 , and 5 deals with the Transversal Hypergraph problem in its most general form. In the main part of the paper , we present two algorithms for Minimum Transversal: one using polynomial space which runs in O(1:6538 n and one", "label": ["minimum transversal", "exact algorithm", "hypergraph", "3-hitting set"], "stemmed_label": ["minimum transvers", "exact algorithm", "hypergraph", "3-hit set"]}
{"doc": "A prevailing feature of mobile telephony systems is that the cell where a mobile user is located may be unknown . Therefore , when the system is to establish a call between users , it may need to search , or page , all the cells that it suspects the users are located in , to find the cells where the users currently reside . The search consumes expensive wireless links and so it is desirable to develop search techniques that page as few cells as possible.We consider cellular systems with c cells and m mobile users roaming among the cells . The location of the users is uncertain as given by m probability distribution vectors . Whenever the system needs to find specific users , it conducts a search operation lasting some number of rounds (the delay constraint) . In each round , the system may check an arbitrary subset of cells to see which users are located there . In this setting the problem of finding one user with minimum expected number of cells searched is known to be solved optimally in polynomial time.In this paper we address the problem of finding several users with the same optimization goal . This task is motivated by the problem of establishing a conference call between mobile users . We first show that the problem is NP-hard . Then we prove that a natural heuristic is an e/(e - 1 )-approximation solution . INTRODUCTION In the last decade , we have witnessed two trends: increasing availability of people and increasing availability of infor- mation . Mobile telephony systems make it possible to talk with people even if they are not residing in predetermined locations (as is the case with conventional phone systems). Internet search engines allow users to accurately and eciently access information stored on websites that have xed location . When information is stored on mobile devices and needs to be retrieved new challenges occur . An intrinsic feature of current mobile telephony systems is that location of the devices is uncertain . A challenge here is to design search algorithms that e-ciently retrieve information given limited knowledge about its location. In this paper we focus on search techniques that are motivated by the problem of establishing a conference call in a wireless phone system . Our goal is to nd a given collection of mobile devices inside a wireless system so as to minimize the usage of expensive wireless links and control the amount of time spent on the search. 1.1 Background and motivation Our problem of establishing wireless conference calls is motivated by the state-of-the-art of wireless technology . Currently deployed wireless personal communication systems are composed of a set of base stations connected by a wired backbone network . The range of radio transmission of a base station determines an area called a cell . Each mobile device that roams inside the system communicates with other devices (mobile or stationary) through base stations using signals . When a mobile device is within the range of a base station the", "label": ["approximation algorithms", "np-hardness", "conference call", "location management", "convex optimization"], "stemmed_label": ["approxim algorithm", "np-hard", "confer call", "locat manag", "convex optim"]}
{"doc": "This paper introduces a class of linear programming examples that cause the simplex method to cycle and that are the simplest possible examples showing this behaviour . The structure of examples from this class repeats after two iterations . Cycling is shown to occur for both the most negative reduced cost and steepest-edge column selection criteria . In addition it is shown that the expand anti-cycling procedure of Gill et al . is not guaranteed to prevent cycling . Introduction Degeneracy in linear programming is of both theoretical and practical impor- tance . It occurs whenever one or more of the basic variables is at its bound, and when this occurs it is possible that an iteration of the simplex method fails to improve the objective function . The simple proof of finiteness of the simplex algorithm relies on a strict improvement in the objective function at each iteration and the fact that the simplex method visits only basic solu- tions , of which there are a finite number . However if the problem is degenerate this proof does not hold: there is the possibility of a consecutive sequence of iterations occurring with no change in the objective function and with the eventual return to a previously encountered basis . Examples , such as Beale's well known example 2 , have been constructed to show that this can happen, supported by EPSRC grant GR/J0842 Preprint submitted to Elsevier Preprint 29 September 1996 though such examples do seem to be very rare in practice . A more common practical situation is where a long but finite sequence of iterations occurs without the objective function improving - a situation called stalling - and this can degrade the algorithm's performance. A related issue is the behaviour of the simplex algorithm in the presence of roundoff error . At a degenerate vertex there is a serious danger of selecting pivots which are small and have a high relative error. A wide range of methods have been suggested to avoid these problems. Lexicographic ordering: These methods are guaranteed to terminate in exact arithmetic but are often prohibitively expensive to implement for the revised simplex method and do not address the problem of inexact arithmetic. Primal-dual alternation methods: These methods were introduced by Balin- ski and Gomory 1 and have recently been developed by Fletcher 3,5,4 . Some of these methods both guarantee to terminate in exact arithmetic and exhibit good behaviour with inexact arithmetic. Constraint perturbation methods and feasible set enlargement methods: These method attempt to reduce the likelyhood of cycling and also attempt to improve the numerical behaviour and reduce the number of iterations. The Devex and expand procedures described below are of this type . In addition it is claimed that stalling cannot occur with expand . Wolfe's method is a recursive perturbation method which guarantees termination in exact arithmetic. In 10 Wolfe introduced a perturbation method which is guaranteed to terminate in a finite number of steps in exact arithmetic . In this method whenever a degenerate vertex is encountered , the bounds producing", "label": ["degeneracy", "simplex method", "expand", "cycling"], "stemmed_label": ["degeneraci", "simplex method", "expand", "cycl"]}
{"doc": "Continuous testing uses excess cycles on a developer's workstation to continuously run regression tests in the background , providing rapid feedback about test failures as source code is edited . It is intended to reduce the time and energy required to keep code well-tested and prevent regression errors from persisting uncaught for long periods of time . This paper reports on a controlled human experiment to evaluate whether students using continuous testing are more successful in completing programming assignments . We also summarize users' subjective impressions and discuss why the results may generalize.The experiment indicates that the tool has a statistically significant effect on success in completing a programming task , but no such effect on time worked . Participants using continuous testing were three times more likely to complete the task before the deadline than those without . Participants using continuous compilation were twice as likely to complete the task , providing empirical support to a common feature in modern development environments . Most participants found continuous testing to be useful and believed that it helped them write better code faster , and 90% would recommend the tool to others . The participants did not find the tool distracting , and intuitively developed ways of incorporating the feedback into their workflow . INTRODUCTION Continuous testing uses excess cycles on a developer's workstation to continuously run regression tests in the background as the developer edits code . It provides developers rapid feedback regarding errors that they have inadvertently introduced . Continuous testing is inspired by continuous compilation , a feature of many Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 11-14 , 2004 , Boston , Massachusetts , USA. modern development environments that gives rapid feedback about compilation errors . This paper experimentally evaluates whether the extra feedback from continuous testing assists developers in a programming task without producing harmful side effects. It is good practice to use a regression test suite while performing development tasks such as enhancing or refactoring an existing codebase . (Test-driven development 3 seeks to extend this situation to all development tasks: before each piece of functionality is added , a test for the functionality is written , added to the suite, and observed to fail.) During development , running the test suite bolsters the developer's confidence that they are making steady progress , and catches regression errors early . The longer a regression error persists without being caught , the larger its drain on pro- ductivity: when the error is found , more code changes must be considered to find the changes that directly pertain to the error , the code changes are no longer fresh in the", "label": ["continuous testing", "continuous compilation", "unit testing", "test-first development"], "stemmed_label": ["continu test", "continu compil", "unit test", "test-first develop"]}
{"doc": "We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures . We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java TreeMap library , using the Java PathFinder model checker . Three different test generation techniques will be introduced and compared , namely , straight model checking of the code , model checking used in a black-box fashion to generate all inputs up to a fixed size , and lastly , model checking used during white-box test input generation . The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data , taking into account complex method preconditions . We evaluate our approaches by generating tests for the red-black tree 16 implementation in the Java TreeMap li- brary . The contributions of our work are: A powerful and exible test input generation frame-work for unit testing . The framework uses an ecient approach to the symbolic execution of code manipulating complex data structures , that takes into account preconditions to stop the analysis of infeasible paths as soon as possible . The framework can be used uniformly both for white-box and black-box testing. We show how our framework can be used for generating tests for code manipulating complex data structures specically red-black trees. We illustrate the exibility of model checking as a tool for test input creation by comparing straight model checking of the code under test , a black-box approach and a white-box approach. 2 . BACKGROUND We describe here the Java PathFinder (JPF) model checker 43 that has been extended with a symbolic execution ca- x: X , y: Y PC: true x: X , y: Y PC: X Y x: X , y: Y PC: X =Y x: X+Y , y: Y PC: X Yint x, 1:if 2: 3: 4: 5: if (x y) x: X+Y , y: X PC: X Y x: Y , y: X PC: X Y x: Y , y: X x: Y , y: X Figure 1: Code that swaps two integers and the corresponding execution tree , where transitions are labelled with program control points pability . We show in Section 4 how we use this extension of JPF for white-box and black-box test input generation. 2.1 Java PathFinder JPF is an explicit-state model checker for Java programs that is built on top of a custom-made Java Virtual Machine (JVM) . JPF can handle all of the language features of Java and it also treats nondeterministic choice expressed in annotations of the program being analyzed | annotations are added to the programs through method calls to a special class Verify . The following methods from the Verify class will be used in this paper: randomBool() returns a boolean value nondeterministically. random(n) returns values 0; n nondeterministically. ignoreIf(cond) forces the model checker to backtrack when cond evaluates to true. JPF has previously been used", "label": ["symbolic execution", "coverage", "testing object-oriented programs", "model checking", "red-black trees"], "stemmed_label": ["symbol execut", "coverag", "test object-ori program", "model check", "red-black tree"]}
{"doc": "A multi-mode software system contains several distinct modes of operation and a controller for deciding when to switch between modes . Even when developers rigorously test a multi-mode system before deployment , they cannot foresee and test for every possible usage scenario . As a result , unexpected situations in which the program fails or underperforms (for example , by choosing a non-optimal mode) may arise . This research aims to mitigate such problems by creating a new mode selector that examines the current situation , then chooses a mode that has been successful in the past , in situations like the current one . The technique , called program steering , creates a new mode selector via machine learning from good behavior in testing or in successful operation . Such a strategy , which generalizes the knowledge that a programmer has built into the system , may select an appropriate mode even when the original controller cannot . We have performed experiments on robot control programs written in a month-long programming competition . Augmenting these programs via our program steering technique had a substantial positive effect on their performance in new environments . INTRODUCTION Software failures often result from the use of software in unexpected or untested situations , in which it does not behave as intended or desired 18 . Software cannot be tested in every situation in which it might be used . Even if exhaustive testing were possi- ble , it is impossible to foresee every situation to test . This research takes a step toward enabling software systems to react appropriately to unanticipated circumstances. Our research focuses on multi-mode software systems . A multi-mode system contains multiple distinct behaviors or input-output relationships , and the program operates in different modes depend- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 11-14 , 2004 , Boston , Massachusetts , USA. ing on characteristics of its environment or its own operation . For example , web servers switch between handling interrupts and polling to avoid thrashing when load is high . Network routers trade off latency and throughput to maintain service , depending on queue sta- tus , load , and traffic patterns . Real-time graphical simulations and video games select which model of an object to render: detailed models when the object is close to the point of view , and coarser models for distant objects . Software-controlled radios , such as cell phones , optimize power dissipation and signal quality , depending on factors such as signal strength , interference , and the number of paths induced by reflections . Compilers select which optimizations to perform based on the estimated", "label": ["program steering", "adaptability", "mode selection", "multi-mode systems"], "stemmed_label": ["program steer", "adapt", "mode select", "multi-mod system"]}
{"doc": "The use of XML as the de facto data exchange standard has allowed integration of heterogeneous web based software systems regardless of implementation platforms and programming languages . On the other hand , the rich tree-structured data representation , and the expressive XML query languages (such as XPath) make formal specification and verification of software systems that manipulate XML data a challenge . In this paper , we present our initial efforts in automated verification of XML data manipulation operations using the SPIN model checker . We present algorithms for translating (bounded) XML data and XPath expressions to Promela , the input language of SPIN . The techniques presented in this paper constitute the basis of our Web Service Analysis Tool (WSAT) which verifies LTL properties of composite web services . INTRODUCTION Web based software systems (e.g . web services) are becoming increasingly important partly due to the wide use of the Web in electronic commerce . Errors in such systems , where multi-million dollar transactions are carried out , can be very costly; ad-hoc repairs after failure are not acceptable . Static analysis techniques and especially model checking can be very valuable in ensuring the correctness and robustness of such systems before they are deployed. It is generally agreed that messages exchanged among web based systems should be in the XML 21 format . For example , almost Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 11-14 , 2004 , Boston , Massachusetts , USA. all web service standards (e.g . WSDL 18 , BPEL4WS 1 , WSCI OWL-S 17 ) are built on XML and related standards including XML Schema 23 and XPath 22 . The rich tree-structured data representation of XML and powerful XPath expressions , how- ever , impede direct application of model checking techniques to the verification of Web based systems . Earlier efforts to verify web services (e.g . 6 , 15 , 12 ) basically focus on only the control flows by abstracting away the XML data semantics during analysis. This paper presents our initial efforts in formal specification and verification of software systems with XPath based manipulation of (bounded) XML data . The techniques presented in this paper constitute the basis of our Web Service Analysis Tool (WSAT) 10 , 19 which can verify Linear Temporal Logic (LTL) properties of conversation protocols 7 and interacting BPEL4WS 1 web services 8 . Clearly , these techniques can also be used for verification of other types of software systems that exchange XML data. We use SPIN 11 as a back-end model checker in verification of XML data manipulation operations . We developed algorithms for translating XML data types", "label": ["model checking", "msl", "xpath", "xml", "promela", "spin", "xml schema", "web service"], "stemmed_label": ["model check", "msl", "xpath", "xml", "promela", "spin", "xml schema", "web servic"]}
{"doc": "Clustering is a fundamental problem in unsupervised learning , and has been studied widely both as a problem of learning mixture models and as an optimization problem . In this paper , we study clustering with respect to the k-median objective function , a natural formulation of clustering in which we attempt to minimize the average distance to cluster centers . One of the main contributions of this paper is a simple but powerful sampling technique that we call successive sampling that could be of independent interest . We show that our sampling procedure can rapidly identify a small set of points (of size just O(k log \\frac n k )) that summarize the input points for the purpose of clustering . Using successive sampling , we develop an algorithm for the k-median problem that runs in O(nk) time for a wide range of values of k and is guaranteed , with high probability , to return a solution with cost at most a constant factor times optimal . We also establish a lower bound of (nk) on any randomized constant-factor approximation algorithm for the k-median problem that succeeds with even a negligible (say \\frac 1 100 ) probability . The best previous upper bound for the problem was (nk) , where the -notation hides polylogarithmic factors in n and k . The best previous lower bound of (nk) applied only to deterministic k-median algorithms . While we focus our presentation on the k-median objective , all our upper bounds are valid for the k-means objective as well . In this context our algorithm compares favorably to the widely used k-means heuristic , which requires O(nk) time for just one iteration and provides no useful approximation guarantees . Introduction Given a set of points and pairwise distances between the points , the goal of clustering problems is to partition the points into a number of sets such that points in each set are \"close\" with respect to some objective function . Clustering algorithms are widely used to organize large data sets in areas such as data mining and information retrieval . For example , we may wish to partition a set of web logs to infer certain usage patterns , or divide a corpus of documents into a small number of related groups . Given a set of points and associated interpoint distances , let the median of the set be the point in the set that minimizes the sum of distances to all other points in the set. (Remark: The median is essentially the discrete analog of the centroid , and is also called the medoid 9 .) The clustering problem we consider asks us to partition n weighted points into k sets such that the sum , over all sets , of the weight of a point times the distance to the median of its set is minimized . Approaches to this type of clustering problem , such as the k-means heuristic, have been well-studied 4 , 9 . We refer to this problem as the clustering variant of the", "label": ["k-median", "discrete location theory", "approximation algorithms", "unsupervised clustering", "k-means"], "stemmed_label": ["k-median", "discret locat theori", "approxim algorithm", "unsupervis cluster", "k-mean"]}
{"doc": "We consider the following clustering problem: we have a complete graph on n vertices (items) , where each edge (u , v) is labeled either + or depending on whether u and v have been deemed to be similar or different . The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels . That is , we want a clustering that maximizes the number of + edges within clusters , plus the number of edges between clusters (equivalently , minimizes the number of disagreements: the number of edges inside clusters plus the number of + edges between clusters) . This formulation is motivated from a document clustering problem in which one has a pairwise similarity function f learned from past data , and the goal is to partition the current set of documents in a way that correlates with f as much as possible&semi; it can also be viewed as a kind of agnostic learning problem.An interesting feature of this clustering formulation is that one does not need to specify the number of clusters k as a separate parameter , as in measures such as k-median or min-sum or min-max clustering . Instead , in our formulation , the optimal number of clusters could be any value between 1 and n , depending on the edge labels . We look at approximation algorithms for both minimizing disagreements and for maximizing agreements . For minimizing disagreements , we give a constant factor approximation . For maximizing agreements we give a PTAS , building on ideas of Goldreich , Goldwasser , and Ron (1998) and de la Veg (1996) . We also show how to extend some of these results to graphs with edge labels in 1 , +1 , and give some results for the case of random noise . Introduction Suppose that you are given a set of n documents to cluster into topics . Unfortunately , you have no idea of what a \"topic\" is . However , you have at your disposal a classifier f(A; B) that given two documents A and B , outputs Department of Computer Science , Carnegie Mellon University. fnikhil,avrim,shuchig@cs.cmu.edu . This research was supported in part by NSF grants CCR-0085982 , CCR-0122581 , CCR- 0105488 , and an IBM Graduate Fellowship. whether or not it believes A and B are similar to each other. For example , perhaps f was learned from some past training data . In this case , a natural approach to clustering is to apply f to every pair of documents in your set , and then to find the clustering that agrees as much as possible with the results. Specifically , we consider the following problem . Given a fully-connected graph G with edges labeled \"+\" (similar) find a partition of the vertices into clusters that agrees as much as possible with the edge labels. In particular , we can look at this in terms of maximizing agreements (the number of + edges inside clusters plus the number", "label": ["document classification", "clustering", "approximation algorithm"], "stemmed_label": ["document classif", "cluster", "approxim algorithm"]}
{"doc": "One of the central problems in information retrieval , data mining , computational biology , statistical analysis , computer vision , geographic analysis , pattern recognition , distributed protocols is the question of classification of data according to some clustering rule . Often the data is noisy and even approximate classification is of extreme importance . The difficulty of such classification stems from the fact that usually the data has many incomparable attributes , and often results in the question of clustering problems in high dimensional spaces . Since they require measuring distance between every pair of data points , standard algorithms for computing the exact clustering solutions use quadratic or nearly quadratic running time&semi; i.e. , O(dn2(d)) time where n is the number of data points , d is the dimension of the space and (d) approaches 0 as d grows . In this paper , we show (for three fairly natural clustering rules) that computing an approximate solution can be done much more efficiently . More specifically , for agglomerative clustering (used , for example , in the Alta Vista search engine) , for the clustering defined by sparse partitions , and for a clustering based on minimum spanning trees we derive randomized (1 approximation algorithms with running times (d2 n2) where 0 depends only on the approximation parameter &epsi; and is independent of the dimension d . Introduction Clustering of data is an essential ingredient in many information retrieval systems (e.g. , for building and maintaining taxonomies) , and plays a central role in statis- tics , pattern recognition , biology , web search engines, distributed networks , and other fields . Recently , the concept of clustering has taken on some added significance as researchers have begun to view \"data mining\" as a question of finding \"hidden clusters\" in large collections of data . (For a survey of clustering methods see 18 , 7 and references therein.) Informally , clustering algorithms attempt to form groups of similar objects into clusters based on the attributes of these ob- jects . The question as to how best to define \"the clustering problem\" seems to be particularly difficult in large unstructured databases whose members are viewed as points in some high dimensional vector space. The most successful formulations of clustering seem to be graph-theoretic formulations , providing results which have the best agreement with human performance 13 . In this formulation , the main ingredient of graph-theoretic clustering can be stated as follows: given n data points in some metric space , do the following: (1) compute some spanning graph (such as the complete graph , or a minimumspanning tree) of the original data set; (2) Delete (in parallel) some edges of this graph (ac- cording to some criterion , such as distance); (3) output clustering (such as connected components or some partitioning of the nodes which depends on the topology) of the resulting graph. For a more concrete example , consider the frame-work of hierarchical clustering where data points are joined into sets of objects , called clusters , with", "label": ["sparse partitions", "high dimensional spaces", "graph-theoretic clustering"], "stemmed_label": ["spars partit", "high dimension space", "graph-theoret cluster"]}
{"doc": "A procedure is presented to untangle unstructured 2D meshes containing inverted elements by node repositioning . The inverted elements may result from node movement in Arbitrary Lagrangian Eulerian (ALE) simulations of continuum mechanics problems with large shear deformation such as fluid flow and metal forming . Meshes with inverted elements may also be created due to the limitations of mesh generation algorithms particularly for nonsimplicial mesh generation . The untangling procedure uses a combination of direct node placement based on geometric computation of the feasible set , and node repositioning driven by numerical optimization of an objective function that achieves its minimum on a valid mesh . It is shown that a combination of the feasible set , based method and the optimization method achieves the best results in untangling complex 2D meshes . Preliminary results are also presented for untangling of 3D unstructured meshes by the same approach . Introduction Arbitrary Lagrangian-Eulerian or ALE methods are a popular class of methods for simulating continuum mechanics problems with large shear deformation such as uid ow and metal forming 1,2 . ALE methods consist of a Lagrangian step in which the mesh nodes move according to the ow of the material , a rezone step in which the mesh is modied to improve its quality and the remapping step in which the solution is transferred from the old mesh to the new , improved mesh . In 3 5 , methods were described to improve the quality of the mesh while keeping it close to the original mesh . However , in order to improve the meshes by the methods described in 3 5 , all elements of the starting mesh must be valid or non-inverted . Therefore , if the Lagrangian step of an ALE simulation causes the mesh to become tangled (i.e. , it has some elements that become inverted) , the mesh must be untangled before the mesh improvement procedures are applied to it. The need for untangling meshes also exists when a mesh generation procedure is unable to create all valid elements in a mesh . This situation may be encountered in the generation of all hexahedral meshes and general polyhedral meshes where there is no guaranteed method of directly generating a valid mesh 6 . It may also be encountered in advancing front based mesh generation of tetrahedral and hexahedral meshes 7 9 where it is possible to generate small cavities that cannot be lled with all positive volume elements . In these cases , it is very useful to have a tool that can untangle the mesh after the initial generation assuming that the right mesh connectivity has been generated. Several researchers have recently begun focusing on the problem of untangling unstructured meshes by node repositioning 10 13 . Freitag and Plassmann 11,14 untangle meshes by optimization of a local function based on maximizing the minimum element area at each mesh vertex . Knupp 12 performs a global optimization of the dierence between the absolute and signed values of element volumes in order to untangle the mesh", "label": ["element validity", "arbitrary lagrangian-eulerian ale simulations", "mesh untangling", "rayleigh taylor simulation", "triangles", "quadrilaterals"], "stemmed_label": ["element valid", "arbitrari lagrangian-eulerian ale simul", "mesh untangl", "rayleigh taylor simul", "triangl", "quadrilater"]}
{"doc": "We address a hierarchical generalization of the well-known disk paging problem . In the hierarchical cooperative caching problem , a set of n machines residing in an ultrametric space cooperate with one another to satisfy a sequence of read requests to a collection of (read-only) files . A seminal result in the area of competitive analysis states that LRU (the widely-used deterministic online paging algorithm based on the \"least recently used\" eviction policy) is constant-competitive if it is given a constant-factor blowup in capacity over the offline algorithm . Does such a constant-competitive deterministic algorithm (with a constant-factor blowup in the machine capacities) exist for the hierarchical cooperative caching problem? The main contribution of the present paper is to answer this question in the negative . More specifically , we establish an (log log n) lower bound on the competitive ratio of any online hierarchical cooperative caching algorithm with capacity blowup O((log n)1-) , where denotes an arbitrarily small positive constant . INTRODUCTION The traditional paging problem , which has been extensively studied , is defined as follows . Given a cache and a sequence of requests for files of uniform sizes , a system has to satisfy the requests one by one . If the file f being requested is in the cache , then no cost is incurred; otherwise a uniform retrieval cost is incurred to place f in the cache. If need be , some files , determined by an online caching algorithm that does not know the future request sequence , are evicted to make room for f . The objective is to minimize the total retrieval cost by wisely choosing which files to evict. The cost of the online algorithm is compared against that of an optimal o#ine algorithm (OPT) that has full knowledge of the request sequence . Following Sleator and Tarjan 10 , we call an online algorithm c-competitive if its cost is at most c times that of OPT for any request sequence . It is well-known that an optimal o#ine strategy is to evict the file that will be requested furthest in the future. The paging problem is also known as caching if the files have nonuniform size and retrieval cost . In their seminal paper , Sleator and Tarjan 10 have shown that LRU (Least- Recently-Used) and several other deterministic paging algorithms are k -competitive , where k is the cache space used by LRU and h is that used by OPT . They have also shown that k k-h+1 is the best possible among all deterministic algorithms . We call k h the capacity blowup of LRU . For files of nonuniform size and retrieval cost , Young 13 has proposed the Landlord algorithm and shown that Landlord is k k-h+1 -competitive . As stated in 13 , the focus of Landlord \"is on simple local caching strategies , rather than distributed strategies in which caches cooperate to cache pages across a network\". In cooperative caching 6 , a set of caches cooperate in serving requests for each other and in", "label": ["online computation", "hierarchical cooperative caching"], "stemmed_label": ["onlin comput", "hierarch cooper cach"]}
{"doc": "This paper is devoted to the proof , applications , and generalisation of a theorem , due to Bird and de Moor , that gave conditions under which a total function can be expressed as a relational fold . The theorem is illustrated with three problems , all dealing with constructing trees with various properties . It is then generalised to give conditions under which the inverse of a partial function can be expressed as a relational hylomorphism . Its proof makes use of Doornbos and Backhouse's theory on well-foundedness and reductivity . Possible applications of the generalised theorem is discussed . Introduction The purpose of this paper is to describe one technique for inverting functions. Why bother with inverse functions? The reader might ask . The reason is that many problems in computation can be specified in terms of computing the inverse of an easily constructed function . Indeed , compression is best specified as the inverse of decompression , parsing the inverse of printing , and so on. But these are not the only applications; inverse sometimes arise in unexpected situations . To illustrate this , we will discuss three problems and solve them as instances of a sinlge technique. The first problem is that of breadth-first labelling . To breadth-first label a tree with respect to a given list is to augment the nodes of the tree with values in the list in breadth-first order . Figure 1 shows the result of breadth-first labelling a tree with 13 nodes with the infinite list 1 . While everybody knows how to do breadth-first traversal , the closely related problem of e#cient breadth-first labelling is not so widely understood. How would one specify this problem , and what does it have to do with inverse us call the type of binary trees Tree A and assume that we Preprint submitted to Elsevier Science 16 May a,1 a f l Fig . 1 . Breadth-first labelling a tree on the left with 1. have at hand the function bft :: Tree A # List A , for breadth-first traversal, and zipTree :: Tree A # Tree B # Tree zipping together two trees of the same shape . To perform breadth-first labelling given a tree t and a list x , we want to zip t with another tree u . What , then , does this tree u has to satisfy? Firstly , it must be of the right shape , a condition that can be enforced by zipTree . Secondly , its breadth-first traversal must be a prefix of the given list x . We thus come up with the following specification: where bft y Now look at the flow of information in the above specification . The functions bft and ++ appear on the left-hand side , meaning that we wish the data to go backwards through them . Let us denote the inverse of a function f by f # , pronounced \"the converse of f \" or more briefly \"f wok\" . The formal definition of f", "label": ["program derivation", "program inversion"], "stemmed_label": ["program deriv", "program invers"]}
{"doc": "We consider the solution of the linear system real values of . This family of shifted systems arises , for example , in Tikhonov regularization and computations in lattice quantum chromodynamics . For each single shift this system can be solved using the conjugate gradient method for least squares problems (CGLS) . In literature various implementations of the , so-called , multishift CGLS methods have been proposed . These methods are mathematically equivalent to applying the CGLS method to each shifted system separately but they solve all systems simultaneously and require only two matrix-vector products (one by A and one by AT) and two inner products per iteration step . Unfortunately , numerical experiments show that , due to roundoff errors , in some cases these implementations of the multishift CGLS method can only attain an accuracy that depends on the square of condition number of the matrix A . In this paper we will argue that , in the multishift CGLS method , the impact on the attainable accuracy of rounding errors in the Lanczos part of the method is independent of the effect of roundoff errors made in the construction of the iterates . By making suitable design choices for both parts , we derive a new (and efficient) implementation that tries to remove the limitation of previous proposals . A partial roundoff error analysis and various numerical experiments show promising results . Introduction In various scientific computations the problem arises to compute solutions to for various values of # . The matrix I denotes the identity matrix . Krylov subspace methods are iterative solution methods for solving linear systems . These methods , with zero initial guess , are characterized by the fact that they construct their approximations in step j from the so-called j dimensional Krylov subspace defined as K j (A , b) # span b , Ab . , A j-1 b . An important property of Krylov subspaces is that they are shift invariant , that is K By exploiting this property , Equation (1.1) can be solved for various values of Mathematical Institute , Utrecht University , P.O . Box 80.010 , NL-3508 Utrecht , The Netherlands. the shift # by constructing a basis for the Krylov subspace only once . This observation has led to many e#cient implementations of known Krylov subspace methods that can handle multiple shifts simultaneously . We refer the interested reader for further information and applications to 4 , 6 , 11 , 9 , 17 , 10 , 22 , 8 , 21 . The multishift variants , in general , require the number of matrix-vector products and inner products of the original method applied to a single system and for the solution of each additional shifted system only a few extra vector updates are needed. In this paper we focus on the numerical solution of the system for several real values of # 0 . The solution of this family of systems plays an important role in Tikhonov regularization 10 and in the computation of the overlap", "label": ["finite precision arithmetic", "tikhonov regularization", "iterative methods", "shifted systems", "accuracy"], "stemmed_label": ["finit precis arithmet", "tikhonov regular", "iter method", "shift system", "accuraci"]}
{"doc": "A matrix-free algorithm , IRLANB , for the efficient computation of the smallest singular triplets of large and possibly sparse matrices is described . Key characteristics of the approach are its use of Lanczos bidiagonalization , implicit restarting , and harmonic Ritz values . The algorithm also uses a deflation strategy that can be applied directly on Lanczos bidiagonalization . A refinement postprocessing phase is applied to the converged singular vectors . The computational costs of the above techniques are kept small as they make direct use of the bidiagonal form obtained in the course of the Lanczos factorization . Several numerical experiments with the method are presented that illustrate its effectiveness and indicate that it performs well compared to existing codes . Introduction Consider the singular value decomposition (SVD) of a matrix loss of generality, m . Denote its singular triplets by In this paper we are interested in computing few , say k , of the smallest singular triplets of a general large sparse matrix . This problem arises in several important applications including image and signal processing 38 , control 6 and matrix pseudospectra 37 . The computation of few extremal singular triplets of large sparse matrices has been the focus of many research e#orts , see 3,9,22,21,30,33,35 as well as Preprint submitted to Elsevier Science 2,10,29,36,15 and numerous references therein . Recent needs in applications such as the ones mentioned earlier , however , have motivated research oriented towards the development of algorithms for the computation of the smallest singular triplets , a problem that is acknowledged to challenge the capabilities of current state-of-the-art software , e.g . see 1,5,7,11,13,14,24 . It is common practice to approximate singular values by computing the eigen-values of equivalent hermitian eigenproblems . Furthermore , since computing the smallest eigenvalues values of a matrix is equivalent to computing the largest eigenvalues values of its inverse , significant work has been done on \"shift-and-invert\" techniques . For example , this approach was adopted in the MATLAB (version svds routine , that is based on ARPACK ( 22 ); the latter, implements one of the most successful theoretical frameworks for the e#ective implicitly restarted Arnoldi technique , based on seminal work of Sorensen, Lehoucq and collaborators . However , as the size of the matrices increases , this approach becomes too expensive in terms of storage and computational costs, as it requires the factorization of and solution with large sparse , possibly indefinite matrices . Developments that attempt to remedy this problem concern inexact inverse iteration and inexact inverse Lanczos methods (see for example 19 and 2 , Sec . 11.2 ) . An alternative approach that avoids such solves and is frequently e#ective is based on the use of harmonic Ritz values 26,33 . In this paper we propose and investigate an algorithm , we call IRLANB , that is based on Lanczos bidiagonalization (LBD) , a method for computing singular values originally due to Golub and Kahan 8 . This is a matrix-free method for the computation of the singular triplets , thus", "label": ["deflation", "implicit restarting", "harmonic ritz values", "pseudospectrum", "refined singular vectors", "lanczos bidiagonalization"], "stemmed_label": ["deflat", "implicit restart", "harmon ritz valu", "pseudospectrum", "refin singular vector", "lanczo bidiagon"]}
{"doc": "Linear temporal logic (LTL) has been widely used for specification and verification of reactive systems . Its standard model is sequences of states (or state transitions) , and formulas describe sequencing of state transitions . When LTL is used to model real-time systems , a state is extended with a time stamp to record when a state transition takes place . Duration calculus (DC) is another well studied approach for real-time systems development . DC models behaviours of a system by functions from the domain of reals representing time to the system states . This paper extends this time domain to the Cartesian product of the real and the natural numbers . With the extended time domain , we provide the chop modality with a non-overlapping interpretation . This allows some linear temporal operators explicitly dealing with the discrete dimension of time to be derivable from the chop modality in essentially the same way that their continuous-time counterparts are in the classical DC . This provides a nice embedding of some timed LTL (TLTL) modalities into DC to unify the methods from DC and LTL for real-time systems development: Requirements and high level design decisions are interval properties and are therefore specified and reasoned about in DC , while properties of an implementation , as well as the refinement relation between two implementations , are specified and verified compositionally and inductively in LTL . Implementation properties are related to requirement and design properties by rules for lifting LTL formulas to DC formulas . Introduction DC is born with a denotational approach ZHR91 , with which a system is modelled within a conventional dynamic systems framework with states that are functions of time , the non-negative reals . When observing a system , DC takes a continuous and global view: a property at a time point is observed through neighbourhoods of that time point , and a Boolean state is observed through its duration in a bounded interval , i.e. , the integral of an indicator function . A property for an interval is specified by an arithmetical relation among durations of states and real numbers. This paper is to appear in Formal Aspects of Computing. When specifying and reasoning about of requirements and high level designs for an embedded real-time or hybrid systems RRH93 , ORS96 , Liu96 , REHR98 , the dynamic systems model is beneficial because it focuses on relevant observable states . Furthermore , the interval logic has simple interpretations in a timing diagram for the states . The requirements will thus focus on sequencing of durational relations between observable states rather than on sequencing individual state transitions . Properties of isolated time points in the dense time domain are considered unobservable and ignored at the high level , therefore transitions are only observed indirectly through the relation among states in the left and right neighbourhoods of the transition point . A typical real-time property is the requirement of a bounded critical duration property, that in every interval bounded by a length d the duration of a state P", "label": ["design", "refinement", "real-time", "specification", "verification"], "stemmed_label": ["design", "refin", "real-tim", "specif", "verif"]}
{"doc": "The unit price seat reservation problem is investigated . The seat reservation problem is the problem of assigning seat numbers on-line to requests for reservations in a train traveling through k stations . We are considering the version where all tickets have the same price and where requests are treated fairly , that is , a request which can be fulfilled must be granted.For fair deterministic algorithms , we provide an asymptotically matching upper bound to the existing lower bound which states that all fair algorithms for this problem are -competitive on accommodating sequences , when there are at least three seats.Additionally , we give an asymptotic upper bound of 7/9 for fair randomized algorithms against oblivious adversaries.We also examine concrete on-line algorithms , First-Fit and Random for the special case of two seats . Tight analyses of their performance are given . Introduction In many train transportation systems , passengers are required to buy seat reservations with their train tickets . The ticketing system must assign a passenger a single seat when that passenger purchases a ticket , without knowing what future requests there will be for seats . Therefore , the seat reservation problem is an on-line problem , and a competitive analysis is appropriate. Assume that a train with n seats travels from a start station to an end station , stopping at k 2 stations , including the rst and the last . The seats are numbered from 1 to n . The start station is station 1 and the end station is station k . Reservations can be made for any trip from a station s to a station t as long as 1 s t k . Each passenger is given a single seat number when the ticket is purchased , which can be any time before departure . The algorithms (ticket agents) may not refuse a passenger if it is possible to accommodate him when he attempts to make his reservation. That is , if there is any seat which is empty for the entire duration of that passenger's trip , the passenger must be assigned a seat . An algorithm of this kind is fair. The algorithms attempt to maximize income , i.e. , the sum of the prices of the tickets sold . Naturally , the performance of an on-line algorithm will depend on the pricing policies for the train tickets . In 6 , two pricing policies are considered: one in which all tickets have the same price , the unit price problem; and one in which the price of a ticket is proportional to the distance traveled , the proportional price problem . This paper focuses on fair algorithms for the unit price problem. The seat reservation problem is closely related to the problem of optical routing with a number of wavelengths 1 , 5 , 9 , 14 , call control 2 , interval graph coloring 12 and interval scheduling 13 . The o-line version of the seat reservation problem can be used to solve the following problems 8 :", "label": ["accomodating sequences", "competitive ratio", "seat reservation problem", "on-line algorithms"], "stemmed_label": ["accomod sequenc", "competit ratio", "seat reserv problem", "on-lin algorithm"]}
{"doc": "When admission control is used , an on-line scheduler chooses whether or not to complete each individual job successfully by its deadline . An important consideration is at what point in time the scheduler determines if a job request will be satisfied , and thus at what point the scheduler is able to provide notification to the job owner as to the fate of the request . In the loosest model , often seen in real-time systems , such a decision can be deferred up until the job's deadline passes . In the strictest model , more suitable for customer-based applications , a scheduler would be required to give notification at the instant that a job request arrives.Unfortunately there seems to be little existing research which explicitly studies the effect of the notification model on the performance guarantees of a scheduler . We undertake such a study by reexamining a problem from the literature . Specifically , we study the effect of the notification model on the non-preemptive scheduling of a single resource in order to maximize utilization . At first glance , it appears severely more restrictive to compare a scheduler required to give immediate notification to one which need not give any notification . Yet we are able to present alternate algorithms which provide immediate notification , while matching most of the performance guarantees which are possible by schedulers which provide no such notification . In only one case are we able to give evidence that providing immediate notification may be more difficult . Introduction We consider the non-preemptive scheduling of a single resource in an online setting . Job requests arrive , with each request specifying the length of time for which the resource is needed as well as a deadline by which the job should be completed . The scheduler is not required to complete all job requests , yet the goal is to maximize the resource utilization . In such a setting , an important consideration is at what point in time the scheduler determines if a job request will be satisfied, and thus at what point the scheduler is able to provide notification to the job owner as to the fate of the request . The natural model for notification has varied greatly between application domains. In traditional real-time systems , for example , admission control has been used for processing jobs with what are termed firm deadlines 16 . If a system issues a job request with a firm deadline this job does not necessarily need to be completed , however completing the job provides no utility if its deadline has passed . In this setting , it is quite natural to allow the scheduler to take a \"wait- and-see\" approach for each request . The scheduler is allowed to defer a final decision on whether or not to service the request up to the time when the deadline passes . From the scheduler's point of view , this is the loosest possible model for providing notification. Department of Mathematical and Computer Sciences , Loyola", "label": ["admission control", "notification", "online scheduling", "firm deadlines"], "stemmed_label": ["admiss control", "notif", "onlin schedul", "firm deadlin"]}
{"doc": "This paper studies the problem of electing a small number of representatives (council) out of a (possible large) group of anonymous candidates . The problem arises in scenarios such as multicast where , to avoid feedback implosion , a small subset of the receivers is chosen to provide feedback on network conditions.We present several algorithms for this problem and analyze the expected number of messages and rounds required for their convergence . In particular , we present an algorithm that almost always converges in one round using a small number of messages (for typical council size) when the number of hosts is known . In the case where the number of hosts is unknown (and too large to be polled) , our algorithms converge in a small number of rounds that improves previous results by Bolot et al . (1994) . INTRODUCTION In many distributed applications there is a need to distributively elect a small group of hosts out of a potentially large population . The elected group needs to be maintained under dynamic network conditions that include new members joining and leaving and network temporary partition A typical application for this problem appears in multicast protocols . Due to the feedback implosion problem, there is a need to elect a small group of representatives out of the (possibly) large set of receivers (multicast group members) . An election mechanism was proposed by Bolot et al . BTW94 to elect a small number of receivers and collect from them feedback regarding loss rate and congestion in the multicast group . Other applications that require distributed group-election are electing hot back-up servers , distributed databases , and distributed network management. A particular example where such algorithms are implemented is the IDMaps project JJJ As part of this project , measurement stations (Tracers) are installed in various locations in the Internet . These tracers measure the distance among themselves and to other areas in the Inter- net . The measurement results are then sent to (potentially many) distance information servers by multicast . To reduce measurement overhead , distance information servers provide feedback for the usefulness of each measurement to the Tracer . To avoid the feedback implosion problem at Tracers there is a need to select one or a few representatives out of the server population. In both the multicast congestion control and the IDMaps example , communication from some data transmitting entity to a group of hosts is done using multicast while the reverse direction is done using unicast transmissions . In both examples the population size may vary over several orders of magnitude , the population may change over time, and the transmitting entity has no initial knowledge of the population size . In the above examples , choosing a single representative is usually undesirable both for redundancy and better statistical representation (in the multicast exam- ple) . Thus , our algorithms are capable of electing a group of any size in a predefined range , Note that if the transmitting entity knows the ids of all the receivers it can", "label": ["multicast", "leader election"], "stemmed_label": ["multicast", "leader elect"]}
{"doc": "Recently Victor Shoup noted that there is a gap in the widely believed security result of OAEP against adaptive chosen-ciphertext attacks . Moreover , he showed that , presumably , OAEP cannot be proven secure from the one-wayness of the underlying trapdoor permutation . This paper establishes another result on the security of OAEP . It proves that OAEP offers semantic security against adaptive chosen-ciphertext attacks , in the random oracle model , under the partial-domain one-wayness of the underlying permutation . Therefore , this uses a formally stronger assumption . Nevertheless , since partial-domain one-wayness of the RSA function is equivalent to its (full-domain) onewayness , it follows that the security of RSA-OAEP can actually be proven under the sole RSA assumption , although the reduction is not tight . Introduction The OAEP conversion method 3 was introduced by Bellare and Rogaway in 1994 and was believed to provide semantic security against adaptive chosen-ciphertext attacks 7 , 12 , based on the one-wayness of a trapdoor permutation, using the (corrected) definition of plaintext-awareness 1 . Victor Shoup 15 recently showed that it is quite unlikely that such a security proof exists - at least for non-malleability - under the one-wayness of the permutation . He also proposed a slightly modified version of OAEP , called OAEP+ , which can be proven secure , under the one-wayness of the permutation. Does Shoup's result mean that OAEP is insecure or that it is impossible to prove the security of OAEP? This is a totally misleading view: the result only states that it is highly unlikely to find any proof , under just the one-wayness assumption . In other words , Shoup's result does not preclude the possibility of proving the security of OAEP from stronger assumptions. This paper uses such a stronger assumption . More precisely , in our reduc- tion , a new computational assumption is introduced to prove the existence of a simulator of the decryption oracle . Based on this idea , we prove that OAEP is semantically secure against adaptive chosen-ciphertext attack in the random oracle model 3 , under the partial-domain one-wayness of the underlying per- mutation , which is stronger than the original assumption. Since partial-domain one-wayness of the RSA function 13 is equivalent to the (full-domain) one-wayness , the security of RSA-OAEP can actually be proven under the one-wayness of the RSA function. The rest of this paper is organized as follows . Section 2 recalls the basic notions of asymmetric encryption and the various security notions . Section 3 reviews the OAEP conversion 3 . Sections 4 and 5 present our new security result together with a formal proof for general OAEP applications . In Section 6, we focus on the RSA application of OAEP , RSA-OAEP. Public-Key Encryption The aim of public-key encryption is to allow anybody who knows the public key of Alice to send her a message that only she will be able to recover it through her private key. 2.1 Definitions A public-key encryption scheme is defined by the three following", "label": ["provable security", "public-key encryption", "oaep", "rsa"], "stemmed_label": ["provabl secur", "public-key encrypt", "oaep", "rsa"]}
{"doc": "Most previous work on the recently developed language-modeling approach to information retrieval focuses on document-specific characteristics , and therefore does not take into account the structure of the surrounding corpus . We propose a novel algorithmic framework in which information provided by document-based language models is enhanced by the incorporation of information drawn from clusters of similar documents . Using this framework , we develop a suite of new algorithms . Even the simplest typically outperforms the standard language-modeling approach in precision and recall , and our new interpolation algorithm posts statistically significant improvements for both metrics over all three corpora tested . INTRODUCTION As is well known , a basic problem in information retrieval is to determine how relevant a particular document is to a query . In the automatic ad hoc retrieval setting , examples of relevant documents are not supplied . Given this absence of explicit relevance evidence , it is important to consider what other information sources can be exploited. In methods patterned after the classic tf.idf document- vector approach to text representation , the focus is mostly Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 25-29,2004 , Sheffield , South Yorkshire , UK. on utilizing within-document features , such as term frequen- cies . Information drawn from the corpus as a whole generally consists of aggregates of statistics gathered from each document considered in isolation; for example , the inverse document frequency is based on checking , for each docu- ment , whether that document contains a particular term. Recent work has demonstrated the eectiveness of an alternative approach wherein probabilistic models of text generation are constructed from documents , and these induced language models (LMs) are used to perform document ranking 15 , 5 . Like tf.idf and related techniques , though , lang- uage-modeling methods typically use only individual-docu- ment features and corpus-wide aggregates of the same . (Cor- pus term counts are generally employed for smoothing , so that unseen text can be assigned non-zero probability.) Neither of the aforementioned approaches typically makes use of a potentially very powerful source of information: the similarity structure of the corpus . Clusters are a convenient representation of similarity whose potential for improving retrieval performance has long been recognized 4 , 16 . From our point of view , one key advantage is that they provide smoothed , more representative statistics for their elements, as has been recognized in statistical natural language processing for some time 3 . For example , we could infer that a document not containing a certain query term is still relevant if the document belongs to a cluster whose component documents generally do contain", "label": ["clustering", "language modeling", "interpolation model", "cluster-based language models", "smoothing", "aspect models"], "stemmed_label": ["cluster", "languag model", "interpol model", "cluster-bas languag model", "smooth", "aspect model"]}
{"doc": "Enumerating all solutions of a relational algebra equation is a natural and powerful operation which , when added as a query language primitive to the nested relational algebra , yields a query language for nested relational databases , equivalent to the well-known powerset algebra . We study sparse equations , which are equations with at most polynomially many solutions . We look at their complexity and compare their expressive power with that of similar notions in the powerset algebra . Introduction Suppose we are allowed to see only a view on a database B , computed by a relational algebra expression e . If we still want to find out what B is , we might try to \"invert\" e (assum- ing we know this expression) , which will only work when we also know the finite domain D of B . Specifically , we can enumerate all databases over D , and test for each X whether it satisfies the equation e(B) . One of these solutions will be B of course , so if the set of all solutions is not too big , it might provide us with useful information to start our detective work. The above simple scenario from database security led us to wonder what can be said in general about the solution of equations in the relational algebra . Generally , if e 1 and e 2 are two algebra expressions over the database schema augmented with some relation variables X 1 , , we can consider the equation e A solution of this equation , given a database B with finite domain D , is a tuple (X of relations over D such that e 1 and e 2 evaluate to the same relation on the augmented database Asking whether there exists a solution of a relational algebra equation on a database is almost exactly the same thing as asking whether an existential second-order logic sentence is true on that database . Hence , by Fagin's theorem Fag74 , EF95 , the problems that can be formulated as finding a solution of some relational algebra equation are nothing but the problems in NP. However , in the present paper , we start from the observation that the set of all solutions of an equation , being a set of tuples of relations, is a nested relation . One can therefore consider the enumeration of all solutions of an equation as a query language primitive , which can be added to the nested relational algebra . We introduce and study this extension of the nested relational algebra , which we call the equation al- gebra . The equation algebra is extremely pow- erful: it is equivalent to the well-known power-set algebra for nested relations . Our particular interest , however , is in what can be expressed in the equation algebra by using only equations that have a solution set of polynomial size on each database . We call such equations sparse. Our interest in sparse equations does not stem from time efficiency considerations . In-", "label": ["sparse expression", "parity", "equation", "fagin's theorem", "relational algebra", "nested relation"], "stemmed_label": ["spars express", "pariti", "equat", "fagin' theorem", "relat algebra", "nest relat"]}
{"doc": "We give a new proof showing that it is NP-hard to color a 3-colorable graph using just 4 colors . This result is already known , S . Khanna , N . Linial , and S . Safra , Combinatorica , 20 (2000) , pp . 393--415 , but our proof is novel because it does not rely on the PCP theorem , while the known one does . This highlights a qualitative difference between the known hardness result for coloring 3-colorable graphs and the factor $n^ \\epsilon $ hardness for approximating the chromatic number of general graphs , as the latter result is known to imply (some form of) PCP theorem M . Bellare , O . Goldreich , and M . Sudan , SIAM J . Comput. , 27 (1998) , pp . 805--915 .Another aspect in which our proof is novel is in its use of the PCP theorem to show that 4-coloring of 3-colorable graphs remains NP-hard even on bounded-degree graphs (this hardness result does not seem to follow from the earlier reduction of Khanna , Linial , and Safra) . We point out that such graphs can always be colored using O(1) colors by a simple greedy algorithm , while the best known algorithm for coloring (general) 3-colorable graphs requires $n^ \\Omega(1) $ colors . Our proof technique also shows that there is an $\\varepsilon_0 0$ such that it is NP-hard to legally 4-color even a $(1-\\varepsilon_0)$ fraction of the edges of a 3-colorable graph . Introduction The graph coloring problem is to assign colors to vertices of a graph G such that no two adjacent vertices receive the same color; such a coloring is referred to as a legal coloring of G . The minimum number of colors required to do a legal coloring is known as the chromatic number of G , and is denoted (G) . Graph coloring is a fundamental and extensively studied problem , which besides its theoretical significance as a canonical NP-hard problem 17 , also arises naturally in a variety of applications including register allocation and timetable/examination scheduling. Coloring a graph G with the minimum number (G) of colors is NP-hard 17 , so the focus shifts to efficiently coloring a graph with an approximately optimum number of colors . Garey and Johnson 10 proved that it is NP-hard to approximate the chromatic number within a factor of (2 ) for any 0 . The best known algorithm for general graphs appears in 14 and colors a graph using a number of colors that is within a factor of O(n(log log n) n) of the optimum (here and elsewhere n refers to the number of vertices in the graph) . There is strong evidence that one cannot do substantially better than this for general graphs , as the recent connection between Probabilistically Checkable Proofs (PCPs) and hardness of approximations 7 , 2 , 1 , has led to strong hardness results for graph coloring also . The first such result was established by Lund and A preliminary version of this", "label": ["np-hardness", "graph coloring", "hardness of approximation", "pcp theorem"], "stemmed_label": ["np-hard", "graph color", "hard of approxim", "pcp theorem"]}
{"doc": "Many data analysis tasks can be viewed as search or mining in a multidimensional space (MDS) . In such MDSs , dimensions capture potentially important factors for given applications , and cells represent combinations of values for the factors . To systematically analyze data in MDS , an interesting notion , called \"cubegrade was recently introduced by Imielinski et al . CHECK END OF SENTENCE , which focuses on the notable changes in measures in MDS by comparing a cell (which we refer to as probe cell) with its gradient cells , namely , its ancestors , descendants , and siblings . We call such queries gradient analysis queries (GQs) . Since an MDS can contain billions of cells , it is important to answer GQs efficiently . In this study , we focus on developing efficient methods for mining GQs constrained by certain (weakly) antimonotone constraints . Instead of conducting an independent gradient-cell search once per probe cell , which is inefficient due to much repeated work , we propose an efficient algorithm , LiveSet-Driven . This algorithm finds all good gradient-probe cell pairs in one search pass . It utilizes measure-value analysis and dimension-match analysis in a set-oriented manner , to achieve bidirectional pruning between the sets of hopeful probe cells and of hopeful gradient cells . Moreover , it adopts a hypertree structure and an H-cubing method to compress data and to maximize sharing of computation . Our performance study shows that this algorithm is efficient and scalable . In addition to data cubes , we extend our study to another important scenario: mining constrained gradients in transactional databases where each item is associated with some measures such as price . Such transactional databases can be viewed as sparse MDSs where items represent dimensions , although they have significantly different characteristics than data cubes . We outline efficient mining methods for this problem in this paper . Introduction Recently , there have been growing interests in multidimensional analysis of relational databases , transactional databases , and data warehouses . Most of such analysis involve data cube-based summary or transaction-based association analysis . However , in many interesting applications one may want to analyze the changes of measures in multidimensional space . For example , one may want to ask what are associated with significant changes of the average house price in the Vancouver area in year 2000 compared against 1999 , and the answer could include statements of the form \"the average price for those sold to professionals in the West End went down by 20% , while those sold to business people in Metrotown went up by 10% , etc.\" Expressions such as \"professionals in the West End\" correspond to cells in data cubes , and describe sectors of the business modeled by the data cube. The problem of mining changes of sophisticated measures in a multidimensional space was first proposed by Imielinski , et al . IKA02 as a cubegrade problem , which can be viewed as a generalization of association rules and data cubes . It", "label": ["data mining", "antimonotonicity", "constraint-based pruning", "dimension-based pruning", "complex measures", "iceberg query", "gradient analysis", "data cube"], "stemmed_label": ["data mine", "antimonoton", "constraint-bas prune", "dimension-bas prune", "complex measur", "iceberg queri", "gradient analysi", "data cube"]}
{"doc": "In this paper , we describe a tool to verify Erlang programs and show , by means of an industrial case study , how this tool is used . The tool includes a number of components , including a translation component , a state space generation component and a model checking component . To verify properties of the code , the tool first translates the Erlang code into a process algebraic specification . The outcome of the translation is made more efficient by taking advantage of the fact that software written in Erlang builds upon software design patterns such as clientserver behaviours . A labelled transition system is constructed from the specification by use of the CRL toolset . The resulting labelled transition system is model checked against a set of properties formulated in the -calculus using the Caesar/Aldbaran toolset.As a case study we focus on a simplified resource manager modelled on a real implementation in the control software of the AXD 301 ATM switch . Some of the key properties we verified for the program are mutual exclusion and non-starvation . Since the toolset supports only the regular alternation-free -calculus , some ingenuity is needed for checking the liveness property non-starvation . The case study has been refined step by step to provide more functionality , with each step motivated by a corresponding formal verification using model checking . Introduction Within Ericsson the functional programming language Erlang 1 is used for the development of concurrent/distributed safety critical software . Faced with the task of creating support for the development of formally veried Erlang programs , as a subtask we have built a tool to enable the use of model checking for such programs. The tool is aimed to be accessible for Erlang programmers without forcing them to learn an extra language (specic for the model checking tool that is used). Using model checking for the formal verication of software is by now a well known eld of research . Basically there are two branches , either one uses a spec- ication language in combination with a model checker to obtain a correct spec- ication that is used to write an implementation in a programming language , or one takes the program code as a starting point and abstracts from that into a model , which can be checked by a model checker . Either way , the implementation is not proved correct by these approaches , but when an error is encountered , this may indicate an error in the implementation . As such , the use of model checking can be seen as a very accurate debugging method. For the rst approach , one of the most successful of the many examples is the combination of the specication language Promela and model checker SPIN 14 . The attractive merit of Promela is that this language is so close to the implementation language C , that it becomes rather easy to derive the implementation from the specication in a direct , fault free way . In case one uses UML as", "label": ["software verification", "formal methods", "functional programming", "erlang", "model checking"], "stemmed_label": ["softwar verif", "formal method", "function program", "erlang", "model check"]}
{"doc": "It is well known that one can build models of full higher-order dependent-type theory (also called the calculus of constructions) using partial equivalence relations (PERs) and assemblies over a partial combinatory algebra . But the idea of categories of PERs and ERs (total equivalence relations) can be applied to other structures as well . In particular , we can easily define the category of ERs and equivalence-preserving continuous mappings over the standard category Top0 of topological T0-spaces; we call these spaces (a topological space together with an ER) equilogical spaces and the resulting category Equ . We show that this category--in contradistinction to Top0--is a cartesian closed category . The direct proof outlined here uses the equivalence of the category Equ to the category PEqu of PERs over algebraic lattices (a full subcategory of Top0 that is well known to be cartesian closed from domain theory) . In another paper with Carboni and Rosolini (cited herein) , a more abstract categorical generalization shows why many such categories are cartesian closed . The category Equ obviously contains Top0 as a full subcategory , and it naturally contains many other well known subcategories . In particular , we show why , as a consequence of work of Ershov , Berger , and others , the Kleene-Kreisel hierarchy of countable functionals of finite types can be naturally constructed in Equ from the natural numbers object N by repeated use in Equ of exponentiation and binary products . We also develop for Equ notions of modest sets (a category equivalent to Equ) and assemblies to explain why a model of dependent type theory is obtained . We make some comparisons of this model to other , known models . Introduction The genesis of this paper is the manuscript 35 \"A New Category?\" privately circulated by Dana Scott in December of 1996 . During the last part of his Supported in part by U.S . National Science Foundation Grant CCR-9409997. Preprint submitted to Elsevier Preprint 29 September 1998 graduate course on Domain Theory he had realized that by using some basic and well-known properties of domains (specifically , algebraic lattices) the category of equivalence relations on T 0 -spaces not only was an extension of the topological category but was cartesian closed. The present paper incorporates original motivation , definitions , and proofs of the earlier manuscript , and we then give an equivalent definition suggesting relationships to the extensive work on partial equivalence relations over partial combinatory algebras (hereafter , PCAs) . In our conference paper 6 , the reader will find an abstract framework due to Carboni and Rosolini in which the categories of equilogical spaces and partial equivalence relations over PCAs fit . Indeed , it is shown that there is a larger category than that of equilogi- cal spaces that is cartesian closed . However , we shall not discuss the abstract categorical framework here (namely , that of exact completions of categories). As in the earlier manuscript , our desire here is to give a fairly concrete description of the structures involved", "label": ["realizability", "domain theory", "type theory", "logic", "topology"], "stemmed_label": ["realiz", "domain theori", "type theori", "logic", "topolog"]}
{"doc": "Two-level languages incorporate binding time information inside types , that is , whether a piece of code is completely known at compile-time , or needs some more inputs and can be evaluated only at run-time . We consider the use of 2-level languages in the framework of partial evaluation , and use a 2-level version of the simply typed lambda calculus with recursion . We give an operational semantics , an equational theory and a denotational semantics , that give an account of the distinction between compilation and execution phases . An adequacy theorem is given to relate the two semantics , showing in particular how they agree on non-termination at compile time . We finally give a more refined model using functor categories . Introduction Partial evaluation is an attempt to ll the gap between interpreting and compil- ing . In the rst case we obtain an easy-to-prove correctness and good exibility to modications . Unfortunately , we usually get also a poor run-time behaviour, often an order of magnitude slower than the non-interpretative counterpart . On the other hand , compiled code is comparatively hard to understand , and prove correct. The aim of partial evaluation is to take a program as input and produce a new program that gives the same output as the original one . But constant evaluations are performed just once , during the program generation process. This new program will incorporate all the data that remains constant , and is called a specialized version of the old one . The following picture illustrates the process: Program compile-time - Residual run-time - Value In this view , it is essential to distinguish between the computations that can be performed at compile-time , called static , and the computations that need some more data to be executed , that are called dynamic: the process of making this distinction is called binding time analysis. A classical example is the function power , that takes two integers x and y, and computes y x , the x-th power of y . This function could be dened as follows Research partially supported by MURST Suppose that we know at compile-time that x is the number 3 . Then x is a static variable and y dynamic , and we can produce a residual program y y y This program is typically more e-cient than f 3 y. There are various ways to perform a binding time analysis , but a promising technique is to use a 2-level language: a language that incorporates binding time information inside its types . Usually these languages have two versions of each data type constructor , one for static and one for dynamic types . 2-level languages were originally introduced in 12 , and have been studied extensively in 18 , but their use for partial evaluation is more recent . Some examples can be found in 4 and 11 . In this paper we study the semantics of a 2-level language , and give an operational semantics and a denotational model . The basic", "label": ["program generation", "partial evaluation", "semantics"], "stemmed_label": ["program gener", "partial evalu", "semant"]}
{"doc": "We describe a method for constructing models of linear logic based on the category of sets and relations . The resulting categories are non-degenerate in general; in particular they are not compact closed nor do they have biproducts . The construction is simple , lifting the structure of a poset to the new category . The underlying poset thus controls the structure of this category , and different posets give rise to differently-flavoured models . As a result , this technique allows the construction of models for both , intuitionistic or classical linear logic as desired . A number of well-known models , for example coherence spaces and hypercoherences , are instances of this method . Introduction Models for (fragments of) Linear Logic can hardly be called scarce|we know the categorical properties required , and a number of examples can be found in the literature . So , why introduce more? In fact , we have been asked in jest whether we would not consider naming this paper Yet another model for Linear Logic. The answer is twofold . For one we provide a tool for constructing models for (fragments of) Linear Logic which gives precise control over such properties as classical versus intuitionistic , that is we can choose to have a negation satisfying the usual equations , or not; Preprint submitted to Elsevier Preprint 26 July 2000 products (&) and coproducts () coincide on objects , or not , and similarly for their units; tensor . ) coincide on objects , or not , and similarly for their units. This is achieved by making specic choices for the two parameters in our construction . It is very easy to do this to match a specied design. From a category-theoretic point of view our construction starts with the compact closed category of sets and relations and adds enough structure to ensure that the resulting category (in general) is not compact closed , nor does it have biproducts . Whether it is symmetric monoidal closed , -autonomous, has products and coproducts depends on the second ingredient , a poset , and its structure as a category. Finally , a number of existing models for linear logic , such as Girard's coherence spaces and phase spaces as well as Ehrhard's hypercoherences , are instances of our construction . Thus we obtain new insight into how those models work, and oer an explanation for the 'collapse' that occurs in those , for example. Looking at models for (classical) linear logic one nds that many of them split the world into a co-variant and a contra-variant part so that negation can be obtained by exchanging the two . Examples for this are Player versus Opponent in games 3 , the pair of sets for Chu spaces or dialectica , and morphisms I - A versus those A - ? in the double glueing construction (see 8,7 ) employed by Tan 11 . Structurally somewhat simpler models , on the other hand , such as coherence spaces or hypercoherences , can do without this kind of", "label": ["categorical models", "linear logic"], "stemmed_label": ["categor model", "linear logic"]}
{"doc": "The main contribution of this paper is a formal characterization of recursive object specifications and their existence based on a denotational untyped semantics of the object calculus . Existence is not guaranteed but can be shown employing Pitts' results on relational properties of domains . The semantics can be used to analyse and verify Abadi and Leino's object logic but it also suggests extensions . For example , specifications of methods may not only refer to fields but also to methods of objects in the store . This can be achieved without compromising the existence theorem . An informal logic of predomains is in use intentionally in order to avoid any commitment to a particular syntax of specification logic . described by its introduction rule w.r.t . object formation. Therefore , the existence of the specification is equivalent to the validity of its introduction rule . The resulting implicit definition of a specification neither guarantees existence nor uniqueness unless \\Phi is of a certain form 1 . It is Domain Theory that provides sufficient machinery to guarantee existence and uniqueness . Therefore , working with a denotational (domain theoretic) semantics puts us into a position to precisely account for this problem. As far as the authors are aware , such a systematic denotational analysis of object logics has not been carried First author partially supported by the EPSRC under grant GR/R65190/01 and the Nuffield Foundation under grant NAL/00244/A. Usually , if \\Phi is monotonic then S is recursively defined . But monotonicity is too strong a condition for object specifications. through yet although there is a successful role model , the LCF (Logic of Computable Functions) logic , for the functional paradigm. The outline of this paper is as follows . Firstly , a denotational semantics of the functional and imperative untyped object calculus of 1 is given . On top of that a notion of specification inspired by the Abadi & Leino logic 2 is defined on the resulting object domains . We prove existence of these specifications under mild assumptions employing Andy Pitts' machinery for relational properties of domains 10 . The existence theorem is not only interesting in its own right , it will be also applied to ffl prove soundness of the object formation rule in 2 (in an untyped way but types can be encoded as specifications ffl exemplify via counterexamples that certain specification can not exist suggest extensions of an existing programming logic 2 , 8 introducing method invariants and logic of higher order store. Moreover , the proposed technique is expected to be applicable to various other object-oriented languages and programming logics. Some basic ideas date back to a draft 13 an abstract of which has been published in 14 . Denotational model of the object calculus In this section we describe a most simple denotational semantics for functional and imperative object calculi within the category PreDom of predomains and partial continuous functions . Let * denote the partial continuous function space between predomains . By f(a)\" we denote that function f applied to a", "label": ["domain theory", "program verification", "programming logic", "object logic", "denotational semantics"], "stemmed_label": ["domain theori", "program verif", "program logic", "object logic", "denot semant"]}
{"doc": "Graph-coloring register allocators eliminate copies by coalescing the source and target nodes of a copy if they do not interfere in the interference graph . Coalescing , however , can be harmful to the colorability of the graph because it tends to yield a graph with nodes of higher degrees . Unlike aggressive coalescing , which coalesces any pair of noninterfering copy-related nodes , conservative coalescing or iterated coalescing perform safe coalescing that preserves the colorability . Unfortunately , these heuristics give up coalescing too early , losing many opportunities for coalescing that would turn out to be safe . Moreover , they ignore the fact that coalescing may even improve the colorability of the graph by reducing the degree of neighbor nodes that are interfering with both the source and target nodes being coalesced . This article proposes a new heuristic called optimistic coalescing which optimistically performs aggressive coalescing , thus exploiting the positive impact of coalescing aggressively , but when a coalesced node is to be spilled , it is split back into separate nodes . Since there is a better chance of coloring one of those splits , we can reduce the overall spill amount . Introduction Many optimizing compilers take the approach of graph coloring for global register allocation 1 . Graph coloring abstracts the problem of assigning registers to live ranges in a program into the problem of assigning colors to nodes in the interference graph . The register allocator attempts to \"color\" the graph with a finite number of machine registers , with one constraint that any two nodes connected by an interference edge must be colored with different registers . If the allocator fails to color the graph , some nodes must be spilled to memory by inserting loads and stores . Graph coloring with a minimal number of spills is a well-known NP-complete problem and many heuristic algorithms have been used 1 , 2 , 3 . One important task of a register allocator is copy propagation . In the context of graph coloring , copy propagation is achieved simply by coloring the source and target node of a copy (which we call copy-related nodes) with a single register if they do not interfere . On the interference graph , this is implemented by coalescing the two nodes into a single node , with their interference edges being unioned . Since many optimization phases before the register allocation including instruction scheduling 4 , store-to-copy promotion 5 , and static single assignment (SSA) translation 6 leave behind many copies that slow down program execution, it is essential to minimize those copies. Coalescing may affect the colorability of the interference graph . Since a coalesced node will have the union of interference edges of the source and target nodes being coalesced , it might not be possible to color the coalesced node . This makes the register allocation problem more challenging because we need to minimize the spill cost while maximizing the number of coalesced copies . A couple of coalescing heuristics have been proposed to", "label": ["noncopy coalescing", "graph coloring", "copy coalescing", "register allocation"], "stemmed_label": ["noncopi coalesc", "graph color", "copi coalesc", "regist alloc"]}
{"doc": "We explore the computational power of networks of small resource-limited mobile agents . We define two new models of computation based on pairwise interactions of finite-state agents in populations of finite but unbounded size . With a fairness condition on interactions , we define the concept of stable computation of a function or predicate , and give protocols that stably compute functions in a class including Boolean combinations of threshold-k , parity , majority , and simple arithmetic . We prove that all stably computable predicates are in NL . With uniform random sampling of pairs to interact , we define the model of conjugating automata and show that any counter machine with O(1) counters of capacity O(n) can be simulated with high probability by a protocol in a population of size n . We prove that all predicates computable with high probability in this model are in P RL . Several open problems and promising future directions are discussed . works : Network Architecture and Design-distributed net- works , network communications , network topology , wireless communication; F.1.1 Computation by Abstract De- vices : Models of Computation; F.1.2 Computation by # Supported in part by NSF grants CCR-9820888 , CCR- 0098078 , CSE-0081823 , CNS-0305258 , and by ONR grant N00014-01-1-0795. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 25-28 , 2004 , St . John's , Newfoundland , Canada. Abstract Devices : Modes of Computation-parallelism and concurrency , probabilistic computation; E.1 Data : Data Structures-distributed data structures General Terms Theory , Algorithms , Performance Keywords Di#use computation , finite-state agent , intermittent com- munication , mobile agent , sensor net , stable computation 1 . SCENARIO: A FLOCK OF BIRDS Suppose we have equipped each bird in a particular flock with a sensor that can determine whether the bird's temperature is elevated or not , and we wish to know whether at least 5 birds in the flock have elevated temperatures . We assume that the sensors are quite limited: each sensor has a constant number of bits of memory and can respond to a global start signal , and two sensors can communicate only when they are su#ciently close to each other. In this scenario , the sensors are mobile , but have no control over how they move , that is , they are passively mo- bile . Initially , we assume that the underlying pattern of movement guarantees a fairness condition on the interac- tions: every pair of birds in the flock repeatedly come su#- ciently close to each other for their sensors to communicate. Under these assumptions , there is a simple protocol ensuring that every sensor eventually", "label": ["intermittent communication", "sensor net", "stable computation", "finite-state agent", "diffuse computation", "mobile agent"], "stemmed_label": ["intermitt commun", "sensor net", "stabl comput", "finite-st agent", "diffus comput", "mobil agent"]}
{"doc": "Group key exchange protocols allow a group of servers communicating over an asynchronous network of point-to-point links to establish a common key , such that an adversary which fully controls the network links (but not the group members) cannot learn the key . Currently known group key exchange protocols rely on the assumption that all group members participate in the protocol and if a single server crashes , then no server may terminate the protocol . In this paper , we propose the first purely asynchronous group key exchange protocol that tolerates a minority of servers to crash . Our solution uses a constant number of rounds , which makes it suitable for use in practice . Furthermore , we also investigate how to provide forward secrecy with respect to an adversary that may break into some servers and observe their internal state . We show that any group key exchange protocol among n servers that tolerates tc 0 servers to crash can only provide forward secrecy if the adversary breaks into less than n - 2tc servers , and propose a group key exchange protocol that achieves this bound . INTRODUCTION Group Key Exchange (GKE) protocols allow a group of servers communicating over a complete network of point-to- point links to establish a common session key such that anyone outside the group that can only observe the network traffic Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. July 25-28 , 2004 , St . Johns , Newfoundland , Canada. cannot learn this key . Such a session key can later be used to achieve cryptographic goals like for example multicast message confidentiality , or multicast data integrity . Hence , GKE protocols are essential for applications such as secure video- or tele-conferencing , or other collaborative applications . To model environments like the Internet , one assumes an asynchronous network where the scheduling of messages is determined by an adversary , and where the servers do not have access to a common clock. The main goals of a GKE protocol are to ensure secrecy of the session key , and to ensure that every member of the group eventually terminates the protocol and computes the session key . So far , GKE protocols have been designed to meet these goals only as long as all members of the group follow the protocol specification 8 , 26 , 3 , 7 . These solutions have the draw-back that if only a single server crashes , then no member of the group will terminate the protocol . This makes such protocols specifically vulnerable to denial of service attacks , as the execution time of the protocol", "label": ["provable security", "universal composability", "group key exchange", "group communication"], "stemmed_label": ["provabl secur", "univers compos", "group key exchang", "group commun"]}
{"doc": "We describe a method for computing the likelihood that a completion joining two contour fragments passes through any given position and orientation in the image plane . Like computations in primary visual cortex (and unlike all previous models of contour completion) , the output of our computation is invariant under rotations and translations of the input pattern . This is achieved by representing the input , output , and intermediate states of the computation in a basis of shiftable-twistable functions . Introduction Any computational model of human visual information processing must reconcile two apparently contradictory observations . First , computations in primary visual cortex are largely Euclidean invariant|an arbitrary rotation and translation of the input pattern of light falling on the retina produces an identical rotation and translation of the output of the computa- tion . Second , simple calculations based on the size of primary visual cortex (60 mm 80 mm) and the observed density of cortical hypercolumns (4/mm 2 ) suggest that the discrete spatial sampling of the visual eld is exceedingly sparse 29 . The apparent contradiction becomes clear when we ask the following questions: How is this remarkable invariance achieved in computations performed by populations of cortical neurons with broadly tuned receptive elds centered at so few locations? Why doesn't our perception of the world change dramatically when we tilt our head by 5 degrees? 1 asks a related question in a recent Nature paper 8 : \\On average , a region of just 1 mm 2 on the surface of the cortex will contain all possible orientation preferences , and , accordingly , can analyze orientation for one small area of the visual eld . This topographical arrangement allows closely spaced objects with dierent orientations to interact . But it also means that a continuous line across the whole visual eld would be cortically depicted in a patchy , discontinuous fashion . How can the spatially separated elements be bound together functionally?\" (a) (b) Figure 1: (a) Ehrenstein Figure . (b) Kanizsa Triangle. One of the main goals of our research is to show how the sparse and seemingly haphazard nature of the sampling of the visual eld can be reconciled with the Euclidean invariance of visual computations . To realize this goal , we introduce the notion of a shiftable-twistable basis of functions on the space , R 2 S 1 , of positions and directions . This notion is a generalization of the notion of a shiftable-steerable basis of functions on the plane , R 2 , introduced by Freeman , Adelson , Simoncelli , and Heeger in two seminal papers 9 , 26 . Freeman and Adelson 9 clearly appreciated the importance of the issues raised above when they devised the notion of a steerable basis to implement rotationally invariant computations. In fact , for computations in the plane the contradictions discussed above were largely resolved with the introduction by Simoncelli et al . 26 of the shiftable-steerable pyramid transform, which was specically designed to perform Euclidean invariant computations on R 2 . The", "label": ["visual cortex", "fokker-planck equation", "boundary completion", "euclidean invariant computation", "shiftable basis"], "stemmed_label": ["visual cortex", "fokker-planck equat", "boundari complet", "euclidean invari comput", "shiftabl basi"]}
{"doc": "A metering scheme is a method by which an audit agency is able to measure the interaction between servers and clients during a certain number of time frames . Naor and Pinkas (Vol . 1403 of LNCS , pp . 576590) proposed metering schemes where any server is able to compute a proof (i.e. , a value to be shown to the audit agency at the end of each time frame) , if and only if it has been visited by a number of clients larger than or equal to some threshold h during the time frame . Masucci and Stinson (Vol . 1895 of LNCS , pp . 7287) showed how to construct a metering scheme realizing any access structure , where the access structure is the family of all subsets of clients which enable a server to compute its proof . They also provided lower bounds on the communication complexity of metering schemes . In this paper we describe a linear algebraic approach to design metering schemes realizing any access structure . Namely , given any access structure , we present a method to construct a metering scheme realizing it from any linear secret sharing scheme with the same access structure . Besides , we prove some properties about the relationship between metering schemes and secret sharing schemes . These properties provide some new bounds on the information distributed to clients and servers in a metering scheme . According to these bounds , the optimality of the metering schemes obtained by our method relies upon the optimality of the linear secret sharing schemes for the given access structure . Introduction The current trend on the Internet suggests that the majority of revenues of web sites come from the advertising potential of the World Wide Web . Like in every other advertising channel , web advertisers must have a way to measure the exposure of their ads by obtaining usage statistics about web sites which contain their ads . Indeed , the amount of money charged to display ads depends on the number of visits received by the web sites . Consequently , advertisers should prevent the web sites from inflating the count of their visits in order to demand more money. An extended abstract of a preliminary version of this paper can be found in 7 . A metering scheme is a method to measure the interaction between servers and clients over a network. In particular , we consider a scenario where there are many servers and clients , and an audit agency whose task is to count the number of clients which have been served by each server during a certain number of time frames . Even though metering originated in the field of web advertisements , there are several other applications of secure metering schemes . For example , Franklin and Malkhi 13 suggested metering schemes as a method to measure the amount of money that companies , willing to pay for the cost required to access their web sites , should pay to the users' ISPs .", "label": ["distributed audit", "metering", "secret sharing", "cryptography", "entropy"], "stemmed_label": ["distribut audit", "meter", "secret share", "cryptographi", "entropi"]}
{"doc": "Motivated by formal models recently proposed in the context of XML , we study automata and logics on strings over infinite alphabets . These are conservative extensions of classical automata and logics defining the regular languages on finite alphabets . Specifically , we consider register and pebble automata , and extensions of first-order logic and monadic second-order logic . For each type of automaton we consider one-way and two-way variants , as well as deterministic , nondeterministic , and alternating control . We investigate the expressiveness and complexity of the automata and their connection to the logics , as well as standard decision problems . Some of our results answer open questions of Kaminski and Francez on register automata . Introduction One of the significant recent developments related to the World Wide Web (WWW) is the emergence of the Extensible Markup Language (XML) as the standard for data exchange on the Web 1 . Since XML documents have a tree structure (usually defined by DTDs) , XML queries can be modeled as mappings from trees to trees (tree transduc- tions) , and schema languages are closely related to tree automata , automata theory has naturally emerged as a central tool in formal work on XML 5 , 17 , 18 , 19 , 20 , 21 , 22 , 23 . The connection to logic and automata proved very fruitful in understanding such languages and in the development of optimization algorithms and static analysis techniques. However , these abstractions ignore an important aspect of XML , namely the presence of data values attached to leaves of trees , and comparison tests performed on them by XML queries . These data values make a big di#erence - indeed , in some cases the difference between decidability and undecidability (e.g. , see 4 ) . It is therefore important to extend the automata and logic formalisms to trees with data values . In this initial investigation we model data values by infinite alphabets , and consider the simpler case of strings rather than trees . Strings are also relevant in the tree case , as most formalisms allow reasoning along paths in the tree . In the case of XML , it would be more accurate to consider strings labeled by a finite alphabet and attach data values to positions in the # A preliminary version with title Towards regular language over infinite alphabets appeared in the proceedings of the 26th International Symposium on Mathematical Foundations of Computer Science (MFCS 2001) , Czech Republic , 2001. Post-doctoral researcher of the Fund for Scientific Research , Flanders. # This author supported in part by the National Science Foundation under grant number IIS-9802288. string . However , this would render the formalism more complicated and has no bearing on the results . Although limited to strings , we believe that our results provide a useful starting point in investigating the more general problem . In particular , our lower-bound results will easily be extended to trees. We only consider models which accept precisely the regular languages", "label": ["automata", "expressiveness", "first-order logic", "monadic second-order logic", "infinite alphabets", "xml", "registers", "pebbles"], "stemmed_label": ["automata", "express", "first-ord logic", "monad second-ord logic", "infinit alphabet", "xml", "regist", "pebbl"]}
{"doc": "A metalogical framework is a logic with an associated methodology that is used to represent other logics and to reason about their metalogical properties . We propose that logical frameworks can be good metalogical frameworks when their theories always have initial models and they support reflective and parameterized reasoning.We develop this thesis both abstractly and concretely . Abstractly , we formalize our proposal as a set of requirements and explain how any logic satisfying these requirements can be used for metalogical reasoning . Concretely , we present membership equational logic as a particular metalogic that satisfies these requirements . Using membership equational logic , and its realization in the Maude system , we show how reflection can be used for different , nontrivial kinds of formal metatheoretic reasoning . In particular , one can prove metatheorems that relate theories or establish properties of parameterized classes of theories . Introduction A logical framework is a formal logic with an associated methodology that is employed for representing and using other logics , theories , and , more generally , formal systems . A minimum requirement for a logical framework is that object logics and their entailment relations can be conservatively represented in the framework logic . Typically we also demand more . For exam- ple , that the representation preserves appropriate kinds of structure and that there is a small conceptual distance between the object logic and its representation and use in the framework logic. To compare logical frameworks and analyze their eectiveness , it is helpful to make further distinctions concerning their intended application . In particular , we can distinguish between logical frameworks , where the emphasis is on reasoning in a logic , in the sense of simulating its derivations in the framework logic , and metalogical frameworks , where the emphasis is on reasoning about logics . Metalogical frameworks are more powerful , as they include the ability to reason about a logic's entailment relation as opposed to merely being adequate to demonstrate entailment . Moreover , if a metalogical framework should provide a basis for formal metathe- ory , it should also support reasoning about relationships between logics . This is standard in metamathematics and is common practice when reasoning about formal systems in computer science. The dierent kinds of applications make dierent demands on the framework logic . In a logical framework it is sucient to use representations of proof rules to construct demonstrations of (object logic) entailments . This is the approach taken in logical frameworks like Isabelle 28 and the Edinburgh LF 15 . Note that under this approach one may formalize logics and theories where induction is present within the theory (e.g. , induction over the natural numbers in Peano Arithmetic) , but induction is not present over the encoded theories . That is , the framework logic does not support induction over the terms and proofs of a theory , and in general there is no reason to assume that sound induction principles exist. In a metalogical framework , it is essential to have", "label": ["rewriting logic", "metalogics", "reflection", "membership equational logic"], "stemmed_label": ["rewrit logic", "metalog", "reflect", "membership equat logic"]}
{"doc": "We analyze preemptive on-line scheduling against randomized adversaries , with the goal to finish an unknown distinguished target job . Our motivation comes from clinical gene search projects , but the subject leads to general theoretical questions of independent interest , including some natural but unusual probabilistic models . We study problem versions with known and unknown processing times of jobs and target probabilities , and models where the on-line player gets some randomized extra information about the target . For some versions we get optimal competitive ratios , expressed in terms of given parameters of instances . In many cells from a certain type of tumor , small end segments of chromosome 1 of varying lengths are deleted . This suggests the conjecture of a tumor suppressor gene located in the shortest missing segment . This putative suppressor gene is knocked out only if it is absent or damaged on the partner chromosome , too . (Note that a somatic cell contains two versions of every chromosome.) Therefore one wishes to identify a gene in that region which exhibits fatal mutations on the partner chromosome in the available examples of tumor cells but works properly in healthy control cells. us represent the chromosome as unit interval 0; 1 , where some right end segment is deleted in every such clinical case . A deletion is characterized by its breakpoint , i.e. the new endpoint of the damaged chromosome . Breakpoint locations are fairly accurately known in all cases . However , checking the status of candidate genes on the corresponding partner chromosome is a time-consuming job , as it requires DNA sequencing , alignment and comparison of sequences , mutation detection , interpretation of ndings , investigation of the eect of genetic changes on the encoded protein and its function in the cell , etc . This does not only take a long time , the processing time is also hard to predict , and one must be prepared for surprises. It is natural to assume that breakpoints follow some xed probability distribution and are independent in dierent examples . Under the conjecture of a single suppressor gene , this target gene must be to the right of all observed breakpoints. One aspect of this gene search problem is: Given a sample of breakpoints and a set of candidate genes , how should we distribute simultaneous work among these candidates so as to optimize the chances of early success? Since this is a vague description of an optimization problem , let us formulate the problem in a more abstract way that also allows several generalizations . A framework and formal problem statements will be given in Section In a set of n objects (here: the candidate genes) , one object is the target (here: the suppressor gene) . Our goal is to identify the unknown target as early as possible . In order to check whether or not an object is the target , one has to perform some job on that object. In view of our application we allow preemptive", "label": ["searching", "bayesian models", "on-line algorithms", "randomized adversary"], "stemmed_label": ["search", "bayesian model", "on-lin algorithm", "random adversari"]}
{"doc": "We present here an implementation relation intended to formalise the notion that a system built of communicating processes is an acceptable implementation of another base , or target , system in the event that the two systems have different interfaces . Such a treatment has clear applicability in the software development process , where (the interface of) an implementation component may be expressed at a different level of abstraction to (the interface of) the relevant specification component.Technically , processes are formalised using Hoare's CSP language , with its standard failures-divergences model . The implementation relation is formulated in terms of failures and divergences of the implementation and target processes . Interface difference is modelled by endowing the implementation relation with parameters called extraction patterns . These are intended to interpret implementation behaviour as target behaviour , and suitably constrain the former in connection to well-formedness and deadlock properties.We extend the results of our previous work and replace implementation relations previously presented by a single , improved scheme . We also remove all the restrictions previously placed upon target processes . Two basic kinds of results are obtained: realisability and compositionality . The latter means that a target composed of several connected systems may be implemented by connecting their respective implementations . The former means that , if target and implementation in fact have the same interface , then the implementation relation they should satisfy collapses into standard implementation pre-order.We also show how to represent processes and extraction patterns in a manner amenable to computer implementation , and detail a graph-theoretic restatement of the conditions defining the implementation relation , from which algorithms for their automatic verification are easily derived . Introduction The software development process often involves refining a high-level specification into a lower-level or more concrete implementation. In the process algebraic context 8 , 16 , 18 , both specification and implementation may be represented as processes , and the notion that a process Q implements a process P is based on the idea that Q is more deterministic than (or equivalent to) P in terms of the chosen semantics . In the following , we shall also refer to such specifications as target or base systems. J.Burton , M.Koutny and G.Pappalardo The process of refining the target into the implementation also permits the control structure of the latter to be changed . In such a case , Q is said to implement P in the twofold sense that: (i) Q describes the internal structure of P in a more concrete and detailed manner; and still (ii) , if this new structure is (conceptually) hidden , Q and P will exhibit the same behaviour at their external interface , which is assumed to be the same for both . Indeed , the standard notions of refinement , such as those of 8 , 16 , 18 , are interested only in the behaviour observable at the interface of processes , and require the interfaces of the specification and implementation to be the same , so as to facilitate comparison. Yet in", "label": ["communicating sequential processes", "theory of parallel and distributed computation", "refinement", "behaviour abstraction", "compositionality", "verification"], "stemmed_label": ["commun sequenti process", "theori of parallel and distribut comput", "refin", "behaviour abstract", "composition", "verif"]}
{"doc": "An information-theoretic model for steganography with a passive adversary is proposed . The adversary's task of distinguishing between an innocent cover message C and a modified message S containing hidden information is interpreted as a hypothesis testing problem . The security of a steganographic system is quantified in terms of the relative entropy (or discrimination) between the distributions of C and S , which yields bounds on the detection capability of any adversary . It is shown that secure steganographic schemes exist in this model provided the covertext distribution satisfies certain conditions . A universal stegosystem is presented in this model that needs no knowledge of the covertext distribution , except that it is generated from independently repeated experiments . Introduction Steganography is the art and science of hiding information such that its presence cannot be detected. Motivated by growing concern about the protection of intellectual property on the Internet and by the threat of a ban for encryption technology , the interest in techniques for information hiding has been increasing over the recent years And96 . Two general directions can be distinguished within information hiding scenarios: protection only against the detection of a message by a passive adversary and hiding a message such that not even an active adversary can remove it . A survey of current steganography can be found in AP98 . Steganography with a passive adversary is perhaps best illustrated by Simmons' ``Prisoners' Problem\" Sim84 . Alice and Bob are in jail and wish to devise an escape plan . All their communication is observed by the adversary (the warden) , who will thwart their plan by transferring them to a high-security prison as soon as he detects any sign of a hidden message . Alice and Bob succeed if Alice can send information to Bob such that Eve does not become suspicious. Hiding information from active adversaries is a different problem since the existence of a hidden message is publicly known , such as in copyright protection schemes . Steganography with active adversaries can be divided into watermarking and fingerprinting . Watermarking supplies digital objects with an identification of origin; all objects are marked in the same way . Fingerprinting, conversely , attempts to identify individual copies of an object by means of embedding a unique marker in every copy that is distributed . If later an illegal copy is found , the copyright owner can identify the buyer by decoding the hidden information (\"traitor tracing\") NFC94 , PS96 , PW97 . Research supported by the Swiss National Science Foundation (SNF). Since most objects to be protected by watermarking or fingerprinting consist of audio or image data , these data types have received most attention so far . A number of generic hiding techniques have been developed whose effects are barely perceptible for humans but can withstand tampering by data transformations that essentially conserve its contents CKLS96 , BGML96 . A common model and terminology for information hiding has been established at the 1996 Information Hiding Workshop Pfi96 . An original , unaltered message is called covertext;", "label": ["covert channel", "universal data compression", "perfect security", "information hiding", "one-time pad", "subliminal channel"], "stemmed_label": ["covert channel", "univers data compress", "perfect secur", "inform hide", "one-tim pad", "sublimin channel"]}
{"doc": "The implicit characterizations of the polynomial-time computable functions FP given by Bellantoni-Cook and Leivant suggest that this class is the complexity-theoretic analog of the primitive recursive functions . Hence , it is natural to add minimization operators to these characterizations and investigate the resulting class of partial functions as a candidate for the analog of the partial recursive functions . We do so in this paper for Cobham's definition of FP by bounded recursion and for Bellantoni-Cook's safe recursion and prove that the resulting classes capture exactly NPMV , the nondeterministic polynomial-time computable partial multifunctions . We also consider the relationship between our schemes and a notion of nondeterministic recursion defined by Leivant and show that the latter characterizes the total functions of NPMV . We view these results as giving evidence that NPMV is the appropriate analog of partial recursive . This view is reinforced by earlier results of Spreen and Stahl who show that for many of the relationships between partial recursive functions and r.e . sets , analogous relationships hold between NPMV and NP sets . Furthermore , since NPMV is obtained from FP in the same way as the recursive functions are obtained from the primitive recursive functions (when defined via function schemes) , this also gives further evidence that FP is properly seen as playing the role of primitive recursion . Introduction When considering the analogy between the arithmetic and polynomial-time hierarchy , a standard view is that polynomial time plays the role of recursive (though not always|see , e.g. , Selman 9 , to which we will return) . The polynomial-time sets are used as the base 0 of the polynomial hierarchy and is dened as those sets polynomial-time in an oracle for some set . However, this view is not unproblematic . The analogy of i with i indicates that NP \\ coNP should be identied with the recursive sets . Under the assumption that P 6= NP \\ coNP , this leaves the polynomial-time sets to be viewed in analogy with some smaller class. A natural choice for this smaller class is the primitive recursive sets (or functions) . This is backed up by Cobham's 4 characterization of FP , the functions computable in polynomial time , by a scheme of recursion on notation that is nothing more than an explicitly bounded version of primitive recursion itself (formulated for binary words) . Further , the work of Bellantoni and Cook 3 and Report date: 24 Oct . 2000 Leivant 6 provides primitive recursive schemes for dening FP with no explicit bounds of any rather controlling the primitive recursion by semantically-inspired , syntactically implemented tiering notions . This approach to characterizing complexity classes without any explicit mention of resources or bounds is typically referred to as implicit computational complexity. However , if we are to identify FP with the primitive recursive functions and view NP \\ coNP as the appropriate analogy for the recursive sets , we are left with the following question: what is the correct analog of the partial recursive functions? Of course", "label": ["implicit computational complexity", "safe recursion", "minimization", "non-deterministic partial multifunctions"], "stemmed_label": ["implicit comput complex", "safe recurs", "minim", "non-determinist partial multifunct"]}
{"doc": "We give a realizability model of Girard-Scedrov-Scott's Bounded Linear Logic (BLL) . This gives a new proof that all numerical functions representable in that system are polytime . Our analysis naturally justifies the design of the BLL syntax and suggests further extensions . Introduction Bounded Linear Logic (BLL) 3 was an early attempt to provide an intrinsic notion of polynomial time computation within a logical system . That is , the aim was not merely to express polynomial time computability in terms of provability of certain restricted formulas, but rather to provide a typed logical system in which computation via cut-elimination or proof normalization is inherently polytime . Since the appearance of this paper , several di#erent typed functional systems for analyzing ptime computability have appeared in the literature 5 , 4 , 10 , 11 , 6 , 7 . For deeper foundational purposes , we should mention Girard's Light Linear Logic (LLL) 4 as a major improvement of the syntax of BLL , in that it eliminates the explicit polynomial I/O size-bounds , but at the expense of introducing more subtle typing distinctions . Moreover , while capturing the same extensional class of polytime functions , it appears to be less flexible than BLL in terms of expressing concrete algorithms. Furthermore BLL has its own merits: from the viewpoint of computer science , BLL is a natural polymorphically-typed functional language in which bounded storage can represent bounded calls to memory. The main theorem in 3 is that the number-theoretic functions representable in BLL are polytime . The proof of this result used sophisticated techniques from the proof theory of linear logic , notably a very detailed analysis of normalization of proof nets with boxes. The normalization strategy itself was of a special kind , inspired from Girard's Geometry of Interaction program . In this paper , we give a direct , semantic proof of this main result which does not involve any notion of reduction , term rewriting , or cut-elimination . Rather, we assign polytime algorithms to proofs in a compositional , syntax-directed manner . We use Research partially supported by EPSRC grant No . GR/N28436 Research supported by an operating grant from the Natural Sciences and Engineering Research Council of Canada. realizability to relate these algorithms to the intended set-theoretic meaning of the proofs themselves . All this is presented in the form of a concrete categorical model of BLL which interprets BLL-formulas as sets with some additional structure and proofs as functions witnessed by polytime algorithms operating on this additional structure . At the same time , our analysis gives a natural interpretation of the BLL syntax which justifies the fine points of its design and might suggest further extensions . For example , our analysis encompasses an a#ne variant of BLL. Our proof is constructive , in the sense that it can be formalized in an extensional version of the Calculus of Inductive Constructions 2 . This provides a new compilation method for turning BLL proofs into equivalent polytime algorithms . Of course in practice one", "label": ["complexity lambda calculus", "finite model theory", "linear logic"], "stemmed_label": ["complex lambda calculu", "finit model theori", "linear logic"]}
{"doc": "A space-efficient algorithm is one in which the output is given in the same location as the input and only a small amount of additional memory is used by the algorithm . We describe four space-efficient algorithms for computing the convex hull of a planar point set . Introduction be a set of n distinct points in the Euclidean plane . The convex hull of S is the minimal convex region that contains every point of S . From this denition , it follows that the convex hull of S is a convex polygon whose vertices are points of S . For convenience , we say that a point is \\on the convex hull of S\" if is a vertex of the convex hull of S. As early as 1972 , Graham 13 gave a convex hull algorithm with O(n log n) worst-case running time in which all branching is done based on the results of comparisons between quadratic polynomials. Shamos 33 later showed that , in any model of computation where sorting has an (n log n) lower bound, every convex hull algorithm must require (n log n) time for some inputs . Despite these matching upper and lower bounds , and probably because of the many applications of convex hulls , a number of other planar convex hull algorithms have been published since Graham's algorithm 1 , 2 , 4 , 6 , 11 , 17 , 21 , 28, Of particular note is the \\Ultimate(?)\" algorithm of Kirkpatrick and Seidel 21 that computes the convex hull of a set of n points in the plane in O(n log h) time , where h is the number of vertices of the convex hull . (Later , the same result was obtained by Chan using a much simpler algorithm 3 .) The same authors show that , on algebraic decision trees of any xed order, (n log h) is a lower bound for computing convex hulls of sets of n points having convex hulls with h vertices. Because of the importance of planar convex hulls , it is natural to try and improve the running time and storage requirements of planar convex hull algorithms . In this paper , we focus on reducing the intermediate storage used in the computation of planar convex hulls . In particular , we describe in-place and in situ algorithms for computing convex hulls . These algorithms take the input points as an array This research was partly funded by the National Science Foundation , the Natural Sciences and Engineering Research Council of Canada and the Danish Natural Science Research Council under contract 9801749 (project Performance Engi- neering). y CIS , Polytechnic University , Six Metrotech , Brooklyn , New York , 11201 . fhbr,jiaconog@poly.edu z Department of Computing , University of Copenhagen , jyrki@diku.dk x School of Computer Science , Carleton University , 1125 Colonel By Dr. , Ottawa , Ontario , CANADA , K1S 5B6. fmorin,morrisong@cs.carleton.ca School of Computer Science , McGill University , godfried@cgm.cs.mcgill.ca and output the vertices of the convex hull in", "label": ["convex hulls", "in-place", "in situ", "computational geometry"], "stemmed_label": ["convex hull", "in-plac", "in situ", "comput geometri"]}
{"doc": "This work stresses the fact that all current proposals for electronic voting schemes disclose the final tally of the votes . In certain situations , like jury voting , this may be undesirable . We present a robust and universally verifiable membership testing scheme (MTS) that allows , among other things , a collection of voters to cast votes and determine whether their tally belongs to some pre-specified small set (e.g. , exceeds a given threshold)--our scheme discloses no additional information than that implied from the knowledge of such membership . We discuss several extensions of our basic MTS . All the constructions presented combine features of two parallel lines of research concerning electronic voting schemes , those based on MIX-networks and in homomorphic encryption . Introduction In a typical trial by jury in the United States , twelve jurors deliberate in private . A foreman appointed by the judge among the jurors presides the deliberations . Jurors might be called upon to decide on several different counts according to a policy which may be complicated . Nevertheless , the simplest and most important jury verdicts are of the binary type , e.g. , innocent/guilty . In criminal cases unanimity is required in order to reach a verdict . In civil cases there are different standards, nine out of twelve votes are representative numbers . Jury deliberations proceed in discussion rounds followed by voting rounds . Voting is performed by raising hands . Hence , a typical requirement of an election protocol , privacy of the votes , is not achieved . This opens the possibility of biases on decisions due to jurors fear of rejection , a posteriori reprisals by interested parties , and/or follow the leader kind of behavior . In fact , just knowledge of tallies can cause undesirable consequences like follow the pack kind of behavior among jurors. A ballot box system could be implemented in order to guarantee privacy . A subset of the jury might be held responsible for tallying the votes and communicating to the others whether a verdict has been reached . Still , this discloses the final tally to a subset of the jury and allows them to manipulate the deliberation process . An outside third party (e.g. , a judge , government employee, etc.) could be responsible for tallying the votes , but this would cast doubts on the whole process since it allows for outside jury manipulation , could cause undesirable leaks on how the jury is leaning , etc. Dept . of Computer Science & Engineering , U . of California , San Diego , CA , and Dept . Cs . de la Computaci'on, U . Chile , ahevia@cs.ucsd.edu . Partially supported by Conicyt via Fondap in Applied Mathematics 1999-2000 and Fondecyt No . 1981182. y Dept . Ing . Matem'atica , Ctr . de Modelamiento Matem'atico , UMR 2071 U . Chile-CNRS , mkiwi@dim.uchile.cl. Gratefully acknowledges the support of Conicyt via Fondecyt No . 1981182 and Fondap in Applied Mathematics 1999-2000. We provide an electronic drop in procedure", "label": ["election scheme", "mix-networks", "majority voting", "membership testing"], "stemmed_label": ["elect scheme", "mix-network", "major vote", "membership test"]}
{"doc": "Sensing devices can be deployed to form a network for monitoring a region of interest . This chapter investigates the detection of a target in the region being monitored by using collaborative target detection algorithms among the sensors . The objective is to develop a low cost sensor deployment strategy to meet a performance criteria . A path exposure metric is proposed to measure the goodness of deployment . Exposure can be defined and efficiently computed for various target activities , targets traveling at variable speed and in the presence of obstacles in the region.Using exposure to evaluate the detection performance , the problem of random sensor deployment is formulated . The problem defines cost functions that take into account the cost of single sensors and the cost of deployment . A sequential sensor deployment approach is then developed . The chapter illustrates that the overall cost of deployment can be minimized to achieve a desired detection performance by appropriately choosing the number of sensors deployed in each step of the sequential deployment strategy . Introduction Recent advances in computing hardware and software are responsible for the emergence of sensor networks capable of observing the en- vironment , processing the data and making decisions based on the ob- servations . Such a network can be used to monitor the environment, detect , classify and locate specific events , and track targets over a specific region . Examples of such systems are in surveillance , monitoring of pollution , tra#c , agriculture or civil infrastructures 15 . The deployment of sensor networks varies with the application considered . It can be predetermined when the environment is su#ciently known and under control , in which case the sensors can be strategically hand placed. In some other applications when the environment is unknown or hostile, the deployment cannot be a priori determined , for example if the sensors are air-dropped from an aircraft or deployed by other means , generally resulting in a random placement. This chapter investigates the deployment of sensor networks performing target detection over a region of interest . In order to detect a target moving in the region , sensors make local observations of the environment and collaborate to produce a global decision that reflects the status of the region covered 3 . In general , this collaboration requires local processing of the observations , communication between di#erent nodes , and information fusion 16 . Since the local observations made by the sensors depend on their position , the performance of the detection algorithm is a function of the deployment , i.e . the number of sensors and their location. Recently , several studies have addressed the problem of deployment with the goal of determining the performance of a given deployment of sensors or determining an optimal deployment to achieve a desired coverage of the monitored region . The analysis of the sensor network performance relies on the model chosen for the detection capacity of the sensors . This chapter presents several models that di#er in their level of abstraction. Then", "label": ["exposure", "sensor networks", "deployment", "collaborative target detection", "value fusion"], "stemmed_label": ["exposur", "sensor network", "deploy", "collabor target detect", "valu fusion"]}
{"doc": "We present a construction of symmetry plane-groups for quasiperiodic point-sets named beta-lattices . The framework is issued from beta-integers counting systems . Beta-lattices are vector superpositions of beta-integers . When 1 is a quadratic Pisot-Vijayaraghavan algebraic unit , the set of beta-integers can be equipped with an abelian group structure and an internal multiplicative law . When we show that these arithmetic and algebraic structures lead to freely generated symmetry plane-groups for beta-lattices . These plane-groups are based on repetitions of discrete adapted rotations and translations we shall refer to as \"beta-rotations\" and \"beta-translations\" . Hence beta-lattices , endowed with beta-rotations and beta-translations , can be viewed like lattices . The quasiperiodic function S(n) , defined on the set of beta-integers as counting the number of small tiles between the origin and the nth beta-integer , plays a central part in these new group structures . In particular , this function behaves asymptotically like a linear function . As an interesting consequence , beta-lattices and their symmetries behave asymptotically like lattices and lattice symmetries , respectively . Introduction Underlying the notion of tiling , there is a point set which can be a Delaunay set . Recall that from a tiling there exist many ways to create a Delaunay set , and conversely , from a point set which is a Delaunay set , infinitely many possibilities exist to form a tiling from it . The most natural correspondence however consists in considering the set of vertices of a tiling as standard Delaunay set associated with this tiling 9 . In the following we will indi#erently speak of tilings or Delaunay sets with this identification , mentioning the edges or not in the figures . In general , there doesn't exist a symmetry group for the tiling of a Delaunay set , nor for the set itself , except for periodic tilings and lattices . Historically , periodic tilings and lattices merge from Crystallography , and are associated with crystals . A crystallographic group of R d , or a space-group in R d , is a discrete group of isometries whose maximal translation subgroup is of rank d , hence isomorphic to Z d . A crystal, as it is commonly used in Physics , is the orbit under the action of a crystallographic group of a finite number of points of R d . Let us recall that , in the context of the 18th problem of Hilbert, Bieberbach has shown that the number of isomorphism classes (equivalently of conjugation classes) of crystallographic groups is finite for all d 19 . Therefore , once a point set of R d which is a crystal is fixed , the number of possible crystallographic groups leaving this point set invariant is finite. Let us recall the example of the square lattice 2 in the classical lattice case . This Delaunay set presents a 4-fold rotational symmetry . The symmetry space-group G associated with # is the semi-direct product of the group of translations of # by its group of rotations its composition", "label": ["plane groups", "tilings", "beta-lattices", "quasicrystals", "pisot numbers"], "stemmed_label": ["plane group", "tile", "beta-lattic", "quasicryst", "pisot number"]}
{"doc": "Existing data mining algorithms on graphs look for nodes satisfying specific properties , such as specific notions of structural similarity or specific measures of link-based importance . While such analyses for predetermined properties can be effective in well-understood domains , sometimes identifying an appropriate property for analysis can be a challenge , and focusing on a single property may neglect other important aspects of the data . In this paper , we develop a foundation for mining the properties themselves . We present a theoretical framework defining the space of graph properties , a variety of mining queries enabled by the framework , techniques to handle the enormous size of the query space , and an experimental system called F-Miner that demonstrates the utility and feasibility of property mining . Introduction Graph analyses have been used for a variety of applications to analyze interrelationships among entities . Some of these analyses concern standard graph-theoretic properties , such as the radius of the graph or embedded cliques . Other analyses yield high-level , subjective information about the data. For example , the web graph has been analyzed using the PageRank 20 and HITS 16 algorithms to identify web pages likely to be deemed \"important\" by the user . The citation structure of scientific papers has been analyzed to find papers related to a given paper 13 , 15 , 21 . These techniques have in common that they analyze graph structures for predetermined properties . Although such analyses can be very effective , coming up with a good property for analysis is often a challenge , especially when little is known about the data to begin with . Moreover , by fixing specific properties for analysis , other important aspects of the data may be ignored . Therefore the space of properties itself should be explored. As a concrete example , consider the simple case of looking for intuitively \"similar\" nodes in the graph of Figure 1. This work was supported by the National Science Foundation under grant IIS-9817799 and by a Junglee Stanford Graduate Fellowship. StudentC Prof1 Prof2 Univ StudentA StudentB Figure 1: Graph example. One possibility is to conclude that Prof1 and Prof2 are similar because they are both pointed-to by Univ , as in the commonly used co-citation metric 21 . Analogously , we may conclude that StudentB and StudentC are similar because they are both pointed-to by Prof2 . On the other hand , we may argue that StudentA , StudentB, and StudentC are all similar because they are pointed-to by a node that is pointed-to by Univ , as in the recursive SimRank metric introduced in 13 . Each or all of these inferences may be valid , depending on the domain and application . However , current methods require the user to fix one measure of similarity (e.g. , co-citation or SimRank) and query for nodes found to be similar under this measure . Ideally , we would like to query simply for \"similar\" nodes and get as a result the sets Prof1, Prof2 , StudentB ,", "label": ["data mining", "graph mining"], "stemmed_label": ["data mine", "graph mine"]}
{"doc": "This paper presents a methodology for using simulated execution to assist a theorem prover in verifying safety properties of distributed systems . Execution-based techniques such as testing can increase confidence in an implementation , provide intuition about behavior , and detect simple errors quickly . They cannot by themselves demonstrate correctness . However , they can aid theorem provers by suggesting necessary lemmas and providing tactics to structure proofs . This paper describes the use of these techniques in a machine-checked proof of correctness of the Paxos algorithm for distributed consensus . Introduction Traditionally , execution serves as a prelude to formal verication . Testing reveals departures from desired behavior that are corrected (either in the code or in the specication of its behavior) before attempting to prove code correct . Testing via simulated execution can do the same even in the absence of a complete implementation . This paper discusses additional ways execution or simulated execution can assist in formal verication , and describes their use in producing a machine-checked proof of a distributed algorithm. First , execution can serve in a more powerful way as a prelude to formal veri- cation . Tools for dynamic program analysis can extract descriptions of program behavior from executions , and programmers can match the extracted descriptions against their expectations . Unlike the traditional use of execution to test behavior , this use can reveal unexpected behaviors , not just departures from anticipated behaviors. Second , execution can help produce the lemmas required for successful proofs of correctness . Unlike human proofs , which are peppered with phrases like \\it is obvious that,\" machine-checked proofs often require many explicit lemmas . To avoid the tedium of enumerating these lemmas by hand , veriers can discover them by using execution and dynamic program analysis. Third , information that directs simulated execution to examine interesting aspects of a program's behavior can also be used to direct a proof of correctness. For example , programmers may ensure that executions cover the entire range of expected behaviors by formulating case splits that distinguish between normal and unusual behaviors; these same case splits can also provide helpful ways of organizing a proof. We illustrate these uses of execution in constructing a formal proof of correctness for Paxos , a distributed algorithm for consensus Lam98,PLL00 . This paper is concerned primarily with a general methodology for verifying distributed algorithms | and with the role execution and automated tools play in that methodology | and not with the details of the Paxos algorithm itself . Our methodology is based on the input/output (I/O) automaton framework LT89 for modeling and verifying distributed algorithms , in which each component of a system is represented as an automaton whose external behavior is dened by a simple mathematical object called a trace. This paper is organized as follows . Section 2 introduces the I/O automaton model , discusses the IOA language and toolkit , which support use of this model, and contrasts the toolkit with related tools that use run-time techniques to aid formal verication", "label": ["dynamic analysis", "static analysis", "theorem proving", "invariant detection"], "stemmed_label": ["dynam analysi", "static analysi", "theorem prove", "invari detect"]}
{"doc": "We study combinatorial optimization problems in which a set of distributed agents must achieve a global objective using only local information . Papadimitriou and Yannakakis Proceedings of the 25th ACM Symposium on Theory of Computing , 1993 , pp . 121--129 initiated the study of such problems in a framework where distributed decision-makers must generate feasible solutions to positive linear programs with information only about local constraints . We extend their model by allowing these distributed decision-makers to perform local communication to acquire information over time and then explore the tradeoff between the amount of communication and the quality of the solution to the linear program that the decision-makers can obtain.Our main result is a distributed algorithm that obtains a $(1 approximation to the optimal linear programming solution while using only a polylogarithmic number of rounds of local communication . This algorithm offers a significant improvement over the logarithmic approximation ratio previously obtained by Awerbuch and Azar Proceedings of the 35th Annual IEEE Symposium on Foundations of Computer Science , 1994 , pp . 240--249 for this problem while providing a comparable running time . Our results apply directly to the application of network flow control , an application in which distributed routers must quickly choose how to allocate bandwidth to connections using only local information to achieve global objectives . The sequential version of our algorithm is faster and considerably simpler than the best known approximation algorithms capable of achieving a $(1 approximation ratio for positive linear programming . Introduction . Processors in a distributed environment must make decisions based only on local data , thus fast distributed algorithms must often do without global information about the system as a whole . This is exactly why computing many target functions in distributed models quickly is provably hard 15 . However , quite surprisingly , some of the most interesting global optimization problems can be very closely approximated based only on local information and a modest amount of local communication. Our work is motivated by the application of developing flow control policies which must achieve global objective functions . Flow control is the mechanism by which routers of a network distribute the available network bandwidth across connections. In our work , routing policies determine the routes in the network that connections must use to transmit packets . The problem of regulating the rates at which the connections may inject data along these fixed routes is the problem of flow control . This connection-oriented , or rate-based , approach to flow control is a standard for routing available bit rate tra#c in ATM networks 9 and is expected to become widely used in packet-switched networks . In this approach , each router in the network must make regulatory decisions based only on local information , which typically consists of the current transmission rates of connections using the router . Most existing flow control policies try to satisfy local objective functions such as max-min fairness 7 , 1 , 11 . However , there are many other practical scenarios in which global objective functions", "label": ["primal-dual", "linear programming", "approximation algorithm", "flow control"], "stemmed_label": ["primal-du", "linear program", "approxim algorithm", "flow control"]}
{"doc": "Let M be a $2\\times 2$ matrix of Laurent polynomials with real coefficients and symmetry . In this paper , we obtain a necessary and sufficient condition for the existence of four Laurent polynomials (or finite-impulse-response filters) u1 , u2 , v1 , v2 with real coefficients and symmetry such that $$ \\left \\begin matrix u_1(z) &v_1(z)\\\\ u_2(z) &v_2(z) \\end matrix \\right \\left \\begin matrix u_1(1/z) &u_2(1/z)\\\\ v_1(1/z) &v_2(1/z)\\end matrix \\right =M(z) \\qquad \\forall\\; z\\in \\CC \\bs \\ 0 \\ $$ and Su1 (z) Sv2 (z)= Su2 (z) Sv1 (z) , where Sp (z)=p(z)/p(1/z) for a nonzero Laurent polynomial . Our criterion can be easily checked and a step-by-step algorithm will be given to construct the symmetric filters u1 , u2 , v1 , v2 . As an application of this result to symmetric framelet filter banks , we present a necessary and sufficient condition for the construction of a symmetric multiresolution analysis tight wavelet frame with two compactly supported generators derived from a given symmetric refinable function . Once such a necessary and sufficient condition is satisfied , an algorithm will be used to construct a symmetric framelet filter bank with two high-pass filters which is of interest in applications such as signal denoising and image processing . As an illustration of our results and algorithms in this paper , we give several examples of symmetric framelet filter banks with two high-pass filters which have good vanishing moments and are derived from various symmetric low-pass filters including some B-spline filters . and high-pass filters , refinable functions. AMS subject classifications . 15A23 , 15A54 , 42C40 1 . Introduction and Motivation . Matrix theory plays an important role in wavelet analysis 4 and filter banks 17 , 18 . In this paper , we are interested in splitting of Laurent polynomials with real coe#cients and symmetry into the form U(z)U(1/z) T for some 2-2 matrix U whose entries are Laurent polynomials with real coe#cients and symmetry . Our investigation on this matrix splitting problem is greatly motivated by the recent development of symmetric tight wavelet frames and framelet filter banks which have been found to be useful and interesting in many applications 1 - 15 . In the following , let us review some necessary background and explain our motivation to study this problem. Since Daubechies constructed her famous family of compactly supported orthonormal wavelet bases in 1988 , wavelets have been extensively studied and successfully applied to many areas . Though orthonormal wavelet bases have many desired properties in applications , as Daubechies pointed out in 4 , except the Haar wavelet which is discontinuous , there is no compactly supported real-valued continuous orthonormal wavelet basis that can have symmetry . However , in many applications , for various purposes , symmetry is a much desired property . In order to achieve symmetry in a wavelet system or a wavelet filter bank , many generalizations of orthonormal wavelet bases have been proposed and investigated in the literature 4 , 18 . In this Research was supported by the Natural Science", "label": ["refinable functions", "low-pass and high-pass filters", "framelet filter banks", "tight wavelet frames", "matrix splitting", "symmetry"], "stemmed_label": ["refin function", "low-pass and high-pass filter", "framelet filter bank", "tight wavelet frame", "matrix split", "symmetri"]}
{"doc": "We present a new approach to termination analysis of numerical computations in logic programs . Traditional approaches fail to analyse them due to non well-foundedness of the integers . We present a technique that allows overcoming these difficulties . Our approach is based on transforming a program in a way that allows integrating and extending techniques originally developed for analysis of numerical computations in the framework of query-mapping pairs with the well-known framework of acceptability . Such an integration not only contributes to the understanding of termination behaviour of numerical computations , but also allows us to perform a correct analysis of such computations automatically , by extending previous work on a constraint-based approach to termination . Finally , we discuss possible extensions of the technique , including incorporating general term orderings . Introduction Numerical computations form an essential part of almost any real-world program . Clearly , in order for a termination analyser to be of practical use it should contain a mechanism for inferring termination of such compu- tations . However , this topic attracted less attention of the research com- munity . In this work we concentrate on automatic termination inference for logic programs depending on numerical computations . Dershowitz et al . 8 showed that termination of general numerical computations , for instance on floating point numbers , may be counter-intuitive , i.e. , the observed behaviour does not necessarily coincide with the theoretically expected one . Thus , we restrict ourselves to integer computations only. While discussing termination of integer computations the following question should be asked: what conditions on the queries should be as- sumed , such that the queries will terminate . We refer to this question as the termination inference problem. Example 1 . p(X) / X ! 7; X1 is X+1; p(X1): This program terminates for queries p(X) , for all integer values of X . Thus , the answer for the termination inference problem is the condition \"true\" . 2 This example also hints at why the traditional approaches to termination analysis fail to prove termination of this example . These approaches are mostly based on the notion of level mapping , that is , a function from the set of all possible atoms to the natural numbers , which should decrease while traversing the rules . In our case , such a level mapping should depend on X , but X can be negative as well! Two approaches for solving this problem are possible . First , one can change the definition of the level mapping to map atoms to integers . How- ever , integers are , in general , not well-founded . To prove termination one ? supported by GOA: generation logic programming language\". should prove that the mapping is to some well-founded subset of integers. In the example above (\\Gamma1; 7) forms such a subset with an ordering -, such that x - y if x ! y , with respect to the usual ordering on integers. The second approach that we present in the paper does not", "label": ["numerical computation", "termination analysis"], "stemmed_label": ["numer comput", "termin analysi"]}
{"doc": "In this paper we present efficient symbolic techniques for probabilistic model checking . These have been implemented in PRISM , a tool for the analysis of probabilistic models such as discrete-time Markov chains , continuous-time Markov chains and Markov decision processes using specifications in the probabilistic temporal logics PCTL and CSL . Motivated by the success of model checkers such as SMV which use BDDs (binary decision diagrams) , we have developed an implementation of PCTL and CSL model checking based on MTBDDs (multi-terminal BDDs) and BDDs . Existing work in this direction has been hindered by the generally poor performance of MTBDD-based numerical computation , which is often substantially slower than explicit methods using sparse matrices . The focus of this paper is a novel hybrid technique which combines aspects of symbolic and explicit approaches to overcome these performance problems . For typical examples , we achieve a dramatic improvement over the purely symbolic approach . In addition , thanks to the compact model representation using MTBDDs , we can verify systems an order of magnitude larger than with sparse matrices , while almost matching or even beating them for speed . Introduction In the design and analysis of software and hardware systems it is often desirable or even necessary to include probabilistic aspects of a system's behaviour . Examples include representing unreliable or unpredictable behaviour in fault-tolerant systems; deriving e-cient algorithms by using electronic coin ipping in decision making; and modelling the arrivals and departures of calls in a wireless cell. Probabilistic model checking refers to a range of techniques for calculating the likelihood of the occurrence of certain events during the execution of systems which exhibit such behaviour . One rst constructs a probabilistic model of the system . Properties such as \\shutdown occurs with probability 0.01 or less\" and \\the video frame will be delivered within 5ms with probability 0.97 or greater\" can be expressed in probabilistic temporal logics . Model checking algorithms ? Supported in part by EPSRC grant GR/M04617 and MathFIT studentship for David Parker. J.-P . Katoen and P . Stevens (Eds.) , 8th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS'02) , volume 2280 of LNCS , pages 52 66 , 2002. c Springer-Verlag Berlin Heidelberg 2002 Marta Kwiatkowska , Gethin Norman , and David Parker have been developed which then automatically verify whether the model satises these properties. Motivated by the success of symbolic model checkers , such as SMV 28 which use BDDs (binary decision diagrams) 11 , we have developed a symbolic probabilistic model checker . In the non-probabilistic setting , model checking involves analysing properties of state transition systems and the manipulation of sets of states . Both these entities can be represented naturally as BDDs , often very compactly 13 . In the probabilistic case , since probability transition matrices and probability vectors are required , BDDs alone are not su-cient , and hence we also use MTBDDs (multi-terminal binary decision diagrams) 17 , 3 , a natural extension of BDDs for representing", "label": ["probabilistic model checking", "symbolic model checking", "binary decision diagrams"], "stemmed_label": ["probabilist model check", "symbol model check", "binari decis diagram"]}
{"doc": "The task of finding a set of test sequences that provides good coverage of industrial circuits is infeasible because of the size of the circuits . For small critical subcircuits of the design , however , designers can create a set of test sequences that achieve good coverage . These sequences cannot be used on the full design because the inputs to the subcircuit may not be accessible . In this work we present an efficient test generation algorithm that receives a test sequence created for the subcircuit and finds a test sequence for the full design that reproduces the given sequence on the subcircuit . The algorithm uses a new technique called dynamic transition relations to increase its efficiency .The most common and most expensive step in our algorithm is the computation of the set of predecessors of a set of states . To make this computation more efficient we exploit a partitioning of the transition relation into a set of simpler relations . At every step we use only those that are necessary , resulting in a smaller relation than the original one . A different relation is used for each step , hence the name dynamic transition relations . The same idea can be used to improve symbolic model checking for the temporal logic CTL.We have implemented the new method in SMV and run it on several large circuits . Our experiments indicate that the new method can provide gains of up to two orders of magnitude in time and space during verification . These results show that dynamic transition relations can make it possible to verify circuits that were previously unmanageable due to their size and complexity . Introduction In recent years we have seen a rapid growth in the complexity and size of industrial de- signs . The verification task of such systems has become extremely complex , requiring new techniques that can handle large scale designs . Formal methods are an example of a new technology that has gained popularity recently in this context . One such method , symbolic model checking has been very successful in hardware verification . Model checkers have been able to find several previously unknown errors in industrial circuits . Many companies are starting to use symbolic model checking in their design cycles as a complement to dynamic validation . We propose a new technique based on symbolic model checking called dynamic transition relations that enhances both formal verification and dynamic validation. Dynamic validation (or simulation) checks that a given run of a system is correct by inputing a sequence of signals (a test sequence) to the design and observing the resulting outputs . Since the number of runs is infinite , the method cannot be exhaustive , i.e. , it cannot check all possible runs . Thus , it is important to obtain a set of test sequences that provides a good coverage of the design . However , this task might not be feasible if the design is too large . Creating a set of test sequences covering most", "label": ["symbolic model checking", "binary decision diagrams", "test sequence generation"], "stemmed_label": ["symbol model check", "binari decis diagram", "test sequenc gener"]}
{"doc": "Group key agreement is a fundamental building block for secure peer group communication systems . Several group key management techniques were proposed in the last decade , all assuming the existence of an underlying group communication infrastructure to provide reliable and ordered message delivery as well as group membership information . Despite analysis , implementation , and deployment of some of these techniques , the actual costs associated with group key management have been poorly understood so far . This resulted in an undesirable tendency: on the one hand , adopting suboptimal security for reliable group communication , while , on the other hand , constructing excessively costly group key management protocols.This paper presents a thorough performance evaluation of five notable distributed key management techniques (for collaborative peer groups) integrated with a reliable group communication system . An in-depth comparison and analysis of the five techniques is presented based on experimental results obtained in actual local- and wide-area networks . The extensive performance measurement experiments conducted for all methods offer insights into their scalability and practicality . Furthermore , our analysis of the experimental results highlights several observations that are not obvious from the theoretical analysis . Introduction The Internet is being increasingly used to support collaborative applications such as voice- and video- conferencing , white-boards , distributed simulations, as well as games , replicated servers and databases of all types . To be effective , these applications need supporting services , such as reliable and ordered message delivery as well as synchronization and fault-tolerance techniques . A reliable group communication system can provide an integrated platform containing such services , thus greatly simplifying the application development process and application complexity. Since most communication over the Internet involves the traversal of insecure networks , basic security services - such as data secrecy , data integrity and entity authentication - are necessary for collaborative applications . These security services can be facilitated if group members share a common secret, which , in turn , makes group key management a fundamental service and a design challenge in secure and reliable group communication systems. 1.1 Key Agreement in Peer Groups Several group key management approaches have been proposed in the last decade . (We stress that these are distinct from multicast key management which aims to minimize costs of key dissemination and re-keying in large , single-source multicast groups.) These approaches generally fall into three categories: distributed and contributory. Centralized group key management is conceptually simple as it involves a single entity (or a small set of that generates and distributes keys to group members . We claim that centralized group key management is not appropriate for peer group communication since the central key server must be , at the same time , continuously available and present in every possible subset of a group in order to support continued operation in the event of arbitrary network partitions. Continuous availability can be addressed with fault-tolerance and replication techniques . Unfortunately, the omni-presence issue is impossible to solve in a scalable and efficient manner. Distributed group key", "label": ["peer groups", "group key management", "secure communication", "group communication"], "stemmed_label": ["peer group", "group key manag", "secur commun", "group commun"]}
{"doc": "All Internet routers contain buffers to hold packets during times of congestion . Today , the size of the buffers is determined by the dynamics of TCP's congestion control algorithm . In particular , the goal is to make sure that when a link is congested , it is busy 100% of the time; which is equivalent to making sure its buffer never goes empty . A widely used rule-of-thumb states that each link needs a buffer of size is the average round-trip time of a flow passing across the link , and C is the data rate of the link . For example , a 10Gb/s router linecard needs approximately 250ms x 2.5Gbits of buffers; and the amount of buffering grows linearly with the line-rate . Such large buffers are challenging for router manufacturers , who must use large , slow , off-chip DRAMs . And queueing delays can be long , have high variance , and may destabilize the congestion control algorithms . In this paper we argue that the rule-of-thumb now outdated and incorrect for backbone routers . This is because of the large number of flows (TCP connections) multiplexed together on a single backbone link . Using theory , simulation and experiments on a network of real routers , we show that a link with n flows requires no more than long-lived or short-lived TCP flows . The consequences on router design are enormous: A 2.5Gb/s link carrying 10,000 flows could reduce its buffers by 99% with negligible difference in throughput; and a 10Gb/s link carrying 50,000 flows requires only 10Mbits of buffering , which can easily be implemented using fast , on-chip SRAM . INTRODUCTION AND MOTIVATION 1.1 Background Internet routers are packet switches , and therefore bu#er packets during times of congestion . Arguably , router bu#ers are the single biggest contributor to uncertainty in the Inter- net . Bu#ers cause queueing delay and delay-variance; when they overflow they cause packet loss , and when they underflow they can degrade throughput . Given the significance of their role , we might reasonably expect the dynamics and sizing of router bu#ers to be well understood , based on a well-grounded theory , and supported by extensive simulation and experimentation . This is not so. Router bu#ers are sized today based on a rule-of-thumb commonly attributed to a 1994 paper by Villamizar and Song 1 .Using experimental measurements of at most eight TCP flows on a 40 Mb/s link , they concluded that - because of the dynamics of TCP's congestion control algorithms - a router needs an amount of bu#ering equal to the average round-trip time of a flow that passes through the router , multiplied by the capacity of the router's net-work interfaces . This is the well-known We will show later that the rule-of-thumb does indeed make sense for one (or a small number of) long-lived TCP flows. Network operators follow the rule-of-thumb and require that router manufacturers provide 250ms (or more) of bu#er- ing 2 . The rule is found in architectural guidelines 3", "label": ["buffer size", "internet router", "tcp", "bandwidth delay product"], "stemmed_label": ["buffer size", "internet router", "tcp", "bandwidth delay product"]}
{"doc": "Currently the Internet has only one level of name resolution , DNS , which converts user-level domain names into IP addresses . In this paper we borrow liberally from the literature to argue that there should be three levels of name resolution: from user-level descriptors to service identifiers; from service identifiers to endpoint identifiers; and from endpoint identifiers to IP addresses . These additional levels of naming and resolution (1) allow services and data to be first class Internet objects (in that they can be directly and persistently named) , (2) seamlessly accommodate mobility and multi-homing and (3) integrate middleboxes (such as NATs and firewalls) into the Internet architecture . We further argue that flat names are a natural choice for the service and endpoint identifiers . Hence , this architecture requires scalable resolution of flat names , a capability that distributed hash tables (DHTs) can provide . INTRODUCTION Despite its tremendous success , the Internet architecture is widely acknowledged to be far from ideal , and the Internet's increasing ubiquity and importance have made its flaws all the more evident and urgent . The case for architectural change has never been stronger , as witnessed by the burgeoning set of architectural critiques and counter-proposals emerging from the research community (e.g. , 2,5-8,41,45,55,56 ) . Ironically , the growth that motivated these proposals now makes their success unlikely: the sheer size of the Internet's installed router infrastructure renders significant changes to IP almost impossible . The decade-long struggle to deploy IPv6 should give any aspiring network architect pause. Rather than attempt the Sisyphean task of modifying routers, we focus on improving a more malleable facet of the architecture: naming . 1 Although this restriction in focus prevents us from addressing issues that inherently involve routers (such as complete denial-of-service protection , fine-grained host-control over routing, and quality-of-service) there are many issues for which changes to IP would be irrelevant-and for which changes to the naming architecture would be crucial. The current Internet has only two global namespaces , DNS names and IP addresses , both of which are tied to pre-existing structures (administrative domains and network topology , respectively). The rigidity and paucity of these namespaces are responsible for a variety of architectural ills . For instance , the Internet is now widely used by applications to gain access to services (processes that are remotely invoked by clients , such as Web servers) and data (files , streams , etc.) , yet the Internet does not have a mechanism for directly and persistently naming data and services . Instead, both are named relative to the hosts on which they reside . Using DNS to name data overloads the names and rigidly associates them with specific domains or network locations , making it inconvenient to move service instances and data , as well as to replicate them 23 , 36 , 50 , 51 , 59 . In this sense , the Internet's current host-centric naming treats data and services as second-class network citizens In addition , users and system administrators often resort", "label": ["naming", "internet architecture", "middleboxes", "global identifiers", "name resolution", "distributed hash tables"], "stemmed_label": ["name", "internet architectur", "middlebox", "global identifi", "name resolut", "distribut hash tabl"]}
{"doc": "This paper presents an inverse kinematics system based on a learned model of human poses . Given a set of constraints , our system can produce the most likely pose satisfying those constraints , in real-time . Training the model on different input data leads to different styles of IK . The model is represented as a probability distribution over the space of all possible poses . This means that our IK system can generate any pose , but prefers poses that are most similar to the space of poses in the training data . We represent the probability with a novel model called a Scaled Gaussian Process Latent Variable Model . The parameters of the model are all learned automatically; no manual tuning is required for the learning component of the system . We additionally describe a novel procedure for interpolating between styles.Our style-based IK can replace conventional IK , wherever it is used in computer animation and computer vision . We demonstrate our system in the context of a number of applications: interactive character posing , trajectory keyframing , real-time motion capture with missing markers , and posing from a 2D image . Overview The main idea of our work is to learn a probability distribution function (PDF) over character poses from motion data , and then use this to select new poses during IK . We represent each pose with a 42-dimensional vector q , which consists of joint angles , and the position and orientation of the root of the kinematic chain . Our approach consists of the following steps: Feature vectors . In order to provide meaningful features for IK , we convert each pose vector to a feature representation y that represents the character pose and velocity in a local coordinate frame . Each motion capture pose qi has a corresponding feature vector yi , where i is an index over the training poses . These features include joint angles , velocity , and vertical orientation , and are described in detail in Section 4. SGPLVM learning . We model the likelihood of motion capture poses using a novel model called a Scaled Gaussian Process Latent Variable Model (SGPLVM) . Given the features yi a set of motion capture poses , we learn the parameters of an SGPLVM , as described in Section 5 . The SGPLVM de?nes a low-dimensional representation of the original data: every pose qi has a corresponding vector xi , usually in a 3-dimensional space . The low-dimensional space of xi values is called the latent space . In the learning process , we estimate the xi parameters for each input pose , along with the parameters of the SGPLVM model (denoted ? , ? , ? , and wk ). This learning process entails numerical optimization of an objective function LGP . The likelihood of new poses is then described by the original poses and the model parameters . In order to keep the model ef?cient , the algorithm selects a subset of the original poses to keep , called the", "label": ["gaussian processes", "inverse kinematics", "motion style", "non-linear dimensionality reduction", "character animation", "style interpolation", "machine learning"], "stemmed_label": ["gaussian process", "invers kinemat", "motion style", "non-linear dimension reduct", "charact anim", "style interpol", "machin learn"]}
{"doc": "In this paper we show that in sorting-based applications of parametric search , Quicksort can replace the parallel sorting algorithms that are usually advocated . Because of the simplicity of Quicksort , this may lead to applications of parametric search that are not only efficient in theory , but in practice as well . Also , we argue that Cole's optimization of certain parametric-search algorithms may be unnecessary under realistic assumptions about the input . Furthermore , we present a generic , flexible , and easy-to-use framework that greatly simplifies the implementation of algorithms based on parametric search . We use our framework to implement an algorithm that solves the Frchet-distance problem . The implementation based on parametric search is faster than the binary-search approach that is often suggested as a practical replacement for the parametric-search technique . Introduction Since the late 1980s , parametric search , the optimization technique developed by Megiddo in the late 1970s and early 1980s 15 , 16 , has become an important tool for solving many geometric optimization queries efficiently . The main principle of parametric search is to compute a value l that optimizes an objective function f with the use of an algorithm A s that solves the corresponding decision problem . The decision problem can be stated as follows: given a value l , decide whether l l , l = l , or l l . The idea is to run a \"generic\" version of A s on the unknown value l . This generic algorithm uses the concrete version of A s to determine the outcome of the decision problem for a set of concrete values; for one of these values l , A s will report that l = l . We will explain the technique in more detail in Section 2 . Usually , applying the concrete version A s is expensive in terms of running time . Megiddo shows how using a parallel version A of A s as the generic algorithm may reduce the number of times A s is called considerably. The technique is rather complicated , as it requires the design of an efficient parallel algorithm . Fortu- nately , the generic algorithm does not necessarily have to solve the same problem as the concrete decision; in several cases , sorting can be used instead 3 , 8 , 11 , 13 , 16 . However , the existing parallel sorting algorithms that have good worst-case time bounds are not easily implemented , and in some cases the hidden constants in the asymptotic running times are enormous 2 . Cole 9 shows how sorting-based parametric search can be optimized even further , but the optimization comes at the expense of making the technique even more complicated than it already is. In this paper we show that Quicksort can be used as the generic algorithm in sorting-based parametric search , instead of a parallel sorting algorithm-see Section 3 . Cole's optimization cannot be applied in this case , but in Section 4 we demonstrate that under", "label": ["implementation", "parametric search"], "stemmed_label": ["implement", "parametr search"]}
{"doc": "We study the problem of providing end-to-end delay guarantees in connection-oriented networks . In this environment , multiple-hop sessions coexist and interfere with one another.Parekh and Gallager showed that the Weighted Fair Queueing (WFQ) scheduling discipline provides a worst-case delay guarantee comparable to (1/i) Ki for a session with rate i and Ki hops . Such delays can occur since a session-i packet can wait for time 1/i at every hop.We describe a randomized work-conserving scheme that guarantees , with high probability , an additive delay bound of approximately 1/i + Ki . This bound is smaller than the multiplicative bound (1/i) Ki of WFQ , especially when the hop count Ki is large . We call our scheme COORDINATED-EARLIEST-DEADLINE-FIRST (CEDF) since it uses an earliest-deadline-first approach in which simple coordination is applied to the deadlines for consecutive hops of a session . The key to the bound is that once a packet has passed through its first server , it can pass through all its subsequent servers quickly.We conduct simulations to compare the delays actually produced by the two scheduling disciplines . In many cases , these actual delays are comparable to their analytical worst-case bounds , implying that CEDF outperforms WFQ . INTRODUCTION The provision of end-to-end delay guarantees in high-speed networks remains one of the most important and widely studied Quality-of-Service (QoS) issues . Many real time audio and video applications rely on the ability of the network to provide small delays . One key mechanism for achieving this aim is scheduling at the outputs of the switches . In this paper , we attempt to minimize end-to-end delay using a novel scheduling scheme. Before we introduce our scheme we first recall the delay bounds for the much studied Weighted Fair Queueing (WFQ) scheduling discipline , also known as Packet-by-Packet Generalized Processor-Sharing (PGPS) . In their seminal papers 1 , 2 , Parekh and Gallager showed that WFQ achieves the following session-i delay bound for Rate Proportional Processor Sharing (RPPS) . 1 (1) For session i , L i is the maximum packet size , K i is the number of servers and r m is the service rate of the mth server . The maximum packet size over all sessions is Lmax . Session i is leaky-bucket constrained with burst size oe i and rate ae i . Throughout this paper , we assume that all service is non-cut-through and non-preemptive. We briefly review the definitions of WFQ and RPPS in Section II. To understand the delay guarantee of (1) better , we compare the delay bound when session i has a single hop (K the bound when session i has multiple hops (K i ? 1) . We observe the following . When the burst size oe i is large then the multiple-hop delay bound is much less than K i times the single-hop delay bound . However , when oe i is small then the multiple-hop delay can be approximately K i times the single-hop delay. To see this , let us assume a uniform packet", "label": ["packet routing", "earliest deadline first", "scheduling", "weighted fair queueing", "delay bounds"], "stemmed_label": ["packet rout", "earliest deadlin first", "schedul", "weight fair queue", "delay bound"]}
{"doc": "We show that a boolean valued function over n variables , where each variable ranges in an arbitrary probability space , can be tested for the property of depending on only J of them using a number of queries that depends only polynomially on J and the approximation parameter . We present several tests that require a number of queries that is polynomial in J and linear in -1 . We showa non-adaptive tests that has one-sided error , an adaptive version of it that requires fewer queries , and a non-adaptive two-sided version of the test that requires the least number of queries . We also show a two-sided non-adaptive test that applies to functions over n boolean variables , and has a more compact analysis.We then provide a lower bound of (J) on the number of queries required for the nonadaptive testing of the above property; a lower bound of (log(J + 1)) for adaptive algorithms naturally follows from this . In establishing this lower bound we also prove a result about random walks on the group Z2q that may be interesting in its own right . We show that for some the distributions of the random walk at times t and t are close to each other , independently of the step distribution of the walk.We also discuss related questions . In particular , when given in advance a known J-junta function h , we show how to test a function f for the property of being identical to h up to a permutation of the variables , in a number of queries that is polynomial in J and -1 . Introduction Combinatorial property testing deals with the following task: For a xed property P and any given input f , one has to distinguish with high probability between the case where f satises P and the case where f is 'far' from satisfying it , accessing the least possible number of bits from the input. A property P is said to be -testable using q queries , or simply (; q)- testable , if there exists a probabilistic algorithm that makes at most q queries on any given input f (it is assumed that the input is accessed using an oracle) , such that if f satises P , then the algorithm accepts it with probability at least 2=3 , and if f is -far from P , that is , if it must be changed in more than an - fraction of the places in order to make it satisfy P , then the algorithm rejects it with probability at least 2=3. A testing algorithm is said to be 1-sided if it accepts with probability any input that satises P . A testing algorithm that determines all its queries in advance , and uses the answers only in deciding whether to accept the input (and not in planning some of the queries) is called a non-adaptive test. The general notion of property testing was rst formulated by Rubinfeld and Sudan 21 , who were motivated mainly by", "label": ["discrete fourier analysis", "property testing", "juntas", "boolean functions"], "stemmed_label": ["discret fourier analysi", "properti test", "junta", "boolean function"]}
{"doc": "An algorithm is presented which generates a triangular mesh to approximate an iso-surface . It starts with a triangulation of a sphere and next applies a series of deformations to this triangulation to transform it into the required surface . These deformations leave the topology invariant , so the final iso-surface should be homeomorphic with a sphere . The algorithm is adaptive in the sense that the lengths of the sides of the triangles in the mesh vary with the local curvature of the underlying surface . A quantitative analysis of the accuracy of the algorithm is given along with an empirical comparison with earlier algorithms . Introduction For a scalar function V defined on IR 3 , an iso-surface 1 is the collection of points r where V (r) takes a given value, . Iso-surfaces play a significant role in computer visualisation . Various researchers have used skeletal iso-surfaces for modelling: ( Blinn 82 , Bloomentha 90 , Wyvill 86 , Nishimura 85 ) and several of the surfaces that are of interest in pure mathematics , physics , or chemistry are iso-surfaces ( Wilhelms 91 ). In order to visualise iso-surfaces , ray tracing is an often used technique ( Nishimura 85 ) which produces high-quality images . In the case of all but trivial cases , however , it is an arduous task to compute points on the iso-surface and the computational burden of ray tracing often imposes restraints on its application. An alternative to ray tracing is the conversion of the iso-surface into polygon meshes which are rendered after- wards; an additionaladvantage of this approach is the availability of a full 3-D approximation of the iso-surface which allows for fast viewing from arbitrary directions , as well as the application of post-processing techniques such as mesh reduction ( Turk 92 ) , relaxation ( Mallet 92 ) or free-form deformation ( Sederberg 86 ). Also , the resulting polygon mesh is a closed manifold , so it may be used in B-rep-based CSG operations ( Requicha 83 ). Also called implicit surface Most currently existing techniques for the polygonisationof iso-surfaces are based on data structures that allow spatial indexing: either a voxel-based structure ( Bloomentha 88 ) or the hash-table structure of ( Wyvill 86 ) may be used. Some inherent disadvantages of these data structures exist: First , the data structure comprises a partitioning of the space rather a tesselation of the surfaces to be polyg- onalised . Especially in the case of animation (e.g . in the computer animation \"The great train rubbery\", Wyvill 88 ) , this is likely to cause geometric artifacts that are fixed with respect to space , thus moving in an incoherent way over every moving surface. Second , there is an apparent mismatch between the number of triangles that is generated by these algorithms and the complexity of the surface that is approximated: even relatively smooth and flat segments of an iso-surface usually result in large amounts of facets . Bloomental ( Bloomentha 88 ) uses an adaptive version of", "label": ["implicit surfaces", "iso-surfaces", "polygonization"], "stemmed_label": ["implicit surfac", "iso-surfac", "polygon"]}
{"doc": "Programs in embedded languages contain invariants that are not automatically detected or enforced by their host language . We show how to use macros to easily implement partial evaluation of embedded interpreters in order to capture invariants encoded in embedded programs and render them explicit in the terms of their host language . We demonstrate the effectiveness of this technique in improving the results of a value flow analysis . output formatting language , and Java 3 supports a declarative sub-language for laying out GUI elements in a window . PLT Scheme 9 offers at least five such languages: one for formatting console output; two for regular expression matching; one for sending queries to a SQL server; and one for laying out HTML pages. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. September 19-21 , 2004 , Snowbird , Utah , USA. In many cases , though not always , programs in these embedded special-purpose programming languages are encoded as strings . Library functions consume these strings and interpret them . Often the interpreters consume additional arguments , which they use as inputs to the little programs. Take a look at this expression in PLT Scheme: (regexp-match \"http://( a-z. *)/( a-z *)/\" line) The function regexp-match is an interpreter for the regular expression language . It consumes two arguments: a string in the regular expression language , which we consider a program , and another string , which is that program's input . A typical use looks like the example above . The first string is actually specified at the call site, while the second string is often given by a variable or an expression that reads from an input port . The interpreter attempts to match the regular expression and the second string. In PLT Scheme , the regular expression language allows programmers to specify subpatterns via parentheses . Our running example contains two such subexpressions: ( a-z. *) and ( a-z *) . If the regular expression interpreter fails to match the regular expression and the string , it produces false (#f); otherwise it produces a list with n+1 elements: the first one for the overall match plus one per subexpression . Say line stands for \"http://aaa.bbb.edu/zzz/\" In this case , the regular expression matches the string , and regexp-match produces the list (list \"http://aaa.bbb.edu/zzz/\" \"aaa.bbb.edu\" The rest of the Scheme program extracts the pieces from this list and computes with them. The regexp-match expression above is a simplified excerpt from the PLT Web Server 12 . Here is a slightly larger fragment: (let ( r (regexp-match \"http://( a-z. *)/( a-z *)/\" line) ) (if r (process-url (third r) (dispatch (second r))) (log-error", "label": ["value flow analysis", "embedded languages", "macros", "partial evaluation"], "stemmed_label": ["valu flow analysi", "embed languag", "macro", "partial evalu"]}
{"doc": "Open Shortest Path First (OSPF) is one of the most commonly used intra-domain internet routing protocol . Traffic flow is routed along shortest paths , splitting flow evenly at nodes where several outgoing links are on shortest paths to the destination . The weights of the links , and thereby the shortest path routes , can be changed by the network operator . The weights could be set proportional to the physical lengths of the links , but often the main goal is to avoid congestion , i.e . overloading of links , and the standard heuristic recommended by Cisco (a major router vendor) is to make the weight of a link inversely proportional to its capacity.We study the problem of optimizing OSPF weights for a given a set of projected demands so as to avoid congestion . We show this problem is NP-hard , even for approximation , and propose a local search heuristic to solve it . We also provide worst-case results about the performance of OSPF routing vs . an optimal multi-commodity flow routing . Our numerical experiments compare the results obtained with our local search heuristic to the optimal multi-commodity flow routing , as well as simple and commonly used heuristics for setting the weights . Experiments were done with a proposed next-generation AT&T WorldNet backbone as well as synthetic internetworks . Introduction Provisioning an Internet Service Provider (ISP) backbone network for intra-domain IP traffic is a big challenge , particularly due to rapid growth of the network and user demands. At times , the network topology and capacity may seem insufficient to meet the current demands . At the same time , there is mounting pressure for ISPs to provide Quality of Service (QoS) in terms of Service Level Agreements (SLAs) with customers , with loose guarantees on delay , loss , and throughput . All of these issues point to the importance of traffic engineering , making more efficient use of existing network resources by tailoring routes to the prevailing traffic. 1.1 The general routing problem Optimizing the use of existing network resources can be seen as a general routing problem defined as follows . We are given a capacitated directed graph whose nodes and arcs represent routers and the capacitated links between them, and a demand matrix D that , for each pair (s; t) of nodes , tells us how much traffic flow we need to send from s to t . We refer to s and t as the source and the destination of the demand . Many of the entries of D may be zero , and in particular , D(s; t) should be zero if there is no path from s to t in G. With each arc a 2 A , we associate a cost function \\Phi a ('(a)) of the load '(a) , depending on how close the load is to the capacity c(a) . More precisely , for each a 2 A , \\Phi a is the continuous function with \\Phi a derivative a 3 for 1=3 -", "label": ["shortest path routing", "local search", "traffic engineering"], "stemmed_label": ["shortest path rout", "local search", "traffic engin"]}
{"doc": "A variant of Reiter's default logic is proposed as a logic for reasoning with (defeasible) observations . Traditionally , default rules are assumed to represent generic information and the facts are assumed to represent specific information about the situation , but in this paper , the specific information derives from defeasible observations represented by (normal free) default rules , and the facts represent (hard) background knowledge . Whenever the evidence underlying some observation is more refined than the evidence underlying another observation , this is modelled by means of a priority between the default rules representing the observations . We thus arrive at an interpretation of prioritized normal free default logic as an observation logic , and we propose a semantics for this observation logic . Finally , we discuss how the proposed observation logic relates to the multiple extension problem and the problem of sensor fusion . Introduction In this paper we propose a variant of Reiter's default logic 8 as a logic for reasoning with (defeasible) observations . A default theory consists of a set of facts and a set of default rules . Traditionally , default rules are assumed to represent general , or generic, information , such as 'typically , birds fly' and the facts are assumed to represent specific information about the situation , such as 'Tweety is a bird' . However , in this paper we consider the case where the specific information derives from defeasible ob- servations , and the general information denotes (hard) background knowledge . These The investigations were carried out as part of the PIONIER-project Reasoning with Uncertainty, subsidized by the Netherlands Organization of Scientific Research (NWO) , under grant pgs-22-262. characteristics apply , for example , to the situation of an autonomous robot navigating through an environment using an a priori given map and its not completely reliable sensors. The nonmonotonic logic proposed in this paper is motivated by the logic of vision proposed in 5 , where perception reports are interpreted in inverse systems of first-order models approximating reality . A perception of OE is modelled as the truth of OE given some approximation plus a defeasible expectation that OE will also be true in more refined approximations . Perceptions based on more refined evidence can defeat this expectation. We abstract from the particular language of 5 and propose prioritized normal free default logic for reasoning with defeasible observations . Each observation is modelled by a normal free default rule , i.e. , a default rule which has a single justification equivalent to its consequent and a tautology as prerequisite . To take account of the fact that an observation can be defeated by another observation based on more refined evidence , we add a preference order on the default rules. The remainder of this paper is organized as follows . In sections 2 and 3 , we briefly review some basic properties of default logic , and in particular of the special case where default rules are normal and free . In section 4 , we describe how normal", "label": ["defeasible observations", "nonmonotonic logic", "multiple extension problem", "prioritized default logic", "sensor fusion", "free default logic"], "stemmed_label": ["defeas observ", "nonmonoton logic", "multipl extens problem", "priorit default logic", "sensor fusion", "free default logic"]}
{"doc": "We initiate a study of bounded clock synchronization under a more severe fault model than that proposed by Lamport and Melliar-Smith 1985 . Realistic aspects of the problem of synchronizing clocks in the presence of faults are considered . One aspect is that clock synchronization is an on-going task , thus the assumption that some of the processors never fail is too optimistic . To cope with this reality , we suggest self-stabilizing protocols that stabilize in any (long enough) period in which less than a third of the processors are faulty . Another aspect is that the clock value of each processor is bounded . A single transient fault may cause the clock to reach the upper bound . Therefore , we suggest a bounded clock that wraps around when appropriate.We present two randomized self-stabilizing protocols for synchronizing bounded clocks in the presence of Byzantine processor failures . The first protocol assumes that processors have a common pulse , while the second protocol does not . A new type of distributed counter based on the Chinese remainder theorem is used as part of the first protocol . Introduction In a distributed system , it is often necessary to keep the logical clocks of the processors synchronized. In such a system physical clocks may drift and messages could have varying delivery times . Moreover, processors may be faulty , and in many cases the type of failures is not predictable in advance . To handle this situation , the worst type of failures must be considered , namely Byzantine faults LSP-82 . In the presence of Byzantine faults a processor can exhibit arbitrary \"malicious\" , \"two faced\" , behavior. The problem of keeping clocks synchronized in the presence of Byzantine faults has been extensively studied (e.g. , HS+-84 , LM-85 , MS-85 , DHS-86 , ST-87 , WL-88 , RSB-90 ) . Lamport and Melliar-Smith LM-85 were the first to present the problem and show that 3f processors are sufficient to tolerate f Byzantine faults . The necessity of 3f processors to tolerate f faults was later proved in DHS-86 . A weaker fault model called authenticated Byzantine allows a protocol that can tolerate any number of faulty processors HS+-84 . In that failure model reintegration of repaired processors is only possible if less than half the processors are faulty . Many of the protocols for this problem assume that the clocks are initially synchronized and thus focus on keeping them synchronized in the presence of clock drift. The problem of how to ensure that the clocks are initially synchronized was addressed in , e.g. , ST-87, WL-88 . In these protocols , some mechanism is assumed that allows all the nonfaulty processors to begin the protocol within a bounded time period of each other . The mechanism essentially is that the processes Supported in part by TAMU Engineering Excellence funds and NSF Presidential Young Investigator Award CCR-9158478. y Department of Mathematics and Computer Science , Ben-Gurion University , Beer-Sheva , 84105 , Israel . e-mail: shlomi@cs.bgu.ac.il. z Department of Computer Science", "label": ["clock synchronization", "self-stabilization", "byzantine failures"], "stemmed_label": ["clock synchron", "self-stabil", "byzantin failur"]}
{"doc": "Extension languages enable users to expand the functionality of an application without touching its source code . Commonly , these languages are dynamically typed languages , such as Lisp , Python , or domain-specific languages , which support runtime plugins via dynamic loading of components . We show that Haskell can be comfortably used as a statically typed extension language for both Haskell and foreign-language applications supported by the Haskell FFI , and that it can perform type-safe dynamic loading of plugins using dynamic types . Moreover , we discuss how plugin support is especially useful to applications where Haskell is used as an embedded domain-specific language (EDSL) . We explain how to realise type-safe plugins using dynamic types , runtime compilation , and dynamic linking , exploiting infrastructure provided by the Glasgow Haskell Compiler . We demonstrate the practicability of our approach with several applications that serve as running examples . Introduction The success of applications , such as Emacs , command shells , web browsers , Microsoft Word , Excel , and The GIMP , is to a significant degree due to them providing users with an extension language . An extension language-whether general purpose (e.g. , Emacs's Lisp) Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. September 22 , 2004 , Snowbird , Utah , USA. or application specific (e.g. , Word macros)-enables users to add new functionality to an application without understanding or re-compiling its source code . Indeed , extension languages have been advocated as an alternative to writing an application in a single language 25 . They are so convenient that some applications , most notably Emacs 32 , consist of only a small core with almost all higher-level functionality being implemented in the extension lan- guage . Code components written in an extension language can usually be loaded at runtime , so that an application can be extended dynamically; such components are often called plugins. In this paper , we discuss the use of Haskell as a typed extension language and outline an approach to the dynamic loading of Haskell plugins based on dynamic types 1 , 2 , 4 , 22 , 37 . We illustrate the broad scope of applications for Haskell plugins and argue that plugins can be viewed as a further step in the development of embedded domain-specific languages (EDSLs)-that is , domain-specific languages (DSLs) that are embedded in a host language (such as Haskell) instead of being implemented from scratch . In particular, when a DSL is used as an extension language , an implementation of that DSL as an EDSL gets plugin support for free by using the framework discussed in this", "label": ["plugins", "functional programming", "dynamic loading", "dynamic typing", "extension languages", "staged type inference"], "stemmed_label": ["plugin", "function program", "dynam load", "dynam type", "extens languag", "stage type infer"]}
{"doc": "In reactive systems , execution is driven by external events to which the system should respond with appropriate actions . Such events can be simple , but systems are often supposed to react to sophisticated situations involving a number of simpler events occurring in accordance with some pattern . A systematic approach to handle this type of systems is to separate the mechanism for detecting composite events from the rest of the application logic.In this paper , we present an event algebra for composite event detection . We show a number of algebraic laws that facilitate formal reasoning , and justify the algebra semantics by showing to what extent the operators comply with intuition . Finally , we present an implementation of the algebra , and identify a large subset of expressions for which detection can be performed with bounded resources . INTRODUCTION Many real-time and embedded systems are reactive , meaning that the execution is driven by external events to which the system should react with an appropriate response . For many applications , the system should react to complex event patterns , sometimes called composite events , rather than to Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. September 27-29 , 2004 , Pisa , Italy. a single event occurrence . A systematic approach to handle this type of systems is to separate the mechanism for detecting composite events from the rest of the application logic. The detection mechanism takes as input primitive events and detects occurrences of composite events which are used as input to the application logic . This separation of concerns facilitates design and analysis of reactive systems , as detection of complex events can be given a formal semantics independent from the application in which it is used , and the remaining application logic is free from auxiliary rules and information about partially completed patterns. Example 1 . Consider a system with input events including a button B , a pressure alarm P and a temperature alarm T , where one desired reaction is that the system should perform an action A when the button is pressed twice within two seconds , unless either of the alarms occurs in between. This can be achieved by a set of rules that specifies reactions to the three events , so that the combined behaviour implements the desired reaction . Alternatively , a separate detection mechanism can be used to define a composite event E that corresponds to the described situation , with a single rule stating that an occurrence of E should trigger the action A . The two approaches are illustrated by Figure 1. A Application logic A Event detection", "label": ["event algebra", "reactive systems", "resource-efficiency", "event detection"], "stemmed_label": ["event algebra", "reactiv system", "resource-effici", "event detect"]}
{"doc": "High-level programming languages offer significant expressivity but provide little or no guarantees about resource use . Resource-bounded languages --- such as hardware-description languages --- provide strong guarantees about the runtime behavior of computations but often lack mechanisms that allow programmers to write more structured , modular , and reusable programs . To overcome this basic tension in language design , recent work advocated the use of Resource-aware Programming (RAP) languages , which take into account the natural distinction between the development platform and the deployment platform for resource-constrained software.This paper investigates the use of RAP languages for the generation of combinatorial circuits . The key challenge that we encounter is that the RAP approach does not safely admit a mechanism to express a posteriori (post-generation) optimizations . The paper proposes and studies the use of abstract interpretation to overcome this problem . The approach is illustrated using an in-depth analysis of the Fast Fourier Transform (FFT) . The generated computations are comparable to those generated by FFTW . INTRODUCTION Hardware description languages are primarily concerned with resource use . But except for very high-end applications , verifying # Supported by NSF ITR-0113569 \"Putting Multi-stage Annotations to Work.\" Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. September 27-29 , 2004 , Pisa , Italy. the correctness of hardware systems can be prohibitively expen- sive . In contrast , software languages are primarily concerned with issues of expressivity , safety , clarity , and maintainability . Software languages provide abstraction mechanisms such as higher-order functions , polymorphism , and general recursion . Such abstraction mechanisms can make designs more maintainable and reusable . They can also keep programs close to the mathematical definitions of the algorithms they implement , which helps with ensuring correctness . Hardware description languages such as VHDL 16 and Verilog 32 provide only limited support for such abstract mechanisms . The growing interest in reconfigurable hardware invites us to consider the integration of the hardware and software worlds , and to consider how verification techniques from one world can be usefully applied in the other . Currently , programming re-configurable hardware is hard 3 : First , software developers are typically not trained to design circuits . Second , specifying circuits by hand can be tedious , error prone , and difficult to maintain . The challenge in integrating both hardware and software worlds can be summarized by a key question: How can we get the raw performance of hardware without giving up the expressivity and clarity of software? 1.1 Generators and Manifest Interfaces Recent work on Resource-aware Programming (RAP) 30 in the context of software generation suggests a promising approach to hardware", "label": ["multi-stage programming", "abstract interpretation"], "stemmed_label": ["multi-stag program", "abstract interpret"]}
{"doc": "Pervasive computing lets users continuously and consistently access an application on heterogeneous devices . However , delivering complex applications on resource-constrained mobile devices such as cell phones is challenging . Application- or system-based adaptations attempt to address the problem , but often at the cost of considerable degradation to application fidelity . The solution is to dynamically partition the application and offload part of the application execution data to a powerful nearby surrogate . This allows delivery of the application in a pervasive computing environment without significant fidelity degradation or expensive application rewriting . Runtime offloading must adapt to different application execution patterns and resource fluctuations in the pervasive computing environment . This offloading inference engine adaptively solves two key decision-making problems in runtime offloading: timely triggering of offloading and efficient partitioning of applications . Both trace-driven simulations and prototype experiments confirm the effectiveness of this adaptive offloading system . Figure 1 . Adaptive of?oading system architecture Partition Selection Function Invocation Data Access Candidate Partition Plan Generation Module Offloading Triggering Inference Application-Specific Offloading Rules Application Execution Monitor Event Filter Bandwidth Monitor Figure 2 . Of?oading inference engine architecture and stability , the of?oading inference engine employs the Fuzzy Control model 13 as the basis for the of?oading triggering inference module . This module can be easily con?gured using application-speci?c of?oading rules . This approach is analogous to Internet Protocol (IP) con?guration for the network connection in a modern operating system . To avoid unnecessary inference overhead , an event ?lter is used to drop insigni?cant resource and application execution change events. After the of?oading inference engine decides to trigger a new of?oading action and selects the new levels of resource utilization , it selects an effective application partitioning from many possible partition plans generated by the partition module of the of?oading platform . The of?oading platform generates a set of candidate partition plans using a simple heuristic algorithm derived from the MINCUT algorithm 17 . To simultaneously meet multiple user requirements for of?oading , the of?oading inference engine uses a composite partitioning cost metric to select the best partition plan . The selected application partition plan indicates which program objects should be of?oaded to the surrogate and which program objects should be pulled back to the mobile device during the new of?oading action. One of the critical resource constraints on the mobile device is its strict memory limitation . Although the memory capacity of mobile devices will continue to increase , the memory limitation will still exist when the user runs multiple applications or multiple instances of the same application . In this article , we focus on describing how to minimize the performance penalty experienced by the application when using adaptive of?oading to relieve the mobile device's memory constraint . Overcoming the memory constraint allows a memory-intensive application to be used on a mobile device with good performance , a result that otherwise cannot be supported without incurring of?oading or ?delity degradation . Although our research 14 has shown that adaptive of?oading could be applied to other resources such as CPU", "label": ["adaptive offloading", "application execution", "pervasive computing", "dynamic partitioning", "mobile device"], "stemmed_label": ["adapt offload", "applic execut", "pervas comput", "dynam partit", "mobil devic"]}
{"doc": "After 15 , 31 , 19 , 8 , 25 , 5 , minimum cut/maximum flow algorithms on graphs emerged as an increasingly useful tool for exact or approximate energy minimization in low-level vision . The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity . Their practical efficiency , however , has to date been studied mainly outside the scope of computer vision . The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision . We compare the running times of several standard algorithms , as well as a new algorithm that we have recently developed . The algorithms we study include both Goldberg-Tarjan style \"push-relabel methods and algorithms based on Ford-Fulkerson style \"augmenting paths . We benchmark these algorithms on a number of typical graphs in the contexts of image restoration , stereo , and segmentation . In many cases , our new algorithm works several times faster than any of the other methods , making near real--time performance possible . An implementation of our max-flow/min-cut algorithm is available upon request for research purposes . Introduction Greig et . al . 10 were rst to discover that powerful min-cut/max- ow algorithms from combinatorial optimization can be used to minimize certain important energy functions in vision . The energies addressed by Greig et . al . and by most later graph based methods (e.g . 15 , 12 , 2 , 11 , 4 , 1 , 18 , 13 , 16 , 17 , 3 , 14 ) can be represented as a posterior energy in MAP-MRF 1 framework: (p;q)2N Pg is a labeling of image P , D () is a data penalty function, V p;q is an interaction potential , and N is a set of all pairs of neighboring pixels. Papers above show that , to date , graph based energy minimization methods provide arguably the most accurate solutions for the specied applications. stands for Maximum A Posterior estimation of a Markov Random Field. Greig et.al . constructed a two terminal graph such that the minimum cost cut of the graph gives a globally optimal binary labeling L in case of the Potts model of interaction in (1) . Previously , exact minimization of energies like (1) was not possible and such energies were approached mainly with iterative algorithms like simulated annealing . In fact , Greig et.al . used their result to show that in practice simulated annealing reaches solutions very far from the global minimum even in very simple image restoration examples. Unfortunately , the result of Greig et.al . remained unnoticed for almost 10 years mainly because the binary labeling limitation looked too restrictive . In the late 90's new computer vision techniques appeared that used min-cut/max- ow algorithms on graphs . 15 was the rst to use these algorithms to compute multi-camera stereo . Later , 12 , 2 showed that with the right edge weights on a similar to 15 graph one can minimize the energy in", "label": ["maximum flow", "segmentation", "minimum cut", "multicamera scene reconstruction", "image restoration", "stereo", "graph algorithms", "index terms- energy minimization"], "stemmed_label": ["maximum flow", "segment", "minimum cut", "multicamera scene reconstruct", "imag restor", "stereo", "graph algorithm", "index terms- energi minim"]}
{"doc": "A fundamental question of complexity theory is the direct product question . A famous example is Yao's XOR-lemma , in which one assumes that some function f is hard on average for small circuits (meaning that every circuit of some fixed size s which attempts to compute f is wrong on a non-negligible fraction of the inputs) and concludes that every circuit of size s' only has a small advantage over guessing randomly when computing .. . f(xk) on independently chosen x1,...,xk . All known proofs of this lemma have the property that s' s . In words , the circuit which attempts to compute fk is smaller than the circuit which attempts to compute f on a single input! This paper addresses the issue of proving strong direct product assertions , that is , ones in which s' ks and is in particular larger than s . We study the question of proving strong direct product question for decision trees and communication protocols . Introduction 1.1 The direct product question Given a boolean function f over domain X and an integer k , we define a function f Intuitively , if f is hard on average , (say f can be computed correctly by some computational class on at most a (1/2 + p)-fraction of of the inputs) , then we expect f #k to be computed correctly on at most a (1/2 )-fraction of the inputs . This intuition is based on an information theoretic analog . In the information theoretic setup f is a biased random coin with probability of heads #k is the exclusive-or of k such independent coins which indeed induces a coin with probability of heads roughly equal to 1/2 . Transferring this intuition from the information theoretic setting to computational settings is much more involved than one can expect at first glance . Such assertions are referred to as direct product assertions. Let us present the direct product question in a general computational setting . Consider some computational resource (such as circuit size , decision tree depth , number of bits exchanged in a communication protocol . Let Res r denote the class of all functions computable using r \"units\" of the resource . In this paper we consider the following classes: . Size s the family of functions computed by circuits of size s. . Comm c the family of functions (on two inputs) computed by a communication protocol which exchanges c bits. . Depth d the family of functions computed by decision trees of depth d. Saying that a function f is \"hard on average\" for Res r means that every algorithm from Res r computes f correctly on a bounded fraction of the inputs 1 . We use the following notation: Suc Res Since f is boolean it can always be computed on at least half the inputs . We will be interested in the advantage the algorithm can get over guessing. Adv Res The direct product question can now be presented as follows: 2 The direct product problem: Is it true", "label": ["product theorems", "average case complexity", "hardness amplification", "xor-lemma"], "stemmed_label": ["product theorem", "averag case complex", "hard amplif", "xor-lemma"]}
{"doc": "The ability to cooperate on common tasks in a distributed setting is key to solving a broad range of computation problems ranging from distributed search such as SETI to distributed simulation and multi-agent collaboration . Do-All , an abstraction of such cooperative activity , is the problem of performing N tasks in a distributed system of P failure-prone processors . Many distributed and parallel algorithms have been developed for this problem and several algorithm simulations have been developed by iterating Do-All algorithms . The efficiency of the solutions for Do-All is measured in terms of work complexity where all processing steps taken by all processors are counted . Work is ideally expressed as a function of N , P , and f , the number of processor crashes . However the known lower bounds and the upper bounds for extant algorithms do not adequately show how work depends on f . We present the first non-trivial lower bounds for Do-All that capture the dependence of work on N , P and f . For the model of computation where processors are able to make perfect load-balancing decisions locally , we also present matching upper bounds . We define the r-iterative Do-All problem that abstracts facts the repeated use of Do-All such as found in typical algorithm simulations . Our f-sensitive analysis enables us to derive tight bounds for r-iterative Do-All work (that are stronger than the r-fold work complexity of a single Do-All) . Our approach that models perfect load-balancing allows for the analysis of specific algorithms to be divided into two parts: (i) the analysis of the cost of tolerating failures while performing work under \"free\" load-balancing , and (ii) the analysis of the cost of implementing load-balancing . We demonstrate the utility and generality of this approach by improving the analysis of two known efficient algorithms . We give an improved analysis of an efficient message-passing algorithm . We also derive a tight and complete analysis of the best known Do-All algorithm for the synchronous shared-memory model . Finally we present a new upper bound on simulations of synchronous shared-memory algorithms on crash-prone processors . Introduction Performing a set of tasks in a decentralized setting is a fundamental problem in distributed comput- ing . This is often challenging because the set of processors available to the computation and their ability to communicate may dynamically change due to perturbations in the computation medium. An abstract statement of this problem , referred to as the Do-All problem | P fault-prone processors perform N independent tasks | is one of the standard problems in the research on the complexity of fault-tolerant distributed computation 9 , 18 . This problem has been studied in a variety of set- tings , e.g. , in shared-memory models (Write-All) 19 , 20 , 26 , in message-passing models 7 , 9 , 11 , and in partitionable networks (Omni-Do) 8 , 15 , 25 . Solutions for Do-All must perform all tasks e-ciently in the presence of specic failure patterns . The e-ciency is assessed in terms", "label": ["fault", "work complexity", "lower bounds", "tolerence", "distributed algorithms"], "stemmed_label": ["fault", "work complex", "lower bound", "toler", "distribut algorithm"]}
{"doc": "This paper studies nested simulation and nested trace semantics over the language BCCSP , a basic formalism to express finite process behaviour . It is shown that none of these semantics affords finite (in)equational axiomatizations over BCCSP . In particular , for each of the nested semantics studied in this paper , the collection of sound , closed (in)equations over a singleton action set is not finitely based . Introduction Labelled transition systems (LTSs) 23 are a fundamental model of concurrent com- putation , which is widely used in light of its flexibility and applicability . In particular, they are the prime model underlying Plotkin's Structural Operational Semantics 30 and , following Milner's pioneering work on CCS 25 , are by now the standard semantic model for various process description languages. LTSs model processes by explicitly describing their states and their transitions from state to state , together with the actions that produced them . Since this view of process behaviours is very detailed , several notions of behavioural equivalence and preorder have been proposed for LTSs . The aim of such behavioural semantics is to identify those (states of) LTSs that afford the same \"observations\" , in some appropriate technical sense . The lack of consensus on what constitutes an appropriate notion of observable behaviour for reactive systems has led to a large number of proposals for behavioural equivalences for concurrent processes . (See the study 14 , where van Glabbeek presents the linear time-branching time spectrum-a lattice of known behavioural equivalences and preorders over LTSs , ordered by inclusion.) One of the criteria that has been put forward for studying the mathematical tractability of the behavioural equivalences in the linear time-branching time spectrum is that they afford elegant , finite equational axiomatizations over fragments of process algebraic languages . Equationally based proof systems play an important role in both the practice and the theory of process algebras . From the point of view of practice , these proof systems can be used to perform system verifications in a purely syntactic way, and form the basis of axiomatic verification tools like , e.g. , PAM 24 . From the theoretical point of view , complete axiomatizations of behavioural equivalences capture the essence of different notions of semantics for processes in terms of a basic collection of identities , and this often allows one to compare semantics which may have been defined in very different styles and frameworks . A review of existing complete equational axiomatizations for many of the behavioural semantics in van Glabbeek's spectrum is offered in 14 . The equational axiomatizations offered ibidem are over the language BCCSP , a common fragment of Milner's CCS 25 and Hoare's CSP 20 suitable for describing finite synchronization trees , and characterize the differences between behavioural semantics in terms of a few revealing axioms. The main omissions in this menagerie of equational axiomatizations for the behavioural semantics in van Glabbeek's spectrum are axiomatizations for 2-nested simulation semantics and possible futures semantics . The relation of 2-nested simulation was introduced by Groote and", "label": ["possible futures", "nested simulation", "nested trace semantics", "concurrency", "non-finitely based algebras", "hennessy-milner logic", "complete axiomatizations", "equational logic", "bccsp", "process algebra"], "stemmed_label": ["possibl futur", "nest simul", "nest trace semant", "concurr", "non-finit base algebra", "hennessy-miln logic", "complet axiomat", "equat logic", "bccsp", "process algebra"]}
{"doc": "Order-sorted logic iucludes many and partially ordered sorts as a sort-hierarchy . In the field of knowledge representation and reasoning , it is useful to develop reasoning systems fbr terminological knowledge , together with assertional knowledge . However , the expression of sort-hierarchies cannot sufficiently capture the lexical diversity of terminological knowledge . In addition to sorts , various kinds of symbols: constants , functions and predicates are semantically and hierarchically associated with each other . This is because natural language words identifying these symbols can be employed in the description of terminological knowledge . In this paper , we present a label-based language for consistently handling the variety of hierarchical relationships among symbol names . For this language we develop a sorted resolution system whose reasoning power is enhanced by adding hierarchical inference rules with labeled substitutions . Introduction Logical languages with class-hierarchy formally concentrate upon representation and reasoning for terminological knowledge (and ontologies 7) ) , together with assertional knowledge . The significant feature is that one can specify classes as sets of individuals and their hierarchical relationships (e.g . is-a rela- tions) in the languages . In the past , there have been several approaches to the formalisms: order-sorted logic , 15 , 16 , 5 , 17) typed logic programming , 1 , 2 , description logics 8 , 13) and object-oriented deduction languages . 12 , 18) In particular, order-sorted logic gives us the advantage of interacting terminological knowledge and assertional knowledge . This logic theoretically corresponds to a first-order predicate logic with sort-hierarchy , where sort symbols are many and partially ordered . The sorted language can represent terminological knowledge as a sort- hierarchy and assertional knowledge as sorted formulas. However , the expression of sort-hierarchies cannot su#ciently capture the lexical diversity of terminological knowledge since hierarchical information exclusive of sorts is ignored in logical languages . The elements of terminological knowledge can be regarded as various kinds of symbols in logic: sorts , constants, functions and predicates , whereas the symbols are semantically separated from each other and merely used as components in formulas . From the viewpoint of symbolic knowledge representation , we require that the symbol names be semantically and hierarchically associated with each other , without losing their roles . To enrich hierarchical reasoning , Kaneiwa and Tojo 10) proposed an order-sorted logic with sort and predicate hierarchies , but the hierarchies did not enable complicated expressions combining di#erent kinds of symbols (e.g . father # parent as a subordinate relation of a function and a predicate). The aim of this paper is to provide a logical framework for consistently handling various hierarchies of symbol names (of sorts , constants , functions and predicates) and reasoning over them . We generalize an order-sorted logic by means of consisting of label-based expressions . A label-based language contains label-based terms and formulas and a label hierarchy , for representing assertional knowledge and terminological knowledge . Labels denote all the symbol names of constants , functions and predicates occurring in terms and formulas , and", "label": ["terminological knowledge", "label-based expressions", "order-sorted logic", "knowledge representation", "resolution system"], "stemmed_label": ["terminolog knowledg", "label-bas express", "order-sort logic", "knowledg represent", "resolut system"]}
{"doc": "Finding a good embedding of a unit disk graph given by its connectivity information is a problem of practical importance in a variety of fields . In wireless ad hoc and sensor networks , such an embedding can be used to obtain virtual coordinates . In this paper , we prove a non-approximability result for the problem of embedding a given unit disk graph . Particularly , we show that if non-neighboring nodes are not allowed to be closer to each other than distance 1 , then two neighbors can be as far apart as 3/2 - , where goes to 0 as n goes to infinity , unless P=NP . We further show that finding a realization of a d-quasi unit disk graph with d 1/2 is NP-hard . INTRODUCTION In a unit disk graph 4 , there is an edge between two nodes u and v if and only if the Euclidean distance between u and v is at most 1 . Equivalently , each node is identified with a disk of unit radius in the plane , and is connected to all nodes within (or on the edge of) its corresponding disk . Unit disk graphs have proven to be useful in modeling various physical real world problems . One prominent application of unit disk graphs can be found in the field of wireless networking , where a unit disk graph represents an idealized multi-hop radio network . Nodes are located in the Euclidean plane and are assumed to have identical (unit) transmission radii . They can communicate only if they are within mutual transmission range . Clearly , the unit disk graph model neatly captures this behavior and it is not surprising that it has become a standard when studying ad hoc and sensor networks. When modeling ad hoc and sensor networks as a unit disk graph , it seems plausible that the connectivity information of the network graph contains su#cient information in order to obtain topologically correct coordinate information. Such coordinate information , in turn , would serve a number of needs arising in many applications of ad hoc and sensor networks. To be more concrete , we are interested in assigning to each node a coordinate in the plane , such that nodes that are neighbors in the connectivity graph have at most Euclidean distance 1 in the plane , and nodes that are not neighbors in the connectivity graph have at least distance 1 . In other words , we would like to embed a given unit disk graph in the plane . Unfortunately , it can be shown that this is impossible in polynomial time unless In 3 , Breu and Kirkpatrick show that given a graph G , deciding whether G is a unit disk graph is NP -complete . Finding a realization of a unit disk graph , that is , finding an embedding which fulfils all unit disk graph constraints , can be polynomially reduced to the recognition problem of 3 by a straightforward re- duction . Assume there is an", "label": ["sensor networks", "unit disk graph", "ad hoc networks", "embedding", "virtual coordinates"], "stemmed_label": ["sensor network", "unit disk graph", "ad hoc network", "embed", "virtual coordin"]}
{"doc": "The checkability designed into the LSL (Larch shared language) is described , and two tools that help perform the checking are discussed . LP (the Larch power) is the principal debugging tool . Its design and development have been motivated primarily by work on LSL , but it also has other uses (e.g . reasoning about circuits and concurrent algorithms) . Because of these other uses , and because they also tend to use LP to analyze Larch interface specifications , the authors have tried not to make LP too LSL-specific . Instead , they have chosen to build a second tool , LSLC (the LSL checker) , to serve as a front-end to LP . LSLC checks the syntax and static semantics of LSL specifications and generates LP proof obligations from their claims . These proof obligations fall into three categories: consistency (that a specification does not contradict itself) , theory containment (that a specification has intended consequences) , and relative completeness (that a set of operators is adequately defined) . An extended example illustrating how LP is used to debug LSL specifications is presented . Introduction Proponents of formal specifications argue that the susceptibility of formal specifications to machine analysis and manipulation increases their value and reduces their cost . The Larch project 9 , 10 , 11 , 12 seeks to support this position by building and using tools that facilitate the construction of formal specifications for program modules. It is not sufficient for specifications to be precise; they should also accurately reflect the specifier's intentions . Without accuracy , precision is useless and misleading . Mistakes from many sources will crop up in specifications . Any practical methodology that relies on specifications must provide means for detecting and correcting their flaws , in short , for debugging them . Parsing and type-checking are useful and easy to do , but don't go far enough. On the other hand , we cannot prove the \"correctness\" of a specification , because there is no absolute standard against which to judge correctness . So we seek tools that will be helpful in detecting and localizing the kinds of errors that we commonly observe. The Larch style of specification emphasizes brevity and clarity rather than executability , so it is usually impossible to validate Larch specifications by testing . Instead , Larch allows specifiers to make precise claims about specifications-claims that , if true , can be verified at specification time . While verification cannot guarantee that a specification meets a specifier's intent , it is a powerful debugging technique; once we have removed the flaws it reveals , we have more confidence in the accuracy of a specification. The claims allowed in Larch specifications are undecidable in the general case , so it is impossible to build a tool that will automatically certify an arbitrary specification . However , it is feasible to build tools that assist specifiers in checking claims as they debug specifications. This paper describes how two such tools fit into our work on LSL , the Larch", "label": ["concurrent algorithms", "larch shared language specifications", "inference mechanisms", "static semantics", "theory containment", "design", "program debugging", "debugging", "larch power", "checkability", "development", "parallel programming", "formal specification", "consistency"], "stemmed_label": ["concurr algorithm", "larch share languag specif", "infer mechan", "static semant", "theori contain", "design", "program debug", "debug", "larch power", "checkabl", "develop", "parallel program", "formal specif", "consist"]}
{"doc": "Recent years have seen the growing popularity of multi-rate wireless network devices (e.g. , 802.11a cards) that can exploit variations in channel conditions and improve overall network throughput . Concurrently , rate adaptation schemes have been developed that selectively increase data transmissions on a link when it offers good channel quality . In this paper , we propose a Medium Access Diversity (MAD) scheme that leverages the benefits of rate adaptation schemes by aggressively exploiting multiuser diversity . The basic mechanism of MAD is to obtain instantaneous channel condition information from multiple receivers and selectively transmit data to a receiver that improves the overall throughput of the network , while maintaining temporal fairness among multiple data flows . We identify and address the challenges in the design and implementation of MAD's three phases: channel probing , data transmission , and receiver scheduling . We also use analytical models to examine the tradeoff between network performance improvement and overhead of channel probing , and derive an asymptotic performance bound for the receiver scheduling algorithms used by MAD . Results from the analysis and the extensive simulations demonstrate that , on average , MAD can improve the overall throughput of IEEE 802.11 wireless LANs by 50% as compared with the best existing rate adaptation scheme . INTRODUCTION The availability and low cost of 802.11 wireless networking products have encouraged a rapid growth in the deployment of wireless Local Area Networks (LANs) . They can extend access to wired intranets such as campus networks , as well as support broadband access to the Internet - particulary at \"hot spots\" . As the use of powerful portable computing devices (laptops , PDAs) with wireless LAN connectivity becomes common , the ability of wireless LANs to cater to large number of users having applications with high band-width requirements is increasingly important . The increasing appetite for bandwidth in wireless LANs has in turn spurred extensive research e#orts to provide high data rates at the physical (PHY) layer . However , the highest feasible rate is ultimately bounded by the channel signal to noise ra- tio , which is time-varying due to both slow and fast fading in mobile environments . This has encouraged the development of multi-rate adaptors , where the PHY layer data rate can e#ectively respond to wide variations in channel con- ditions; the di#erence between the lowest and highest data rates is expected to widen even further with emerging PHY layer technologies . This is evident by comparison of IEEE 802.11a 12 with legacy 802.11 standard 11 : the lowest data rate increased by a factor of 6 while the highest rate increased by a factor of 27 . The number of distinct data rates supported by PHY is increasing as well and the trend in next generation PHY technologies such as MIMO and Adaptive-Bit-Loading OFDM 8 is to provide wider , almost continuous range of data rates that can be tailored to the given channel quality. The multi-rate support at the PHY layer o#ers primitives for upper layers to respond in an agile", "label": ["medium access", "multiuser diversity", "scheduling", "wireless lan"], "stemmed_label": ["medium access", "multius divers", "schedul", "wireless lan"]}
{"doc": "This paper addresses the problems of counting proof-trees (as introduced by Venkateswaran and Tompa) and counting proof-circuits , a related but seemingly more natural question . These problems lead to a common generalization of straight-line programs which we call polynomial replacement systems PRSs . We contribute a classification of these systems and we investigate their complexity . Diverse problems falling within the scope of this study include , for example , counting proof-circuits and evaluating $\\ \\cup,+\\ $-circuits over the natural numbers . A number of complexity results are obtained , including a proof that counting proof-circuits is $\\numP$-complete . Introduction 1.1 Motivation g3 When and \\Theta replace and \" in the adjacent figure , the gate g 1 on input evaluates to 9 . Equivalently , the tree-like Boolean circuit T obtained from the circuit drawn has 9 proof trees VT89 , i.e . 9 different minimal subcircuits witnessing that T outputs 1 (gates replicated to form T are independent) . This relationship between proof tree counting and monotone arithmetic circuits was used by Venkateswaran Ven92 to characterize nondeterministic time classes , including #P Val79 , and by Vinay Vin91a to characterize the counting version of LOGCFL Sud78 . The same relationship triggered the investigation of #NC 1 by Caussinus et al . CMTV98 , and that of #AC 0 by Allender et al . AAD97 . See AML98 , L\"eT98 , All98 for recent results and for motivation to study such \"small\" arithmetic classes. A recent goal has been to capture small arithmetic classes by counting objects other than proof trees , notably paths in graphs . Allender et al . AAB succeeded in identifying appropriate graphs for #AC 0 . Our early motivation for the present work was the desire to avoid unwinding circuits into trees before counting their \"proofs\" . Define a proof circuit to be a minimal subcircuit witnessing that a circuit outputs 1 . More precisely , for a Boolean circuit C and an input x , a proof circuit is an edge-induced connected subcircuit of C which evaluates to 1 on x . This subcircuit must contain the output gate of C , as well as exactly one C-edge into each -gate and all C-edges Informatique et recherche op'erationnelle , Universit'e de Montr'eal , C.P . 6128 , Succ . Centre-Ville , Montr'eal (Qu'ebec) , H3C 3J7 Canada . Research performed in part while on leave at the Universitat Tubingen . Supported by the (German) DFG , the (Canadian) NSERC and the (Qu'ebec) FCAR . mckenzie@iro.umontreal.ca y Theoretische Informatik , Universitat Wurzburg , Am Exerzierplatz 3 , 97072 Wurzburg , Germany . Research supported by Northern Telecom . vollmer@informatik.uni-wuerzburg.de z Theoretische Informatik , Universitat Wurzburg , Am Exerzierplatz 3 , 97072 Wurzburg , Germany . Research supported by DFG , grant Wa 847/1-2 . wagner@informatik.uni-wuerzburg.de into each \"-gate . The reader should convince herself that the circuit depicted above , which had 9 proof trees on input x proof circuits on that input. What counting classes arise from counting proof circuits instead of trees? This", "label": ["counting classes", "arithmetic circuit", "computational complexity"], "stemmed_label": ["count class", "arithmet circuit", "comput complex"]}
{"doc": "In this paper we consider the problem of testing bipartiteness of general graphs . The problem has previously been studied in two models , one most suitable for dense graphs and one most suitable for bounded-degree graphs . Roughly speaking , dense graphs can be tested for bipartiteness with constant complexity , while the complexity of testing bounded-degree graphs is $\\tilde \\Theta (\\sqrt n )$ , where $n$ is the number of vertices in the graph (and $\\tilde \\Theta (f(n))$ means $\\Theta(f(n)\\cdot \\rm polylog (f(n)))$) . Thus there is a large gap between the complexity of testing in the two cases.In this work we bridge the gap described above . In particular , we study the problem of testing bipartiteness in a model that is suitable for all densities . We present an algorithm whose complexity is $\\tilde O (\\min(\\sqrt n ,n^2/m))$ , where $m$ is the number of edges in the graph , and we match it with an almost tight lower bound . Introduction Property testing algorithms 16 , 8 are algorithms that perform approximate decisions. Namely , for a predetermined property P they should decide whether a given object O has property P or is far from having property P . In order to perform this approximate decision they are given query access to the object O . Property testing problems are hence defined by the type of objects in question , the property tested , the type of queries allowed , and the notion of distance to having a property . Much of the focus of property testing has been on testing properties of graphs . In this context several models have been considered . In all models , for a fixed graph property P , the algorithm is required to accept graphs that have P and to reject graphs that are -far from having P , for a given distance parameter . In all cases the algorithm is allowed a constant probability of failure . The models differ in the type of queries they allow and in the notion of distance they use (which underlies the definition of being -far from having the property) . The complexity of the algorithm is measured by the number of queries to the object Q it performs. 1.1 Models for Testing Graph Properties The first model , introduced in 8 , is the adjacency-matrix model . In this model the algorithm may perform queries of the form: \"Is there an edge between vertices u and v This work is part of the author's Ph.D . thesis prepared at Tel Aviv University under the supervision of Prof . Noga Alon , and Prof . Michael Krivelevich. ?? E-mail: krivelev@post.tau.ac.il. Research supported by the Israel Science Foundation (grant number in the graph?\" That is , the algorithm may probe the adjacency matrix representing the graph . We refer to such queries as vertex-pair queries . The notion of distance is also linked to this representation: a graph is said to be -far from having property P if more than modifications should be performed", "label": ["bipartiteness", "property testing", "randomized algorithms"], "stemmed_label": ["bipartit", "properti test", "random algorithm"]}
{"doc": "Sparse Gaussian elimination with partial pivoting computes the factorization of a sparse matrix A , where the row ordering P is selected during factorization using standard partial pivoting with row interchanges . The goal is to select a column preordering , Q , based solely on the nonzero pattern of A , that limits the worst-case number of nonzeros in the factorization . The fill-in also depends on P , but Q is selected to reduce an upper bound on the fill-in for any subsequent choice of P . The choice of Q can have a dramatic impact on the number of nonzeros in L and U . One scheme for determining a good column ordering for A is to compute a symmetric ordering that reduces fill-in in the Cholesky factorization of ATA . A conventional minimum degree ordering algorithm would require the sparsity structure of ATA to be computed , which can be expensive both in terms of space and time since ATA may be much denser than A . An alternative is to compute Q directly from the sparsity structure of A; this strategy is used by MATLAB's COLMMD preordering algorithm . A new ordering algorithm , COLAMD , is presented . It is based on the same strategy but uses a better ordering heuristic . COLAMD is faster and computes better orderings , with fewer nonzeros in the factors of the matrix . Introduction Sparse Gaussian elimination with partial pivoting computes the factorization for the sparse nonsymmetric matrix A , where P and Q are permutation matrices , L is a lower triangular matrix , and U is an upper triangular matrix . Gilbert and Peierls 30 have shown that sparse partial pivoting can be implemented in time proportional to the number of point operations required . The method is used by Matlab when solving a system of linear equations when A is sparse 27 . An improved implementation is in a sparse matrix package , SuperLU 11 . The solution process starts by nding a sparsity-preserving permutation Q . Next , the permutation P is selected during numerical factorization using standard partial pivoting with row interchanges . The permutation P is selected without regard to sparsity . Our goal is to compute a sparsity-preserving permutation Q solely from the pattern of A such that the LU factorization remains as sparse as possible , regardless of the subsequent choice of P . Our resulting code has been incorporated in SuperLU and in Matlab Version 6. Section 2 provides the theoretical background for our algorithm . In Section 3 , we describe symbolic LU factorization (with no column interchanges) as a precursor to the colamd ordering algorithm presented in Section 4 . Section 4 also describes the various metrics for selecting columns that we evaluated in the design of the code . Experimental results for square nonsymmetric matrices , rectangular matrices , and symmetric matrices are presented in Section 5 . Section 6 presents our conclusions , and describes how to obtain the colamd and symamd codes. Our notation is", "label": ["sparse nonsymmetric matrices", "ordering methods", "linear equations"], "stemmed_label": ["spars nonsymmetr matric", "order method", "linear equat"]}
{"doc": "Given an undirected graph with edge costs and a subset ofk=3 nodes calledterminals , a multiway , ork-way , cut is a subset of the edges whose removal disconnects each terminal from the others . The multiway cut problem is to find a minimum-cost multiway cut . This problem is Max-SNP hard . Recently , Calinescu et al . (Calinescu , G. , H . Karloff , Y . Rabani . 2000 . An improved approximation algorithm for Multiway Cut.J . Comput . System Sci.60(3) 564--574) gave a novel geometric relaxation of the problem and a rounding scheme that produced a (3/2-1/ k)-approximation algorithm.In this paper , we study their geometric relaxation . In particular , we study the worst-case ratio between the value of the relaxation and the value of the minimum multicut (the so-called integrality gap of the relaxation) . Fork=3 , we show the integrality gap is 12/11 , giving tight upper and lower bounds . That is , we exhibit a family of graphs with integrality gaps arbitrarily close to 12/11 and give an algorithm that finds a cut of value 12/11 times the relaxation value . Our lower bound shows that this is the best possible performance guarantee for any algorithm based purely on the value of the relaxation . Our upper bound meets the lower bound and improves the factor of 7/6 shown by Calinescu et al.For allk , we show that there exists a rounding scheme with performance ratio equal to the integrality gap , and we give explicit constructions of polynomial-time rounding schemes that lead to improved upper bounds . Fork=4 and 5 , our best upper bounds are based on computer-constructed rounding schemes (with computer proofs of correctness) . For generalk we give an algorithm with performance ratio 1.3438-e k .Our results were discovered with the help of computational experiments that we also describe here . Introduction As the field of approximation algorithms matures , methodologies are emerging that apply broadly to many NP-hard optimization problems . One such approach (e.g. , 7, has been the use of metric and geometric embeddings in addressing graph optimization problems. Faced with a discrete graph optimization problem , one formulates a relaxation that maps each graph node into a metric or geometric space , which in turn induces lengths on the graph's edges . One solves this relaxation opti- mally , and then derives from the relaxed solution a near-optimal solution to the original problem. This approach has been applied successfully 2 to the min-cost multiway cut problem , a natural generalization of the minimum (s , t)-cut problem to more than two terminals . An instance consists of a graph with edge- costs and a set of distinguished nodes (the terminals). The goal is to find a minimum-cost set of edges whose removal separates the terminals . If the number of terminals is k , we call such a set of edges a k-way cut. The first approximation algorithm for the multiway cut problem in general graphs was given by Dahlhous, Johnson , Papadimitriou ,", "label": ["multiway cut", "approximation algorithm"], "stemmed_label": ["multiway cut", "approxim algorithm"]}
{"doc": "We consider the following integer feasibility problem: Given positive integer numbersa0,a1 , .. . , a n , with gcd( a1,... , a n does there exist a vectorx?Z n =0satisfyinga x= a0? We prove that if the coefficientsa1,... , a nhave a certain decomposable structure , then the Frobenius number associated witha1,... , a n , i.e. , the largest value ofa0 for whicha x= a0 does not have a nonnegative integer solution , is close to a known upper bound . In the instances we consider , we takea0 to be the Frobenius number . Furthermore , we show that the decomposable structure ofa1,... , a nmakes the solution of a lattice reformulation of our problem almost trivial , since the number of lattice hyperplanes that intersect the polytope resulting from the reformulation in the direction of the last coordinate is going to be very small . For branch-and-bound such instances are difficult to solve , since they are infeasible and have large values ofa0/ a i , 1= i= n . We illustrate our results by some computational examples . Introduction 1.1 Problem Statement and Summary of Results In the past decade there has been substantial progress in computational integer programming . Many large and complex instances can now be solved. There are , however , still many small instances that seem extremely hard to tackle by standard methods such as branch-and-bound or branch-and- cut , and it is still quite unclear what makes these instances so hard . Examples are the so-called market share problems , Cornu'ejols and Dawande (1999) , and Aardal et al . (2000a) , some feasibility problems reported on by Aardal et al . (2000b) , and certain portfolio planning problems , Louveaux and Wolsey (2000) . All of these are related to the following simple problem. Let a 0 ; a a n be positive integer numbers with a The problem is: Does P contain an integer vector? (2) If the components of x may take any integer value , then the problem is easy . There exists a vector x 2 Z n satisfying only if a 0 is an integer multiple of gcd(a The non-negativity requirement on x makes the problem NP-complete . In this study we focus on infeasible instances to rule out that a search algorithm terminates fast because it found a feasible solution by luck . The largest value of a 0 such that the instance of (2) given by the input a is infeasible is called the Frobenius number of a denoted by F (a Infeasible instances with large ratios a 0 =a hard for branch-and-bound . In this context we address two topics. The first one is to provide a sufficient explanation why certain coefficients will yield large Frobenius numbers than others of comparable sizes . In Theorem 1 we demonstrate that the Frobenius number is relatively large if it is possible to decompose the a-coefficients as a large compared to i and jr i j. This leads to the second topic: we give a sufficient", "label": ["lattice basis reduction", "frobenius number", "branching on hyperplanes"], "stemmed_label": ["lattic basi reduct", "frobeniu number", "branch on hyperplan"]}
{"doc": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects . Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager . The basic idea is to represent an object by a collection of parts arranged in a deformable configuration . The appearance of each part is modeled separately , and the deformable configuration is represented by spring-like connections between pairs of parts . These models allow for qualitative descriptions of visual appearance , and are suitable for generic recognition problems . We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples , presenting efficient algorithms in both cases . We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images . Introduction Research in object recognition is increasingly concerned with the ability to recognize generic classes of objects rather than just specific instances . In this paper , we consider both the problem of recognizing objects using generic part-based models and the problem of learning such models from example images . Our work is motivated by the pictorial structure representation introduced by Fischler and Elschlager 16 (a) (b) Figure 1: Sample results for detection of a face (a); and a human body (b) . Each image shows the globally best location for the corresponding object , as computed by our algorithms . The object models were learned from training examples. thirty years ago , where an object is modeled by a collection of parts arranged in a deformable configuration . Each part encodes local visual properties of the object, and the deformable configuration is characterized by spring-like connections between certain pairs of parts . The best match of such a model to an image is found by minimizing an energy function that measures both a match cost for each part and a deformation cost for each pair of connected parts. While the pictorial structure formulation is appealing in its simplicity and gener- ality , several shortcomings have limited its use: (i) the resulting energy minimization problem is hard to solve e#ciently , (ii) the model has many parameters , and (iii) it is often desirable to find more than a single best (minimum energy) match . In this paper we address these limitations , providing techniques that are practical for a broad range of object recognition problems . We illustrate the method for two quite di#erent generic recognition tasks , finding faces and finding people . For faces , the parts are features such as the eyes , nose and mouth , and the spring-like connections allow for variation in the relative locations of these features . For people , the parts are the limbs , torso and head , and the spring-like connections allow for articulation at the joints . Matching results with these two models are illustrated in Figure 1. The main contributions", "label": ["energy minimization", "part-based object recognition", "statistical models"], "stemmed_label": ["energi minim", "part-bas object recognit", "statist model"]}
{"doc": "We study here a natural situation when constraint programming can be entirely reduced to rule-based programming . To this end we explain first how one can compute on constraint satisfaction problems using rules represented by simple first-order formulas . Then we consider constraint satisfaction problems that are based on predefined , explicitly given constraints . To solve them we first derive rules from these explicitly given constraints and limit the computation process to a repeated application of these rules , combined with labeling . We consider two types of rule here . The first type , that we call equality rules , leads to a new notion of local consistency , called rule consistency that turns out to be weaker than arc consistency for constraints of arbitrary arity (called hyper-arc consistency in Marriott & Stuckey (1998)) . For Boolean constraints rule consistency coincides with the closure under the well-known propagation rules for Boolean constraints . The second type of rules , that we call membership rules , yields a rule-based characterization of arc consistency . To show feasibility of this rule-based approach to constraint programming , we show how both types of rules can be automatically generated , as CHR rules of Frhwirth (1995) . This yields an implementation of this approach to programming by means of constraint logic programming . We illustrate the usefulness of this approach to constraint programming by discussing various examples , including Boolean constraints , two typical examples of many valued logics , constraints dealing with Waltz's language for describing polyhedral scenes , and Allen's qualitative approach to temporal logic . Introduction 1.1 Background This paper is concerned with two styles of programming: constraint programming and rule-based programming. In constraint programming the programming process is limited to a generation Krzysztof R . Apt and Eric Monfroy of constraints and a solution of the so obtained constraint satisfaction problems (CSP's) by general or domain dependent methods. In rule-based programming the programming process consists of a repeated application of rules . A theoretical basis for this programming paradigm consists of so-called production rules that were introduced in the seventies , see , e.g. , (Luger 1998) pages 171-186 , though the idea goes back to the works of A . Thue and of E . Post in first half of twentieth century . The production rules are condition-action pairs , where the condition part is used to determine whether the rule is applicable and the action part defines the action to be taken . The most known programming language built around this programming paradigm was OPS5 of (Forgy , 1981). Recently , there has been a revival of interest in rule-based programming in the context of constraint programming . The earliest example is the CHR language of (Fr-uhwirth , 1995) that is a part of the ECL i PS e system . (For a more recent and more complete overview of CHR see (Fr-uhwirth , 1998).) The CHR rules extend the syntax of constraint logic programming by allowing two atoms in the conclusion and employing guards . These rules", "label": ["constraint programming", "rule-based programming", "finite domain"], "stemmed_label": ["constraint program", "rule-bas program", "finit domain"]}
{"doc": "We present a prescriptive type system with parametric polymorphism and subtyping for constraint logic programs . The aim of this type system is to detect programming errors statically . It introduces a type discipline for constraint logic programs and modules , while maintaining the capabilities of performing the usual coercions between constraint domains , and of typing meta-programming predicates , thanks to the exibility of subtyping . The property of subject reduction expresses the consistency of a prescriptive type system w.r.t . the execution model: if a program is well-typed , then all derivations starting from a well-typed goal are again well-typed . That property is proved w.r.t . the abstract execution model of constraint programming which proceeds by accumulation of constraints only , and w.r.t . an enriched execution model with type constraints for substitutions . We describe our implementation of the system for type checking and type inference . We report our experimental results on type checking ISO-Prolog , the (constraint) libraries of Sicstus Prolog and other Prolog programs . Introduction The class CLP(X ) of Constraint Logic Programming languages was introduced by Jaar and Lassez (Jaar & Lassez , 1987) as a generalization of the innovative features introduced by Colmerauer in Prolog II (Colmerauer , 1984; Colmerauer, namely computing in Prolog with other structures than the Herbrand terms, with inequality constraints and with co-routining. Inherited from the Prolog tradition , CLP(X ) programs are untyped . Usually the structure of interest X is however a quite complex combination of basic structures that may include integer arithmetic , real arithmetic , booleans , lists , Herbrand terms , innite terms , etc . with implicit coercions between constraint domains like in Prolog IV (Colmerauer , 1996) . Even the early CLP(R) system of (Jaar & Lassez , 1987) already combines Herbrand terms with arithmetic expressions in a non-symmetrical way: any arithmetic expression may appear under a Herbrand function symbol , e.g . in a list , but not the other way around . The framework of many sorted logic in (Jaar & Lassez , 1987) is not adequate for representing the type system underlying such a combination , as it forces Herbrand function symbols Francois Fages and Emmanuel Coquery to have a unique type (e.g . over reals or Herbrand terms) , whereas Herbrand functions can be used polymorphically , e.g . in f(1) and f(f(1)) , or the list constructor in a list of list of numbers 3 . The type system of Mycroft-O'Keefe (Mycroft & O'Keefe , 1984; Lakshman & Reddy , 1991; Hill & Topor , 1992) is an adaptation to logic programming of the rst type system with parametric polymorphism , that was introduced by Damas- Milner for the functional programming language ML . In this system , types are rst- order terms , type variables inside types , like in list() , express type parameters. Programs dened over a data structure of type list() can be used polymorphically over any homogeneous list of elements of some type . Such a type system for Prolog is", "label": ["metaprogramming", "type systems", "prolog", "constraint logic programming", "subtyping"], "stemmed_label": ["metaprogram", "type system", "prolog", "constraint logic program", "subtyp"]}
{"doc": "In existing simulation proof techniques , a single step in a lower-level specification may be simulated by an extended execution fragment in a higher-level one . As a result , it is cumbersome to mechanize these techniques using general-purpose theorem provers . Moreover , it is undecidable whether a given relation is a simulation , even if tautology checking is decidable for the underlying specification logic . This article studies various types of i normed simulations /i . In a normed simulation , each step in a lower-level specification can be simulated by at most one step in the higher-level one , for any related pair of states . In earlier work we demonstrated that normed simulations are quite useful as a vehicle for the formalization of refinement proofs via theorem provers . Here we show that normed simulations also have pleasant theoretical properties: (1) under some reasonable assumptions , it is decidable whether a given relation is a normed forward simulation , provided tautology checking is decidable for the underlying logic; (2) at the semantic level , normed forward and backward simulations together form a complete proof method for establishing behavior inclusion , provided that the higher-level specification has finite invisible nondeterminism . Introduction Simulation relations and renement functions are widely used to prove that a lower-level specica- tion of a reactive system correctly implements a higher-level one; see AL91 , LV95 , Lyn96 , RE98 for overviews and numerous references to applications . Technically , a simulation (or renement) is a relation (or function) R between the states of a lower-level specication A and a higher-level specication B , that satises a condition like (If lower-level state s and higher-level state u are related , and in A there is a transition from s to t , then there is a matching transition in B from u to a state v that relates to t; see also Figure 1.) The existence of a simulation implies that any behavior of A can also be exhibited by B. a a Figure 1: Transfer condition (1). The main reason why simulations are useful is that they reduce global reasoning about behaviors and executions to local reasoning about states and transitions . However , to the best of our knowledge , all complete simulation proof methods that appear in the literature fall back on some form of global reasoning in the case of specications containing internal (or stuttering) transitions. The usual transfer condition for forward simulations LV95 , for instance , says (Each lower-level transition can be simulated by a sequence of higher-level transitions which , apart from the action that has to be matched , may also contain an arbitrary number of internal \\\" transitions; see also Figure 2.) Thus the research program to reduce global reasoning to local reasoning has not been carried out to its completion . In manual proofs of simulation relations, a a a Figure 2: Transfer condition (2). this is usually not a problem: in practice lower-level transitions are typically matched by at most one higher-level transition; moreover", "label": ["automata", "computer-aided verification", "prophecy variables", "forward simulations", "normed simulations", "refinement mappings", "backward simulations", "history variables"], "stemmed_label": ["automata", "computer-aid verif", "propheci variabl", "forward simul", "norm simul", "refin map", "backward simul", "histori variabl"]}
{"doc": "In this paper , we analyze the node spatial distribution of mobile wireless ad hoc networks . Characterizing this distribution is of fundamental importance in the analysis of many relevant properties of mobile ad hoc networks , such as connectivity , average route length , and network capacity . In particular , we have investigated under what conditions the node spatial distribution resulting after a large number of mobility steps resembles the uniform distribution . This is motivated by the fact that the existing theoretical results concerning mobile ad hoc networks are based on this assumption . In order to test this hypothesis , we performed extensive simulations using two well-known mobility models: the random waypoint model , which resembles intentional movement , and a Brownian-like model , which resembles nonintentional movement . Our analysis has shown that in Brownian-like motion the uniformity assumption does hold , and that the intensity of the concentration of nodes in the center of the deployment region that occurs in the random waypoint model heavily depends on the choice of some mobility parameters . For extreme values of these parameters , the uniformity assumption is impaired . INTRODUCTION ad hoc networks have received increasing interest in the scientic community in recent years . However, due to their complex and unstructured nature , very few analytical results describing their fundamental properties have been derived . Among them , the most notable concern the connectivity and coverage problems for stationary networks, which have been analyzed in 10 , 20 . A common assumption in these studies is that nodes are distributed in a given area according to a probability distribution; the value of the node transmitting range ensuring a connected network (or coverage of the deployment area) with high probability is then derived . Another important theoretical result for stationary ad hoc networks is presented in 11 , where it is shown that the capacity of the network does not scale with its size. If deriving analytical results for stationary networks is dif- cult , even more challenging is deriving theoretical results regarding mobile ad hoc networks . This has been done , for example , in 9 , where it is shown that , contrary to the stationary case , the capacity of mobile ad hoc networks can actually scale with the size . Less general analytical results for mobile networks have been derived in 1 , 17 , where two variations of the DSR routing protocol are evaluated in a theoretical framework. As in the case of stationary networks , these results rely on some assumptions on the node spatial distribution , which are designed to simplify the analysis . In particular , in 1, 9 it is assumed that: 1 . (uniformity assumption) in any snapshot of the mobile network the nodes are distributed uniformly and independently at random in the deployment area; 2 . (independence assumption) dierent snapshots are independent . With these hypotheses , a mobile network composed by n nodes performing N mobility steps can be modeled as N independent experiments ,", "label": ["mobility modeling", "mobile ad hoc networks", "random waypoint model", "node spatial distribution"], "stemmed_label": ["mobil model", "mobil ad hoc network", "random waypoint model", "node spatial distribut"]}
{"doc": "The proliferation of new data-intensive applications in asymmetric communication environments has led to an increasing interest in the development of push-based techniques , in which the information is broadcast to a large population of clients in order to achieve the most efficient use of the limited server and communication resources . It is important to note that quite often the data that is broadcast is time-critical in nature . Most of the related current research focuses on a pure push-based approach (Broadcast Disks model) , where the transmission of data is done without allowing explicit requests from the users . More recently , some bidirectional models incorporating a low-capacity uplink channel have been proposed in order to increase the functionality of the Broadcast Disks model . However , the impact of integration of the uplink channel has been investigated using only static client profiles or ignoring the existence of time-sensitive data . None of the existing models integrates all the characteristics needed to perform effectively in a real-world , dynamic time-critical asymmetric communication environment . In this paper we present an adaptive data dissemination model and the associated on-line scheduling algorithms . These improve the functionality and performance of bidirectional broadcast models , maximizing the total number of satisfied users in asymmetric communication environments with dynamic client profiles and time requirements (e.g. , mobile systems) . This is achieved by means of dynamic adaptation of the broadcast program to the needs of the users , taking into account the bandwidth constraints inherent in asymmetric communication environments and the deadline requirements of the user requests . Performance is evaluated by simulation of a real-time asymmetric communication environment Introduction There is a growing need for information servers with capabilities to handle large amounts of information accessed by a potentially unlimited number of users in asymmetric communication environments (e.g. , traffic information , stock quotes , weather , news) . The volume of information transmitted from the server to the users is much larger than the volume of information transmitted from the users to the server in such environments . In most cases , the users require the information by a certain time , and therefore , an adequate model should integrate the ability to serve information with deadline constraints associated with the requests of the data . We will refer to these as time-critical asymmetric communication environments . For example , let us consider a traffic information server and the driver of a vehicle who , at some point ahead in the road , needs to take one of two possible routes in order to get to her destination . Obviously , it is necessary for the server to provide the driver with the desired traffic information (for example, one of the routes is congested because there has been an accident) before the decision point is reached , otherwise the information has no value for the driver. One way to try to meet the needs of such applications is to use the classic client/server model. Unfortunately , it suffers from a lack of scalability", "label": ["asymmetric communication", "time-critical data", "push-based techniques", "scheduling", "broadcast data dissemination"], "stemmed_label": ["asymmetr commun", "time-crit data", "push-bas techniqu", "schedul", "broadcast data dissemin"]}
{"doc": "A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps , regardless of the execution speeds of the other processes . The problem of constructing a wait-free implementation of one data object from another lies at the heart of much recent work in concurrent algorithms , concurrent data structures , and multiprocessor architectures . First , we introduce a simple and general technique , based on reduction to a concensus protocol , for proving statements of the form , there is no wait-free implementation of X by Y . We derive a hierarchy of objects such that no object at one level has a wait-free implementation in terms of objects at lower levels . In particular , we show that atomic read/write registers , which have been the focus of much recent attention , are at the bottom of the hierarchy: thay cannot be used to construct wait-free implementations of many simple and familiar data types . Moreover , classical synchronization primitives such astest&set and fetch&add , while more powerful than read and write , are also computationally weak , as are the standard message-passing primitives . Second , nevertheless , we show that there do exist simple universal objects from which one can construct a wait-free implementation of any sequential object . Introduction A concurrent object is a data structure shared by concurrent processes . Algorithms for implementing concurrent objects lie at the heart of many important problems in concurrent systems . The traditional approach to implementing such objects centers around the use of critical sections: only one process at a time is allowed to operate on the object . Nevertheless , critical sections are poorly suited for asynchronous , fault-tolerant systems: if a faulty process is halted or delayed in a critical section , non-faulty processes will also be unable to progress . Even in a failure-free system , a process can encounter unexpected delay as a result of a page fault or cache miss , by exhausting its scheduling quantum , or if it is swapped out . Similar problems arise in heterogeneous architectures , where some processors may be inherently faster than others , and some memory locations may be slower to access. A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps , regardless of the execution speeds of the other processes . The wait-free condition provides fault-tolerance: no process can be prevented from completing an operation by undetected halting failures of other processes , or by arbitrary variations in their speed . The fundamental problem of wait-free synchronization can be phrased as follows: Given two concurrent objects X and Y , does there exist a wait-free implementation of X by Y? It is clear how to show that a wait-free implementation exists: one displays it . Most of the current literature takes this approach . Examples include \"atomic\" registers from non-atomic \"safe\" registers 19 , complex", "label": ["wait-free synchronization", "linearization"], "stemmed_label": ["wait-fre synchron", "linear"]}
{"doc": "We introduce a short signature scheme based on the Computational DiffieHellman assumption on certain elliptic and hyperelliptic curves . For standard security parameters , the signature length is about half that of a DSA signature with a similar level of security . Our short signature scheme is designed for systems where signatures are typed in by a human or are sent over a low-bandwidth channel . We survey a number of properties of our signature scheme such as signature aggregation and batch verification . Introduction Short digital signatures are needed in environments with strong bandwidth constraints . For ex- ample , product registration systems often ask users to key in a signature provided on a CD label. When a human is asked to type in a digital signature , the shortest possible signature is needed. Similarly , due to space constraints , short signatures are needed when one prints a bar-coded digital signature on a postage stamp 41 , 37 . As a third example , consider legacy protocols that allocate a xed short eld for non-repudiation 1 , 25 . One would like to use the most secure signature that ts in the alloted eld length. The two most frequently used signatures schemes , RSA and DSA , produce relatively long signatures compared to the security they provide . For example , when one uses a 1024-bit modulus, RSA signatures are 1024 bits long . Similarly , when one uses a 1024-bit modulus , standard DSA signatures are 320 bits long . Elliptic curve variants of DSA , such as ECDSA , are also 320 bits long 2 . A 320-bit signature is too long to be keyed in by a human. We propose a signature scheme whose length is approximately 170 bits and which provides a level of security similar to that of 320-bit DSA signatures . Our signature scheme is secure against existential forgery under a chosen-message attack (in the random oracle model) assuming the Computational Di-e-Hellman problem (CDH) is hard on certain elliptic curves over a nite eld . Generating a signature is a simple multiplication on the curve . Verifying the signature is done using a bilinear pairing on the curve . Our signature scheme inherently uses properties of curves. Consequently , there is no equivalent of our scheme in F . Constructing short signatures is an old problem . Several proposals show how to shorten DSA while preserving the same level of security . Naccache and Stern 37 propose a variant of DSA where the signature length is approximately 240 bits . Mironov 35 suggests a DSA variant with a similar length and gives a concrete security analysis of the construction (in the random oracle model) . Another technique proposed for reducing DSA signature length is signatures with message recovery 38 , 41 . In such systems one encodes a part of the message into the signature thus This is the full version of a paper that appeared in Asiacrypt '01 12 . y Supported by NSF and the Packard Foundation. shortening the total length of", "label": ["short signatures", "digital signatures", "bilinear maps", "elliptic curves", "pairings"], "stemmed_label": ["short signatur", "digit signatur", "bilinear map", "ellipt curv", "pair"]}
{"doc": "We propose a formal framework for the security analysis of on-demand source routing protocols for wireless ad hoc networks . Our approach is based on the well-known simulation paradigm that has been proposed to prove the security of cryptographic protocols . Our main contribution is the application of the simulation-based approach in the context of ad hoc routing . This involves a precise definition of a real-world model , which describes the real operation of the protocol , and an ideal-world model , which captures what the protocol wants to achieve in terms of security . Both models take into account the peculiarities of wireless communications and ad hoc routing . Then , we give a formal definition of routing security in terms of indistinguishability of the two models from the point of view of honest parties . We demonstrate the usefulness of our approach by analyzing two \"secure\" ad hoc routing protocols , SRP and Ariadne . This analysis leads to the discovery of as yet unknown attacks against both protocols . Finally , we propose a new ad hoc routing protocol and prove it to be secure in our model . Introduction Routing is one of the most basic networking functions in mobile ad hoc networks . Hence , an adversary can easily paralyze the operation of the network by attacking the routing protocol . This has been realized by many researchers , and several \"secure\" routing protocols have been proposed for ad hoc networks (see 11 for a survey) . However , the security of those protocols have been analyzed either by informal means only , or with formal methods that have never been intended for the analysis of this kind of protocols . In this paper , we present a new attack on Ariadne , a previously published \"secure\" routing protocol 8 . Other attacks can be found in 4 . These attacks clearly demonstrate that flaws can be very subtle , and therefore , hard to discover by informal reasoning . Hence , we advocate a more systematic approach to analyzing ad hoc routing protocols , which is based on a rigorous mathematical model , in which precise definitions of security can be given , and sound proof techniques can be developed. Routing has two main functions: route discovery and packet forwarding . The former is concerned with discovering routes between nodes , whereas the latter is about sending data packets through the previously discovered routes . There are different types of ad hoc routing protocols . One can distinguish proactive (e.g. , OLSR 5 ) and reactive (e.g. , AODV 17 and DSR 12 ) protocols . Protocols of the latter category are also called on-demand protocols . Another type of classification distinguishes routing table based protocols (e.g. , AODV) and source routing protocols (e.g. , DSR) . In this paper, we focus on the route discovery part of on-demand source routing protocols , but we believe that the general principles of our approach are applicable to the route discovery part of other types of protocols", "label": ["ad hoc networks", "provable security", "routing protocols", "on-demand source routing", "simulatability"], "stemmed_label": ["ad hoc network", "provabl secur", "rout protocol", "on-demand sourc rout", "simulat"]}
{"doc": "Anonymity networks have long relied on diversity of node location for protection against attacks---typically an adversary who can observe a larger fraction of the network can launch a more effective attack . We investigate the diversity of two deployed anonymity networks , Mixmaster and Tor , with respect to an adversary who controls a single Internet administrative domain . Specifically , we implement a variant of a recently proposed technique that passively estimates the set of administrative domains (also known as autonomous systems , or ASes) between two arbitrary end-hosts without having access to either end of the path . Using this technique , we analyze the AS-level paths that are likely to be used in these anonymity networks . We find several cases in each network where multiple nodes are in the same administrative domain . Further , many paths between nodes , and between nodes and popular endpoints , traverse the same domain . INTRODUCTION Anonymity networks aim to provide communications privacy for individuals or groups on the Internet , but these networks are still vulnerable to powerful eavesdroppers . A variety of organizations, ranging from corrupt law enforcement to curious ISPs , can passively observe large pieces of the Internet . Against high-latency mix networks such as Mixmaster 27 , an adversary who observes a large volume of network traffic can notice over time that certain recipients are more likely to receive messages after particular senders have transmitted messages 15 , 26 . Low-latency networks like Onion Routing 18 , 31 are more directly vulnerable: an eaves- Permission to make digital or hard copies of all or part o f this work for personal or classroom use is granted without fee provided that c opies are not made or distributed for profit or commercial advantage and that co pies bear this notice and the full citation on the first page . To copy otherwis e , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. October 28 , 2004 , Washington , DC , USA. dropper on both ends of the connection can quickly link sender to recipient through packet counting or timing attacks 16 , 23 , 35 . Anonymity designs use three strategies to mitigate these attacks. Batching and pooling: The network collects a group of input messages and reorders them before they exit , to hinder the adversary from learning which message in the batch originated from a given sender 12 , 34 . Padding: Senders provide decoy traffic as well as normal traffic to complicate the adversary's attempts to correlate sender and receiver 8 , 14 , 23 . Dispersal: Reducing the chance that the adversary sees both endpoints for a given communication may entirely block some attacks on low-latency networks , and slow intersection attacks on high-latency networks. Dispersal can be achieved by increasing the number of nodes in the network so an adversary of a given strength sees less of the net-work 1 , 6 , 33 ; by arranging the overlay", "label": ["interdomain routing", "mix networks", "anonymity"], "stemmed_label": ["interdomain rout", "mix network", "anonym"]}
{"doc": "In 1998 , Asperti and Mairson proved that the cost of reducing a -term using an optimal -reducer (a la Lvy) cannot be bound by any elementary function in the number of shared-beta steps . We prove in this paper that an analogous result holds for Lamping's abstract algorithm . That is , there is no elementary function in the number of shared beta steps bounding the number of duplication steps of the optimal reducer . This theorem vindicates the oracle of Lamping's algorithm as the culprit for the negative result of Asperti and Mairson . The result is obtained using as a technical tool Elementary Affine Logic . Introduction In the last ten years there has been a steady interest in optimal reduction of -terms (or , more generally , of functional programs) . The very story started , in fact , more than twenty years ago , with Jean-Jacques Levy's thesis Lev78 . The problem he attacked was to nd an execution strategy for -terms minimizing the number of -reductions . It was already known that no such strategy exists which reduces only one redex (i.e. , a single function call) at the time . Levy's insight was to discover that a parallel optimal strategy exists, the one reducing in a single step all the redexes belonging to the same family , a crucial notion he introduced . However, Levy lacked the programming technology to implement his strategy . He showed it was eective , but no one knew at that time what kind of data structure could be used to dynamically maintain the families in such a way that all the redexes of a given family could be somehow shared and , there- fore , reduced as a single step . The solution came in 1989, when independently Kathail Kat90 and Lamping Lam90 gave abstract -calculus machines which reduced terms as prescribed by Levy's optimality theory . Lamping's graph rewriting approach is the one that received most interest, and after his breakthrough other variants of optimal reducers have been proposed , especially by Gonthier , Abadi and Levy GnAL92a and Asperti Asp95 . We will refer to all of them as the optimal sharing graph approach. All these variants share a common core | the abstract algorithm in the terminology of AM98 | and dier in the way they implement the bookkeeping work needed to maintain the families . The algorithms are described as elegant graph rewriting systems , where any rule rewrites only a pair of facing nodes (and then it can be easily implemented as a constant time operation) . The abstract algorithm is responsible for the performing of the shared -rule and for the incremental duplication of subterms . It is the job of the bookkeeping part | also called the oracle | to maintain in the graph enough distributed information to make the abstract algorithm correct with respect to the standard - reduction (see Section 2 , or AG98 for a complete account). Since all the reduction rules can be implemented as constant time operations", "label": ["complexity", "elementary affine logic", "graph rewriting", "optimal reduction"], "stemmed_label": ["complex", "elementari affin logic", "graph rewrit", "optim reduct"]}
{"doc": "We show that the class of monotone 2 sup O(log i n /i ) /sup -term DNF formulae can be PAC learned in polynomial time under the uniform distribution from random examples only . This is an exponential improvement over the best previous polynomial-time algorithms in this model , which could learn monotone o(log sup 2 /sup i n /i )-term DNF . We also show that various classes of small constant-depth circuits which compute monotone functions are PAC learnable in polynomial time under the uniform distribution . All of our results extend to learning under any constant-bounded product distribution . Introduction A disjunctive normal form formula , or DNF , is a disjunction of conjunctions of Boolean literals. The size of a DNF is the number of conjunctions (also known as terms) which it contains . In a seminal 1984 paper 26 Valiant introduced the distribution-free model of Probably Approximately Correct (PAC) learning from random examples and posed the question of whether polynomial-size DNF are PAC learnable in polynomial time . Over the past fifteen years the DNF learning problem has been widely viewed as one of the most important - and challenging - open questions in computational learning theory . This paper substantially improves the best previous results for a well-studied restricted version of the DNF learning problem. 1.1 Previous Work The lack of progress on Valiant's original question - are polynomial-size DNF learnable from random examples drawn from an arbitrary distribution in polynomial time? - has led many researchers to study restricted versions of the DNF learning problem . As detailed below , the restrictions which have been considered include: ffl allowing the learner to make membership queries for the value of the target function at points selected by the learner; ffl requiring that the learner succeed only under restricted distributions on examples , such as the uniform distribution , rather than all distributions; ffl requiring that the learner succeed only for restricted subclasses of DNF formulae such as DNF with a bounded number of terms. A SAT-k DNF is a DNF in which each truth assignment satisfies at most k terms . Khardon 19 gave a polynomial time membership query algorithm for learning polynomial-size SAT-1 DNF under the uniform distribution; this result was later strengthened by Blum et al . 3 to SAT-k DNF for any constant k: Bellare 5 gave a polynomial time membership query algorithm for learning O(log n)- term DNF under the uniform distribution (a somewhat more general result was given by Blum and Rudich 6 ) . Mansour 23 gave a n O(log log n) -time membership query algorithm which learns arbitrary polynomial-size DNF under the uniform distribution . In a celebrated result , Jackson 15 gave a polynomial-time membership query algorithm for learning polynomial-size DNF under constant-bounded product distributions . His algorithm , the efficiency of which was subsequently improved by several authors 8 , 20 , is the only known polynomial time algorithm for learning the unrestricted class of polynomial size DNF in any nontrivial learning model. In the standard PAC model", "label": ["computational learning theory", "dnf formula", "pac learning", "monotone boolean function"], "stemmed_label": ["comput learn theori", "dnf formula", "pac learn", "monoton boolean function"]}
{"doc": "Dynamic detection of likely invariants is a program analysis that generalizes over observed values to hypothesize program properties . The reported program properties are a set of likely invariants over the program , also known as an operational abstraction . Operational abstractions are useful in testing , verification , bug detection , refactoring , comparing behavior , and many other tasks . Previous techniques for dynamic invariant detection scale poorly or report too few properties . Incremental algorithms are attractive because they process each observed value only once and thus scale well with data sizes . Previous incremental algorithms only checked and reported a small number of properties . This paper takes steps toward correcting this problem . The paper presents two new incremental algorithms for invariant detection and compares them analytically and experimentally to two existing algorithms . Furthermore , the paper presents four optimizations and shows how to implement them in the context of incremental algorithms . The result is more scalable invariant detection that does not sacrifice functionality . Introduction This paper presents and evaluates algorithms and optimizations for obtaining an operational abstraction - a formal description of properties that held on a series of program runs and can be expected to hold on future runs . The task of generating an operational abstraction is also known as dynamic detection of likely invariants , or dynamic invariant detection. Dynamic invariant detection is an important and practical prob- lem . Operational abstractions have been used in verifying safety properties 35 , 30 , 31 , automating theorem-proving 27 , 28 , identifying refactoring opportunities 19 , predicate abstraction 8 , 9 , generating test cases 38 , 39 , 13 , 14 , selecting and prioritizing test cases 16 , explaining test failures 12 , predicting incompatibilities Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. SIGSOFT'04/FSE-12 , Oct . 31-Nov . 6 , 2004 , Newport Beach , CA , USA. in component upgrades 24 , 25 , error detection 34 , 15 , 33 , 23, 4 , error isolation 37 , 21 , and choosing modalities 22 , among other tasks . Dynamic invariant detection has been independently implemented by several research groups , and related tools that also produce formal descriptions of run-time behavior have seen wide use (see Section 10). While dynamic invariant detection is valuable , implementing it efficiently is challenging . A naive implementation is straightforward but fails to scale to problems of substantial size . The key parameters that control runtime are the runtime of the subject program (a longer-running program produces more data to be analyzed), number of variables and fields examined , size of", "label": ["reversing optimizations", "batch algorithm", "incremental algorithm", "dynamic invariant detection"], "stemmed_label": ["revers optim", "batch algorithm", "increment algorithm", "dynam invari detect"]}
{"doc": "We show that a number of recent definitions and constructions of fuzzy extractors are not adequate for multiple uses of the same fuzzy secret---a major shortcoming in the case of biometric applications . We propose two particularly stringent security models that specifically address the case of fuzzy secret reuse , respectively from an outsider and an insider perspective , in what we call a chosen perturbation attack . We characterize the conditions that fuzzy extractors need to satisfy to be secure , and present generic constructions from ordinary building blocks . As an illustration , we demonstrate how to use a biometric secret in a remote fuzzy authentication protocol that does not require any storage on the client's side . Introduction Often , one would like to be able to use some piece of cryptographic machinery , not with an exact, strictly random string as secret , but with an approximate , noisy rendition of it , which furthermore would not be perfectly random either . Such a \"fuzzy\" secret could be a measurement on a somewhat hidden biometric feature-a retinal scan rather than a thumbprint- , a long password imperfectly committed to memory , or even one's spontaneous answers to a list of subjective questions EHMS00, FJ01 . Ideally , one would like to have a method to convert the above into as many cryptographically strong secrets usable for any purpose we like . A number of constructions geared toward specific applications have surfaced in the last few years DFM98 , JW99 , MRW99 , JS02 . Not surprisingly, related lines of work have also been pursued in di#erent contexts , e.g. , for privacy amplification BBCM95 , BBR88 , or for coping with noisy channels Cre97 . The general idea is based on a two-step process , where an extraction function first transforms any su#ciently random fuzzy secret into an almost uniform random private string , and outputs some public information which is used in the regeneration step to reconstitute the exact same private string from a close enough approximation of the original fuzzy secret . Dodis et al . DRS04 propose the most general definitions , and also introduce the notion of secure sketch (here renamed fuzzy sketch to avoid ambiguities) , which works like an extractor except that no private string is extracted; rather , the goal is to allow an exact reconstruction of the original input given an approximation thereof . Although the repeated use of the regeneration function on many inputs is typically allowed , all these schemes implicitly assume that no more than a single extraction is ever performed from any secret-clearly a problematic state of a#airs for biometric applications. Toward a more robust definition of fuzzy sketch and extractor , we propose a security model based on the stringent notion of adaptive chosen perturbation attacks , wherein the adversary may query an oracle to perform extractions and regenerations based on chosen perturbations of the secret under attack . If the adversary is only given an extraction oracle , we speak of an outsider attack;", "label": ["fuzzy extractor", "chosen perturbation security", "biometric keying", "zero storage biometric authentication"], "stemmed_label": ["fuzzi extractor", "chosen perturb secur", "biometr key", "zero storag biometr authent"]}
{"doc": "A forward-secure encryption scheme protects secret keys from exposure by evolving the keys with time . Forward security has several unique requirements in hierarchical identity-based encryption (HIBE) scheme: (1) users join dynamically; (2) encryption is joining-time-oblivious; (3) users evolve secret keys autonomously . We present a scalable forward-secure HIBE (fs-HIBE) scheme satisfying the above properties . We also show how our fs-HIBE scheme can be used to construct a forward-secure public-key broadcast encryption scheme , which protects the secrecy of prior transmissions in the broadcast encryption setting . We further generalize fs-HIBE into a collusion-resistant multiple hierarchical ID-based encryption scheme , which can be used for secure communications with entities having multiple roles in role-based access control . The security of our schemes is based on the bilinear Diffie-Hellman assumption in the random oracle model . Introduction The idea of an identity-based encryption (IBE) scheme is that an arbitrary string can serve as a public key . The main advantage of this approach is to largely reduce the need for public key certificates and certificate authorities , because a public key is associated with identity information such as a user's email address . A first scheme for identity-based encryption (BF-IBE) was based on the bilinear Di#e-Hellman assumption in the random oracle model by Boneh and Franklin 11 . In IBE schemes private key generator (PKG) is responsible for generating private keys for all users, and therefore is a performance bottleneck for organizations with large number of users . Hierarchical identity-based encryption (HIBE) schemes 9 , 22 , 26 were proposed to alleviate the workload of a root PKG by delegating private key generation and identity authentication to lower-level PKGs. In a HIBE scheme , a root PKG needs only to generate private keys for domain-level PKGs , who in turn generate private keys for users in their domains in the next level . The organization of PKGs and users forms a hierarchy that is rooted by the root PKG . To encrypt a message , Alice needs to obtain the public parameters of Bob's root PKG , and the ID for Bob and for those domain-level PKGs that are on the path from the root to Bob; there are no lower-level parameters . Gentry and Silverberg 22 extended BF-IBE scheme and presented a fully scalable hierarchical identity-based encryption (GS-HIBE) scheme . Later , a HIBE construction with a weaker notion of security was given by Boneh and Boyen 9 . Most recently , new IBE and HIBE constructions that can be proved to have the full security without the random oracle model 8 , 36 were given. # Department of Computer Science , Brown University , Providence , RI 02912 , dyao , anna @cs.brown.edu. Department of Computer Science , Courant Institute of Mathematical Sciences , New York University , New York, NY 10012 , fazio , dodis @cs.nyu.edu Due to the inherent key-escrow property 1 , the standard notion of HIBE security crucially depends on secret keys remaining secret . Key exposure is a realistic threat over the lifetime of such", "label": ["broadcast encryption", "forward security", "id-based encryption"], "stemmed_label": ["broadcast encrypt", "forward secur", "id-bas encrypt"]}
{"doc": "A general model of software development environments that consists of structures , mechanisms , and policies is presented . The advantage of this model is that it distinguishes intuitively those aspects of an environment that are useful in comparing and contrasting software development environments . Four classes of environments-the individual , the family , the city . and the state-are characterized by means of a sociological metaphor based on scale . The utility of the taxonomy is that it delineates the important classes of interactions among software developers and exposes the ways in which current software development environments inadequately support the development of large systems . The generality of the model is demonstrated by its application to a previously published taxonomy that categorizes environments according to how they relate to language-centered , structure-oriented , toolkit , and method-based environments . Introduction A model is useful primarily for the insight it provides about particular instances and collections of instances . By abstracting away non-essential details that often differ in trivial ways from instance to instance and by generalizing the essential details into the components of the model , we derive a tool for evaluating and classifying these instances - in ways that we had not thought of before we constructed our model . It is with this purpose in mind - classification and evaluation - that we introduce a general model of software development environments (SDEs) . Our model consists of three components: policies, mechanisms and structures. Once we have defined this general model of software development environments , there are various points of view from which we might classify environments . We might , for example , classify the SDEs according to their coverage of the software life cycle; or classify them according to the kinds of tools that they provide , contrasting those that provide a kernel set with those that provide an extended set; etc . Each of these classifications yields useful comparisons and insights. Another important point of view , which we have not seen in the literature , is a classification of SDEs relative to the problems of scale - what is required of software development environments for projects of different sizes taking into account the numbers of people and the length of the project as well as the size and complexity of the system . Note that the distinction between programming-in-the-small and programming-in-the-large 7 has some intimations of the problems of scale . However , this distinction is basically one of single-unit versus multiple-unit systems and captures only a small part of this problem. We build software systems that range from small to very large , and will be able to build even larger systems as hardware gets cheaper and more powerful . What has not been sufficiently considered is the effect of the scale of systems on the tools needed to build them*. Thus , the main focus of this paper - and , indeed , of our research - is the problem of scale . We introduce a classification of SDEs in terms of a", "label": ["language centered environments", "toolkit environments", "method-based environments", "software development environments", "structure-oriented environments", "programming environments", "sociological metaphor"], "stemmed_label": ["languag center environ", "toolkit environ", "method-bas environ", "softwar develop environ", "structure-ori environ", "program environ", "sociolog metaphor"]}
{"doc": "Computing the solution of the initial value problem in ordinary differential equations (ODEs) may be only part of a larger task . One such task is finding where an algebraic function of the solution (an event function) has a root (an event occurs) . This is a task which is difficult both in theory and in software practice . For certain useful kinds of event functions , it is possible to avoid two fundamental difficulties . It is described how to achieve the reliable solutions of such problems in a way that allows the capability to be grafted onto popular codes for the initial value problem . Introduction Computing the solution , yfflR n , of the initial value problem in ordinary differential equations, may be only part of a larger task . Possibly the most common such task is to find either a first point t 0 ? a or a set of points ft s g , a that one of the equations is satisfied at . The g j are called \"event functions\" , and event j is said to occur at t s when t s is a root of the jth event function . This paper is concerned with a class of such problems which have each event function g j defined as a polynomial in either y or y 0 . Specifically , we assume that g j in (1.2) has the form either or (x) is a component of the solution vector y(x) . More general polynomial forms of g j can be treated by the same techniques at the expense of rather more complicated machinery . Common problems such as (i) finding where a component of the solution assumes a given value , and (ii) finding where a component of the solution has an extremum have the form (1.3) or (1.4) with a single event function . We allow several event functions of both forms at the same time , and so can solve more complicated problems such as (iii) tabulating values of a dependent variable y (iv) determining the location of switching points or points of discontinuity defined in terms of linear functions of a dependent variable y (v) determining zeros of a general event function q(x; by adjoining a differential equation for q to the system (1.1). The difficulty of the event location problem is often not appreciated . In the next section we investigate the theoretical difficulties . Two fundamental difficulties are that , with the usual approaches , one cannot be sure of noticing an event at all , and that if one realizes that an event has occurred , one cannot be sure of finding the first occurrence . For the special problems we consider here , we present an efficient way to overcome both these difficulties , at least in principle; other difficulties remain. In Section 3 we state the key observation and describe how to exploit it. The presence of more than one event function causes many complications . We present a software design which is reasonably", "label": ["dense output", "root finding", "event location"], "stemmed_label": ["dens output", "root find", "event locat"]}
{"doc": "We introduce and analyze a new mixed finite element method for the numerical approximation of stationary incompressible magneto-hydrodynamics (MHD) problems in polygonal and polyhedral domains . The method is based on standard inf-sup stable elements for the discretization of the hydrodynamic unknowns and on nodal elements for the discretization of the magnetic variables . In order to achieve convergence in non-convex domains , the magnetic bilinear form is suitably modified using the weighted regularization technique recently developed in Numer . Math . 93 (2002) 239 . We first discuss the well-posedness of this approach and establish a novel existence and uniqueness result for non-linear MHD problems with small data . We then derive quasi-optimal error bounds for the proposed finite element method and show the convergence of the approximate solutions in non-convex domains . The theoretical results are confirmed in a series of numerical experiments for a linear two-dimensional Oseen-type MHD problem , demonstrating that weighted regularization is indispensable for the resolution of the strongest magnetic singularities . Introduction Incompressible magneto-hydrodynamics (MHD) describes the flow of a vis- cous , incompressible and electrically conducting fluid . The governing partial di#erential equations are obtained by coupling the incompressible Navier-Stokes equations with Maxwell's equations and arise in several engineering applications such as , for example , liquid metals in magnetic pumps or aluminum electrolysis , see , e.g. , 20 . In the stationary case , the resulting multi-field problem is of the form: find the velocity field u(x) , the hydrodynamic pressure and the magnetic field in# , in# , div in# , in# , supplemented with suitable boundary conditions on # Here,# is a bounded domain in R 3 , and the functions f and g are given source terms , with g being solenoidal . Furthermore , R e is the hydrodynamic Reynolds number , Rm the magnetic Reynolds number , and S the coupling number . These numbers are defined by denoting the characteristic values of the magnetic field and the velocity , respectively . The parameter L is the characteristic length scale of the problem . The constants # and # represent the density and the viscosity of the fluid , and - and # are the magnetic permeability and the electric conductivity, respectively . In industrial applications , one typically has R e Over the last few years , several finite element methods (FEM) to numerically solve the incompressible MHD equations and linearizations thereof have been proposed that are based on nodal (i.e. , H 1(#79260428# finite elements for the magnetic field b , combined with standard discretizations of the hydrodynamic unknowns u and . We mention here 1,13,16-18 and the references cited therein . However , it has been known for some time that in non-convex polyhedra of engineering practice the magnetic field components may have regularity below H 1(# and that nodal FEM discretizations of the magnetic operator , albeit stable , can converge quasi-optimally to a magnetic field that certain singular solution components induced by reentrant vertices or edges (for more details , see ,", "label": ["weighted regularization", "mixed methods", "incompressible magneto-hydrodynamics"], "stemmed_label": ["weight regular", "mix method", "incompress magneto-hydrodynam"]}
{"doc": "We present an I/O-efficient dynamic data structure for point location in a general planar subdivision . Our structure uses O( i N/B /i ) disk blocks of size i B /i to store a subdivision of size i N /i . Queries can be answered in O(log inf i B /i /inf sup 2 /sup i N /i ) I/Os in the worst-case , and insertions and deletions can be performed in O(log inf i B /i /inf sup 2 /sup i N /i ) and O(log inf i B /i /inf i N /i ) I/Os amortized , respectively . Part of our data structure is based on an external version of the so-called logarithmic method that allows for efficient dynamization of static external-memory data structures with certain characteristics . Another important part of our structure is an external data structure for vertical ray-shooting among line segments in the plane with endpoints on i B /i lines , developed using an external version of dynamic fractional cascading . We believe that these methods could prove helpful in the development of other dynamic external memory data structures . Introduction Planar point location is dened as follows: Given a planar subdivision with N vertices (i.e., a decomposition of the plane into polygonal regions induced by a straight-line planar graph), preprocess into a data structure so that , for an arbitrary query point , the face of containing can be reported quickly . This problem arises in several applications , including graphics , spatial databases , and geographic information systems . The planar subdivisions arising in many of these applications are too massive to t in internal memory and must reside on disk . In such instances, the I/O communication is the bottleneck instead of the CPU running time . Most of the work to date , especially if we allow the edges and vertices of to be changed dynamically , has focused on minimizing the CPU running time under the assumption that the subdivision ts in main An extended abstract version of this paper was presented at the sixteenth annual ACM Symposium on Computational Geometry (SoCG'00). y Supported in part by National Science Foundation ESS grant EIA 9870734 , RI grant EIA-9972879 , and CAREER grant CCR 9984099 . Email: large@cs.duke.edu. z Part of this work was done while visiting Duke University . Email: jan@math.uni-muenster.de. memory 7 , 11 , 12 , 17 , 20 , 24 . Only a few results are known for I/O-ecient point location when the subdivision is stored in external memory 1 , 5 , 14 , 18 , 27 . In this paper , we develop the rst space- and I/O-ecient dynamic data structure for planar point location in general subdivisions. Previously such a structure was only known for the case of a monotone 1 subdivision 1 . 1.1 Previous results In internal memory , Edelsbrunner et al . 16 proposed an optimal data structure for point location in monotone subdivisions with O(N) space , O(N) preprocessing time , and O(log 2 N) query time. For arbitrary", "label": ["dynamic data structures", "external memory", "point location", "i/o efficient"], "stemmed_label": ["dynam data structur", "extern memori", "point locat", "i/o effici"]}
{"doc": "We develop upper and lower bound arguments for counting acceptance modes of communication protocols . A number of separation results for counting communication complexity classes is established . This extends the investigation of the complexity of communication between two processors in terms of complexity classes initiated by Babai et al . (Proceedings of the 27th IEEE FOCS , 1986 , pp . 337-347) and continued in several papers (e.g. , J . Comput . System Sci . 41 (1990) 402; 49 (1994) 247; Proceedings of the 36th IEEE FOCS , 1995 , pp . 6-15) . In particular , it will be shown that for all pairs of distinct primes i /i and i q /i the communication complexity classes MOD inf i /i /inf i P /i sup cc /sup and MOD inf i q /i /inf i P /i sup cc /sup are incomparable with regard to inclusion . The same is true for PP sup cc /sup and MOD inf i m /i /inf i P /i sup cc /sup , for any number i m /i 2 . Moreover , non-determinism and modularity are incomparable to a large extend . On the other hand , if i m /i = i /i inf 1 /inf i l /i inf 1 /inf '...' i /i inf r /inf i l /i inf r /inf is the prime decomposition of i m /i 2 , then the complexity classes MOD inf i m /i /inf i P /i sup cc /sup and MOD inf i (m) /i /inf i P /i sup cc /sup coincide , where i (m) /i = i /i inf 1 /inf '...' i /i inf r /inf . The results are obtained by characterizing the modular and probabilistic communication complexity in terms of the minimum rank of matrices ranging over certain equivalence classes . Methods from algebra and analytic geometry are used . This paper is the completely revised and strongly extended version of the conference paper Damm et al . (Proc . 9th Ann . STACS , pp . 281-291) where a subset of the results was presented . Introduction Communication complexity plays an important role in theoretical studies: many of the known lower-bound results are obtained by analyzing the communication between various parts of the computational device . This concerns area-time tradeoffs for VLSI-computations ( 1 , 9 ) , time-space tradeoffs for Turing machines , width-length tradeoffs for oblivious and usual branching programs and hing programs ( 2 , 12 ) . Moreover , lower bounds on the depth of monotone circuits ( 16 ) , structural results in designing pseudorandom sequences ( 4 ) , and lower bounds on the size of special threshold circuits of depth 3 ( 8 ) should be mentioned in this connection. Babai , Frankl , and Simon in 3 introduced the investigation of the complexity of communication between two processors in terms of complexity classes . They showed some analogies between Turing machine classes like P , NP , PP , etc . and the", "label": ["modularity", "protocol", "upper bound", "probabilism", "non-determinism", "lower bound", "communication complexity class"], "stemmed_label": ["modular", "protocol", "upper bound", "probabil", "non-determin", "lower bound", "commun complex class"]}
{"doc": "In this paper , we propose an extension to the personal communication services (PCS) location management protocol which uses dynamically overlapped registration areas . The scheme is based on monitoring the aggregate mobility and call pattern of the users during each reconfiguration period and adapting to the mobility and call patterns by either expanding or shrinking registration areas at the end of each reconfiguration period . We analytically characterize the trade-off resulting from the inclusion or exclusion of a cell in a registration area in terms of expected change in aggregate database access cost and signaling overhead . This characterization is used to guide the registration area adaption in a manner in which the signaling and database access load on any given location register (LR) does not exceed a specified limit . Our simulation results show that it is useful to dynamically adapt the registration areas to the aggregate mobility and call patterns of the mobile units when the mobility pattern exhibits locality . For such mobility and call patterns , the proposed scheme can greatly reduce the average signaling and database access load on LRs . Further , the cost of adapting the registration areas is shown to be low in terms of memory and communication requirements . Introduction Personal communication services (PCS) allow mobile users with wireless terminals to receive calls irrespective of their location in a seamless manner . PCS networks have a cellular architecture: the geographical area is divided into cells with one base station per cell . The mobile user's portable terminals communicate via wireless with fixed Address for Correspondence: Sandeep K . S . Gupta , Department of Computer Science , Colorado State University , Ft . Collins , CO radio ports in the base station . Delivering calls to the mobile terminals requires that the current location (point of attachment) of the mobile terminal be known in order for the network to route the calls to the mobile terminal . The task of tracking the location of mobile terminals is known as location management (or tracking) 2 , 16 , 6 , 1 , 3 , 8 . Location management involves two basic operations: update and search . A mobile terminal updates its location periodically or otherwise . Whenever a call needs to be delivered to the mobile , the network uses the last know location of the mobile terminal to search for the mobile in the vicinity of that area . This may involve paging for the mobile terminal in certain neighborhood of the last known location of the mobile terminal . As has been demonstrated in several works , there is a tradeoff between update and search costs . Strategy which tries to reduce one cost tends to decrease the other , and vice versa . For example , if a mobile updates it's location more often then it can be searched more easily. One of the strategy used in conventional systems to balance the cost of update and search is the use of registration area (RA) approach to location tracking . The", "label": ["distributed location management", "cellular network", "adaptive protocol", "distributed load balancing", "dynamic optimization", "mobile communication network", "distributed algorithm"], "stemmed_label": ["distribut locat manag", "cellular network", "adapt protocol", "distribut load balanc", "dynam optim", "mobil commun network", "distribut algorithm"]}
{"doc": "This paper explores the use of compiler optimizations which optimize the layout of instructions in memory . The target is to enable the code to make better use of the underlying hardware resources regardless of the specific details of the processor/architecture in order to increase fetch performance . The Software Trace Cache (STC) is a code layout algorithm with a broader target than previous layout optimizations . We target not only an improvement in the instruction cache hit rate , but also an increase in the effective fetch width of the fetch engine . The STC algorithm organizes basic blocks into chains trying to make sequentially executed basic blocks reside in consecutive memory positions , then maps the basic block chains in memory to minimize conflict misses in the important sections of the program . We evaluate and analyze in detail the impact of the STC , and code layout optimizations in general , on the three main aspects of fetch performance: the instruction cache hit rate , the effective fetch width , and the branch prediction accuracy . Our results show that layout optimized codes have some special characteristics that make them more amenable for high-performance instruction They have a very high rate of not-taken branches and execute long chains of sequential instructions; also , they make very effective use of instruction cache lines , mapping only useful instructions which will execute close in time , increasing both spatial and temporal locality . Introduction Instruction fetch bandwidth may become a major limiting factor for future aggressive wide-issue superscalars . Conse- quently , it is crucial to develop software and hardware techniques that interact to deliver multiple basic blocks to the processor every cycle. Unfortunately , for many important codes , this is hard to do . For instance , database codes and several integer SPEC This research has been supported by CICYT grant TIC-0511- authors) , the Generalitat de Catalunya grants ACI 97- 26 (Josep L . Larriba-Pey and Josep Torrellas) and 1998FI-00306- APTIND (Alex Ram'irez) , the Commission for Cultural , Educational and Scientific Exchange between the United States of America and Spain (Josep L . Larriba-Pey , Josep Torrellas and Mateo Valero), NSF grant MIP-9619351 (Josep Torrellas) and CEPBA . Alex Ram'irez wants to thank all his fellow PBC's for their time and efforts . The authors want to thank Xavi Serrano for all his help setting up and analyzing PostgreSQL. y University of Illinois at Urbana Champaign , USA. applications have frequent control flow transfers and high instruction-cache miss rates . These characteristics make supplying a high number of useful instructions a difficult task , even in the presence of aiding devices like the Hardware Trace Cache (HTC) 4 , 12 . On the software side , it is possible to reorder the code in memory so that it is easier to supply useful instructions to the execution unit . Code reordering can target the elimination of cache conflicts 5 , 6 , 8 , 7 , 10 , 13 . In addition , it can also map", "label": ["compiler optimizations", "trace cache", "instruction fetch", "index terms- pipeline processors", "branch prediction"], "stemmed_label": ["compil optim", "trace cach", "instruct fetch", "index terms- pipelin processor", "branch predict"]}
{"doc": "We solve an open problem concerning the mixing time of symmetric random walk on the n-dimensional cube truncated by a hyperplane , showing that it is polynomial in n . As a consequence , we obtain a fully polynomial randomized approximation scheme for counting the feasible solutions of a 0-1 knapsack problem . The results extend to the case of any fixed number of hyperplanes . The key ingredient in our analysis is a combinatorial construction we call a \"balanced almost uniform permutation,\" which is of independent interest . Introduction For a positive real vector a and real number b, let denote the set of 0-1 vectors for which a x a Geometrically , we can view as the set of vertices of the n-dimensional cube f0; 1g n which lie on one side of the hyperplane a Combinatorially, is the set of feasible solutions to the 0-1 knapsack problem dened by a and b: if we think of the a i as the weights of a set of n items , and b as the capacity (weight limit) of a knapsack , then there is a 1-1 correspondence between vectors xand subsets of items X whose aggregated weight does not exceed the knapsack capacity, given by 1g . We shall write a(X) for the weight of X , i.e., i2X a i . This paper is concerned with the problem of computing i.e. , counting the number of feasible solutions to the knapsack problem . The problem is #P-complete in exact form , so we aim for a good approximation algorithm , specically a fully-polynomial randomized approximation scheme (fpras). By a well-known relationship based on self-reducibility 12 , 11 , this is equivalent to constructing a polynomial time algorithm for sampling elements of (almost) uniformly at random. In recent years there has been a steady stream of results of this kind for #P-complete counting problems (see , for example , 13 , 11 , 8 for surveys); however , the 0-1 knapsack problem still stands A preliminary version of this paper appeared in Proceedings of the 40th IEEE Symposium on Foundations of Computer Science , October 1999 , pp . 230 240. y Department of Statistics , Evans Hall , University of California , Berkeley CA 94720 . Email: morris@stat.berkeley.edu . Supported by NSF graduate and post-doctoral fellowships and by NSF grant ECS- 9873086. z Computer Science Division , Soda Hall , University of California , Berkeley CA 94720-1776 . Email: sinclair@cs.berkeley.edu . Supported in part by NSF grants CCR-9505448 and CCR-9820951. as one of a small handful of canonical problems that have so far resisted attack . Indeed , it has been quoted as an open problem in several places 4 , 11 , 13 , 15 . This interest stems in part from its combinatorial signicance and its appealing geometric structure , and in part from the challenge it poses to existing methods . In this paper , we resolve this issue by constructing an fpras for the 0-1 knapsack problem . Along the way we introduce some new", "label": ["random permutations", "knapsack problem", "balanced permutations", "random sampling", "hypercubes", "markov chains", "random walks"], "stemmed_label": ["random permut", "knapsack problem", "balanc permut", "random sampl", "hypercub", "markov chain", "random walk"]}
{"doc": "This paper proposes a framework for detecting global state predicates in systems of processes with approximately-synchronized real-time clocks . Timestamps from these clocks are used to define two orderings on events: \"definitely occurred before\" and \"possibly occurred before\" . These orderings lead naturally to definitions of 3 distinct detection modalities , i.e. , 3 meanings of \"predicate held during a computation\" , namely: Poss sup i db /i /sup (\" possibly held\") , definitely held\") , and Inst (\" definitely held in a specific global state\") . This paper defines these modalities and gives efficient algorithms for detecting them . The algorithms are based on algorithms of Garg and Waldecker , Alagar and Venkatesan , Cooper and Marzullo , and Fromentin and Raynal . Complexity analysis shows that under reasonable assumptions , these real-time-clock-based detection algorithms are less expensive than detection algorithms based on Lamport's happened-before ordering . Sample applications are given to illustrate the benefits of this approach . Introduction A history of a distributed system can be modeled as a sequence of events . Since execution of a particular sequence of events leaves the system in a well-defined global state , a history uniquely determines the sequence of global states through which the system has passed . Un- fortunately , in a distributed system without perfect clock synchronization , it is , in general, A preliminary description of this work appeared in 30 . y Scott D . Stoller (stoller@cs.indiana.edu , www.cs.indiana.edu/~stoller/) is with the Department of Computer Science , Indiana University , Bloomington , IN. impossible for a process to determine the order in which events on different processors actually occurred . Therefore , no process can determine the sequence of global states through which the system passed . This leads to an obvious difficulty for detecting whether a global state predicate (hereafter simply called a \"predicate\") held. Cooper and Marzullo proposed a solution for asynchronous distributed systems 6 . Their solution involves two modalities , which we denote by Poss hb initely\") . These modalities are based on logical time 18 as embodied in the happened- before relation hb ! , a partial ordering 1 of events that reflects potential causal dependencies. Happened-before is not a total order , so it does not uniquely determine the history , but it does restrict the possibilities . Given a predicate \\Phi , a computation satisfies Poss hb there is some interleaving of events that is consistent with happened-before and in which the system passes through a global state satisfying \\Phi . A computation satisfies for every interleaving of events that is consistent with happened-before , the system passes through a global state satisfying \\Phi. Cooper and Marzullo's definitions of these modalities established an important conceptual framework for predicate detection in asynchronous systems , which has been the basis for considerable research 8 , 13 , 4 , 17 , 32 , 14 , 5 , 12 . In practice , though , Poss hb other modalities based on happened-before have significant drawbacks in many cases . First, in many systems", "label": ["real-time monitoring", "global predicate detection", "distributed debugging", "consistent global states"], "stemmed_label": ["real-tim monitor", "global predic detect", "distribut debug", "consist global state"]}
{"doc": "A superstabilizing protocol is a protocol that (i) is self-stabilizing , meaning that it can recover from an arbitrarily severe transient fault; and (ii) can recover from a local transient fault while satisfying a passage predicate during recovery . This paper investigates the possibility of superstabilizing protocols for mutual exclusion in a ring of processors , where a local fault consists of any transient fault at a single processor; the passage predicate specifies that there be at most one token in the ring , with the single exception of a spurious token colocated with the transient fault . The first result of the paper is an impossibility theorem for a class of superstabilizing mutual exclusion protocols . Two unidirectional protocols are then presented to show that conditions for impossibility can independently be relaxed so that superstabilization is possible using either additional time or communication registers . A bidirectional protocol subsequently demonstrates that superstabilization in i O /i (1) time is possible . All three superstabilizing protocols are optimal with respect to the number of communication registers used . Introduction The notion of superstabilization is introduced in DH95 as a refinement of (self-) stabilization. Superstabilization continues the trend of recent research that combines stabilization with other forms of fault handling AG93 , GP93 , BB95 . The main attraction of stabilization is the possibility of software that initializes itself without requiring an external signal , which can be useful in the presence of transient faults or in distributed systems that asynchronously reconfigure (perhaps in the normal course of phased computation) . Stabilizing protocols are typically engineered for the worst case of a transient fault and are not designed to mask the most likely cases of faults or reconfigurations . Fault-tolerant behavior has been classified as either masking or nonmasking in AG93 . Briefly put , a protocol is masking fault-tolerant if its users A preliminary report of this research appears in Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications PDPTA'95 , pp . 31-40 , 1995. do not observe illegitimate protocol behavior during recovery after a fault: error-correcting codes , for example , mask faults within the limit of their tolerances . Stabilizing protocols are nonmasking , meaning that an observer of a protocol can witness corrupted output variables and incorrect behavior up to the point where recovery is complete . Superstabilization can be viewed as a partial masking technique for likely cases of transient faults and reconfigurations, while retaining stabilization to deal with arbitrarily severe transient faults. The focus of stabilization is convergence to a stable , legitimate behavior from an arbitrary initial state . The choice of an arbitrary initial state models the worst case possibility for a transient failure in a system: all the program counters , internal registers , channels , and so on could be set to unpredictable and inconsistent values by a transient fault . But a transient fault does not destroy code or hardware , and this fact enables a system to restore its state, after some convergence period , to", "label": ["mutual exclusion", "fault-containment", "self-stabilization"], "stemmed_label": ["mutual exclus", "fault-contain", "self-stabil"]}
{"doc": "A secure reliable multicast protocol enables a process to send a message to a group of recipients such that all correct destinations receive the same message , despite the malicious efforts of fewer than a third of the total number of processes , including the sender . This has been shown to be a useful tool in building secure distributed services , albeit with a cost that typically grows linearly with the size of the system . For very large networks , for which this is prohibitive , we present two approaches for reducing the cost: First , we show a protocol whose cost is on the order of the number of tolerated failures . Secondly , we show how relaxing the consistency requirement to a probabilistic guarantee can reduce the associated cost , effectively to a constant . Introduction Communication over a large and sparse internet is a challenging problem because communication links experience diverse delays and failures . Moreover , in a wide area network (WAN) , security is most needed, since communicating parties are geographically dispersed and thus are more prone to attacks . The problem addressed in this paper is how to distribute messages among a large group of participants so that all the (correctly behaving) participants agree on mes- sages' contents , despite the malicious cooperation of up to a third of the members. Previous work on this problem suffers from message complexity and computation cost that do not Copyright 1997 IEEE . Published in the Proceedings of ICDCS'97 , May 27-30 , 1997 in Baltimore , Maryland . Personal use of this material is permitted . However , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works , must be obtained from the IEEE. scale to very large communication groups: Toueg's echo broadcast 12 requires O(n 2 ) authenticated message exchanges for each message delivery (where n is the size of the group) . Reiter improved this message complexity in the ECHO protocol of the Rampart system 9 through the usage of digital signatures. The ECHO protocol incurs O(n) signed message ex- changes , and thus , message complexity is improved at the expense of increased computation cost . Malkhi and Reiter 6 extended this approach to amortize the cost of computing digital signatures over multiple messages through a technique called acknowledgment chaining , where a signed acknowledgment directly verifies the message it acknowledges and idirectly , every message it acknowledges . Nevertheless , O(n) digital signatures sit in the critical path between message sending and its delivery . For a very large group of hundreds or thousands of members , this may be too prohibitive. In this paper , we propose two approaches for bringing down the cost and delay associated with reliable broadcast . First , we show a protocol whose cost is on the order of the number of tolerated failures . Secondly, we show", "label": ["wide area network", "probabilistic algorithms", "secure multicast"], "stemmed_label": ["wide area network", "probabilist algorithm", "secur multicast"]}
{"doc": "A useless checkpoint is a local checkpoint that cannot be part of a consistent global checkpoint . This paper addresses the following problem . Given a set of processes that take (basic) local checkpoints in an independent and unknown way , the problem is to design communication-induced checkpointing protocols that direct processes to take additional local (forced) checkpoints to ensure no local checkpoint is useless . The paper first proves two properties related to integer timestamps which are associated with each local checkpoint . The first property is a necessary and sufficient condition that these timestamps must satisfy for no checkpoint to be useless . The second property provides an easy timestamp-based determination of consistent global checkpoints . Then , a general communication-induced checkpointing protocol is proposed . This protocol , derived from the two previous properties , actually defines a family of timestamp-based communication-induced checkpointing protocols . It is shown that several existing checkpointing protocols for the same problem are particular instances of the general protocol . The design of this general protocol is motivated by the use of communication-induced checkpointing protocols in \"consistent global checkpoint\"-based distributed applications such as the detection of stable or unstable properties and the determination of distributed breakpoints . Introduction A local checkpoint is a snapshot of a local state of a process , a global checkpoint is a set of local checkpoints , one from each process , and a consistent global checkpoint is a global checkpoint such that no message sent by a process after its local checkpoint is received by another process before its local checkpoint . So , the consistency of global checkpoints strongly depends on the flow of messages exchanged by processes . The determination of consistent global checkpoints is a fundamental problem in distributed computing and arise in many applications such as detection of stable properties 5 , 12, 17 , determination of breakpoints 7 , 10 , 20 , detection of unstable properties 2 , 6 , 11 , 13 , rollback recovery upon failure occurences 8 , 14 , 22 , etc. When processes independently take their local checkpoints there is a risk that no consistent global checkpoint can ever be formed (except the first one composed of their initial states) . This is caused by the well-known unbounded domino effect 22 . Even if consistent global checkpoints can be formed, it is still possible that some local checkpoints can never be included in a consistent global checkpoint; such local checkpoints are called useless. To prevent useless checkpoints , and thus safely prevent the domino effect , some coordination in the taking of local checkpoints is required . In the family of coordinated protocols 5 , 15 , processes use additional control messages to synchronize their checkpointing activities . This additional synchronization may result in reduced process autonomy and degraded performance of the underlying application. These drawbacks have given rise to the development of a family of communication-induced checkpointing protocols . In this family the coordination is achieved by piggybacking control information on application messages: no control messages", "label": ["fault-tolerance", "checkpointing protocols", "asynchronous distributed system"], "stemmed_label": ["fault-toler", "checkpoint protocol", "asynchron distribut system"]}
{"doc": "The complexity of designing protocols has led to compositional techniques for designing and verifying protocols . We propose a technique based on the notion of parallel composition of protocols . We view a composite protocol as an interleaved execution of the component protocols subject to a set of constraints . Using the constraints as building blocks , we define several constraint-based structures with each structure combining the properties of the component protocols in a different way . For instance , the component protocols of a multifunction protocol can be structured so that the composite protocol performs all the individual functions concurrently or performs only one of them depending on the order of initiation of the component protocols . We provide inference rules to infer safety and liveness properties of the composite protocol . Some properties are derived from those of the component protocols while others are derived from the structuring mechanism (the set of constraints) used to combine the component protocols . Introduction Distributed protocols are typically complex and perform several functions . The modules performing the various functions may interact with one another in a complex manner which makes the design and verification of protocols a difficult task . Several formalisms for specifying protocols have been proposed 9 , 2 , 14 which provide basic operators for process synchronization . For modular design of protocols , several structuring techniques for protocols specified in these formalisms have been pro- posed . These structuring techniques follow the \"separation of concerns\" paradigm in which the functionality of a protocol is first decomposed into subfunctions , protocols for the various subfunctions are designed separately , and then combined using a fixed set of rules to obtain a protocol for the entire problem . An advantage of such a technique is that it allows the designer to focus on one aspect (subfunction) at a time . In addition , in certain cases , properties of the composite protocol can be inferred from those of the component protocols. Sequential composition is one such structuring technique which allows design of protocols performing multiple functions in sequence 8 , 7 , 6 , 16 , 13 , 15 . Let be two protocols . If P performs the first subtask and Q performs the second subtask then the sequential composition of P and Q requires P i to execute before Q i at each site i . For example , if P performs connection establishment and Q is a data transfer protocol then P ; Q denotes the protocol which first establishes a connection and then transfers the data . Sufficient conditions can be derived to infer properties of the combined protocol . For example , showed that if the component protocols are deadlock free and properly terminating then the composite protocol is also deadlock-free and properly terminating. In many multifunction protocols , several activities may have to be performed concurrently . In such cases , we have to combine the component protocols so that they can execute in an interleaved manner and interact with one another . We", "label": ["multifunction protocols", "safety and liveness properties", "protocol composition", "distributed protocols"], "stemmed_label": ["multifunct protocol", "safeti and live properti", "protocol composit", "distribut protocol"]}
{"doc": "Quorum systems are well-known tools for ensuring the consistency and availability of replicated data despite the benign failure of data repositories . In this paper we consider the arbitrary (Byzantine) failure of data repositories and present the first study of quorum system requirements and constructions that ensure data availability and consistency despite these failures . We also consider the load associated with our quorum systems , i.e. , the minimal access probability of the busiest server . For services subject to arbitrary failures , we demonstrate quorum systems over i n /i servers with a load of i O /i (1/ i n /i ) , thus meeting the lower bound on load for benignly fault-tolerant quorum systems . We explore several variations of our quorum systems and extend our constructions to cope with arbitrary client failures . Introduction A well known way to enhance the availability and performance of a replicated service is by using quorums . A quorum system for a universe of servers is a collection of subsets of servers , each pair of which intersect . Intuitively , each quorum can operate on behalf of the system , thus increasing its availability and performance , while the intersection property guarantees that operations done on distinct quorums preserve consistency. In this paper we consider the arbitrary (Byzantine) failure of clients and servers , and initiate the study of quorum systems in this model . Intuitively , a quorum system tolerant of Byzantine failures is a collection of subsets of servers , each pair of which intersect in a set containing sufficiently many correct servers to guarantee consistency of the replicated data as seen by clients . We provide the following contributions. 1 . We define the class of masking quorum systems , with which data can be consistently replicated in a way that is resilient to the arbitrary failure of data repositories . We present several example constructions of such systems and show necessary and sufficient conditions for the existence of masking quorum systems under different failure assumptions. 2 . We explore two variations of masking quorum systems . The first , called dissemination quorum systems , is suited for services that receive and distribute self-verifying information from correct clients (e.g. , digitally signed values) that faulty servers can fail to redistribute but cannot undetectably alter . The second variation , called opaque masking quorum systems , is similar to regular masking quorums in that it makes no assumption of self-verifying data , but it differs in that clients do not need to know the failure scenarios for which the service was designed . This somewhat simplifies the client protocol and , in the case that the failures are maliciously induced , reveals less information to clients that could guide an adversary attempting to compromise the system. 3 . We explore the load of each type of quorum system , where the load of a quorum system is the minimal access probability of the busiest server , minimizing over all strategies for picking quorums . We present a masking", "label": ["byzantine failures", "quorum systems", "replication", "fault tolerance"], "stemmed_label": ["byzantin failur", "quorum system", "replic", "fault toler"]}
{"doc": "We tackle a natural problem from distributed computing , involving time-stamps . Let i /i = i /i inf 1 /inf , i /i inf 2 /inf , ..., i /i inf N /inf be a set of computing agents or processes which synchronize with each other from time to time and exchange information about themselves and others . The gossip problem is the following: Whenever a set i P /i i P /i meets , the processes in i P /i must decide amongst themselves which of them has the latest information , direct or indirect , about each agent i /i in the system . We propose an algorithm to solve this problem which is finite-state and local . Formally , this means that our algorithm can be implemented as an asynchronous automation . Introduction The aim of this paper is to tackle a natural problem from distributed computing , involving time-stamps . Let be a set of computing agents or processes which synchronize with each other from time to time and exchange information about themselves and others . The gossip problem is the following: Whenever a set P ' P meets , the processes in P must decide amongst themselves which of them has the latest information, direct or indirect , about each agent in the system. This is easily accomplished if the agents decide to \"time-stamp\" every synchronization and pass these time-stamps along with each exchange of information . This does not require that all their clocks be synchronized . For example , each process can use an independent counter . When a set P ' P meets , the processes in P jointly agree on a new value for their counters which exceeds the maximum of the counter values currently held by them . Thus , for any process , the time-stamps assigned to synchronization events involving form a strictly increasing sequence (albeit with gaps between successive time- stamps) . So , the problem of deciding who has the latest information about reduces to that of checking for the largest time-stamp. This scheme has the following drawback: As the computation progresses these counter values increase without bound and most of the agents' time would be taken up in passing on large numbers , as opposed to actual gossip. We propose an algorithm using counters which take on values from a bounded , finite set . We assign an independent counter to each subset of processes which can potentially synchronize . These counters are updated when the corresponding sets of processes meet. The update is performed jointly by the processes which meet. Since our set of counter values is bounded , time-stamps have to be reused and , in general , different synchronizations involving a particular set of processes will acquire the same time-stamp during a computation . Despite this , our algorithm guarantees that whenever a set P ' P meets , the processes in P can decide correctly which of them has the best information about any other agent in the system . Thus , in", "label": ["asynchronous automata", "synchronous communication", "bounded time-stamps", "distributed algorithms"], "stemmed_label": ["asynchron automata", "synchron commun", "bound time-stamp", "distribut algorithm"]}
{"doc": "This paper presents a protocol for leader election in complete networks with a sense of direction . Sense of direction provides nodes the capability of distinguishing between their incident links according to a global scheme . We propose a protocol for leader election which requires i O(N) /i messages and i O /i (log i N /i ) time . The protocol is message optimal and the time complexity is a significant improvement over currently known protocols for this problem . Introduction Leader election is a fundamental problem in distributed computing and has been studied in various computation models . In the leader election problem , there are N processors in the network , each having a unique identity . Initially all nodes are passive and are unaware of the identity of any other node . An arbitrary subset of nodes , called the candidates , wake up spontaneously and start the protocol . On the termination of the protocol , exactly one node announces itself the leader . In this paper , we consider the problem of electing a leader in an asynchronous complete network , where each pair of nodes is connected by a bidirectional link. For a complete network in which a node is unable to distinguish between its incident links , 4 showed log N) messages are required for electing a leader. However , 5 showed that the lower bound of \\Omega\\Gamma N log N) messages does not hold * This work was supported by NSF grants CCR-9211621 and CCR-9502506 . Some of the results on this paper appeared in the ACM Symposium on Principles of Distributed Computing , 1992. for complete networks with sense of direction 8 and gave a protocol which requires O(N) messages and O(N) time (assuming that the transmission delay for each message is at most one time unit , the computation time is negligible and the processes start asynchronously) . network has a sense of direction if there exists a directed Hamiltonion cycle and each edge incident at a node is labeled with the distance of the node at the other end of this edge along this Hamiltonion cycle . Figure 1 shows a complete network containing six nodes with a sense of direction . In this figure , for example , the edge (b; d) is labeled 2 and 4 at nodes b and d respectively (because d is at distance 2 from b along the cycle and b is distance 4 from d along the cycle). A protocol with O(N) time complexity and O(N) message complexity is also given in 6 . In the protocols in 5 and 6 , a node captures at least a majority of nodes before it declares itself as the leader . We observe that in the presence of sense of direction , a node does not have to capture a majority of nodes in order to be elected the leader . We use this idea to obtain a protocol which requires O(N) messages and O(log N) time . The protocol proceeds in two phases .", "label": ["complete networks", "leader election", "distributed algorithm", "message complexity"], "stemmed_label": ["complet network", "leader elect", "distribut algorithm", "messag complex"]}
{"doc": "A naming protocol assigns unique names (keys) to every process out of a set of communicating processes . We construct a randomized wait-free naming protocol using wait-free atomic read/write registers (shared variables) as process intercommunication primitives . Each process has its own private register and can read all others . The addresses/names each one uses for the others are possibly different: Processes i /i and i q /i address the register of process i r /i in a way not known to each other . For i n /i processes and 0 , the protocol uses a name space of size (1 + ) i n /i and i O /i ( i n /i log i n /i log log i n /i ) running time (read/writes to shared bits) with probability at least 1- i o /i (1) , and i O /i ( i n /i log sup 2 /sup i n /i ) overall expected running time . The protocol is based on the wait-free implementation of a novel -Test&SetOnce object that randomly and fast selects a winner from a set of i q /i contenders with probability at least in the face of the strongest possible adaptive adversary . Introduction A naming protocol concurrently executed by each process out of a subset of n processes selects for the host process a unique name from a common name space . The name space should be small , preferably of size n . The processes may or may not have a name to start with . If they do , the resulting variant of the naming problem is called the renaming problem. In a distributed or concurrent system , distinct names are useful and sometimes mandatory in a variety of situations including mutual exclusion , resource allocation , leader election and choice coordination . In such cases a naming protocol can be put to good use . When processes are created and terminated dynamically-a common occurrence in distributed and concurrent systems-the name space may grow while the number of processes remains bounded . A renaming procedure is used to size down the name space . Examples of network protocols that crash on duplicate names or perform more efficiently for small name ranges are found in 27 and 30 . A naming protocol is also useful in allocation of identical resources with a name as a permit to a resource . Since our algorithms are wait-free (see below) they are also highly fault-tolerant . Managing the assignment of resources to competing processes corresponds to a repetitive variant of the naming problem 7 . In the sequel we also write \"key\" for \"name\" and \"key range\" for \"name space.\" Interprocess Communication: We use interprocess communication through shared memory and allow arbitrarily initialized shared memory (dirty memory model) as in 23 . Shared memory primitives such as wait-free atomic read/write registers 21 , 22 are widely used in the theory of distributed algorithms 16 . A deterministic protocol executed by n processes is wait-free if there is a finite function f such", "label": ["symmetry breaking", "atomicity", "asynchronous distributed protocols", "test-and-set objects", "wait-free read/write registers", "randomized algorithms", "fault-tolerance", "shared memory", "adaptive adversary", "naming problem", "unique process id"], "stemmed_label": ["symmetri break", "atom", "asynchron distribut protocol", "test-and-set object", "wait-fre read/writ regist", "random algorithm", "fault-toler", "share memori", "adapt adversari", "name problem", "uniqu process id"]}
{"doc": "We present lower bounds on the amount of communication that matrix multiplication algorithms must perform on a distributed-memory parallel computer . We denote the number of processors by i P /i and the dimension of square matrices by i n /i . We show that the most widely used class of algorithms , the so-called two-dimensional (2D) algorithms , are optimal , in the sense that in any algorithm that only uses i O /i ( i n /i sup 2 /sup / i P /i ) words of memory per processor , at least one processor must send or receive ( i n /i sup 2 /sup / i P /i sup 1/2 /sup ) words . We also show that algorithms from another class , the so-called three-dimensional (3D) algorithms , are also optimal . These algorithms use replication to reduce communication . We show that in any algorithm that uses i O /i ( i n /i sup 2 /sup / i P /i sup 2/3 /sup ) words of memory per processor , at least one processor must send or receive ( i n /i sup 2 /sup / i P /i sup 2/3 /sup ) words . Furthermore , we show a continuous tradeoff between the size of local memories and the amount of communication that must be performed . The 2D and 3D bounds are essentially instantiations of this tradeoff . We also show that if the input is distributed across the local memories of multiple nodes without replication , then ( i n /i sup 2 /sup ) words must cross any bisection cut of the machine . All our bounds apply only to conventional ( i n /i sup 3 /sup ) algorithms . They do not apply to Strassen's algorithm or other i o /i ( i n /i sup 3 /sup ) algorithms . INTRODUCTION Although communication is a bottleneck in many computations running on distributed-memory parallel computers and on clusters of workstations or servers , few communication lower bounds have been proved . We know a great deal about the amount of communication that specic algorithms perform , but we know little about how much communication they must perform. We present lower bounds on the amount of communication that is required to multiply matrices by a conventional algorithm on a distributed-memory parallel computer . The analysis uses a unied framework that also applies to the analysis of capacity cache misses in a sequential matrix-multiplication algorithm. We use a simple yet realistic computational model to prove the lower bounds . We model a parallel computer as a collection of P processor-memory nodes connected by a communication network . That is , all the memory is distributed among the nodes , which can communicate across a network . Our analysis bounds the number of words that must be sent and received by at least one of the nodes . The bounds apply even if a processor-memory node includes several processors , which is fairly common today in machines ranging from clusters of dual-processor", "label": ["communication", "lower bounds", "distributed memory", "matrix multiplication"], "stemmed_label": ["commun", "lower bound", "distribut memori", "matrix multipl"]}
{"doc": "We study a generalization of covering problems called partial covering . Here we wish to cover only a desired number of elements , rather than covering all elements as in standard covering problems . For example , in i k /i -partial set cover , we wish to choose a minimum number of sets to cover at least i k /i elements . For i k /i -partial set cover , if each element occurs in at most i f /i sets , then we derive a primal-dual i f /i -approximation algorithm (thus implying a 2-approximation for i k /i -partial vertex cover) in polynomial time . Without making any assumption about the number of sets an element is in , for instances where each set has cardinality at most three , we obtain an approximation of 4/3 . We also present better-than-2-approximation algorithms for i k /i -partial vertex cover on bounded degree graphs , and for vertex cover on expanders of bounded average degree . We obtain a polynomial-time approximation scheme for i k /i -partial vertex cover on planar graphs , and for covering i k /i points in i R sup d /sup /i by disks . Introduction Covering problems are widely studied in discrete op- timization: basically , these problems involve picking a least-cost collection of sets to cover elements . Classical problems in this framework include the general set cover problem , of which a widely studied special case is the vertex cover problem . (The vertex cover problem is a special case of set cover in which the edges correspond to elements and vertices correspond to sets; in this set cover instance , each element is in exactly two sets.) Both these problems are NP-hard and polynomial-time approximation algorithms for both are well studied . For set cover see 12 , 26 , 29 . For vertex cover see 6 , 7 , 13 , 21 , 22 , 30 . In this paper we study the generalization of \"cov- ering\" to \"partial covering\" 27 , 31 . Specifically , in k-set cover , we wish to find a minimum number (or, in the weighted version , a minimum weight collec- tion) of sets that cover at least k elements . When k is the total number of elements , we obtain the regular set cover problem; similarly for k-vertex cover. (We sometimes refer to k-set cover as \"partial set cover\" , and k-vertex cover as \"partial vertex cover\"; the case where k equals the total number of elements is referred to as \"full coverage\".) This generalization is motivated by the fact that real data (in clustering for example) often has errors (also called outliers). Thus , discarding the (small) number of constraints posed by such errors/outliers is permissible. Suppose we need to build facilities to provide service within a fixed radius to a certain fraction of the population . We can model this as a partial set cover problem . The main issue in partial covering is: which k elements should we choose", "label": ["vertex cover", "approximation algorithms", "primal-dual methods", "set cover", "partial covering", "randomized rounding"], "stemmed_label": ["vertex cover", "approxim algorithm", "primal-du method", "set cover", "partial cover", "random round"]}
{"doc": "A minimally unsatisfiable subformula (MUS) is a subset of clauses of a given CNF formula which is unsatisfiable but becomes satisfiable as soon as any of its clauses is removed . The selection of a MUS is of great relevance in many practical applications . This expecially holds when the propositional formula encoding the application is required to have a well-defined satisfiability property (either to be satisfiable or to be unsatisfiable) . While selection of a MUS is a hard problem in general , we show classes of formulae where this problem can be solved efficiently . This is done by using a variant of Farkas' lemma and solving a linear programming problem . Successful results on real-world contradiction detection problems are presented . The satis?ability problem (SAT) consists in determining whether there exists a truth assignment True,False for the variables such that F evaluates to True . Extensive references can be found in (Chandru and Hooker , 1999; Gu et al. , 1997; Kleine Bu?ning and Lettman , 1999; Truemper , 1998). Generally , when an instance F encodes a system or a structure one must design , F should have a well-de?ned solution property (either to be satis?able or to be unsatis?able) . When F is unsatis?able , but it should be satis?able , we would like to modify the underlying system in order to make F satis?able . Conversely , when F is unsatis?able and it should be so , if the underlying system needs to be re-designed , we would like to keep F unsatis?able . The ?rst problem can sometimes be c Kluwer Academic Publishers . Printed in the Netherlands. approached by solving the maximum satis?ability problem (Max-SAT), see e.g . (Battiti and Protasi , 1998) . This consists in ?nding a truth assignment for the variables maximizing the number of clauses Cj which evaluates to True . So far , satis?ability can be restored by removing from the underlying system all elements corresponding to clauses which could not be satis?ed . However , such approach is not desirable in many practical cases . Very often , in fact , we cannot just delete a part of our system , because we need the functionalities contained in that part. Instead , we would like to locate and understand the problem , and, basing on this information , re-design only the small part of the system causing the problem . As for the second problem , we typically would like to know which part of the underlying system should not be changed, and which one can be modi?ed (or possibly removed) . Both of the above problems can be approached by looking for a minimally unsatis?able subset of clauses (MUS) within an unsatis?able F (see Sect . 2). An algorithm for selecting an approximation of a MUS is proposed in (Bruni , 2002) . The problem of deciding whether a CNF formula contains a minimally unsatis?able (MU) subformula of ?xed de?ciency ? , for all ? , is proved NP-complete in (Kleine Bu?ning and Zhao , 2002). Related", "label": ["unsatisfiability", "mus selection", "infeasibility analysis"], "stemmed_label": ["unsatisfi", "mu select", "infeas analysi"]}
{"doc": "The i crossing number /i cr( i G /i ) of a graph i G /i is the minimum possible number of edge crossings in a drawing of i G /i in the plane , while the i pair-crossing number /i pcr( i G /i ) is the smallest number of pairs of edges that cross in a drawing of i G /i in the plane . While cr( i G /i ) pcr( i G /i ) holds trivially , it is not known whether a strict inequality can ever occur (this question was raised by Mohar and Pach and Tth) . We aim at bounding cr( i G /i ) in terms of pcr( i G /i ) . Using the methods of Leighton and Rao , Bhatt and Leighton , and Even , Guha and Schieber , we prove that One of the main steps is an analogy of the well-known lower bound cr( i G /i ) = ( i b /i ( i G /i ) sup 2 /sup ) - i O /i (ssqd( i G /i )) , where i b(G) /i is the i bisection width /i of i G /i , that is , the smallest number of edges that have to be removed so that no component of the resulting graph has more than 2/3 i n /i vertices . We show that We also prove by similar methods that a graph i G /i with crossing number log sup 2 /sup i n /i has a nonplanar subgraph on at most i O /i ( i nm /i log sup 2 /sup i n /i / i k /i ) vertices , where i m /i is the number of edges , is the maximum degree in i G /i , and i C /i is a suitable sufficiently large constant . Introduction By a drawing of a (multi)graph G , we mean a drawing in the plane such that every edge is represented by an arc . The arcs are allowed to cross , but they may not pass through vertices (except for their endpoints) and no point is an internal point of three or more arcs. A crossing is a common internal point of two arcs. The crossing number cr(G) is the minimum possible number of crossings in a drawing of G . The pair-crossing number pcr(G) is the minimum possible number of (unordered) pairs of edges that cross in a drawing of G . Pach and Toth 13 were the rst to formulate explicitly the denition of pcr(G) , and they raised the problem of whether which had previously been overlooked in papers on the crossing number of graphs. Surprisingly , this problem appears quite challenging . A natural approach to proving equality is , given a drawing witnessing pcr(G) , to modify it locally so that multiple crossings of pairs of edges are eliminated . An example of Kratochvl and Matousek 5 shows that in general , given a drawing , it need not be possible to", "label": ["expansion", "crossing number", "graph drawing", "pair-crossing number"], "stemmed_label": ["expans", "cross number", "graph draw", "pair-cross number"]}
{"doc": "We present source tracing as a new viable approach to routing in ad hoc networks in which routers communicate the second-to-last hop and distance in preferred paths to destinations . We introduce a table-driven protocol (BEST) in which routers maintain routing information for all destinations , and an on-demand routing protocol (DST) in which routers maintain routing information for only those destinations to whom they need to forward data . Simulation experiments are used to compare these protocols with DSR , which has been shown to incur less control overhead that other on-demand routing protocols . The simulations show that DST requires far less control packets to achieve comparable or better average delays and percentage of packet delivered than DSR , and that BEST achieves comparable results to DSR while maintaining routing information for all destinations . INTRODUCTION Ad hoc networks (or multi-hop packet-radio networks) consist of mobile routers interconnecting hosts . These networks are useful in tactical and commercial scenarios in which there is no base-station infrastructure present . The deployment of such routers is ad hoc and the topology of the net-work is very dynamic , because of host and router mobility, signal loss and interference , and power outages . Further- more , the bandwidth available for the exchange of routing information in ad hoc networks is far lesser than the band-width available in a wired internet. Routing for ad hoc networks can be classied into two main types: table-driven and on-demand . Table driven routing attempts to maintain consistent information about the path from each node to every other node in the network . The Destination-Sequenced Distance-Vector Routing (DSDV) protocol is a table driven algorithm that modies the distributed Bellman-Ford routing algorithm to include timestamps that prevent loop-formation 15 . The Wireless Routing Protocol (WRP) is a distance vector routing protocol which belongs to the class of path-nding algorithms that exchange This work was supported in part by the Defense Advanced Research Projects Agency (DARPA) under grant F30602- 97-2-0338. second-to-last hop (predecessor) to destinations in addition to distances to destinations 13 . This extra information helps remove the \\counting-to-innity\" problem that most distance vector routing algorithms suer from 1 . It also speeds up route convergence when a link failure occurs. On-demand routing protocols have been designed to limit the amount of bandwidth consumed in maintaining up-to- date routes to all destinations in a network by maintaining routes to only those destinations to which the routers need to forward data tra-c . The basic approach consists of allowing a router that does not know how to reach a destination to send a ood-search message to obtain the path information it needs . There are several recent examples of this approach (e.g. , AODV 16 , ABR 19 , DSR 12 , TORA 14 , SSA 5 , ZRP 11 ) and the routing protocols dier on the spe- cic mechanisms used to disseminate ood-search packets and their responses , cache the information heard from other nodes' searches , determine the cost of a link , and determine the", "label": ["ad hoc networks", "on-demand routing", "wireless routing"], "stemmed_label": ["ad hoc network", "on-demand rout", "wireless rout"]}
{"doc": "The Web is a source of valuable information , but the process of collecting , organizing , and effectively utilizing the resources it contains is difficult . We describe CorpusBuilder , an approach for automatically generating Web search queries for collecting documents matching a minority concept . The concept used for this paper is that of text documents belonging to a minority natural language on the Web . Individual documents are automatically labeled as relevant or nonrelevant using a language filter , and the feedback is used to learn what query lengths and inclusion/exclusion term-selection methods are helpful for finding previously unseen documents in the target language . Our system learns to select good query terms using a variety of term scoring methods . Using i odds ratio /i scores calculated over the documents acquired was one of the most consistently accurate query-generation methods . To reduce the number of estimated parameters , we parameterize the query length using a Gamma distribution and present empirical results with learning methods that vary the time horizon used when learning from the results of past queries . We find that our system performs well whether we initialize it with a whole document or with a handful of words elicited from a user . Experiments applying the same approach to multiple languages are also presented showing that our approach generalizes well across several languages regardless of the initial conditions . Introduction Electronic text corpora are used for modeling language in many language technology applications , including speech recognition (Jelinek , 1999) , optical character recognition , handwriting recognition , machine translation (Brown et al. , 1993) , and spelling correction (Golding & Roth , 1999) . They are also useful for linguistic and sociolinguistic studies , as they are readily searchable and statistics can easily be computed. Current methods for creating text corpora for specific languages require a lot of manual human effort and are very time-consuming . The Linguistic Data Consortium (LDC) has corpora for twenty languages (Liberman & Cieri , 1998) while Web search engines currently perform language identification on about a dozen of the languages they index , allowing language-specific searches in those languages . Documents in many other languages are also indexed , though no explicit labeling of the language they are written in is available. The WWW has been gaining popularity as a resource for multilingual content . Resnik (Resnik , 1999) explored the Web as a source for parallel text and automatically constructed a parallel corpus of English and French . In this paper , We describe techniques which only require the user to give a handful of keywords or documents for automatically collecting language specific resources from the Web and present a system which automatically generates Web search queries to construct corpora for minority languages . Our proposed approach requires no human intervention once the system is provided with the initial documents and is a very cheap and fast way to collect corpora for minority languages from the Web. In general , to quickly find documents in a specific", "label": ["online learning", "query generation", "web mining", "corpus construction"], "stemmed_label": ["onlin learn", "queri gener", "web mine", "corpu construct"]}
{"doc": "The authors describe a novel maximum-entropy (maxent) approach for generating online recommendations as a user navigates through a collection of documents . They show how to handle high-dimensional sparse data and represent it as a collection of ordered sequences of document requests . This representation and the maxent approach have several advantages: (1) you can naturally model long-term interactions and dependencies in the data sequences; (2) you can query the model quickly once it is learned , which makes the method applicable to high-volume Web servers; and (3) you obtain empirically high-quality recommendations . Although maxent learning is computationally infeasible if implemented in the straightforward way , the authors explored data clustering and several algorithmic techniques to make learning practical even in high dimensions . They present several methods for combining the predictions of maxent models learned in different clusters . They conducted offline tests using over six months' worth of data from ResearchIndex , a popular online repository of over 470,000 computer science documents . They show that their maxent algorithm is one of the most accurate recommenders , as compared to such techniques as correlation , a mixture of Markov models , a mixture of multinomial models , individual similarity-based recommenders currently available on ResearchIndex , and even various combinations of current ResearchIndex recommenders . INTRODUCTION AND RELATED WORK Recommender systems attempt to automate the process of \"word of mouth\" recommendations within a community . Typical application environments are dynamic in many respects: users come and go , users' preferences and goals change , items are added and removed , and user navigation itself is a dynamic process . Recommendation domains are also often high dimensional and sparse , with tens or hundreds of thousands of items, among which very few are known to any particular user. Consider , for instance , the problem of generating recommendations in ResearchIndex (a.k.a. , CiteSeer) , 1 an online digital library of computer science papers , receiving thousands of user accesses per hour . The site automatically locates computer science papers found on the Web , indexes their full text , allows browsing via the literature citation graph , and isolates the text around citations , among other services 5 . Figure 1 gives a typical screen shot of a document details page in ResearchIndex . Shown are the title and authors of the paper , download options and a number of similarity-based recommenders predicting to the user the documents of possible interest based on the features of the current document. The archive contains over 470,000 documents including the full text of each document , citation links between documents, and a wealth of user access data . With so many documents, D . Pavlov is with Yahoo! Inc . This work was done at NEC Laboratories America. D . Pennock is a Senior Research Scientist at Overture Services. E . Manavoglu and C.L . Giles are with The Pennsylvania State University. Searching the World Wide Web (1998) (Make Steve Lawrence , C . Lee Giles Science Home/Search Context Related View or download: nec.com/~lawrence/.chscience98.ps.gz", "label": ["mixture models", "recommender systems", "sequence modeling", "maximum entropy model"], "stemmed_label": ["mixtur model", "recommend system", "sequenc model", "maximum entropi model"]}
{"doc": "Data mining is under attack from privacy advocates because of a misunderstanding about what it actually is and a valid concern about how it's generally done . This article shows how technology from the security community can change data mining for the better , providing all its benefits while still maintaining privacy . Introduction Explosive progress in networking , storage , and processor technologies has led to the creation of ultra large databases that record unprecedented amount of transactional information . In tandem with this dramatic increase in digital data , concerns about informational privacy have emerged globally Tim97 Eco99 eu998 Off98 . Privacy issues are further exacerbated now that the World Wide Web makes it easy for the new data to be automatically collected and added to databases The concerns over massive collection of data are naturally extending to analytic tools applied to data . Data mining , with its promise to efficiently discover valuable, non-obvious information from large databases , is particularly vulnerable to misuse CM96 The98 Off98 ECB99 . A fruitful direction for future research in data mining will be the development of techniques that incorporate privacy concerns Agr99 . Specifically , we address the following question . Since the primary task in data mining is the development of models about aggregated data , can we develop accurate models without access to precise information in individual data records? The underlying assumption is that a person will be willing to selectively divulge information in exchange of value such models can provide Wes99 . Example of the value provided include filtering to weed out unwanted information , better search results with less effort , and automatic triggers HS99 . A recent survey of web users classified 17% of respondents as privacy fundamentalists who will not provide data to a web site even if privacy protection measures are in place . How- ever , the concerns of 56% of respondents constituting the pragmatic majority were significantly reduced by the presence of privacy protection measures . The remaining 27% were marginally concerned and generally willing to provide data to web sites , although they often expressed a mild general concern about privacy . Another recent survey of web users Wes99 found that 86% of respondents believe that participation in information- for-benefits programs is a matter of individual privacy choice . A resounding 82% said that having a privacy policy would matter; only 14% said that was not important as long as they got benefit . Furthermore , people are not equally protective of every field in their data records Wes99 CRA99a . Specifically , a person ffl may not divulge at all the values of certain fields; ffl may not mind giving true values of certain fields; ffl may be willing to give not true values but modified values of certain fields. Given a population that satisfies the above assump- tions , we address the concrete problem of building decision-tree classifiers BFOS84 Qui93 and show that that it is possible to develop accurate models while respecting users' privacy concerns . Classification is one", "label": ["privacy", "data mining"], "stemmed_label": ["privaci", "data mine"]}
{"doc": "A data warehouse stores materialized views of data from one or more sources , with the purpose of efficiently implementing decision-support or OLAP queries . One of the most important decisions in designing a data warehouse is the selection of materialized views to be maintained at the warehouse . The goal is to select an appropriate set of views that minimizes total query response time and the cost of maintaining the selected views , given a limited amount of resource , e.g. , materialization time , storage space , etc . In this article , we have developed a theoretical framework for the general problem of selection of views in a data warehouse . We present polynomial-time heuristics for a selection of views to optimize total query response time under a disk-space constraint , for some important special cases of the general data warehouse scenario , viz.: 1) an AND view graph , where each query/view has a unique evaluation , e.g. , when a multiple-query optimizer can be used to general a global evaluation plan for the queries , and 2) an OR view graph , in which any view can be computed from any one of its related views , e.g. , data cubes . We present proofs showing that the algorithms are guaranteed to provide a solution that is fairly close to (within a constant factor ratio of) the optimal solution . We extend our heuristic to the general AND-OR view graphs . Finally , we address in detail the view-selection problem under the maintenance cost constraint and present provably competitive heuristics . Introduction A data warehouse is a repository of integrated information available for querying and analysis IK93 , Wid95 . Figure 1 illustrates the architecture of a typical warehouse 96 . The information stored at the warehouse is in the form of views , referred to as materialized views , derived from the data in the sources . In order to keep a materialized view consistent with the data at sources , the view has to be incrementally maintained ZGMHW95 , GM95 . This maintenance of views incurs what is known as view maintenance or update costs. In this paper , we concentrate on the problem of selecting an appropriate set of materialized views , one of the most important design decisions in designing a data warehouse . Given some storage space constraint , the problem is to select a set of derived views to minimize total query response time and the cost of maintaining the selected views . We refer to this problem as the view-selection problem. Related work on this problem has been as follows . HRU96 presents and analyzes algorithms for selection of views in the special case of \"data cubes.\" Wrapper Wrapper Wrapper Metadata Store Manager View Manager View Source Query Processor Integrator Monitor Monitor Wrapper Monitor Wrapper Data Warehouse View Specifier Administrator Fig . 1 . A typical data warehouse architecture Gupta et al . in GHRU96 extend their result to selection of views and indexes in data cubes . Both these", "label": ["index terms- views", "materialization", "view selection", "data warehouse"], "stemmed_label": ["index terms- view", "materi", "view select", "data warehous"]}
{"doc": "We introduce efficient learning equilibrium (ELE) , a normative approach to learning in noncooperative settings . In ELE , the learning algorithms themselves are required to be in equilibrium . In addition , the learning algorithms must arrive at a desired value after polynomial time , and a deviation from the prescribed ELE becomes irrational after polynomial time . We prove the existence of an ELE (where the desired value is the expected payoff in a Nash equilibrium) and of a Pareto-ELE (where the objective is the maximization of social surplus) in repeated games with perfect monitoring . We also show that an ELE does not always exist in the imperfect monitoring case . Finally , we discuss the extension of these results to general-sum stochastic games . Introduction Reinforcement learning in the context of multi-agent interaction has attracted the attention of researchers in cognitive psychology , experimental economics , machine learning , articial intelligence , and related elds for quite some time 13 , 6 . Much of this work uses repeated games 5 , 8 and stochastic games 16 , 15 , 12 , 2 as models of such interactions. The literature on learning in games in game theory 8 is mainly concerned with the understanding of learning procedures that if adopted by the dierent agents will converge at the end to an equilibrium of the corresponding game . The game itself may be known; the idea is to show that simple dynamics lead to rational behavior , as prescribed by a Nash equilibrium. The learning algorithms themselves are not required to satisfy any rationality requirement; it is what they converge to , if adopted by all agents that should be in equilibrium . When facing uncertainty about the game that is played , game-theorists adopt a Bayesian approach. The typical assumption in that approach is that there exists a probability distribution on the possible games , which is common-knowledge . The notion of equilibrium is extended to this context of games with incomplete information , and is treated as the appropriate solution concept . In this context , agents are assumed to be rational agents adopting the corresponding (Bayes-) Nash equilibrium , and learning is not an issue. Our major claim is that the game-theoretic approach is not in line with the goals of multi-agent reinforcement learning research in AI and must be modied . First , the Bayesian approach used to model partial information is not in line with the common approach in theoretical computer science and computational learning for dealing with uncertainty . Second, the descriptive motivation underlying learning research in game-theory diers considerably from the normative motivation for learning research in AI , and these dierences have important ramications . We now explain these issues in more detail. First , consider the Bayesian model of partial information . To date , most work in machine learning , and in particular , work on single-agent reinforcement learning has taken a dierent approach , motivated largely by work on online algorithms in computer science . Here , no", "label": ["stochastic games", "repeated games", "multi-agent learning", "learning equilibrium", "efficiency", "ex-post equilibrium"], "stemmed_label": ["stochast game", "repeat game", "multi-ag learn", "learn equilibrium", "effici", "ex-post equilibrium"]}
{"doc": "In the framework of self-stabilizing systems , the convergence proof is generally done by exhibiting a measure that strictly decreases until a legitimate configuration is reached . The discovery of such a measure is very specific and requires a deep understanding of the studied transition system . In contrast we propose here a simple method for proving convergence , which regards self-stabilizing systems as string rewrite systems , and adapts a procedure initially designed by Dershowitz for proving termination of string rewrite systems . In order to make the method terminate more often , we also propose an adapted procedure that manipulates \"schemes\" , i.e . regular sets of words , and incorporates a process of scheme generalization . The interest of the method is illustrated on several nontrivial examples . Introduction Introduced by Dijkstra , with three mutual exclusion algorithms on a ring of processes 11 , the notion of self-stabilization has been largely studied for the last ten years (see 29,31 for surveys) . In this paper , we consider a system which consists of a ring of machines controlled by a \"central demon\" . Its configuration is the concatenation of the component local states and it is characterized by a set S of transitions defined over configurations . The system is self-stabilizing with respect to a subset L of legitimate configurations when , regardless of the initial configuration and regardless of the transition selected at each step by the central demon , it is guaranteed to reach a configuration of L within a finite number of steps . The set L is assumed to have a closure property: from a legitimate configuration in L , the system persistently remains in L . It is also frequent to This paper is a revised and extended version of a communication given by the three first authors , at Symp . DISC'99 , under the title \"A new rewrite method for proving convergence of self-stabilizing systems\" (LNCS 1693 , Springer-Verlag , pp . 240-253). assume that there is no-deadlock . With these two hypotheses , it is easy to show that a system is self-stabilizing iff it has the no-cycle property: there is no cyclic sequence of transitions which contains some configuration w 62 L . This property is often proved by exhibiting a norm function defined over the set of configu- rations , whose value strictly decreases after each transition (or each bounded sequence of transitions) as long as the configuration is not legitimate 31 . Since such a measure is usually very specific to the considered system , finding one is very difficult and requires a deep understanding of this system (see e.g. 23,14,4 ). We propose here a new approach for proving the absence of cycle . Configurations are viewed as words of a formal language , transitions of S as rewrite rules , and the no-cycle property as a variant of the nontermination property for rewrite rules . The absence of infinite sequences will be shown by refining the generation procedure of reduction chains 1 , first proposed", "label": ["self-stabilization", "rewriting systems"], "stemmed_label": ["self-stabil", "rewrit system"]}
{"doc": "A locally decodable code (LDC) encodes n-bit strings x in m-bit codewords C(x) in such a way that one can recover any bit xi from a corrupted codeword by querying only a few bits of that word . We use a quantum argument to prove that LDCs with 2 classical queries require exponential 2(n) . Previously , this was known only for linear codes (Goldreich et al. , in: Proceedings of 17th IEEE Conference on Computation Complexity , 2002 , pp . 175-183) . The proof proceeds by showing that a 2-query LDC can be decoded with a single quantum query , when defined in an appropriate sense . It goes on to establish an exponential lower bound on any 'l-query locally quantum-decodable code' . We extend our lower bounds to non-binary alphabets and also somewhat improve the polynomial lower bounds by Katz and Trevisan for LDCs with more than 2 queries . Furthermore , we show that q quantum queries allow more succinct LDCs than the best known LDCs with q classical queries . Finally , we give new classical lower bounds and quantum upper bounds for the setting of private information retrieval . In particular , we exhibit a quantum 2-server private information retrieval (PIR) scheme with O(n3/10) qubits of communication , beating the O(n1/3) bits of communication of the best known classical 2-server PIR . Introduction 1.1 Setting correcting codes allow one to encode an n-bit string x into an m-bit codeword C(x) in such a way that x can still be recovered even if the codeword is corrupted in a number of places. For example , codewords of length already su-ce to recover from errors in a constant fraction of the bitpositions of the codeword , even in linear time 33 . One disadvantage of such \\standard\" error correction is that one usually needs to consider all or most of the (corrupted) A preliminary version of this paper appeared in STOC'03 22 . y Supported by DARPA under agreement number F 30602 01-2 0524 . Part of this work was done when visiting CWI. z Most of this work was done while a postdoc at UC Berkeley , supported by Talent grant S 62 565 from the Netherlands Organization for Scientic Research (NWO) . Also (partially) funded by projects QAIP (IST 1999 and RESQ (IST-2001-37559) of the IST-FET programme of the EC. codeword to recover anything about x . If one is only interested in recovering one or a few of the bits of x , then more e-cient schemes are possible , which allow us to extract small parts of encoded information from a corrupted codeword , while looking at (\\querying\") only a few positions of that word . Such schemes are called locally decodable codes (LDCs) . They have found various applications in complexity theory and cryptography , such as self-correcting computations 5 , 24, 17 , 16 , 18 , Probabilistically Checkable Proofs 2 , worst-case to average-case reductions 3 , 34 , private information retrieval 11 , and extractors 25 . Informally , LDCs", "label": ["locally decodable codes", "private information retrieval", "quantum computing"], "stemmed_label": ["local decod code", "privat inform retriev", "quantum comput"]}
{"doc": "In this paper , we show that any n point metric space can be embedded into a distribution over dominating tree metrics such that the expected stretch of any edge is O(log n) . This improves upon the result of Bartal who gave a bound of O(log n log log n) . Moreover , our result is existentially tight; there exist metric spaces where any tree embedding must have distortion (log n)-distortion . This problem lies at the heart of numerous approximation and online algorithms including ones for group Steiner tree , metric labeling , buy-at-bulk network design and metrical task system . Our result improves the performance guarantees for all of these problems . INTRODUCTION 1.1 Metric approximations The problem of approximating a given graph metric by a \"simpler\" metric has been a subject of extensive research, motivated from several di#erent perspectives . A particularly simple metric of choice , also favored from the algorithmic # Supported by NSF grants CCR-0105533 and CCR- 9820897. # Supported in part by a DPST scholarship and NSF grant CCR-0105533. Supported by NSF grant CCR-0105533. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. STOC'03 , June 9-11 , 2003 , San Diego , California , USA. ACM 1-58113-674-9/03/0006 .$5.00. point of view , is a tree metric , i.e . a metric arising from shortest path distance on a tree containing the given points. Ideally we would like that distances in the tree metric are no smaller than those in the original metric and we would like to bound the distortion or the maximum increase . However, there are simple graphs (e.g . the n-cycle) for which the distortion must be # n) 41 , 7 , 25 . To circumvent this , Karp 30 considered approximating the cycle by a probability distribution over paths , and showed a simple distribution such that the expected length of each edge is no more than twice its original length . This gave a competitive ratio of 2 for the k-server problem (on a cycle) that had motivated this approach . Alon , Karp , Peleg and West 1 looked at approximating arbitrary graph metrics by (a distribution over) spanning trees , and showed an upper bound of 2 O( # log n log log n) on the distortion. Bartal 7 formally defined probabilistic embeddings and improved on the previous result by showing how to probabilistically approximate metrics by tree metrics with distortion O(log 2 n) . Unlike the result of Alon et.al . 1 , Bartal's trees were not spanning trees of the original graph , and had additional Steiner points . He however showed that this probabilistic approximation leads", "label": ["tree metrics", "embeddings", "metrics"], "stemmed_label": ["tree metric", "embed", "metric"]}
{"doc": "We present solutions to statically load-balance scatter operations in parallel codes run on grids . Our load-balancing strategy is based on the modification of the data distributions used in scatter operations . We study the replacement of scatter operations with parameterized scatters , allowing custom distributions of data . The paper presents: (1) a general algorithm which finds an optimal distribution of data across processors; (2) a quicker guaranteed heuristic relying on hypotheses on communications and computations; (3) a policy on the ordering of the processors . Experimental results with an MPI scientific code illustrate the benefits obtained from our load-balancing . Introduction Traditionally , users have developed scientific applications with a parallel computer in mind , assuming an homogeneous set of processors linked with an homogeneous and fast network . However , Grids 10 of computational resources usually include heterogeneous processors , and heterogeneous network links that are orders of magnitude slower than in a parallel computer . Therefore , the execution on Grids of applications designed for parallel computers usually leads to poor performance as the distribution of workload does not take the heterogeneity into account. Hence the need for tools able to analyze and transform existing parallel applications to improve their performances on heterogeneous environments by load-balancing their ex- ecution . Furthermore , we are not willing to fully rewrite the original applications but we are rather seeking transformations which modify the original source code as little as possible. This research is supported by the French Ministry of Research through the ACI-GRID program. Among the usual operations found in parallel codes is the scatter operation , which is one of the collective operations usually shipped with message passing libraries . For instance , the mostly used message passing library MPI 16 provides a MPI_Scatter primitive that allows the programmer to distribute even parts of data to the processors in the MPI communicator. The less intrusive modification enabling a performance gain in an heterogeneous environment consists in using a communication library adapted to heterogeneity . Thus, much work has been devoted to that purpose: for MPI, numerous projects including Magpie 15 , MPI-StarT 13 , and MPICH-G2 8 , aim at improving communications performance in presence of heterogeneous networks . Most of the gain is obtained by reworking the design of collective communication primitives . For instance , MPICH-G2 performs often better than MPICH to disseminate information held by a processor to several others . While MPICH always use a binomial tree to propagate data , MPICH-G2 is able to switch to a flat tree broadcast when network latency is high 14 . Making the communication library aware of the precise network topology is not easy: MPICH-G2 queries the underlying Globus 9 environment to retrieve information about the network topology that the user may have specified through environment variables . Such network-aware libraries bring interesting results as compared to standard communication libraries . However , these improvements are often not sufficient to attain performance considered acceptable by users when the processors are also heteroge- neous . Balancing the computation tasks", "label": ["heterogeneous computing", "grid computing", "parallel programming", "load-balancing", "scatter operation"], "stemmed_label": ["heterogen comput", "grid comput", "parallel program", "load-balanc", "scatter oper"]}
{"doc": "The dynamic behavior of a network in which information is changing continuously over time requires robust and efficient mechanisms for keeping nodes updated about new information . Gossip protocols are mechanisms for this task in which nodes communicate with one another according to some underlying deterministic or randomized algorithm , exchanging information in each communication step . In a variety of contexts , the use of randomization to propagate information has been found to provide better reliability and scalability than more regimented deterministic approaches.In many settings , such as a cluster of distributed computing hosts , new information is generated at individual nodes , and is most \"interesting\" to nodes that are nearby . Thus , we propose distance-based propagation bounds as a performance measure for gossip mechanisms: a node at distance d from the origin of a new piece of information should be able to learn about this information with a delay that grows slowly with d , and is independent of the size of the network.For nodes arranged with uniform density in Euclidean space , we present natural gossip mechanisms , called spatial gossip , that satisfy such a guarantee: new information is spread to nodes at distance d , with high probability , in O(log1 steps . Such a bound combines the desirable qualitative features of uniform gossip , in which information is spread with a delay that is logarithmic in the full network size , and deterministic flooding , in which information is spread with a delay that is linear in the distance and independent of the network size . Our mechanisms and their analysis resolve a conjecture of Demers et al . 1987 .We further show an application of our gossip mechanisms to a basic resource location problem , in which nodes seek to rapidly learn the location of the nearest copy of a resource in a network . This problem , which is of considerable practical importance , can be solved by a very simple protocol using Spatial Gossip , whereas we can show that no protocol built on top of uniform gossip can inform nodes of their approximately nearest resource within poly-logarithmic time . The analysis relies on an additional useful property of spatial gossip , namely that information travels from its source to sinks along short paths not visiting points of the network far from the two nodes . Introduction Gossip algorithms The dynamic behavior of a network in which information is changing continuously over time requires robust and e#cient mechanisms for keeping nodes updated about new information. For example , we may have a network of sensors measuring properties of the physical world, and performing computations on the collective set of measurements in a distributed fashion (see e.g . 4 , 6 , 8 , 9 ) . As measured values change , we would like for them to be propagated through the network rapidly . Or we may have a distributed network of computing hosts that need to be informed about significant changes in the load on machines , or the appearance", "label": ["resource location", "decentralized algorithm", "gossip"], "stemmed_label": ["resourc locat", "decentr algorithm", "gossip"]}
{"doc": "We consider the problem of approximating a given m n matrix A by another matrix of specified rank k , which is smaller than m and n . The Singular Value Decomposition (SVD) can be used to find the \"best\" such approximation . However , it takes time polynomial in m , n which is prohibitive for some modern applications . In this article , we develop an algorithm that is qualitatively faster , provided we may sample the entries of the matrix in accordance with a natural probability distribution . In many applications , such sampling can be done efficiently . Our main result is a randomized algorithm to find the description of a matrix D* of rank at most k so that holds with probability at least 1 (where &verbar;&verbar;F is the Frobenius norm) . The algorithm takes time polynomial in k,1/&epsi; , log(1/) only and is independent of m and n . In particular , this implies that in constant time , it can be determined if a given matrix of arbitrary size has a good low-rank approximation . INTRODUCTION Real-world data often has a large a number of attributes (features/dimensions) . A natural question is whether in fact it is generated by a small model , i.e. , with a much smaller number of parameters than the number of attributes . One way to formalize this question is the problem of finding a low-rank approximation: given an m - n matrix A , find a matrix D of rank at most k so that ||A - D|| F is as small as possible (for any matrix M , the Frobenius norm , ||.|| F , is defined as F Alternatively , if we view the rows of A as points in R n , then it is the problem of finding a k-dimensional linear subspace that minimizes the sum of squared distances to the points . This problem arises in many contexts , partly because some matrix algorithms are more e#cient for low-rank matrices . It is also interesting to consider other norms , e.g. , the 2-norm (see Section 6) , but we will mostly focus on the Frobenius norm. The traditional Singular Value Decomposition (SVD) can be used to solve the problem in time O(min mn 2 , nm 2 ) . For many applications motivated by information retrieval and the web , this is too slow and one needs a linear or sublinear algorithm . To speed up SVD-based low-rank approximation , Papadimitriou et al. 2000 suggested random projection as a pre-processing step , i.e. , project the rows of A to an O(log n)-dimensional subspace and then find the SVD in that subspace. This reduces the worst-case complexity to O(mn log n) for a small loss in approximation quality . This is still too high. How fast can the problem be solved? At first sight , it seems that# mn) is a lower bound - if A has only a single non-zero entry , one has to examine all its entries to find a", "label": ["matrix algorithms", "sampling", "low-rank approximation"], "stemmed_label": ["matrix algorithm", "sampl", "low-rank approxim"]}
{"doc": "In this paper we study the following question posed by H . S . Wilf: what is , asymptotically as $n\\rightarrow \\infty$ , the probability that a randomly chosen part size in a random composition of an integer n has multiplicity m? More specifically , given positive integers n and m , suppose that a composition $\\lambda$ of n is selected uniformly at random and then , out of the set of part sizes in $\\lambda$ , a part size j is chosen uniformly at random . Let $\\P(A_n^ (m) )$ be the probability that j has multiplicity m . We show that for fixed m , $\\P(A_n^ (m) $) goes to 0 at the rate $1/\\ln n$ . A more careful analysis uncovers an unexpected result: $(\\ln n)\\P(A_n^ (m) )$ does not have a limit but instead oscillates around the value $1/m$ as $n\\to\\infty$.This work is a counterpart of a recent paper of Corteel , Pittel , Savage , and Wilf , who studied the same problem in the case of partitions rather than compositions . Introduction In this paper we consider the multiplicity of a randomly chosen part size in a random composition of an integer n . Let us recall that a multiset is a partition of an integer n if the - j are positive integers , called parts , such that Compositions are merely partitions in which the order of parts is significant . Thus , for example , the integer 3 admits three partitions , f1; f2; 1g and f3g , and four compositions , namely (1; 1; 1) , (1; 2) , (2; 1) and (3). Part of the research of the first author was carried out while he was visiting Department of Mathematics of Lehigh University in the spring semester of 1999 . He would like to thank the Department for its hospitality y Research supported in part by National Science Foundation Grant DMS9622772 Integer partitions (as deterministic objects) have been studied for quite some time , but Erd-os and Lehner 5 were apparently the first to study integer partitions from the probabilistic perspective , namely , they considered the set of all partitions , P (n) , of an integer n , as a probability space equipped with the uniform probability measure . Quantities of interest are treated as random variables and one can study their probabilistic properties , most typically , the limiting properties as n ! 1 . Erd-os and Lehner , for example , considered the limiting distribution of the total number of parts in a partition . Their paper opened a new line of investigation. Goh and Schmutz 10 obtained the central limit theorem for the number of different part sizes in a random partition , that is , they proved that the number of different part sizes , appropriately normalized , has , approximately , the standard Gaussian distribution . (Several years earlier Wilf 17 found an asymptotic formula for the expected number of distinct part sizes.) This approach culminated in an important paper by Fristedt 9 ,", "label": ["compositions of an integer", "geometric random variables", "random compositions"], "stemmed_label": ["composit of an integ", "geometr random variabl", "random composit"]}
{"doc": "In the 0-extension problem , we are given a weighted graph with some nodes marked as terminals and a semimetric on the set of terminals . Our goal is to assign the rest of the nodes to terminals so as to minimize the sum , over all edges , of the product of the edge's weight and the distance between the terminals to which its endpoints are assigned . This problem generalizes the multiway cut problem of Dahlhaus et al . SIAM J . Comput. , 23 (1994) , pp . 864--894 and is closely related to the metric labeling problem introduced by Kleinberg and Tardos Proceedings of the 40th IEEE Annual Symposium on Foundations of Computer Science , New York , 1999 , pp . 14--23 .We present approximation algorithms for \\sc 0-Extension . In arbitrary graphs , we present a O(log k)-approximation algorithm , k being the number of terminals . We also give O(1)-approximation guarantees for weighted planar graphs . Our results are based on a natural metric relaxation of the problem previously considered by Karzanov European J . Combin. , 19 (1998) , pp . 71--101 . It is similar in flavor to the linear programming relaxation of Garg , Vazirani , and Yannakakis SIAM J . Comput. , 25 (1996) , pp . 235--251 for the multicut problem , and similar to relaxations for other graph partitioning problems . We prove that the integrality ratio of the metric relaxation is at least $c \\sqrt \\lg k $ for a positive c for infinitely many k . Our results improve some of the results of Kleinberg and Tardos , and they further our understanding on how to use metric relaxations . Introduction Let V be a finite set , let T V , and let d be a semimetric on T . 1 Then a semimetric - on V is an extension of d to V iff for every in addition , for every then - is a 0-extension of d to V . We consider the following optimization problem (denoted 0-EXTENSION): Given a graph E) with non-negative edge weights c subset T of the nodes , and a semimetric d on T , find a 0-extension - of d to V that minimizes the total weighted length of the edges. It helps to compare 0-EXTENSION to the multiway cut problem of Dahlhaus , Johnson , Papadimitriou , Seymour , and Yannakakis 5 , 6 . MULTIWAY CUT is the following problem: Given a graph E) with nonnegative edge weights R , and a subset T V of terminals , find a mapping so as to minimize X In other words , find a set of edges of minimum total weight whose removal disconnects all terminal pairs . If we define d to be the uniform metric on T , i.e. , exactly this problem: Find so as to minimize c(u; v) d(f(u); f(v)); as Now 0-EXTENSION is the natural generalization of MULTIWAY CUT in which , instead of being the uniform metric , d is an arbitrary", "label": ["graph partitioning", "linear programming relaxation", "approximation algorithm", "metric space"], "stemmed_label": ["graph partit", "linear program relax", "approxim algorithm", "metric space"]}
{"doc": "We show how to use numerical continuation to compute the intersection $C=A\\cap B$ of two algebraic sets A and B , where A , B , and C are numerically represented by witness sets . En route to this result , we first show how to find the irreducible decomposition of a system of polynomials restricted to an algebraic set . The intersection of components A and B then follows by considering the decomposition of the diagonal system of equations u restricted to u,v $\\in$ A $\\times$ B . An offshoot of this new approach is that one can solve a large system of equations by finding the solution components of its subsystems and then intersecting these . It also allows one to find the intersection of two components of the two polynomial systems , which is not possible with any previous numerical continuation approach . Introduction . In a series of papers 12 , 13 , 14 , 15 , 17 , we have proposed numerical continuation algorithms that use witness sets as the basic construct for representing solution components of a system of polynomial equations on C N . Witness sets are the central concept of a young subject that we call numerical algebraic geometry , which uses numerical continuation 1 , 2 and generalizes earlier work in computing isolated solutions of polynomial systems 8 , 9 . The main concern of this paper is to provide an algorithm for computing the intersection of two solution components A , B from two possibly identical polynomial systems f , g , whose witness sets have been given . It is important to realize that naively combining f , g into one system f , g is not su#cient , even if we were willing to put aside the potentially prohibitive size of the combined system . For example , suppose A is the line x as a solution component of is the line x 1 - x as a solution component of which is the isolated point (0 , 0), does not appear as an irreducible component of the system Questions involving intersection of components arise naturally in applications. Just as a single polynomial in one variable has multiple roots , a system of polynomial equations in several variables can have multiple solution components; these components can even appear at di#erent dimensions (points , curves , surfaces , etc.) from the same set of equations . We may wish to find the intersection of just one of those components with another algebraic set . In our new approach , only the degrees of the components being intersected come into play in the determination of the number of paths followed by the homotopies that we use . This is important since the degree of # The authors acknowledge the support of the Volkswagen-Stiftung (RiP-program at Oberwolfach). Department of Mathematics , University of Notre Dame , Notre Dame , IN 46556-4618 , USA Email: sommese@nd.edu URL: http://www.nd.edu/-sommese . This material is based upon work supported by the National Science Foundation under Grant No", "label": ["generic points", "homotopy continuation", "numerical algebraic geometry", "irreducible components", "polynomial system", "components of solutions", "embedding"], "stemmed_label": ["gener point", "homotopi continu", "numer algebra geometri", "irreduc compon", "polynomi system", "compon of solut", "embed"]}
{"doc": "Two different ways of defining ad-hoc polymorphic operations commonly occur in programming languages . With the first form polymorphic operations are defined inductively on the structure of types while with the second form polymorphic operations are defined for specific sets of types.In intensional type analysis operations are defined by induction on the structure of types . Therefore no new cases are necessary for user-defined types , because these types are eQuivalent to their underlying structure . However , intensional type analysis is \"closed\" to extension , as the behavior of the operations cannot be differentiated for the new types , thus destroying the distinctions that these types are designed to express.Haskell type classes on the other hand define polymorphic operations for sets of types . Operations defined by class instances are considered \"open\"---the programmer can add instances for new types without modifying existing code . However , the operations must be extended with specialized code for each new type , and it may be tedious or even impossible to add extensions that apply to a large universe of new types.Both approaches have their benefits , so it is important to let programmers decide which is most appropriate for their needs . In this paper , we define a language that supports both forms of ad-hoc polymorphism , using the same basic constructs . INTRODUCTION With ad-hoc polymorphism the execution of programs depends on type information . A parametrically polymorphic Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. September 19-22 , 2004 , Snowbird , Utah. function must behave the same for all instantiations . How- ever , the instance of an ad-hoc polymorphic function for integers may behave di#erently from the instance for booleans. We call functions that depend on type information type-directed Ad-hoc polymorphism is a compelling addition to a typed programming language . It is well suited for dynamic environments where it can be used to implement dynamic typ- ing , dynamic loading and marshalling . It is also essential to the definition of generic versions of many basic operations such as equality and structural traversals . In particular, ad-hoc polymorphism simplifies programming with complicated data structures , eliminating the need for repetitive \"boilerplate code\" . For example , the implementation of a compiler may include many data structures for representing intermediate languages and many passes over these data structures . Without type-directed programming , the same code for traversing abstract syntax must be implemented for each intermediate language . The generic traversals defined by ad-hoc polymorphism allow the programmer to concentrate on the important parts of a transformation. Currently , there are two forms of ad-hoc polymorphism in typed , functional languages", "label": ["ad-hoc polymorphism", "reflexivity", "intensional type analysis", "generativity"], "stemmed_label": ["ad-hoc polymorph", "reflex", "intension type analysi", "gener"]}
{"doc": "Haskell's type classes allow ad-hoc overloading , or type-indexing , of functions . A natural generalisation is to allow type-indexing of data types as well . It turns out that this idea directly supports a powerful form of abstraction called associated types , which are available in C++ using traits classes . Associated types are useful in many applications , especially for self-optimising libraries that adapt their data representations and algorithms in a type-directed manner.In this paper , we introduce and motivate associated types as a rather natural generalisation of Haskell's existing type classes . Formally , we present a type system that includes a type-directed translation into an explicitly typed target language akin to System F; the existence of this translation ensures that the addition of associated data types to an existing Haskell compiler only requires changes to the front end . INTRODUCTION In a recent OOPSLA paper , Garcia et al . compare the support for generic programming o#ered by Haskell , ML, C++ , C# , and Java , using a graph-manipulation library as a motivating example 11 . They o#er a table of qualitative conclusions , in which Haskell is rated favourably in all respects except one: access to so-called associated types . For example , we may want to represent arrays in a manner that depends on its element type . So , given an element type e, there is an associated type Array e of arrays of those elements # The first two authors have been partly funded by the Australian Research Council under grant number DP0211203. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee. POPL'05 , January 12-14 , 2005 , Long Beach , California , USA. Extending the syntax of Haskell data declarations , we might define Array as follows: data Array data Array data Array (a , PairArray (Array a) (Array b) Here , we represent an array of integers as an unboxed array, an array of booleans as a bit vector , and an array of pairs as a pair of arrays . (We assume that UIntArr and BitVector are built-in types representing unboxed integer arrays and bit vectors respectively.) These specialised representations are more e#cient , in terms of both space and runtime of typical operations , than a type-invariant parametric representation. Data types whose concrete representation depends on one or more type parameters are called type analysing 15 or type indexed 18 . In this paper , we shall demonstrate that type-indexed types can be understood as class-local data type declara- tions , and that in fact this is a natural extension of Haskell's type class overloading system . For example , the", "label": ["self-optimising libraries", "type-directed translation", "type-indexed types", "type classes", "associated types"], "stemmed_label": ["self-optimis librari", "type-direct translat", "type-index type", "type class", "associ type"]}
{"doc": "Ergodicity and throughput bound characterization are addressed for a subclass of timed and stochastic Petri nets , interleaving qualitative and quantitative theories . The nets considered represent an extension of the well-known subclass of marked graphs , defined as having a unique consistent firing count vector , independently of the stochastic interpretation of the net model . In particular , persistent and mono-T-semiflow net subclasses are considered . Upper and lower throughput bounds are computed using linear programming problems defined on the incidence matrix of the underlying net . The bounds proposed depend on the initial marking and the mean values of the delays but not on the probability distributions (thus including both the deterministic and the stochastic cases) . From a different perspective , the considered subclasses of synchronized queuing networks; thus , the proposed bounds can be applied to these networks . Introduction In this paper , which is an improved version of 1 , 1 we study the possibility of obtaining upper and lower bounds on the steady-state performance of two Petri net (PN , for short) subclasses that are characterized by having a unique consistent firing count vector . Although restricted , the two net subclasses represent two different kind of generalizations of marked graphs (MGs , in what follows) , thus some basic results from 2 are briefly recalled . In particular in this work we study the throughput of transitions , defined as the average number of firings per time unit . We derive results that depend only on the mean values and neither on the higher moments nor on the form of the probability distributions of the random variables that describe the timing of the system . Both deterministic and stochastic timings are covered by our bounds . In some sense this independence of the probability distribution is a useful generalization of the results , since higher moments of the delays and forms of the probability distributions are usually unknown for real cases , and difficult to estimate and assess . Another extension that becomes possible taking the bounding approach instead of the exact computation , is that we can derive bounds also in the case of marking non-ergodic systems. We assume the reader is familiar with the structure , firing rules , and basic properties of net models (see 3 for a nice recent survey) . Let us recall some notation here: is a net with re and P ost incidence functions take values in f0; 1g , N is said ordinary . PRE, POST , and are n \\Theta m matrices representing the P re , P ost , and global incidence functions. Vectors Y - 0 , Y T called conservative components (T-semi- flows , also called consistent components) . M (M 0 ) is a marking (initial marking) . Finally , oe represents a fireable sequence , while ~oe is the firing count vector associated to oe . If M is reachable from M 0 (i.e . 9oe s.t . M 0 oeiM ) , then In a PN there is", "label": ["linear programming", "unique consistent firing count vector", "persistent nets", "synchronized queuing networks", "petri nets", "mono-t-semiflow net subclasses", "incidence matrix", "ergodicity", "throughput bounds", "marked graphs"], "stemmed_label": ["linear program", "uniqu consist fire count vector", "persist net", "synchron queu network", "petri net", "mono-t-semiflow net subclass", "incid matrix", "ergod", "throughput bound", "mark graph"]}
{"doc": "A multiple resolution algorithm is presented for segmenting images into regions with differing statistical behavior . In addition , an algorithm is developed for determining the number of statistically distinct regions in an image and estimating the parameters of those regions . Both algorithms use a causal Gaussian autoregressive model to describe the mean , variance , and spatial correlation of the image textures . Together , the algorithms can be used to perform unsupervised texture segmentation . The multiple resolution segmentation algorithm first segments images at coarse resolution and then progresses to finer resolutions until individual pixels are classified . This method results in accurate segmentations and requires significantly less computation than some previously known methods . The field containing the classification of each pixel in the image is modeled as a Markov random field . Segmentation at each resolution is then performed by maximizing the a posteriori probability of this field subject to the resolution constraint . At each resolution , the a posteriori probability is maximized by a deterministic greedy algorithm which iteratively chooses the classification of individual pixels or pixel blocks . The unsupervised parameter estimation algorithm determines both the number of textures and their parameters by minimizing a global criterion based on the AIC information criterion . Clusters corresponding to the individual textures are formed by alternately estimating the cluster parameters and repartitioning the data into those clusters . Concurrently , the number of distinct textures is estimated by combining clusters until a minimum of the criterion is reached . Introduction The objective of texture segmentation is to separate an image into regions of distinct statistical behavior . An implicit assumption in this process is that the statistics of each region are stationary and that each region extends over a significant area . Therefore , it is reasonable to assume that image pixels which are spatially close are likely to be of the same texture . In addition , any texture segmentation algorithm which independently classifies each pixel in an image is likely to perform poorly since locally there may not be sufficient information to make a good decision . For these rea- sons , most segmentation algorithms either implicitly or explicitly impose some form of smoothness in the resulting segmentation . For example , this may be done by dividing the image into arbitrary blocks and classifying the texture of each block separately . However , if the block size chosen is too small , discriminating among similar textures may be difficult . Alternatively , if the block size is too large , regions of differing texture may be lost . In either case , the resulting boundaries will not be accurate since there is no reason to believe that the actual texture boundaries occurred along the block boundaries . Alternatively , a number of authors have proposed more natural methods of imposing smoothness constraints on the segmentation of an image 6 , 4 , 3 , 2 , 1 , 11 . These methods use a random field with smooth spatial behavior to model the", "label": ["statistical behavior", "classification", "variance", "picture processing", "posteriori probability", "deterministic greedy algorithm", "markov random field", "statistics", "textured images", "pattern recognition", "probability", "parameter estimation", "unsupervised texture segmentation", "spatial correlation", "multiple resolution segmentation", "causal gaussian autoregressive model", "coarse resolution", "aic information criterion"], "stemmed_label": ["statist behavior", "classif", "varianc", "pictur process", "posteriori probabl", "determinist greedi algorithm", "markov random field", "statist", "textur imag", "pattern recognit", "probabl", "paramet estim", "unsupervis textur segment", "spatial correl", "multipl resolut segment", "causal gaussian autoregress model", "coars resolut", "aic inform criterion"]}
{"doc": "Model-based recognition and motion tracking depend upon the ability to solve for projection and model parameters that will best fit a 3-D model to matching 2-D image features . The author extends current methods of parameter solving to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation , variable dimensions , or surface deformations . Numerical stabilization methods are developed that take account of inherent inaccuracies in the image measurements and allow useful solutions to be determined even when there are fewer matches than unknown parameters . The Levenberg-Marquardt method is used to always ensure convergence of the solution . These techniques allow model-based vision to be used for a much wider class of problems than was possible with previous methods . Their application is demonstrated for tracking the motion of curved , parameterized objects . Introduction Model-based vision allows prior knowledge of the shape and appearance of specific objects to be used during the process of visual interpretation . Reliable identifications can be made by identifying consistent partial matches between the models and features extracted from the image , thereby allowing the system to make inferences about the scene that go beyond what is explicitly available from the image . By providing this link between perception and prior knowledge of the components of the scene , model-based recognition is an essential component of most potential applications of vision. One important component of model-based vision is the ability to solve for the values of all viewpoint and model parameters that will best fit a model to some matching image features. This is important because it allows some tentative initial matches to constrain the locations of other features of the model , and thereby generate new matches that can be used to verify or reject the initial interpretation . The reliability of this process and the final interpretation can be greatly improved by taking account of all available quantitative information to constrain the unknown parameters during the matching process . In addition , parameter determination is necessary for identifying object sub-categories , for interpreting images of articulated or flexible objects , and for robotic interaction with the objects. In most cases , it is possible to solve for all unknown parameters for a 3-D model from matches to a single 2-D image . However , in some circumstances-such as when both the size and distance of the model is unknown-the accuracy of parameter determination can be substantially improved by simultaneously fitting the model to images taken from more than one viewpoint . The methods presented here can be used in either situation. The locations of projected model features in an image are a non-linear function of the view-point and model parameters . Therefore , the solution is based on Newton's method of linearization and iteration to perform a least-squares minimization . This is augmented by a stabilization method that incorporates a prior model of the range of uncertainty in each parameter and estimates of the standard deviation of each image measurement . This allows useful approximate solutions", "label": ["motion tracking", "curve fitting", "arbitrary curved surfaces", "2d image matching", "levenberg-marquardt method", "picture processing", "3d model", "model based pattern recognition", "pattern recognition"], "stemmed_label": ["motion track", "curv fit", "arbitrari curv surfac", "2d imag match", "levenberg-marquardt method", "pictur process", "3d model", "model base pattern recognit", "pattern recognit"]}
{"doc": "We present an interactive modeling and animation system that facilitates the integration of a variety of simulation and animation paradigms . This system permits the modeling of diverse objects that change in shape , appearance , and behaviour over time . Our system thus extends modeling tools to include animation controls . Changes can be effected by various methods of control , including scripted , gestural , and behavioral specification . The system is an extensible testbed that supports research in the interaction of disparate control methods embodied in controller objects . This paper discusses some of the issues involved in modeling such interactions and the mechanisms implemented to provide solutions to some of these issues.The system's object-oriented architecture uses delegation hierarchies to let objects change all of their attributes dynamically . Objects include displayable objects , controllers , cameras , lights , renderers , and user interfaces . Techniques used to obtain interactive performance include the use of data-dependency networks , lazy evaluation , and extensive caching to exploit inter- and intra-frame coherency . Introduction Over the last two decades , graphics research has concentrated on three main areas , loosely categorized as image synthesis , shape modeling , and behavioral modeling . While image synthesis (ren- dering) was stressed in the late 70s and early 80s , the emphasis has recently shifted to the modeling of various objects and phenomena - indeed , many researchers believe that graphics today is model- ing . We wish to expand the definition of \"modeling\" to include the realms of simulation , animation , rendering , and user interaction. Since the mid-60s , our research has focused on tools for creating electronic books , specifically hypermedia documents with interactive illustrations 21 . Such illustrations allow readers to interact not just with a canned \"movie\" but with a stored , parameterized model of a phenomenon they are trying to understand . Interactive illustrations require simulation and animation of the underlying model in an interactive , real-time environment. Because we want to create interactive illustrations for a wide range of topics , our modeling tools must handle large (and exten- sible) sets of objects and operations on those objects that change any of their physical attributes over time . We need a rich collection of methods for controlling the time-varying structure and behavior of the objects , especially as they interact under various application-dependent systems of rules . In other words , we cannot use a single, \"silver-bullet\" modeling or animation technique. The essence of animation control is the specification of time-varying properties . Traditional graphics packages (such as PHIGS+, Dor-e , and RenderMan) , however , have no explicit notion of time. In these packages , time can be specified only implicitly , as the byproduct of a sequence of editing operations on the database or display-list representation . While today's animation systems do allow time to be explicitly specified , they generally permit only a subset of an object's properties to vary over time . They also tend to be restricted in the objects", "label": ["delegation", "real-time animation", "user interaction", "object-oriented design", "interactive illustrations", "electronic books"], "stemmed_label": ["deleg", "real-tim anim", "user interact", "object-ori design", "interact illustr", "electron book"]}
{"doc": "This paper introduces new techniques for interactive piecewise flattening of parametric 3-D surfaces , leading to a non-distorted , hence realistic , texture mapping . Cuts are allowed on the mapped texture and we make a compromise between discontinuities and distortions . These techniques are based on results from differential geometry , more precisely on the notion of \"geodesic curvature\": isoparametric curves of the surface are mapped , in a constructive way , onto curves in the texture plane with preservation of geodesic curvature at each point . As an application , we give a concrete example which is a first step towards an efficient and robust CAD tool for shoe modeling . Introduction Texture mapping techniques are widely used to reproduce textural information available in a planar image onto a 3-D surface . This is made possible by making a correspondence between a planar image and a 3-D surface , in order to give each sample point of the output screen reached by the projected 3-D surface an intensity value computed from a point or a set of points of the 2-D image sample . This correspondence is called the \"mapping function\". Catmull 8 first introduced a recursive subdivision algorithm to map a 2-D rectangular image onto a 3-D bicubic patch . This method has been refined and enhanced by several authors 9 , 6 . These techniques are equivalent to warping the planar rectangle until it takes the shape of the bicubic patch . Unfortunately , these techniques do not preserve distances or angles , resulting in spatial distortions of texture patterns , which can sometimes change the visual appearance of the texture on the surface . Other authors have proposed solutions to reduce these distortions . Bier et al . 5 proposed a 2-part mapping which consists in decomposing the mapping in two steps: the texture pattern is first embedded in a 3-D intermediate surface and then projected onto the target surface in a way that depends only on the geometry of the target object . The distortion is reduced by heuristically choosing the appropriate intermediate surface and the projection method . Unfortunately this is not always easy to do . Fiume et al . 13 have proposed a \"polygonal conformal mapping\" to map a polygon (e.g., a square) onto an arbitrary convex polygon with preservation of angles . This technique gives good results on polygons for some applications . However , the technique does not preserve distances, Current address: Institut Francais du P'etrole 1 et 4 avenue de thus creating distortions . Moreover , it is not easily extendable to In 17 , Ma et al . used an optimization technique to minimize distortions for general surfaces . The mapping is performed on a grid of sample points of the 3-D surface . Starting from an arbitrary initial mapping , the algorithm converges to the optimal mapping by minimizing a global metric taking into account distances between each point and its direct neighbours on the 3-D grid . A similar technique was proposed at the same time by", "label": ["differential geometry", "geodesic curvature", "piecewise surface flattening", "non distorted texture mapping"], "stemmed_label": ["differenti geometri", "geodes curvatur", "piecewis surfac flatten", "non distort textur map"]}
{"doc": "A multiorder routing strategy is developed which is loop-free even in the presence of link/node failures . Unlike most conventional methods in which the same routing strategy is applied indiscriminately to all nodes in the network , nodes under this proposal may adopt different routing strategies according to the network structure . Formulas are developed to determine the minimal order of routing strategy for each node to eliminate looping completely . A systematic procedure for striking a compromise between the operational overhead and network adaptability is proposed . Several illustrative examples are presented . INTRODUCTION For packet switching networks , routing is a key to their performance and reliability 1 , 2 . Among the various routing algorithms proposed thus far 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , distributed adap- ive routing algorithms have drawn considerable attention because of their high potential for l e reliability and adaptability . The ARPANET's previous routing strategy (APRS) 3 is a typica xample of these . Under APRS , the path from one node to every other node is not determined a e in advance . Instead , every node maintains a network delay table to record the shortest delay vi ach link emanating from the node . A minimal delay table in a node , which contains the e delays of the optimal paths (i.e. , the path requiring the minimal delay) from that node to all th ther nodes is passed to all of its adjacent nodes as a routing message at every fixed time inter- _____ rout e val (e.g. , 128 ms in APRS) . Note , however , that under APRS each node sends the sam ng message to all__ its neighbors without making any distinction between receiving nodes . This forces some nodes to receive useless routing messages , thereby resulting in undesirable looping n case of link/node failures . The network recovery process after certain failures will thus be F delayed 11 . An example of the network recovery process under APRS for the network in ig . 1 is given in Table 1 . Notice that it requires 20 , 19 , 17 and 20 time intervals , respectively for N , N , N and N to get their new optimal paths to N . A The routing algorithms proposed in 5 , 6 , 7 have the same major features as the one i PRS , except they employ more provisions to cope with network failures . However , they still A cannot avoid some inherent drawbacks such as poor adaptability and inefficiency 7 , 12 . The RPANET's current routing strategy (ACRS) 8 uses a different approach for handling routing tmessages . In ACRS , every node in the network is required to keep and maintain informa ion of the entire network . ACRS will always reach a correct routing decision as long as the s global information at each node is accurate and consistent . However , this strategy require e every node to", "label": ["minimal order loop free routing strategy", "network adaptability", "packet switching", "operational overhead", "computer networks", "multiorder routing strategy"], "stemmed_label": ["minim order loop free rout strategi", "network adapt", "packet switch", "oper overhead", "comput network", "multiord rout strategi"]}
{"doc": "In constructive solid geometry , geometric solids are represented as trees whose leaves are labeled by primitive solids and whose internal nodes are labeled by set-theoretic operations . A bounding function in this context is an upper or lower estimate on the extent of the constituent sets; such bounds are commonly used to speed up algorithms based on such trees . We introduce the class of totally consistent bounding functions , which have the desirable properties of allowing surprisingly good bounds to be built quickly . Both outer and inner bounds can be refined using a set of rewrite rules , for which we give some complexity and convergence results . We have implemented the refinement rules for outer bounds within a solid modeling system , where they have proved especially useful for intersection testing in three and four dimensions . Our implementations have used boxes as bounds , but different classes (shapes) of bounds are also explored . The rewrite rules are also applicable to relatively slow , exact operations , which we explore for their theoretical insight , and to general Boolean algebras . Results concerning the relationship between these bounds and active zones are also noted . Introduction Outer bounds are commonly used to speed up geometric algorithms . For example , if we wish to tell whether two geometric entities intersect , then if we form spheres around the entities and the spheres do not intersect , we deduce that the entities cannot intersect . This concept of a bound is so 'obvious' that it may seem strange that we can spend an entire paper talking about bounds! However , some subtleties arise if we allow bounds which are not bounds in the normal sense but do have desirable computational properties . We will show that these other types of bounds are possible , and useful , when geometric entities are described constructively. In Constructive Solid Geometry (CSG) , we build up complicated shapes from a collection of simple shapes 11 . We can think of a CSG description as a tree , in which the internal nodes correspond to set operations , and the leaf nodes correspond to the simple shapes , or primitives , and the branches of the tree imply functional application . To compute the shape represented by the tree , we start at the leaves and work our way up the tree , applying set operations as we go . Many modelling systems use CSG as their primary construction method (e.g. , 3 , 6 ) , and many other systems permit constructive operations in making up their data-structures (e.g. , 2 ). The normal way of applying bounds with a CSG tree is to attach suitable supersets of the primitives (the bounds) to the leaf nodes . However we can then extend the notion of a bound to every node in the tree , as follows . If we have a binary node T , corresponding to a union operation , and we know that its child nodes represent shapes that are", "label": ["representation simplification", "robotics", "collision detection", "constructive solid geometry", "solid modeling", "boolean algebra", "interference detection"], "stemmed_label": ["represent simplif", "robot", "collis detect", "construct solid geometri", "solid model", "boolean algebra", "interfer detect"]}
{"doc": "In this paper three problems for a connectionist account of language are considered:1 . What is the nature of linguistic representations?2 . How can complex structural relationships such as constituent structure be represented?3 . How can the apparently open-ended nature of language be accommodated by a fixed-resource system?Using a prediction task , a simple recurrent network (SRN) is trained on multiclausal sentences which contain multiply-embedded relative clauses . Principal component analysis of the hidden unit activation patterns reveals that the network solves the task by developing complex distributed representations which encode the relevant grammatical relations and hierarchical constituent structure . Differences between the SRN state representations and the more traditional pushdown store are discussed in the final section . INTRODUCTION In recent years there has been considerable progress in developing connectionist models of language . This work has demonstrated the ability of network models to account for a variety of phenomena in phonology (e.g. , Gasser & Lee , 1990; Hare , 1990; Touretzky , 1989; Touretzky & Wheeler , 1989) , morphology (e.g. , Hare , Corina , Cottrell, 1989; MacWhinney et al , 1989; Plunkett & Marchman , 1989; Rumelhart & McClelland, 1986b; Ryder , 1989) , spoken word recognition (McClelland & Elman , 1986) , written word recognition (Rumelhart &McClelland , 1986; Seidenberg &McClelland , 1989) , speech production (Dell , 1986; Stemberger , 1985) , and role assignment (Kawamoto & McClelland, 1986; Miikkulainen & Dyer , 1989a; St . John & McClelland , 1989) . It is clear that connectionist networks have many properties which make them attractive for language processing At the same time , there remain significant shortcomings to current work . This is hardly surprising: natural language is a very difficult domain . It poses difficult challenges for any paradigm . These challenges should be seen a positive light . They test the power of the framework and can also motivate the development of new connectionist approaches In this paper I would like to focus on what I see as three of the principal challenges to a successful connectionist account of language . They are: hat is the nature of the linguistic representations? ow can complex structural relationships such as constituency be ow can the apparently open-ended nature of language be accommodated by a fixed-resource system? Interestingly , these problems are closely intertwined , and all have to do with representation (In press , Machine Learning) One approach which addresses the first two problems is to use localist represen- tations . In localist networks , nodes are assigned discrete interpretations . In such models (e.g . Kawamoto & McClelland , 1986; St . John & McClelland , 1988) nodes may represent grammatical roles (e.g. , agent , theme , modifier) or relations (e.g. , subject , daughter-of). These may be then bound to other nodes which represent the word-tokens which instantiate them either by spatial assignment (Kawamoto & McClelland , 1986; Miikkulainen & Dyer , 1989b) , concurrent activation (St . John & McClelland , 1989) , or various other techniques (e.g. , Smolensky ,", "label": ["grammatical structure", "simple recurrent networks", "distributed representations"], "stemmed_label": ["grammat structur", "simpl recurr network", "distribut represent"]}
{"doc": "The authors present embeddings of complete binary trees into butterfly networks with or without wrap-around connections . Let m be an even integer and q=m+(log m)-1 . The authors show how to embed a 2/sup q+1/-1-node complete binary tree T(q) into a (m+1)2/sup m+1/-node wrap-around butterfly B/sub w/(m+1) with a dilation of 4 , and how to embed T(q) into a (m+2)2/sup m+2/-node wrap-around butterfly B/sub w/(m+2) with an optimal dilation of 2 . They also present an embedding of a wrap-around butterfly B/sub w/(m) into a (m+1)2/sup m/-node no-wrap-around butterfly B(m) with a dilation of 3 . Using this embedding it is shown that T(q) can be embedded into a no-wrap butterfly B(m+1) (resp . B(m+2)) with a dilation of 8 (resp . 5) . Introduction is an important issue in parallel processing 2 , 3 , 4 , 5 , 6 , 7 , 8 , 10 , 12 . In this paper we study the relationship between a complete binary tree network T and a butterfly network B and present embeddings of T into B: Let T (q) be a 2 q+1 \\Gamma 1-node complete binary tree, is an even integer . Let Bw (m) (resp . B(m)) be a m2 m - node (resp . (m butterfly with (resp . without) wrap-around connections. In 4 , Bhatt et . al . showed how to embed T (q) into Bw (m+3) with a dilation of 4: While this embedding has constant expansion , it uses a butterfly that has 8 times 1 as many nodes as necessary . In this paper we first present two improved embeddings for T (q): One embeds T (q) into Bw (m a dilation of 4: Another one embeds T (q) into with an optimal dilation of 2: These two embeddings and the one presented in 4 , use the wrap-around connections of a butterfly heavily . We show that a butterfly with wrap-around connections is (up to a constant factor) no more powerful than one without wrap-around connections . More precisely , we show how to embed Bw (m) into a no wrap-around butterfly network B(m) with a dilation of 3: Using this embedding we are able to embed T (q) into B(m + 1) with a dilation of 8 and into B(m + 2) with a dilation of 5: We next give definitions and notation used throughout this paper. An embedding ! f; g ? of T into B is defined by a bijective mapping f from the nodes of T to the nodes of B together with a mapping g that maps every edge of T onto a path g(e) connecting f(v) and f(w) . We refer to f as the assignment . Two commonly and extensively studied cost measures of an embedding are the dilation and the expansion 1 , 4 , 9 , 11 . The dilation is defined as the maximum distance in B between two adjacent nodes in T , and the expansion is defined as the ratio of the number of nodes in B to the", "label": ["multiprocessor interconnection networks", "butterfly networks", "trees mathematics", "wrap-around connections", "embeddings", "complete binary trees"], "stemmed_label": ["multiprocessor interconnect network", "butterfli network", "tree mathemat", "wrap-around connect", "embed", "complet binari tree"]}
{"doc": "A packaging system that allows diverse software components to be easily interconnected within heterogeneous programming environments is described . Interface software and stubs are generated for programmers automatically once the programmers express their application's geometry in a few simple rules and module interconnection language attributes . By generating custom interface code for each application , based on analysis and extraction of interfacing requirements , the system is able to produce executables whose run-time performance is comparable to manually integrated applications . The system is implemented within the Unix environment . INTRODUCTION In an era of escalating software costs , reuse of software components is an economic necessity. Equally acute is the need to integrate components in the presence of heterogeneity , whether in source languages , architectures , or communication media . Unfortunately , additional software must be developed to implement interfacing decisions for each heterogeneous configuration . Application programs must be adapted to use the desired architecture and communication media, or they must be extended to do so . Interface software can be expensive to create , and must be rewritten whenever components are reused in different configurations. One way to increase the potential for software reuse is to limit the growth of dependencies between components . For example , module interconnection languages (MILs) have been effective in managing structural dependencies , i.e. , those concerning visibility or compatibility of variables and interface names 5 . However , the availability of heterogeneous systems increases the likelihood for geometric coupling , which are dependencies due to the relation between components and where they execute in the underlying architecture . To minimize these dependencies , programmers typically organize their programs so that calls to an underlying communication system are as isolated as possible . They hope that stubs will localize the impact of subsequent changes in the communication system , therefore reduce the cost of reusing the component . This approach is generally successful , but there is still the manual tasks of identifying the remote interfaces, creating the stub code , and determining how the stub should be integrated with the application. When programmers must adapt their components for each new application , some economic benefits of reuse are lost . In order to regain them , we must turn to automatic techniques , from which several questions arise . How do we generate the interface software needed for one application component to interoperate with another? How are the components and interface software packaged together into executable objects? How do we analyze source programs to discover potential dependencies in the first place? These are problems we focus on in this paper. We will describe a method for automating the generation of custom interface software for heterogeneous configurations . Whereas previous research has focused on 'stub generation' alone , our approach generates stubs as well as the configuration methods needed to integrate an application. Using this approach , developers may build support tools that hide the details of how software configurations are 'packaged' into executables. This method is implemented in a system called", "label": ["heterogeneous execution environments", "packaging system", "module interconnection language attributes", "configuration management", "interfacing requirements", "diverse software components", "user interfaces", "heterogeneous programming environments", "custom interface code", "geometry", "programming environments", "unix environment", "automatic programming"], "stemmed_label": ["heterogen execut environ", "packag system", "modul interconnect languag attribut", "configur manag", "interfac requir", "divers softwar compon", "user interfac", "heterogen program environ", "custom interfac code", "geometri", "program environ", "unix environ", "automat program"]}
{"doc": "Program slicing is applied to the software maintenance problem by extending the notion of a program slice (that originally required both a variable and line number) to a decomposition slice , one that captures all computation on a given variable , i.e. , is independent of line numbers . Using the lattice of single variable decomposition slices ordered by set inclusion , it is shown how a slice-based decomposition for programs can be formed . One can then delineate the effects of a proposed change by isolating those effects in a single component of the decomposition . This gives maintainers a straightforward technique for determining those statements and variables which may be modified in a component and those which may not . Using the decomposition , a set of principles to prohibit changes which will interfere with unmodified components is provided . These semantically consistent changes can then be merged back into the original program in linear time . Introduction In \"Kill that Code!,\" 32 Gerald Weinberg alludes to his private list of the world's most expensive program errors . The top three disasters were caused by a change to exactly one line of code: \"each one involved the change of a single digit in a previously correct program.\" The argument goes that since the change was to only one line , the usual mechanisms for change control could be circumvented . And , of course , the results were catastrophic . Weinberg offers a partial explanation: \"unexpected linkages,\" i.e. , the value of the modified variable was used in some other place in the program . The top three of this list of ignominy are attributed to linkage . More recently , in a special section of the March , 1987 issue of IEEE Transactions on Software Engineering , Schneidewind 30 notes that one of the reasons that maintenance is difficult is that it is hard to determine when a code change will affect some other piece of code . We present herein a method for maintainers to use that addresses this issue. While some may view software maintenance as a less intellectually demanding activity than development, the central premise of this work is that software maintenance is more demanding . The added difficulty is due in large part to the semantic constraints that are placed on the maintainer . These constraints can be loosely characterized as the attempt to avoid unexpected linkages . Some 4 , 14 have addressed this problem by attempting to eliminate these semantic constraints and then providing the maintainer with a tool that will pinpoint potential inconsistencies after changes have been implemented . This makes maintenance appear to be more like development , since the programmer does not need to worry about linkages: once the change is made , the tool is invoked and the inconsistencies (if any) are located . One would expect that the tool would proceed to resolve these inconsistencies , but it has been shown that this problem is NP-hard 14 . Thus , the maintainer can be presented with a problem", "label": ["set inclusion", "linear time", "program testing", "software maintenance", "line number", "software maintenance problem", "semantically consistent changes", "program slice", "program slicing", "slice-based decomposition", "single variable decomposition slices", "unmodified components"], "stemmed_label": ["set inclus", "linear time", "program test", "softwar mainten", "line number", "softwar mainten problem", "semant consist chang", "program slice", "program slice", "slice-bas decomposit", "singl variabl decomposit slice", "unmodifi compon"]}
{"doc": "An adaptive program is one that changes its behavior base on the current state of its environment . This notion of adaptivity is formalized , and a logic for reasoning about adaptive programs is presented . The logic includes several composition operators that can be used to define an adaptive program in terms of given constituent programs; programs resulting from these compositions retain the adaptive properties of their constituent programs . The authors begin by discussing adaptive sequential programs , then extend the discussion to adaptive distributed programs . The relationship between adaptivity and self-stabilization is discussed . A case study for constructing an adaptive distributed program where a token is circulated in a ring of processes is presented . Introduction An adaptive program is one that changes its behavior according to its environment . Often, the motivation for changing the program behavior is to satisfy some performance criteria: the performance of one behavior is superior to that of other behaviors in some environment . In this case , adaptivity is a technique for performance optimization in a dynamic environment. Another reason for changing the program behavior has to do with logical correctness: only one behavior is correct in a certain environment . In this case , adaptivity is a matter of the program functioning properly in a changing environment. This paper is an investigation of a particular class of adaptive programs . The following examples motivate the investigation. ffl Consider a system of distributed processes that communicate via a shared bus . At each instance , the processes use either one of two protocols to control their access to the bus - an Ethernet-like protocol 11 and a token-ring protocol 9 . The Ethernet-like protocol performs well during periods of low contention (when a small number of processes need to use the bus) , but performs poorly during periods of high con- tention . On the other hand , the token-ring protocol works well during periods of high contention , but is less efficient than the Ethernet-like protocol during periods of low contention . The system should dynamically switch between the Ethernet-like protocol and the token-ring protocol based on the activity of the bus . Ideally , any switch from one protocol to another should occur instantaneously at all processes; however , because the system is distributed , there may be a short period in which some processes have switched protocols while other processes have not. ffl A resource allocation program is required to minimize the amortized cost of resource allocation . Two strategies are employed for resource allocation: a pessimistic strategy and an optimistic one . Comparing the amortized cost of the two strategies , it happens that the pessimistic strategy has a lower cost when worst-case resource requests are a significant proportion of all resource requests; otherwise the optimistic strategy has a lower cost . The program monitors resource requests and , from time to time , switches from one strategy to another as is appropriate. ffl In a distributed system for traffic control , traffic routes are changed", "label": ["adaptivity", "token ring networks", "adaptive distributed programs", "formal logic", "adaptive systems", "composition operators", "self-stabilization", "programming theory", "parallel programming", "adaptive sequential programs", "constituent programs"], "stemmed_label": ["adapt", "token ring network", "adapt distribut program", "formal logic", "adapt system", "composit oper", "self-stabil", "program theori", "parallel program", "adapt sequenti program", "constitu program"]}
{"doc": "The efficiency of the basic operations of a NUMA (nonuniform memory access) multiprocessor determines the parallel processing performance on a NUMA multiprocessor . The authors present several analytical models for predicting and evaluating the overhead of interprocessor communication , process scheduling , process synchronization , and remote memory access , where network contention and memory contention are considered . Performance measurements to support the models and analyses through several numerical examples have been done on the BBN GP1000 , a NUMA shared-memory multiprocessor . Analytical and experimental results give a comprehensive understanding of the various effects , which are important for the effective use of NUMA shared-memory multiprocessor . The results presented can be used to determine optimal strategies in developing an efficient programming environment for a NUMA system . a distributed memory multicomputer environment in which data sharing and communication are conducted by message-passing through the network . The bus-based shared memory multiproces- sors , such as the Encore Multimax and Sequent Symmetry always make an uniform memory access (UMA) to the shared data because of the exclusive use of the bus per data access . The simple bus structure limits the size of the UMA multiprocessor to a small scale , for example up to cessors . In a NUMA architecture , the shared memory environment is built through a distributed architecture - each processor has its local memory and is also able to access to all other memory models through a switching network . Therefore , a NUMA architecture can scale large number of processors in shared memory multiprocessor design . Examples of current NUMA architectures include BBN Butterfly family (see e.g . 3 - 5 , 16 , 23 ) , Cedar at the University of Illinois (see e.g . 14 , 26 ) , the IBM RP3 (see e.g . 21 ) , Cm* and PLUS at Carnegie-Mellon University (see e.g . 9 , 17 , 22 ) , Hector (see 25 ) and Paradigm (see 11 ) , in which the BBN butterfly machines are the only systems commercially available , and the rest are research model architectures. 1.1 Programming models on a NUMA architectures Programming models on a NUMA architecture can be classified into three types: distributed mem- partially shared memory and fully shared memory . Under the distributed programming model, each node is viewed as a complete computer supported by a processor , a local memory and some I/O facilities physically on one board which connects to all other nodes in the system . An important factor in the efficiency of the distributed memory model is the effectiveness with which data can be exchanged among its many nodes . The partially shared memory programming model provides noncached access to shared memory , with program code and private data stored in local memory. Programming requires partitioning the application across all the nodes in load time which explores the processor locality best but provides no dynamic process scheduling in run time . The shared memory synchronization primitives such as a barrier are supported for synchronizing processors", "label": ["analytical models", "programming environment", "process synchronization", "bbn gp1000", "parallel processing performance", "nonuniform memory access", "multiprocessing systems", "performance evaluation", "process scheduling", "network contention", "parallel processing", "scheduling", "numa shared-memory multiprocessor", "interprocessor communication", "remote memory access", "memory contention", "optimal strategies"], "stemmed_label": ["analyt model", "program environ", "process synchron", "bbn gp1000", "parallel process perform", "nonuniform memori access", "multiprocess system", "perform evalu", "process schedul", "network content", "parallel process", "schedul", "numa shared-memori multiprocessor", "interprocessor commun", "remot memori access", "memori content", "optim strategi"]}
{"doc": "Previous work on superimposed coding has been characterized by two aspects . First , it is generally assumed that signatures are generated from logical text blocks of the same size; that is , each block contains the same number of unique terms after stopword and duplicate removal . We call this approach the fixed-size block (FSB) method , since each text block has the same size , as measured by the number of unique terms contained in it . Second , with only a few exceptions 6,7,8,9,17 , most previous work has assumed that each term in the text contributes the same number of ones to the signature (i.e. , the weight of the term signatures is fixed) . The main objective of this paper is to derive an optimal weight assignment that assigns weights to document terms according to their occurrence and query frequencies in order to minimize the false-drop probability . The optimal scheme can account for both uniform and nonuniform occurence and query frequencies , and the signature generation method is still based on hashing rather than on table lookup . Furthermore , a new way of generating signatures , the fixed-weight block (FWB) method , is introduced . FWB controls the weight of every signature to a constant , whereas in FSB , only the expected signature weight is constant . We have shown that FWB has a lower false-drop probability than that of the FSB method , but its storage overhead is slightly higher . Other advantages of FWB are that the optimal weight assignment can be obtained analytically without making unrealistic assumptions and that the formula for computing the term signature weights is simple and efficient . Introduction Many applications such as library systems and office automation systems must access to a large amount of textual data . Since traditional database management systems are mainly for handling formatted records , they have limited facilities for retrieving textual data . One approach which has been widely studied as an efficient access method for text retrieval is the signature file method 6,9,12 . A signature file has a storage overhead much smaller than that of an inverted file . Its simple file structure facilitates database maintenance (e.g., fast insertion and deletion) as well as parallel search on special hardware 10 and general-purpose parallel computers 19 . Also , it can support both text retrieval and multiattribute retrieval in relational databases . However , signature files suffer from two drawbacks: (1) They are slow compared to inverted files , and (2) they produce false drops; that is , the signature file may identify a block as one satisfying the query but in fact it is not. The first problem stems from the fact that the size of the signature file is proportional to the size of the database . Thus , a straightforward , exhaustive , search algorithm on the signature file will have a linear time complexity with respect to the database size , and the performance will become a problem for large databases. Many techniques have been", "label": ["signature file", "optimization", "access method", "coding methods", "text retrieval", "information retrieval", "document retrieval", "superimposed coding"], "stemmed_label": ["signatur file", "optim", "access method", "code method", "text retriev", "inform retriev", "document retriev", "superimpos code"]}
{"doc": "Two of the more important concurrent logic programming languages with nonflat guards are GHC and Parlog . They balance the requirements of having clean semantics and providing good control facilities rather differently , and their respective merits are compared and contrasted . Since concurrent logic programming would benefit from both , but neither language is able to express all the programs expressible in the other language , a lingua franca of these languages is defined and justified . A method is given for translating GHC and Parlog to and from it . The method preserves the arities and execution conditions of each clause . It enables a lingua franca implementation to support both languages transparently , and to provide a simple concurrent logic programming language suitable for programming in its own right . Introduction Among concurrent logic programming or CLP languages like Concurrent Prolog 16 two of the most prominent are GHC 21 and Parlog 6 . GHC and Parlog have similar execution models but complementary virtues as will be argued . Hence it could be desirable to find some common denominator of both languages , which is sufficiently expressive to be worth programming in its own right , and yet is sufficiently close to both languages to be inter- translatable with them . Implementations of this language would support programming in GHC and Parlog as well as in its own common denominator style . If this lingua franca was simpler to implement than either GHC and Parlog , then the benefits of a more streamlined implementation could be realised as well . This paper describes such a lingua franca. 2 . GHC and Parlog A GHC or Parlog program is a set of relations R 1 , . , R n . Each R i is made up of guarded Horn clauses of the same name and arity . In Edinburgh Prolog syntax where H , G 1 , . G m , are atomic formulae (unitary Prolog goals) each clause has the following form H :- G 1 and . and G m | B 1 and . and B n The clause's head H gives its relation name and arity , and the G i s and B j s are its guard and body goals , separated by the commitment operator | . The meta-symbol and signifies a conjunction operator . The primitive true , which always succeeds , fills empty guards or bodies . The clause's declarative reading is H is true if G 1 and . and G m and B 1 and . and B n are true and is a place filler in GHC for the parallel conjunction operator \",\" , and in Parlog for either the parallel \",\" or the sequential conjunction operator \"&\" . One or more clauses form an ordered relation or . or C n . where each C i is a guarded Horn clause , or is a meta-symbol acting as a place filler for a clause search operator , and the symbol \".\" terminates the relation . In", "label": ["parallel languages", "nonflat guards", "ghc", "language translation", "concurrent logic programming languages", "execution conditions", "logic programming", "lingua franca", "clean semantics", "parlog", "parallel programming", "control facilities"], "stemmed_label": ["parallel languag", "nonflat guard", "ghc", "languag translat", "concurr logic program languag", "execut condit", "logic program", "lingua franca", "clean semant", "parlog", "parallel program", "control facil"]}
{"doc": "A single method for normalizing the control-flow of programs to facilitate program transformations , program analysis , and automatic parallelization is presented . While previous methods result in programs whose control flowgraphs are reducible , programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods . In particular , all control-flow cycles are normalized into single-entry , single-exit while loops and all GOTOs are eliminated . Furthermore , the method avoids problems of code replication that are characteristic of node-splitting techniques . This restructuring obviates the control dependence graph , since afterwards control dependence relations are manifest in the syntax tree of the program . Transformations that effect this normalization are presented , and the complexity of the method is studied . Introduction The problem we are considering here is the normalization of the control-flow of programs with the goal of facilitating program transformations , program This work was supported in part by the National Science Foundation under Grant No . NSF MIP-8410110 , the U.S . Department of Energy under Grant No . DE-FG02- 85ER25001 , the Office of Naval Research under Grant No . ONR N00014-88-K-0686 , the U.S . Air Force Office of Scientific Research under Grant No . AFOSR-F49620-86-C- 0136 , and by a donation from the IBM Corporation. analysis , and automatic parallelization . There are several ways in which our technique makes these processes easier. First , it reduces the number of syntactic constructions that must be treated by the system of analysis or transformation . This lessens the complexity of many compilation algorithms , which are often driven by the structure of the program . If the program structure is highly regular , the number of cases and conditions that must be considered to analyze or parallelize the program is simply decreased. Second , it converts all control-flow cycles into single-entry , single-exit while loops and eliminates all branching instructions . These may have dramatic consequences on compilation . For example , loops that contain exit branches are difficult to parallelize since the number of iterations they will perform is unknown prior to their execution . Likewise , goto's may be used to create cycles of control-flow . These hidden loops may cause a loss of parallelism , both because the loops they describe are missed by techniques of parallelization that apply only to do loops , and also because the control-flow of other loops and sometimes entire subroutines may be disturbed by such cycles . Similarly the use of goto's makes program transformations and analyses more difficult and inefficient in general , for the reason that the simple compositionality of control-flow is lost. In terms of semantics , we may say that in the absence of goto's , a direct semantics may be given , whereas in their presence , a continuation semantics is needed . The increased complexity of a continuation semantics is translated to increased complexity in any program analysis that models the semantics , e.g., abstract interpretation", "label": ["node-splitting techniques", "parallel algorithms", "automatic parallelization", "control dependence relations", "control flowgraphs", "complexity", "graph theory", "control-flow cycles", "computational complexity", "syntax tree", "gotos", "structured programming", "control-flow normalization algorithm"], "stemmed_label": ["node-split techniqu", "parallel algorithm", "automat parallel", "control depend relat", "control flowgraph", "complex", "graph theori", "control-flow cycl", "comput complex", "syntax tree", "goto", "structur program", "control-flow normal algorithm"]}
{"doc": "In shared-memory parallel programs that use explicit synchronization , race conditions result when accesses to shared memory are not properly synchronized . Race conditions are often considered to be manifestations of bugs , since their presence can cause the program to behave unexpectedly . Unfortunately , there has been little agreement in the literature as to precisely what constitutes a race condition . Two different notions have been implicitly considered: one pertaining to programs intended to be deterministic (which we call general races) and the other to nondeterministic programs containing critical sections (which we call data races) . However , the differences between general races and data races have not yet been recognized . This paper examines these differences by characterizing races using a formal model and exploring their properties . We show that two variations of each type of race exist: feasible general races and data races capture the intuitive notions desired for debugging and apparent races capture less accurate notions implicitly assumed by most dynamic race detection methods . We also show that locating feasible races is an NP-hard problem , implying that only the apparent races , which are approximations to feasible races , can be detected in practice . The complexity of dynamically locating apparent races depends on the type of synchronization used by the program . Apparent races can be exhaustively located efficiently only for weak types of synchronization that are incapable of implementing mutual exclusion . This result has important implications since we argue that debugging general races requires exhaustive race detection and is inherently harder than debugging data races (which requires only partial race detection) . Programs containing data races can therefore be efficiently debugged by locating certain easily identifiable races . In contrast , programs containing general races require more complex debugging techniques . Introduction In shared-memory parallel programs , if accesses to shared memory are not properly synchronized , time-dependent failures called race conditions can result . Race conditions occur when different processes access shared data without explicit synchronization . Because races can cause the program to behave in ways unexpected by the programmer , detecting them is an important aspect of debugging . However , in the literature , there seems to be little agreement as to precisely what constitutes a race condition . Indeed , two different notions have been used , but the distinction between them has not been previously recognized . Because no consistent terminology has appeared, several terms have been used with different intended meanings , such as access anomaly 6-8 , 12 , 18 , data race 1 , 4 , 5 , 11 , 16 , 20 , 22 , critical race 13 , harmful shared-memory access 24 , race condition 10 , 26 , or just race 2 , 9 , 17 . This paper explores the nature of race conditions and uncovers some previously hidden issues regarding the accuracy and complexity of dynamic race detection . We present the following results. (1) Two fundamentally different types of races , that capture different kinds of", "label": ["race conditions", "critical sections", "nondeterminacy", "parallel programs", "debugging", "data races"], "stemmed_label": ["race condit", "critic section", "nondeterminaci", "parallel program", "debug", "data race"]}
{"doc": "Qualitative models arising in artificial intelligence domain often concern real systems that are difficult to represent with traditional means . However , some promise for dealing with such systems is offered by research in simulation methodology . Such research produces models that combine both continuous and discrete-event formalisms . Nevertheless , the aims and approaches of the AI and the simulation communities remain rather mutually ill understood . Consequently , there is a need to bridge theory and methodology in order to have a uniform language when either analyzing or reasoning about physical systems . This article introduces a methodology and formalism for developing multiple , cooperative models of physical systems of the type studied in qualitative physics . The formalism combines discrete-event and continuous models and offers an approach to building intelligent machines capable of physical modeling and reasoning . Introduction Humans appear to use qualitative models when answering questions such as \"What happens after the pot of water heats up?\" or \"What caused the water to overflow the pot?\" Whether they actually do use qualitative models is not something that we will address in this paper. We will address , instead , the relationship between qualitative and quantitative modeling from the perspective of systems and simulation theory and methodology 13 , 14 . This work was prompted by two needs: (1) a need to bridge gaps between the artificial intelligence (AI) and simulation communities' representations of system models , and (2) a need to derive more formal approaches to the development of models for systems typically studied by AI qualitative modellers . With respect to the AI and simulation communities , both groups have terminology that is very similar in focus . For instance , an \"envisionment\" 5 would be termed a \"reachability tree\" or \"finite state automaton\" in the systems literature , and a \"landmark\" 21 would be termed a \"discrete event.\" There are many other correlations; we name four of them in table 1 . A more complete discussion of the commonalities and points of controversy is given by Fishwick and Zeigler 15 . In any event , there are enough similarities in the goals of AI and simulation research to contend that methods in simulation modeling can play a strong role in AI. There has been a considerable amount of research performed in the AI sub-disciplines of qualitative reasoning 3 , 39 and simulation 21 , qualitative physics 17 and model based reasoning 34 . The chief problems being addressed by AI researchers in qualitative simula- tion , for instance , revolve around reducing the explosive number of states obtained during envisionment 22 , 36 by applying more constraints . The explosion is a result of having a model whose structure and parameters are too ill-defined . Simulation researchers have dealt with fuzzy parameters 10 , 9 ; however , there has been little simulation research into the problem of studying systems whose structural -rather than parametric- constraints are uncertain (i.e. , not knowing whether two states are joined in the structure of a finite state automaton).", "label": ["combined simulation", "abstraction levels", "qualitative simulation", "homomorphism", "systems theory", "multimodeling"], "stemmed_label": ["combin simul", "abstract level", "qualit simul", "homomorph", "system theori", "multimodel"]}
{"doc": "A relational database workload analyzer (REDWAR) is developed to characterize the workload in a DB2 environment . This is applied to study a production DB2 system where a structured query language (SQL) trace for a two-hour interval and an image copy of the database catalog were obtained . The results of the workload study are summarized . The structure and complexity of SQL statements , the makeup and run-time behavior of transactions/queries , and the composition of relations and views are discussed . The results obtained provide the important information needed to build a benchmark workload to evaluate the alternative design tradeoffs of database systems . Introduction As relational database systems grow increasingly popular , throughput and response time requirements are becoming ever more stringent 1 . There is a clear need to understand the workload so systems can be better designed 2 - 6 . The workload has implications for both software and hardware designs . For example , query optimizers often make assumption of uniform distribution of attribute values in access path selection 7 8 . In the presence of data skew , where certain attribute values are more popular than others , the uniform assumption can lead to non-optimal access path selection and degraded performance 9 . Furthermore , the access plan of a query is often generated before execution time to reduce run time overhead 7 . However , the frequent occurrences of input variables (whose values are determined at run time) in the predicates of SQL statements would support the adaptive approach to access plan selection in 10 . Although a debit-credit type banking workload has often been cited to compare transaction processing systems 11 , the workload is very simplistic . Consequently , to examine workloads in other application environments which can better reflect in general the functions and capabilities of a relational system is very important for us to evaluate various design issues of database systems , and is thus taken as the objective of this paper. Using a RElational Database Workload AnalyzeR (REDWAR) , developed at IBM Research , we study in this paper the structure and complexity of SQL statements , the makeup and behavior of transactions/queries , and the composition of relations and views in a DB2 like environment . As SQL statements can be quite complex , we study the SQL statement composition to analyze the percentage of SQL statements having each type of constructs like WHERE , GROUP BY , HAVING, ORDER BY , subquery , aggregate function , etc . The number of predicates in the WHERE clause, the distribution of the predicate types and operand types , and the number of columns in the SELECT clause are analyzed . The numbers of relations in the FROM , the GROUP BY and the ORDER BY clauses , respectively , are also investigated . The view definition can be similarly analyzed . The transaction statistics gathered include the number of SQL statements of each type executed , the number of tuples scanned and retrieved/updated/inserted/deleted , the number of pages accessed", "label": ["run-time behavior", "sql", "relational databases", "dp management", "redwar", "database theory", "views", "database catalog", "structured query language", "relational database workload analyzer", "benchmark workload", "query languages", "systems analysis", "db2 environment", "design tradeoffs"], "stemmed_label": ["run-tim behavior", "sql", "relat databas", "dp manag", "redwar", "databas theori", "view", "databas catalog", "structur queri languag", "relat databas workload analyz", "benchmark workload", "queri languag", "system analysi", "db2 environ", "design tradeoff"]}
{"doc": "A mechanism for modeling timing , precedence , and data-consistency constraints on concurrently executing processes is presented . The model allows durations and intervals between events to be specified . An algorithm is provided to detect schedules which may be unsafe with respect to the constraints . This work , motivated by the design and validation of autonomous error-recovery strategies on the Galileo spacecraft , appears to be applicable to a variety of asynchronous real-time systems . INTRODUCTION This paper presents a technique for detecting unsafe schedules involving the asynchronous software processes responsible for error recovery onboard spacecraft . These autonomous processes are constrained at the event level by timing , precedence , and data-consistency rules . A schedule (ordering of events) that violates these constraints can jeopardize the spacecraft and is labeled unsafe . Safety involves those correctness properties required by the static portions of the specifications 3 . The motivation for this work comes from the difficulty of analyzing the potential process interactions during spacecraft error recovery . A single failure on the spacecraft may at times trigger several different processes whose actions must then be compatible . More than one failure may also occur at a time , causing several error-recovery processes to be invoked . In addition , there is at any time a unique sequence of uplinked commands (instructions to subsystems) executing on the spacecraft . These commands must also be compatible with the actions of the error-recovery software. During system development any possibility of interaction between a sequence of commands and the error-recovery software is carefully scrutinized . Often , with the limited software tools currently available , this is a tedious and difficult task . A tool such as the IEEE Transactions on Software Engineering,18:8 , Aug , 1992 . This work was supported in part by NASA Grant NGT-50269 . Author's mailing address is Department of Computer Science , Iowa State University, Ames , IA 50011 one described here , which provides a graphical representation of the relevant command constraints and an algorithm to aid in detecting unsafe interleavings of the software processes, can help in this analysis. The need for tools able to detect unsafe interleavings of processes will increase in future spacecraft missions 14 , 18 , 25 . Spacecraft will become more complicated as hardware advances and distributed architectures allow both more science and more autonomy . The opportunity for unplanned interactions will grow as concurrency increases . The additional computer capability embedded in future science instruments will bring with it the risk of more complicated interfaces with other subsystems. However , as spacecraft become more complex and employ more concurrent processors, software simulation becomes more costly and time-consuming to develop . Hardware testbeds usually depend on scarce spare components and are too slow to test many paths . The result is that as the opportunity for spacecraft concurrency increases , the ability to detect unsafe schedules involving those concurrent processes is not increasing commensurately . The complexity of the spacecraft requires the capability to model and analyze precedence , timing,", "label": ["data-consistency constraints", "precedence", "real-time systems", "concurrently executing processes", "asynchronous real-time systems", "galileo spacecraft", "scheduling", "modeling timing", "unsafe error recovery schedules", "fault tolerant computing", "aerospace computing"], "stemmed_label": ["data-consist constraint", "preced", "real-tim system", "concurr execut process", "asynchron real-tim system", "galileo spacecraft", "schedul", "model time", "unsaf error recoveri schedul", "fault toler comput", "aerospac comput"]}
{"doc": "A suite of computer programs for the evaluation of Bessel functions and modified Bessel functions of orders zero and one for a vector of real arguments is described . Distinguishing characteristics of these programs are that (a) they are portable across a wide range of machines , and (b) they are vectorized in the case when multiple function evaluations are to be performed . The performance of the new programs are compared with software from the FNLIB collection of Fullerton on which the new software is based . Introduction Bessel functions of real argument and integer order are among the most commonly occurring special functions of applied mathematics , and most software libraries contain routines for their evaluation . One of the most successful collections of routines for evaluating these and other special functions is the FNLIB package developed by Wayne Fullerton at the Los This paper appeared in the ACM Transactions on Mathematical Software , volume 4 , pp . 456-469 . Contribution of the National Institute of Standards and Technology (NIST) , not subject to copyright in the United States . Identification of commercial products in this paper does not imply recommendation or endorsement by NIST. y Authors' addresses: Computing and Applied Mathematics Laboratory , National Institute of Standards and Technology , Gaithersburg , MD 20899 . Electronic mail: boisvert@cam.nist.gov and saun- ders@cam.nist.gov , respectively Alamos National Laboratories in the late 1970s 10 . One of the most important features of FNLIB is its portability . Parameterized by the PORT machine constants 9 , FNLIB codes are regularly used on machines from IBM PCs to Cray Y-MPs . Versions of these codes have found their way into several well-known libraries such as the IMSL SFUN/LIBRARY 11 , and the SLATEC Common Math Library 2 . They are also available from netlib 7 . More recently , increased attention has been paid to the development of algorithms and software which take advantage of vector processors . On such machines , for example , special versions of many standard Fortran math functions are available , so that the compiler can vectorize loops such as the following. The ability to vectorize such loops is crucial in many applications. In this paper we describe a set of Fortran-callable subprograms which extend this functionality to the Bessel functions I . This has been done by producing modified versions of the FNLIB routines BESI0 , BESI1 , BESJ0 , BESJ1 , BESK0, BESK1 , BESY0 and BESY1 , as well as their double precision versions . The new routines maintain the portability of FNLIB with the advantage of being vectorizable in cases when multiple function evaluations are required . In Section 2 we review the basic design of the FNLIB routines . In Section 3 we discuss various issues involved in the vectorization of these algorithms . This is followed by a short description of the user interface of our implementation in Section 4 . Finally , in Section 5 we describe the testing of the new software , and evaluate its performance on various scalar", "label": ["special function", "mathematical software", "modified bessel function", "hyperbolic bessel function", "vectorized software", "order zero and one", "portable software", "bessel function"], "stemmed_label": ["special function", "mathemat softwar", "modifi bessel function", "hyperbol bessel function", "vector softwar", "order zero and one", "portabl softwar", "bessel function"]}
{"doc": "The Continuous Media File System , CMFS , supports real-time storage and retrieval of continuous media data (digital audio and video) on disk . CMFS clients read or write files in sessions , each with a guaranteed minimum data rate . Multiple sessions , perhaps with different rates , and non-real-time access can proceed concurrently . CMFS addresses several interrelated design issues; real-time semantics fo sessions , disk layout , an acceptance test for new sessions , and disk scheduling policy . We use simulation to compare different design choices . INTRODUCTION Current disk drives have raw data rates of 5 to 10 million bits per second (Mbps) or more. Such rates suffice for many forms of digital audio and motion video (continuous media , or CM) data: audio data rates are from 8 Kbps to 1.4 Mbps , while compressed video ranges from one to several Mbps . However , when a disk is accessed via a general-purpose file system , the data rates seen by clients are generally lower and may vary unpredictably. We have developed a Continuous Media File System (CMFS) whose clients read and write files in \"sessions\" , each with a guaranteed minimum data rate . Multiple sessions , perhaps with different data rates , can coexist . CMFS can handle non-real-time traffic concurrently with these real-time sessions. Authors' addresses: D.P . Anderson , 1891 East Francisco Blvd . San Rafael , CA 94901 . Y . Osawa , MO Business Development Division , Storage Systems Group , Sony Corporation , 2255 Okata , Atsugi , Kanagawa 243 Japan . R . Govindan , CS Division , EECS Department , UC Berkeley , Berkeley , CA 94720. This work was performed at the University of California at Berkeley , and was supported by NSF Infrastructure Grant CDA- 8722788 , NSF PYI grant CCR-86-57529 , the California MICRO program , and Sun Microsystems. To provide data rate guarantees , CMFS addresses the following interrelated issues: # Real-time semantics: The CMFS client interface , described in Section 2 , has flexible but well-defined real-time semantics. # Disk layout: Section 4 gives the CMFS assumptions about disk layout. Acceptance test: Section 5 describes how CMFS determines if a new session can be accommodated. alternative policies for ordering disk read and write operations are discussed in Sections 6 and 7. Several broad classes of CM data servers can be envisioned: workstation file systems that handle voice mail messages as well as other data; network-accessible archives of data resources (lectures , hypermedia documents , etc.) for research and education; and , with the advent of B-ISDN networks , commercial information services offering movies , news , and music to hundreds or thousands of concurrent clients . High-level issues such as security , naming and indexing , and file structuring differ among these classes; we do not deal with these issues here . However , there is a common need to store and retrieve data streams with predictable real-time performance; thus the concepts and techniques of CMFS apply to each class. CMFS is", "label": ["disk scheduling", "multimedia"], "stemmed_label": ["disk schedul", "multimedia"]}
{"doc": "The method of temporal differences (TD) is one way of making consistent predictions about the future . This paper uses some analysis of Watkins (1989) to extend a convergence theorem due to Sutton (1988) from the case which only uses information from adjacent time steps to that involving information from arbitrary ones.It also considers how this version of TD behaves in the face of linearly dependent representations for statesdemonstrating that it still converges , but to a different answer from the least mean squares algorithm . Finally it adapts Watkins' theorem that \\cal Q-learning , his closely related prediction and action learning method , converges with probability one , to demonstrate this strong form of convergence for a slightly modified version of TD . Introduction Many systems operate in temporally extended circumstances , for which whole sequences of states rather than just individual ones are important . Such systems may frequently have to predict some future outcome , based on a potentially stochastic relationship between it and their current states . Furthermore , it is often important for them to be able to learn these predictions based on experience. Consider a simple version of this problem in which the task is to predict the expected ultimate terminal values starting from each state of an absorbing Markov process , and for which some further random processes generate these terminating values at the absorbing states . One way to make these predictions is to learn the transition matrix of the chain and the expected values from each absorbing state , and then solve a simultaneous equation in one fell swoop . A simpler alternative is to learn the predictions directly , without first learning the transitions. The methods of temporal differences (TD) , first defined as such by Sutton 16 , 17 , fall into this simpler category . Given some parametric way of predicting the expected values of states , they alter the parameters to reduce the inconsistency between the estimates from one state and the estimates from the next state or states . This learning can happen incrementally , as the system observes its states and terminal values . Sutton 17 proved some results about the convergence of a particular case of a TD method. Many control problems can be formalised in terms of controlled , absorbing , Markov pro- cesses , for which each policy , ie mapping from states to actions , defines an absorbing Markov chain . The engineering method of dynamic programming (DP) 4 uses the predictions of the expected terminal values as a way of judging and hence improving policies, and TD methods can also be extended to accomplish this . As discussed extensively by Watkins 19 and Barto , Sutton and Watkins 3 , TD is actually very closely related to DP in ways that significantly illuminate its workings. This paper uses Watkins' insights to extend Sutton's theorem from a special case of TD, which considers inconsistencies only between adjacent states , to the general case in which arbitrary states are important , weighted exponentially less", "label": ["temporal differences", "reinforcement learning", "asynchronous dynamic programming"], "stemmed_label": ["tempor differ", "reinforc learn", "asynchron dynam program"]}
{"doc": "Distributed client/server models are becoming increasingly prevalent in multimedia systems and advanced user interface design . A multimedia application , for example , may play and record audio , use speech recognition input , and use a window system for graphical I/O . The software architecture of such a system can be simplified if the application communicates to multiple servers (e.g. , audio servers , recognition servers) that each manage different types of input and output . This paper describes tools for rapidly prototyping distributed asynchronous servers and applications , with an emphasis on supporting highly interactive user interfaces , temporal media , and multi-modal I/O . The Socket Manager handles low-level connection management and device I/O by supporting a callback mechanism for connection initiation , shutdown , and for reading incoming data . The Byte Stream Manager consists of an RPC compiler and run-time library that supports synchronous and asynchronous calls , with both a programmatic interface and a telnet interface that allows the server to act as a command interpreter . This paper details the tools developed for building asynchronous servers , several audio and speech servers built using these tools , and applications that exploit the features provided by the servers . INTRODUCTION The software tools described in this paper draw from predecessor systems , and emphasize the features found to be important in building user interfaces and highly interactive applications involving speech and audio . The goal of this work is to provide an environment for the rapid prototyping of distributed asynchronous servers and applications , with an emphasis on supporting multiple media and multi-modal I/O , while working with existing user interface software and within current software engineering paradigms. Distributed client/server models have been in use for over a decade,and are becoming increasingly prevalent in multimedia systemsand advanced user interface design . In many current graphical user interfaces , such as those using the X Window System , client applications communicate with a window system server that manages screen output and mouse/keyboard input 17 . It is advantageous to use a similar software design methodology for developing new user interfaces that use other forms of I/O , suchas speechrecognition and synthesis , or incorporate temporal media , such as recorded speech. This distributed design allows multiple applications to share limited I/O resources (e.g. , a display , microphone , loudspeaker , etc.) without any knowledge of the other applications . The software tools described in this paper assist in the creation of servers and client applications , and address some of the issues of prototyping and debugging in such a distributed environment. 1.1 Application Environment A multimedia application may play and record audio , use speech recognition input , speech synthesis output , access remote information services , and use a window system for graphical I/O . The architecture of such a system can be simplified if the application communicates to multiple servers (e.g. , audio servers , recognition servers , synthesis servers) that each manage different types of input and output . In such an environment", "label": ["speech and studio applications", "remote procedure call", "asynchronous message passing", "speech recognition and synthesis", "audio servers", "distributed client-server architecture"], "stemmed_label": ["speech and studio applic", "remot procedur call", "asynchron messag pass", "speech recognit and synthesi", "audio server", "distribut client-serv architectur"]}
{"doc": "Graphical user interfaces (GUI) provide intuitive and easy means for users to communicate with computers . However , construction of GUI software requires complex programming that is far from being intuitive . Because of the semantic gap between the textual application program and its graphical interface , the programmer himself must conceptually maintain the correspondence between the textual programming and the graphical image of the resulting interface . Instead , we propose a programming environment based on the programming by visual example (PBVE) scheme , which allows the GUI designers to program visual interfaces for their applications by drawing the example visualization of application data with a direct manipulation interface . Our system , TRIP3 , realizes this with (1) the bi-directional translation model between the (abstract) application data and the pictorial data of the GUI , and (2) the ability to generate mapping rules for the translation from example application data and its corresponding example visualization . The latter is made possible by the use of generalization of visual examples , where the system is able to automatically generate generalized mapping rules from a given set of examples . Introduction The advent of workstations and personal computers with high-resolution graphics has realized graphical user interfaces (GUI) 8 , where information is visualized with colors and movements instead of flat and flavor- less text 2 , 5 , 3 . The complexity and development cost of GUI are , however , considerably higher compared to those of conventional text-based interfaces , primarily due to the followings: (1) Specification of interface components , which is inherently graphical , is achieved with conventional programming languages , which are inherently textual , and (2) programmers must somehow maintain the correspondence between abstract data in the application and its visual representation , with explicit textual programming. An obvious solution to problem (1) is to employ direct manipulation in programming the GUI itself , thereby allowing the programmer to graphically manipulate and layout the UI components . However , direct manipulation is inherently \"concrete\" , i.e. , it lacks the means of \"abstraction\" , which is essential to programming in gen- eral . The previous approaches to utilize direct manipulation in GUI programming , therefore , do not usually serve as a solution to (2) , i.e. , programming the general correspondence between application data and its visual representation. Expressing the correspondence between application data and its visual representation declaratively is a step towards a solution to problem (2) . Our previous re-search proposed the bi-directional translation model and a prototype system TRIP2 25 . TRIP2 realizes bi-directional translation between application data and its visual representation with a set of declarative translation (mapping) rules . Modification of the application data is directly reflected to its visualization , and con- versely , graphical editing is directly reflected to the application data. Programming in TRIP2 was , however , still confined to the realm of text-based specification; thus , although it was far easier and involved less coding compared to conventional GUI programming , specification of mapping rules for", "label": ["constraints", "graphical user interface", "direct manipulation", "visualization", "layouts", "programming by example"], "stemmed_label": ["constraint", "graphic user interfac", "direct manipul", "visual", "layout", "program by exampl"]}
{"doc": "We present a simple randomized algorithm which solves linear programs with n constraints and d variables in expected O(nde(d ln(n+1))1/4) time in the unit cost model (where we count the number of arithmetic operations on the numbers in the input) . The expectation is over the internal randomizations performed by the algorithm , and holds for any input . The algorithm is presented in an abstract framework , which facilitates its application to several other related problems . The algorithm has been presented in a previous work by the authors ShW , but its analysis and the subexponential complexity bound are new . Introduction Linear programming is one of the basic problems in combinatorial optimization , and as such has received considerable attention in the last four decades . Many algorithms have been proposed for its solution , starting with the simplex algorithm and its relatives Dan , proceeding through the polynomial-time solutions of Khachiyan Kha and Karmarkar Kar , and continuing with several more recent techniques (reviewed below) . While some of the proposed algorithms have proven out to be extremely efficient in practice , analysis of their running time has not been fully satisfactory so far . For example , the simplex algorithm was shown to be exponential in the worst case KlM . The algorithms of Khachiyan and of Karmarkar have polynomial bit-complexity , but the number of arithmetic operations they perform depends on the size of the coefficients defining the input and it cannot be bounded solely in terms of n (the number of constraints) and d (the number of vari- ables) . In this paper we assume a different model of computation , namely the real RAM, widely used in computational geometry . Here the input may contain arbitrary real num- bers , and each arithmetic operation with real numbers is charged unit cost . To distinguish complexity bounds in this model from bounds in the bit-complexity model , we call them combinatorial. Until recently , the best known combinatorial bounds were exponential in either n or d; a subexponential (randomized) bound is given in a very recent paper of Kalai Kal and also in this paper . One of the major open problems in the area is to find a strongly polynomial algorithm (i.e . of combinatorial polynomial complexity) for linear programming. In this paper we describe a simple randomized algorithm which solves linear programs with n inequalities and d variables with expected d ln(n= d )+O( d+ln n) g) arithmetic operations . In conjunction with Clarkson's linear programming algorithm Cla3 , this gives an expected bound of O(d d The expectation of the running time is with respect to the internal randomizations performed by the algorithm , and holds for any input . This complexity matches that of a recent algorithm due to Kalai Kal . (Except for the constant in the exponent , the only significant difference is that Kalai has a version of his algorithm which runs in e O( d) as long as n is linear in d . We can guarantee", "label": ["randomized incremental algorithms", "linear programming", "combinatorial optimization", "computational geometry"], "stemmed_label": ["random increment algorithm", "linear program", "combinatori optim", "comput geometri"]}
{"doc": "The Virtual Reality user interface style allows the user to manipulate virtual objects in a 3D environment using 3D input devices . This style is best suited to application areas where traditional two dimensional styles fall short , but the current programming effort required to produce a VR application is somewhat large . We have built a toolkit called MR , which facilitates the development of VR applications . The toolkit provides support for distributed computing , head-mounted displays , room geometry , performance monitoring , hand input devices , and sound feedback . In this paper , the architecture of the toolkit is outlined , the programmer's view is described , and two simple applications are described . Introduction The Virtual Reality user interface style denotes highly-interactive three dimensional control of a computational model . The user enters a virtual space , and manipulates and explores the application data using natural 3D interaction techniques . This style usually requires the use of non-traditional devices such as head-mounted displays , and hand measurement equipment (gloves) . The core requirement of this style is support for real-time three dimensional interactive animation. This results in the following issues: 1 . The real-time generation of synchronized stereoscopic images for a head-mounted display is not supported by most commonly-available 3D graphics workstations . As a result , two workstationsmust be operated in tandem to provide two video signals . Consistent images must be presented in synchrony to the user. 2 . Low-level support for new I/O devices such as position trackers , gloves , and so on must be provided for efficiency and lag minimization , while high-level abstractions are required by the application programmer 3 . Applications must be designed independently of the tracker geometry , room geometry and device con- figuration , yet correct handling of geometric data is vital to avoid user confusion. 4 . The real-time nature of the task demands that a performance monitoring tools be available for performance optimization and for debugging. The MR toolkit we describe in this paper is developed to address these concerns. Previous Work Other groups have worked on support for this user interface style . Zeltzer and his colleagues at MIT produced a general purpose package for building interactive simulation systems , especially for task level animation systems Zeltzer 1989 . The key element in the package is a constraint network to which all the objects are connected . Once the status of an object is updated , all the constraints which involve this object are informed and evaluated . By using constraint propagation , the gestural input from the DataGlove can also be viewed as an object . New DataGlove gestures trigger gesture- dependent constraints which then produce the reaction to the user's activity. Card , Mackinlay and Robertson at Xerox have produced an architectural model for VR user interfaces called the Cognitive Coprocessor Architecture Robert- son 1989 . The purpose of the Cognitive Coprocessor Architecture is to support \"multiple , asynchronous , interactive agents\" and smooth animation . It is based on a", "label": ["user interface software", "virtual reality", "interactive 3d graphics"], "stemmed_label": ["user interfac softwar", "virtual realiti", "interact 3d graphic"]}
{"doc": "In recent years , the computer science community has realized the advantages of GUIs (Graphical User Interfaces) . Because high-quality GUIs are difficult to build , support tools such as UIMSs , UI Toolkits , and Interface Builders have been developed . Although these tools are powerful , they typically make two assumptions: first , that the programmer has some familiarity with the GUI model , and second , that he is willing to invest several weeks becoming proficient with the tool . These tools typically operate only on specific platforms , such as DOS , the Macintosh , or UNIX/X-windows . The existing tools are beyond the reach of most undergraduate computer science majors , or professional programmers who wish to quickly build GUIs without investing the time to become specialists in GUI design . For this class of users , we developed SUIT , the Simple User Iinterface Toolkit . SUIT is an attempt to distill the fundamental components of an interface builder and GUI toolkit , and to explain those concepts with the tool itself , all in a short period of time . We have measured that college juniors with no previous GUI programming experience can use SUIT productively after less than three hours . SUIT is a C subroutine library which provides an external control UIMS , an interactive layout editor , and a set of standard widgets , such as sliders , buttons , and check boxes . SUIT-based applications run transparently across the Macintosh , DOS , and UNIX/X platforms . SUIT has been exported to hundreds of external sites on the internet . This paper describes SUIT's architecture , the design decisions we made during its development , and the lessons we learned from extensive observations of over 120 users . Introduction This is a practice and experience paper which describes our experience with SUIT , the Simple User Interface Toolkit . In recent years , support tools for building GUIs , called UIMSs , UI toolkits , and interface builders , have gained popularity , but they have been heavily skewed towards programmers who are willing to invest a large amount of time in mastering them . While these tools are appropriate for many professionals in the field , their extended learning curves make them prohibitive for undergraduate students or other programmers who wish to build GUIs , but who do not wish to invest weeks in mastering the tool base . GUI building tools can be very deceptive: providing an interactive builder that provides mouse-based interface editing can obscure the fact that if the programmer is not familiar with the callback model for GUIs , attempting to attach functionality to the screen components will be extremely confusing. In academia , we should be exposing our students to good GUI-building tools , not as a speciality item in a graduate level graphics course , but in mainstream courses , such as undergraduate software engineering or \"projects\" courses . Unfortunately , these courses cannot sacrifice several weeks in order to teach the concepts hidden", "label": ["portability", "software tools", "graphical user interface", "learnability", "user interface toolkit", "export", "uims", "pedagogy", "rapid prototyping", "gui"], "stemmed_label": ["portabl", "softwar tool", "graphic user interfac", "learnabl", "user interfac toolkit", "export", "uim", "pedagogi", "rapid prototyp", "gui"]}
{"doc": "Lexical ambiguity is a pervasive problem in natural language processing . However , little quantitative information is available about the extent of the problem or about the impact that it has on information retrieval systems . We report on an analysis of lexical ambiguity in information retrieval test collections and on experiments to determine the utility of word meanings for separating relevant from nonrelevant documents . The experiments show that there is considerable ambiguity even in a specialized database . Word senses provide a significant separation between relevant and nonrelevant documents , but several factors contribute to determining whether disambiguation will make an improvement in performance . For example , resolving lexical ambiguity was found to have little impact on retrieval effectiveness for documents that have many words in common with the query . Other uses of word sense disambiguation in an information retrieval context are discussed . Introduction The goal of an information retrieval system is to locate relevant documents in response to a user's query . Documents are typically retrieved as a ranked list , where the ranking is based on estimations of relevance 5 . The retrieval model for an information retrieval system specifies how documents and queries are represented , and how these representations are compared to produce relevance estimates . The performance of the system is evaluated with respect to standard test collections that provide a set of queries , a set of documents , and a set of relevance judgments that indicate which documents are relevant to each query . These judgments are provided by the users who supply the queries , and serve as a standard for evaluating performance . Information retrieval research is concerned with finding representations and methods of comparison that will accurately discriminate between relevant and non-relevant documents. Many retrieval systems represent documents and queries by the words they contain , and base the comparison on the number of words they have in common . The more words the query and document have in common , the higher the document is ranked; this is referred to as a 'coordination match' . Performance is improved by weighting query and document words using frequency information from the collection and individual document texts 27 . There are two problems with using words to represent the content of documents . The first problem is that words are ambiguous , and this ambiguity can cause documents to be retrieved that are not relevant . Consider the following description of a search that was performed using the keyword \"AIDS\": Unfortunately , not all 34 references were about AIDS , the disease . The references included \"two helpful aids during the first three months after total hip replacement\" , and \"aids in diagnosing abnormal voiding patterns\" . 17 One response to this problem is to use phrases to reduce ambiguity (e.g. , specifying 'hearing aids' if that is the desired sense) 27 . It is not always possible , however , to provide phrases in which the word occurs only with the desired sense . In addition , the", "label": ["document retrieval", "disambiguation", "word senses", "semantically based search"], "stemmed_label": ["document retriev", "disambigu", "word sens", "semant base search"]}
{"doc": "A simulation-based method for obtaining numerical estimates of the reliability of N-version , real-time software is proposed . An extended stochastic Petri net is used to represent the synchronization structure of N versions of the software , where dependencies among versions are modeled through correlated sampling of module execution times . The distributions of execution times are derived from automatically generated test cases that are based on mutation testing . Since these test cases are designed to reveal software faults , the associated execution times and reliability estimates are likely to be conservative . Experimental results using specifications for NASA's planetary lander control software suggest that mutation-based testing could hold greater potential for enhancing reliability than the desirable but perhaps unachievable goal of independence among N versions . Nevertheless , some support for N-version enhancement of high-quality , mutation-tested code is also offered . Mutation analysis could also be valuable in the design of fault-tolerant software systems . Introduction The use of multi-version software to improve computer system reliability remains a topic of vigorous debate 2 , 15 , 17 , 18 . One cause for concern is easily seen in considering a simple model of majority voting: if each of three voters independently votes \"yes\" (meaning a correct vote) with probability , then the probability of a majority \"yes\" decision is 3p which is larger than when is larger than 1=2 . However , if the votes are perfectly correlated , then the probability of a majority \"yes\" decision is just itself , and there is no improvement. Thus the issue is readily identified as \"version correlation,\" but the meaning of this phrase in the software development environment can be elusive . A substantial clarification was provided by Eckhardt and Lee 12 and by Littlewood and Miller 19 . Using Littlewood's notation 19 , we let random variable X represent an input to any of a collection P of programs designed to perform the same task , and let \\Theta(x) be the probability that a randomly chosen program from P fails on specific input x . The expected value of the random variable \\Theta(X the probability that a randomly chosen program fails on a randomly chosen input . The key observation from 12 , 19 is that independently developed programs do not necessarily fail indepen- dently . The probability that two independently chosen programs from P both fail on the same randomly chosen input is easily seen to be E \\Theta(X but the probability of both failing on independently chosen inputs is E \\Theta(X these terms differ by the variance , V \\Theta(X ) . Similarly, if \\Theta A (x) is the probability that a randomly selected program from development methodology A fails on input x , and \\Theta B (x) the same for methodology B , then the probability that both independently selected programs fail on the same randomly chosen input is E \\Theta A (X )\\Theta B (X) , which differs from independent failures , E \\Theta A (X) E \\Theta B (X) , unless the covariance , COV", "label": ["software reliability", "software faults", "nasa", "synchronization structure", "dependencies", "stochastic petri net", "planetary lander control software", "simulation", "mutation analysis", "module execution times", "mutation-tested code", "fault-tolerant software systems", "computational complexity", "numerical estimates", "real-time software reliability", "petri nets", "correlated sampling", "fault tolerant computing", "mutation testing"], "stemmed_label": ["softwar reliabl", "softwar fault", "nasa", "synchron structur", "depend", "stochast petri net", "planetari lander control softwar", "simul", "mutat analysi", "modul execut time", "mutation-test code", "fault-toler softwar system", "comput complex", "numer estim", "real-tim softwar reliabl", "petri net", "correl sampl", "fault toler comput", "mutat test"]}
{"doc": "The benefits of using a synchronous data-flow language for programming critical real-time systems are investigated . These benefits concern ergonomy (since the dataflow approach meets traditional description tools used in this domain) and ability to support formal design and verification methods . It is shown , using a simple example , how the language LUSTRE and its associated verification tool LESAR , can be used to design a program , to specify its critical properties , and to verify these properties . As the language LUSTRE and its uses have already been discussed in several papers , emphasis is put on program verification . Introduction It is useless to repeat why real-time programs are among those in which errors can have the most dramatic consequences . Thus , these programs constitute a domain where there is a special need of rigorous design methods . We advocate a \"language approach\" to this problem , arguing that the programming language used has a direct influence in the quality of the software , from several points of view: (i) The language should allow a natural description of the problem to be solved . In particular, it should be close to the traditional tools used in its application field. (ii) The language should be formally sound , in order to support formal verification methods. (iii) The language should be simple enough to minimize the risk of misunderstanding about program meanings. These were our main goals in designing the language Lustre 11 , 18 . To meet the criterion (i), we started from the traditional description tools used in the design of process control systems: At a higher level , these tools consist of mathematical formalisms (differential equations , boolean while at a lower level , people often use data-flow nets (block-diagrams , analog schemas , switch or gate networks , These two classes of tools are closely related: For instance, This work was partially supported by ESPRIT Basic Research Action \"SPEC\" and by a contract from Merlin Gerin differential equations , finite difference equations , boolean equations can be straightforwardly translated , respectively , into analog schemas , block-diagrams and gate networks . At least the class of high level tools also meets our criterion (ii) , since they are derived from the mathematical language . Other authors (e.g. , 23 , 2 ) claimed that such declarative formalisms are simpler and cleaner than usual imperative languages , where assignments , side-effects , aliasing , parameter passing mechanisms , are unnatural phenomena which are difficult to understand and manage. We agree with this claim , and therefore consider that these declarative formalisms constitute a good basis for designing a programming language meeting the criterion (iii). Lustre is a synchronous data-flow language , initially inspired from Lucid . As in Lucid , any Lustre variable or expression is considered to represent the sequence of values it takes during the whole execution of the program , and Lustre operators are considered to operate globally over these sequences . The synchronous nature of the language consists in assuming that", "label": ["parallel languages", "dataflow approach", "real-time systems", "formal design", "program verification", "critical real-time systems", "verification tool lesar", "verification methods", "parallel programming", "synchronous data-flow language", "traditional description tools", "ergonomy", "data-flow language lustre", "critical properties"], "stemmed_label": ["parallel languag", "dataflow approach", "real-tim system", "formal design", "program verif", "critic real-tim system", "verif tool lesar", "verif method", "parallel program", "synchron data-flow languag", "tradit descript tool", "ergonomi", "data-flow languag lustr", "critic properti"]}
{"doc": "A procedure is given for recognizing sets of inference rules that generate polynomial time decidable inference relations . The procedure can automatically recognize the tractability of the inference rules underlying congruence closure . The recognition of tractability for that particular rule set constitutes mechanical verification of a theorem originally proved independently by Kozen and Shostak . The procedure is algorithmic , rather than heuristic , and the class of automatically recognizable tractable rule sets can be precisely characterized . A series of examples of rule sets whose tractability is nontrivial , yet machine recognizable , is also given . The technical framework developed here is viewed as a first step toward a general theory of tractable inference relations . Introduction Certain well known algorithms can be viewed as polynomial time decision procedures for inference relations . For example , transitive closure determines whether a formula of the form x ! y can be proven from given inequalities and a transitivity axiom . The union-find procedure determines whether an equality can be proven from given equations and the reflexivity , tran- sitivity , and symmetry axioms of equality . The congruence closure procedure determines whether an equality can be proven from a given set of equations and the symmetry , reflexivity , transitivity , and congruence axioms of equality 1 . Each of these algorithms can be viewed as a decision procedure for the inference relation generated by a certain set of inference rules . This paper identifies a general class of \"local\" rule sets . These rule sets have the desirable property that the generated inference relation is polynomial time decidable. Consider a set R of inference rules and let 'R be the inference relation generated by R , i.e. , the relation such that \\Sigma 'R \\Phi if there exists a derivation of \\Phi from \\Sigma using the rules in R . The rule set R is called local if whenever \\Sigma 'R \\Phi there exists a local derivation of \\Phi from \\Sigma - a derivation is local if every proper subexpression of a formula in the derivation is either a proper subexpression of \\Phi , a proper subexpression of a member of \\Sigma , or appears as a subexpression of an inference rule in R . One can show that , for any rule set R , one can determine , in polynomial time in the size of \\Sigma and \\Phi, whether or not there exists a local derivation of \\Phi from \\Sigma . If R is local , i.e., the existence of a derivation ensures the existence of a local derivation , then the inference relation 'R is polynomial time decideable. One can easily show that a rule set consisting of a single transitivity rule is local . The same is true of the rule set underlying the union-find procedure, i.e. , the reflexivity , symmetry , and transitivity axioms of equality . The rule set underlying congruence closure , i.e. , the reflexivity , symmetry , transitivity, and substitution axioms of equality , is also local , although", "label": ["inference rules", "machine inference", "proof systems", "proof theory", "mechanical verification", "automated reasoning", "polynomial-time algorithm", "theorem proving"], "stemmed_label": ["infer rule", "machin infer", "proof system", "proof theori", "mechan verif", "autom reason", "polynomial-tim algorithm", "theorem prove"]}
{"doc": "One of the most fundamental operations when simulating a stochastic discrete-event dynamic system is the generation of a nonuniform discrete random variate . The simplest form of this operation can be stated as follows: Generate a random variable X that is distributed over the integers 1,2,,n such that are fixed nonnegative numbers . The well-known alias algorithm is available to accomplish this task in O(1) time . A more difficult problem is to generate variates for X when the ai's are changing with time . We present three rejection-based algorithms for this task , and for each algorithm we characterize the performance in terms of acceptance probability and the expected effort to generate a variate . We show that , under fairly unrestrictive conditions , the long-run expected effort is O(1) . Applications to Markovian queuing networks are discussed . We also compare the three algorithms with competing schemes appearing in the literature . Introduction The problem of generating a nonuniform discrete random variate is fundamental to the simulation of any discrete event stochastic system . The simplest version of this problem is to generate a variate for a random variable X such that P given that the i 's do not change with time . The well-known `alias algorithm' (e.g. , see 2 pp . 158-160) takes O(n) preprocessing time , after which it can generate a variate in O(1) time . In this paper we are interested in developing efficient algorithms for the case of the changing with time . Such a procedure is desirable in the simulation of multi-dimensional Markov processes , such as those used to model queueing and telephone networks. A definition of the problem is as follows . Suppose that for each are given n non-negative numbers a 1 be a sequence of independent random variables such that a a The problem is to generate a variate for X(s) for each realization of fX(s)g) . We refer to the integers in ng as the 'outcomes' of X . Call a i (s) the rate for outcome i at time s . In the static version of the problem , the rates do not change with time . In the dynamic version , zero or more of the a i (s)'s change each time s is incremented. In discrete event simulation the number of a i (s)'s that change each time s is incremented is typically small . The algorithms developed in this paper attempt to exploit this special property. In Section 2 we first show how the rejection algorithm can be employed to generate variates with changing distributions . The performance of the algorithm can be characterized by its acceptance probability . We then develop two additional algorithms which , at the expense of additional memory , can improve significantly the acceptance probability . In Section 3 we suppose that the rates are random and are determined by a (discrete state space) Markov process , as is typically the case in applications . We explicitly characterize the long-run acceptance probability and the long-run expected effort of", "label": ["randomized algorithms", "queuing networks"], "stemmed_label": ["random algorithm", "queu network"]}
{"doc": "ESP is a language for modeling rule-based software processes that take place in a distributed software development environment . It is based on PoliS , an abstract coordination model that relies on Multiple Tuple Spaces , i.e. , collections of tuples a la Linda . PoliS extends Linda aiming at the specification and coordination of logically distributed systems . ESP (Extended Shared Prolog) combines the PoliS mechanisms to deal with concurrency and distribution , with the logic-programming language Prolog , to deal with rules and deduction . Such a combination of a coordination model and a logic language provides a powerful framework in which experiments about rule-based software process programming can be performed and evaluated . Introduction Introduction The theme of software process modeling has been recently addressed by several specific conferences , see for instance 1,21,25 ; for a survey , see 19 . This interest stems from the fact that activities involved in software development are so complicate , expensive and error-prone that it seems necessary to completely specify the development process , in order to gain control of it and improve its quality . A software process program should formally define the activities that are carried out in the development of a software project , providing guidance to the agents involved and controlling the overall evolution of the project status 33 . In this paper we devote our attention to the fact that a software process takes place necessarily within a software development environment . The environment supports and coordinates the interactions of the project members , allows the use of programming tools , and monitors the evolution of the project documents. We will show that the environment can be designed with the goal of explicitly modeling and coordinating the process itself . In fact , we suggest that a natural way to model a software process consists of introducing a suitable abstract machine defining the environment in which the software process is developed and a suitable programming language able to control the process evolution . Our guiding principle is that , in order to specify a software process , we must clarify the coordination model 13 that has to be used by all the agents , i.e. , we must make explicit the communication mechanisms that are at the basis of the interaction protocols used by the participants of a software project . We identify the coordination model with the abstract architecture of the environment that supports the execution of the process itself. The main contribution of this paper is the definition of an abstract paradigm for modeling coordination of activities that take place inside a software development environment . The paradigm is called PoliSpaces (or PoliS) , because it is based on Multiple Tuple Spaces 23 . PoliS allows a software process designer to model a software process that takes place inside a multi-user , distributed development environment . In modeling the activities that form the software process our approach is similar to that used in MARVEL 8,9 and Merlin 24,34 : each activity that takes place", "label": ["rule-based programming", "concurrency", "multiuser programming environment", "logic programming", "software process modeling", "software process"], "stemmed_label": ["rule-bas program", "concurr", "multius program environ", "logic program", "softwar process model", "softwar process"]}
{"doc": "Mutation analysis is a powerful technique for assessing and improving the quality of test data used to unit test software . Unfortunately , current automated mutation analysis systems suffer from severe performance problems . This paper presents a new method for performing mutation analysis that uses program schemata to encode all mutants for a program into one metaprogram , which is subsequently compiled and run at speeds substantially higher than achieved by previous interpretive systems . Preliminary performance improvements of over 300% are reported . This method has the additional advantages of being easier to implement than interpretive systems , being simpler to port across a wide range of hardware and software platforms , and using the same compiler and run-time support system that is used during development and/or deployment . Introduction Programs 1 are tested by executing them against test inputs and examining the resulting outputs for errors . The intent of this testing process is to increase our confidence in the correctness of the tested code . However , when testing is poorly con- ducted , in an ad-hoc manner , our confidence may be misplaced . Poorly selected test data that does not adequately exercise a program must be deemed \"low quality\" . Systematic testing techniques establish test data adequacy criteria that seek to measure the quality of the test data used to exercise a given program . One powerful testing technique that uses an adequacy criterion is mutation testing 11 , 13 , 14 . In mutation testing , the test set is analyzed to determine a quality measure called the mutation adequacy score ; this process is called mutation analysis. Unfortunately , the conventional method of performing mutation analysis , which requires interpreting many slightly differing versions of the same pro- gram , has significant problems . Automated mutation analysis systems based on the conventional method are slow , laborious to build , and usually unable to completely emulate the intended operational environment of the software being tested. The principle reason conventional mutation analysis systems are slow is because they are interpre- tive . As one study noted , \"current implementations of mutation tools are unacceptably slow and are only suitable for testing relatively small programs\" 16 . Thus , while conventional systems have proved useful for experimentation with mutation testing, the widespread practical use of mutation analysis has been stymied by the enormous computational We use the word program to denote the software under test , which may be a complete program or some smaller unit, such as a procedure. requirements of these conventional systems . Con- ventional , interpretive systems are also laborious to build . To test software written in a specific lan- guage , interpreter-based systems must incorporate ALL the compilation characteristics and run-time semantics of that language . For certain languages, such as Ada , this is a formidable undertaking . Since dialectical differences often exist , the degree of compliance to language standards becomes a problem. Also , subtle changes in program behavior may occur since the program under test is", "label": ["program schemata", "fault-based testing", "mutation analysis", "software testing"], "stemmed_label": ["program schemata", "fault-bas test", "mutat analysi", "softwar test"]}
{"doc": "We discuss fundamental limitations of or-parallel execution models of nondeterministic programming languages . Or-parallelism corresponds to the execution of different nondeterministic computational paths in parallel . A natural way to represent the state of (parallel) execution of a nondeterministic program is by means of an or-parallel tree . We identify three important criteria that underlie the design of or-parallel implementations based on the or-parallel tree: constant-time access to variables , constant-time task creation , and constant-time task switching , where the term constant-time means that the time for these operations is independent of the number of nodes in the or-parallel tree , as well as the size of each node . We prove that all three criteria cannot be simultaneously satisfied by any or-parallel execution model based on a finite number of processors but unbounded memory . We discuss in detail the application of our result to the class of logic programming languages and show how our result can serve as a useful way to categorize the various or-parallel methods proposed in this field . We also discuss the suitability of different or-parallel implemenation strategies for different parallel architectures . Introduction This paper explores fundamental limitations of or-parallel execution models of nondeterministic programming languages . We use the term 'nondeter- minism' in the automata-theoretic sense of \\don't know\" nondeterminism, rather than in the sense of \\don't care\" nondeterminism . Or-parallel execution of nondeterministic programs involves the parallel exploration of the multiple search paths arising due to nondeterministic choices . An important subclass of these languages is the class of logic programming languages . In these languages , execution involves the solution of goals with respect to a set of clauses , and or-parallelism arises whenever a goal unies with more than one clause head , in which case the corresponding clause bodies are executed in parallel . In general , exploiting or-parallelism is a useful way to speed up the solution to search problems in articial intelligence and applications of symbolic computation and reasoning , such as theorem proving , natural language analysis , etc. A natural way to represent the state of (parallel) execution of a non-deterministic program is by means of an or-parallel tree . In this paper , we analyze execution models that are based on the or-parallel tree . We base our analysis upon the following three criteria for an ideal or-parallel execution model: 1 . the cost of environment creation should be constant-time; 2 . the cost of variable access and binding should be constant-time; and 3 . the cost of task switching should be constant-time. We use the term 'constant-time' to mean that the time for these operations is independent of the number of nodes in the or-parallel tree , as well as the size of each node . While the connection between these criteria might appear remote at rst , they actually are derived from the three principal operations in any nondeterministic programming system (sequential or parallel): procedure call (which involves environment creation) , assignment statements and parameter transmission (which involves variable access and binding),", "label": ["or-parallel execution models"], "stemmed_label": ["or-parallel execut model"]}
{"doc": "We propose an object-oriented data model that generalizes the relational , hierarchical , and network models . A database scheme in this model is a directed graph , whose leaves represent data and whose internal nodes represent connections among the data . Instances are constructed from objects , which have separate names and values . We define a logic for the model , and describe a nonprocedural query language that is based on the logic . We also describe an algebraic query language and show that it is equivalent to the logical language . Introduction Research in database theory during the 1970's and the early 1980's has focused mainly on the relational model Cod70 , due to its elegance and mathematical simplicity . This very simplicity , however , has gradually been recognized as one of the major disadvantages of the relational model: it forces the stored data to have a flat structure that real data does not always have SS77 , Cod79 . This has motivated a great deal of research during the past decade on structured data models: the so-called semantic data models (cf. ? , ? ) , nested relations (cf . ? , ? ) , and complex objects (cf . The reader is referred to ? , ? , ? for excellent surveys. Two works that we found in particular inspiring are by Jacobs Jac79, Jac82 and by Hull and Yap HY82 . Jacobs describes \"database logic,\" a mathematical model for databases that claims to generalize all three principal data models . Hull and Yap HY82 describe the \"format model,\" which generalizes the relational and hierarchical models . In the format model, database schemes are viewed as trees , in which each leaf represents data, and each internal node represents some connection among the data. Both these models are unsatisfactory in their ability to restructure data, i.e. , the ability to query the database . While Hull and Yap ignore the issue of a data manipulation language , Jacobs' treatment is an overkill-his query language enables one to write noncomputable queries Var83 . Furthermore , both approaches fail to model a significant aspect of hierarchical and network database management systems , which is the ability to use virtual records . Virtual records are essentially pointers to physical records, and they are used to avoid redundancy in the database Ull82 . Note that virtual records introduce cyclicity not only in the schema level but also at the instance level. In the model we propose here , a database scheme is an arbitrary directed graph . As in the format model , leaves (i.e. , nodes with no outgoing edges) represent data , and internal nodes represent connections among the data. While it is not hard to model cyclicity at the schema level , it is not quite apparent how to do it at the instance level , without running into cyclic defini- tions . Our solution is to distinguish between object names and object values, or , equivalently , between the address space and the data space .", "label": ["relational database", "algebra", "database schema", "logic", "tuple calculus"], "stemmed_label": ["relat databas", "algebra", "databas schema", "logic", "tupl calculu"]}
{"doc": "||MAPLE|| (speak: parallel Maple) is a portable system for parallel symbolic computation . The system is built as an interface between the parallel declarative programming language Strand and the sequential computer algebra system Maple , thus providing the elegance of Strand and the power of the existing sequential algorithms in Maple . The implementation of different parallel programming paradigms shows that it is fairly easy to parallelize even complex algebraic algorithms using this system . Sample applications (among them algorithms solving multivariate nonlinear equation systems) are implemented on various parallel architectures . For example a straightforward parallelization of the complex and important problem of real root isolation has been parallelized using a generic Strand program of fewer than 20 lines of code and a slight modification of 5 lines in the original sequential Maple source . Even with such a simple modification we gained a speed-up of 5 times , that is better than those reported by others in the literature . Introduction Symbolic computation is an important part of applied ma- thematics , physics , engineering and other areas . Nowadays sequential computer algebra systems like Maple , Mathematica and Reduce are widely used . But currently it is only possible to solve small examples , because of the inherent complexity of the problems in symbolic computation . In particular , a lot of problems involving non-linear equation Supported by: Austrian Science Foundation (FWF) , ESPRIT-III POSSO project systems cannot be solved symbolically within a reasonable amount of time using today's computers . Furthermore , for a lot of algorithms it is not even possible to predict their runtime and memory demands for a given input. How should we deal with such problems? An obvious solution is parallelization . Todays fast parallel computers are theoretically able to solve huge problems , but for solving large problems , we face the following situation: ffl Sequential computer algebra systems have big sequential libraries and fast implementations of the basic algorithms but are not yet suitable for parallel computers ffl Parallel programming languages are well suited for parallel programming , but have no libraries for solving problems in symbolic computation. Thus our goal should be to reuse the huge library in existing computer algebra systems and , additionally , to get easy access to the power of today's parallel computers. Several attempts at parallelizing Maple have been made before . In Watt , 1986 the UNIX fork and join primitives were used for parallelism . The programmer had to develop his parallel algorithm on a very low level . An improvement was done in Char , 1990 where Linda is used . Linda is more hardware independent , but programmers still have to worry about creation of parallel processes and communication between them . The system was implemented on a shared memory machine but still had problems with communication and job creation overhead. There are also several parallelizations of other computer algebra systems available: the C based SAC algebra library has been parallelized for shared memory machines only . An implementation by Kuechlin ,", "label": ["logic programming", "computer algebra systems"], "stemmed_label": ["logic program", "comput algebra system"]}
{"doc": "This paper describes a set of interfaces for numerical subroutines . Typing a short (often one-line) description allows one to solve problems in application domains including least-squares data fitting , differential equations , minimization , root finding , and integration . Our approach of template-driven programming makes it easy to build such an interface: a simple one takes a few hours to construct , while a few days suffice to build the most complex program we describe . Introduction Numerical subroutine packages are one of the oldest and most effective approaches to software re- use . Experts familiar with a good library can rapidly combine tested and robust components into useful software. As effective as they are for experts , however , most large libraries are difficult for the casual user. Suppose , for instance , that a programmer desires to find a root of a nonlinear equation . This usually entails looking up the appropriate routine , modifying a sample program , compiling the program with links to the appropriate libraries , testing (and possibly debugging) the code , and interpreting the output to find the answer . This process can easily take an hour or two . Rice 1989 , . 2 summarizes the problem: The user must write code in the target programming language which creates the input and output data structures and which invokes the procedures . This code is usually lengthy compared to invocation of the library procedures. Many solutions have been proposed for this problem . Gill , Murray , Picken , Wright 1979 describe principles for constructing subroutine libraries that are easy to use . Large environments such as MATLAB and S provide elegant interfaces to sophisticated software libraries . Such environments are excellent for both expert and novice users , but require many programmer-years to build. We wish to make it easy for individual programmers to quickly build effective interfaces for their software libraries . In this paper we describe a set of programs that provide an interface to the Port subroutine library described by Fox 1984 . Each program solves a popular form of a common numerical prob- lem . Here , for instance , is a dialog in which we first find a root of the function sin(x) in the interval 3 , 4 and then find a root of x in the interval 0.1 , 0.9 : __________________ Maria Fernandez is currently with the Department of Computer Science , Princeton University , Princeton , NJ 08544 . Electronic addresses: jlb@research.att.com , mff@princeton.edu , bwk@research.att.com, nls@research.att.com. (The dollar sign is the system prompt.) Behind the scenes , the Root program uses a template to write , compile and execute a Fortran program that calls the appropriate subroutine . We refer to this approach as \"template-driven programming\". We undertook to construct similar interfaces for other parts of the Port library , with the following design goals: . The interfaces should be accessible to novices , yet powerful enough to be convenient for experienced users. . The problem specifications should be succinct. . The", "label": ["maple", "fortran", "unix shell"], "stemmed_label": ["mapl", "fortran", "unix shell"]}
{"doc": "In the past , nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values . In such domains , the examples can be treated as points and distance metrics can use standard definitions . In symbolic domains , a more sophisticated treatment of the feature space is required . We introduce a nearest neighbor algorithm for learning in domains with symbolic features . Our algorithm calculates distance tables that allow it to produce real-valued distances between instances , and attaches weights to the instances to further modify the structure of feature space . We show that this technique produces excellent classification accuracy on three problems that have been studied by machine learning researchers: predicting protein secondary structure , identifying DNA promoter sequences , and pronouncing English text . Direct experimental comparisons with the other learning algorithms show that our nearest neighbor algorithm is comparable or superior in all three domains . In addition , our algorithm has advantages in training speed , simplicity , and perspicuity . We conclude that experimental evidence favors the use and continued development of nearest neighbor algorithms for domains such as the ones studied here . Introduction Learning to classify objects is fundamental problem in artificial intelligence and other fields , one which has been attacked from many angles . Despite many successes , there are some domains in which the task has proven very difficult , due either to the inherent difficulty of the domain or to the lack of sufficient data for learning . For example , instance-based learning programs (also called exemplar-based (Salzberg , 1990) or nearest neighbor (Cover and Hart , 1967) methods) , which learn by storing examples as points in a feature space , require some means of measuring distance between examples (Aha, 1989; Aha and Kibler , 1989; Salzberg , 1989; Cost and Salzberg , 1990) . An example is usually a vector of feature values plus a category label . When the features are numeric , normalized Euclidean distance can be used to compare examples . However , when the feature values have symbolic , unordered values (e.g. , the letters of the alphabet , which have no natural inter-letter \"distance\") , nearest neighbor methods typically resort to much simpler met- rics , such as counting the features that match . (Towell et al . (1990) recently used this metric for the nearest neighbor algorithm in their comparative study.) Simpler metrics may fail to capture the complexity of the problem domains , and as a result may not perform well. In this paper , we present a more sophisticated instance-based algorithm designed for domains in which some or all of the feature values are sym- bolic . Our algorithm constructs modified \"value difference\" tables (in the style of (Stanfill and Waltz , 1986)) to produce a non-Euclidean distance metric , and we introduce the idea of \"exception spaces\" that result when weights are attached to individual examples . The combination of these two techniques results is a robust instance-based learning", "label": ["text pronunciation", "protein structure", "nearest neighbor", "exemplar-based learning", "instance-based learning"], "stemmed_label": ["text pronunci", "protein structur", "nearest neighbor", "exemplar-bas learn", "instance-bas learn"]}
{"doc": "A visual execution model for Ada tasking can help programmers attain a deeper understanding of the tasking semantics . It can illustrate subtleties in semantic definitions that are not apparent in natural language design . We describe a contour model of Ada tasking that depicts asynchronous tasks (threads of control) , relationships between the environments in which tasks execute , and the manner in which tasks interact . The use of this high-level execution model makes it possible to see what happens during execution of a program . The paper provides an introduction to the contour model of Ada tasking and demonstrates its use . Introduction The Ada programming language is intended for use in real-time applications such as flight navigation or process control software . For this reason , tasking figures prominently in the language design . The semantics of tasking , however, is extremely complex . At the same time that tasking provides the flexibility and control required for the implementation of real-time and embedded software , it is undoubtedly the most difficult of all the Ada language features to understand and to learn to use effectively. This paper describes a visual execution model designed to help software practitioners attain a deeper understanding of the semantics of Ada tasking. Derived from Johnston's contour model for block-structured languages 17 , our model helps a programmer visualize the effects of executing tasking statements. It illustrates subtleties in the semantics of tasking that are not apparent in Copyright 1993 c by ACM , Inc . Permission to copy and distribute this document is hereby granted provided that this notice is retained on all copies , that copies are not altered, and that ACM is credited when the material is used to form other copyright policies standard natural language descriptions of Ada and the motivation for nuances in the definitions of tasking primitives. The Ada Language Reference Manual (ALRM) 21 is the definitive reference for all Ada language features , including tasking . A variety of Ada language text books , e.g . 3 and 10 , describe the language in a more tutorial format , and at least one specializes in Ada tasking 11 . These descriptions , however , lack concreteness , being purposely vague to allow for variations in language imple- mentations . Textual descriptions typically group language constructs according to general features (e.g. , declarations , statements , subprograms , packages, exception handling , tasking) and combine informal explanation with example program fragments . Such descriptions tend to be incomplete and ambiguous. Moreover , the style of presentation obscures subtleties in the interaction of different language features , making it difficult to recognize inconsistencies among the definitions of separate language features . The existence of Ada Issues 1 , and the hundreds of requests for clarifications of the tasking semantics alone, attest to the inadequacy of these natural language descriptions. Formal semantic specifications based on axiomatic or denotational techniques 7 address many of the shortcomings of natural language descriptions. The use of rigorous mathematical notations results in specifications that are", "label": ["contour model", "visual execution model"], "stemmed_label": ["contour model", "visual execut model"]}
{"doc": "Software processes are complex entities that may last for long periods of time and are carried out through the interaction of humans and computerized tools . They need to continuously evolve in order to cope with different kinds of changes or customizations both in the organization and in the technologies used to support software production activities.In recent years , many software process support technologies have been developed , and have currently been further extended and used in trial projects . Moreover , some research prototypes have generated commercial products , that are marketed and currently used in industrial organizations . Despite these significant efforts and results , however , there is still little conceptual characterization and assessment of the properties of software processes and related support environments . It is difficult to compare and assess existing approaches . Even a common characterization of the problems to be addressed seems to be problematic and difficult to achieve . This is particularly true when we consider the process evolution problem , for which it does not seem that a common view of the issue has been established yet.This paper aims at proposing a conceptual framework to describe and assess flexible and evolving software processes . It is based on the assumption that a software process is composed of two main components: a software production process to carry out software production activities , and a software meta-process to improve and evolve the whole software process.The general requirements and properties of the process domain are first discussed , and the meta-process concept is introduced . Then , we discuss several process related concepts and , in particular , the relationship between the meta-process and the rest of the software process . Methods and technologies needed to support the meta-process are highlighted and discussed . Finally , we apply the resulting framework to an example , in order to show the potential and expected benefits of the proposed approach . Introduction During the last decades the problem of producing high quality software products has become increasingly complex and difficult to manage . One reason for this is the rapid evolution of technologies and methods to produce software , together with an increased complexity of the applications to be developed . These two factors are strongly interrelated: advances in the technology enable creation of new products , services and activities , or modification of old ones, which in their turn produce new needs , feedbacks , and requirements to software technology providers . Secondly , software processes are human-oriented CFFS92 , and the interactions among humans and between humans and the tools that support their activities are characterized by high variability and unpredictability . This fact further increases the complexity of the resulting software process , and puts hard demands on management . Finally , software processes may last for long periods of time , and are thus likely to undergo many changes during their lifetime in order to cope with new requirements BL79 . Examples of such changes are the substitution of (part of) the technologies used", "label": ["software process", "process evolution and improvement", "process modeling", "metaprocess"], "stemmed_label": ["softwar process", "process evolut and improv", "process model", "metaprocess"]}
{"doc": "Improvement of message latency and network utilization in torus interconnection networks by increasing adaptivity in wormhole routing algorithms is studied . A recently proposed partially adaptive algorithm and four new fully-adaptive routing algorithms are compared with the well-known e-cube algorithm for uniform , hotspot , and local traffic patterns . Our simulations indicate that the partially adaptive north-last algorithm , which causes unbalanced traffic in the network , performs worse than the nonadaptive e-cube routing algorithm for all three traffic patterns . Another result of our study is that the performance does not necessarily improve with full-adaptivity . In particular , a commonly discussed fully-adaptive routing algorithm , which uses 2n virtual channels per physical channel of a k-ary n-cube , performs worse than e-cube for uniform and hotspot traffic patterns . The other three fully-adaptive algorithms , which give priority to messages based on distances traveled , perform much better than the e-cube and partially-adaptive algorithms for all three traffic patterns . One of the conclusions of this study is that adaptivity , full or partial , is not necessarily a benefit in wormhole routing . Introduction Point-to-point k-ary n-cube and related networks are being used in many recent experimental and commercial multicomputers and multiprocessors 2 , 11 , 26 , 9, 3 . A k-ary n-cube network has an n-dimensional grid structure with k nodes (processors) in each dimension such that every node is connected to two other nodes in each dimension by direct communication links. Routing algorithms , which specify how messages can be sent among processors , are crucial for the efficient operation of a parallel computer . For maximum system performance , a routing algorithm should have high throughput and exhibit the following important features 17 : low-latency message delivery , avoidance of deadlocks , livelocks , and starvation , and ability to work well under various traffic patterns . Since message latencies increase with increase in the number of hops , we consider only minimal routing algorithms as per which a message always moves closer to its destination with each hop taken; another advantage of minimal routing is that livelocks are avoided . The issue of starvation can be avoided by allocating resources such as channels and buffers in FIFO order . Ensuring deadlock-freedom is more difficult and depends heavily on the design of the routing algorithm. Store-and-forward (saf) 5 and wormhole (wh) 14 are two popular switching techniques for interconnection networks . With saf technique , the message latency is the product of the number of hops taken and the sum of the average queuing delay and transmission time of the message per hop. In the wh technique , a message is divided into a sequence of fixed-size units of data , called flits . If a communication channel transmits the first flit of a message , it must transmit all the remaining flits of the same message before transmitting flits of another mes- sage . At any given time , the flits corresponding to a message occupy contiguous channels in the network. In this", "label": ["k-ary n-cubes", "deadlocks", "wormhole routing", "message routing", "multicomputer networks", "adaptive routing", "store-and-forward routing"], "stemmed_label": ["k-ari n-cube", "deadlock", "wormhol rout", "messag rout", "multicomput network", "adapt rout", "store-and-forward rout"]}
{"doc": "An X multiplexor allows a single X Window System client to be displayed and interacted with on several X servers simultaneously . Such a service is necessary for the construction of a computer-supported cooperative work (CSCW) environment such as JVTOS (Joint Viewing and Tele-Operation Service) which is being implemented within RACE II project CIO1 . This paper describes several existing X multiplexors and evaluates their usefulness for JVTOS . Introduction A computer-supported cooperative work (CSCW) environment requires joint viewing . This allows multiple users , each on his own computer workstation , to view and interact with a single application . One solution to this problem is to build a new set of cooperation-aware applications which explicitly support this requirement . Such an approach has several problems . Perhaps the most critical of these is that users would be limited to the use of only special cooperation- aware applications . Given the diversity of computer applications available , this requirement appears very limiting. An X protocol multiplexor (MUX) is another solution to the joint viewing problem . AMUX is a special program which exploits properties of the X Window System to allow joint viewing with unmodified X applications (clients) . Such an approach is called application sharing and has several advantages . First , users are not required to use new applications, they can share their existing applications . Also , the joint viewing system does not need to be modified to incorporate new applications or changes to existing applications . And finally , the task of developing a CSCW environment will be greatly reduced . Instead of reimplementing many existing programs , the developers need only implement the MUX program. The X Window System uses a client/server model . Each workstation is an X server which presents information to the user and receives his responses . Each application program which receives user input or generates output is an X client. Clients and servers communicate using the X protocol through a network connection . This allows a client to execute on a different machine than its user interface , which is presented by its server . The X protocol describes a list of re- quests , events , responses , and errors that can be sent over a client/server connection . A client sends a series of requests to its server . The server then performs the requested actions , such as reporting its status , or drawing windows and their contents . An X server sends a series of responses and events to each of its clients . Responses contain answers to client requests , and events allow the server to report user activity such as key presses and mouse movement . Because all user interface activity of an X client must pass through the client/server connection , it is possible to manipulate this stream with a MUX to provide joint viewing functionality. A MUX must provide three services: connection , multiplexing , and filtering . Connection consists of intercepting the client/server connection . AMUX appears to be a normal server", "label": ["computer-supported cooperative work", "x protocol multiplexer", "distributed systems", "joint viewing and tele-operation service", "computer conferencing", "application sharing", "x window system"], "stemmed_label": ["computer-support cooper work", "x protocol multiplex", "distribut system", "joint view and tele-oper servic", "comput conferenc", "applic share", "x window system"]}
{"doc": "We consider a class of random walks on a lattice , introduced by Gessel and Zeilberger , for which the reflection principle can be used to count the number of k-step walks between two points which stay within a chamber of a Weyl group . We prove three independent results about such reflectable walks: first , a classification of all such walks&semi; second , many determinant formulas for walk numbers and their generating functions&semi; third , an equality between the walk numbers and the multiplicities of irreducibles in the kth tensor power of certain Lie group representations associated to the walk types . Our results apply to the defining representations of the classical groups , as well as some spin representations of the orthogonal groups . Introduction The ballot problem , a classical problem in random walks , asks how many ways there are to walk from the origin to a point (- unit-length steps in the positive coordinate directions while staying in the region . The solution is known in terms of the hook- length formula for Young tableaux; a combinatorial proof , using a reflection argument , is given in 16 , 18 . In 5 , Gessel and Zeilberger consider a more general question , for which some of the same techniques apply . For certain \"reflectable\" walk-types , we want to count the number of k-step walks between two points of a lattice, Supported by an NSF Graduate Fellowship. staying within a chamber of a Weyl group . The steps must have certain allowable lengths and directions. In this paper , we show that this is equivalent to decomposing into irreducibles the kth tensor power of certain representations of reductive Lie groups . We classify the reflectable walk-types and their corresponding repre- sentations . For many cases , we derive determinant formulas for the number of walks , or equivalently , for the multiplicities of irreducibles in tensor powers. In particular , our formulas apply to the defining representations of the classical groups , as well as some spin representations of the orthogonal groups. Our results are closely related to those obtained by Proctor 11 . Reflectable random walks 2.1 Definitions A walk-type is defined by a lattice L , a set S of allowable steps between lattice points , and a polygonal cone C to which the walks are confined . Without affecting the walk problems , we may restrict L and C to the linear span of S , so that L , S , and C have the same linear span . (We may weight the steps with the relative probabilities of choosing each , but this will make little difference in what follows.) We will assume C is a Weyl chamber . That is , defined by a system of simple roots \\Delta ae R n as the orthogonal reflections r ff : ~x 7! ~x \\Gamma 2(ff;~x) ff preserve L and S for all ff in \\Delta; and the r ff generate a finite group W of linear transformations , the Weyl group.", "label": ["weyl group", "hyperbolic bessel function", "random walk", "representation of lie group", "tensor power"], "stemmed_label": ["weyl group", "hyperbol bessel function", "random walk", "represent of lie group", "tensor power"]}
{"doc": "The theoretical background for the design of deadlock-free adaptive routing algorithmsfor wormhole networks is developed . The author proposes some basic definitions and twotheorems . These create the conditions to verify that an adaptive algorithm isdeadlock-free , even when there are cycles in the channel dependency graph . Two designmethodologies are also proposed . The first supplies algorithms with a high degree offreedom , without increasing the number of physical channels . The second methodology isintended for the design of fault-tolerant algorithms . Some examples are given to show theapplication of the methodologies . Simulations show the performance improvement thatcan be achieved by designing the routing algorithms with the new theory . Introduction Multicomputers 1 rely on an interconnection network between processors to support the message-passing mechanism . The network latency 1 can be defined as the time from when the head of a message enters the network at the source until the tail emerges at the destination . In first generation multicom- puters , a store-and-forward mechanism has been used to route messages . Each time a message reaches a node , it is buffered in local memory , and the processor interrupted to execute the routing algorithm . Accordingly , the network latency is proportional to the distance between the source and the destination. However , second generation multicomputers are most distinguished by message routing hardware that makes the topology of the message-passing network practically invisible to the programmer . The message routing hardware uses a routing mechanism known as wormhole routing 10 . As messages are typically at least a few words long , each message is serialized into a sequence of parallel data units , referred to as flow control units , or flits 9 . The flit at the head of a message governs the route . As the header flit advances along the specified route , the remaining flits follow it in a pipeline fashion . If the header encounters a channel already in use , it is blocked until the channel is freed; the flow control within the network blocks the trailing flits. This form of routing and flow control has two important advantages over the store-and-forward routing used in first generation multicomputers . Firstly, it avoids using storage bandwidth in the nodes through which messages are routed . Secondly , this routing technique makes the message latency largely insensitive to the distance in the message-passing network . Since the flits move through the network in a pipeline fashion , in the absence of channel contention, the network latency equals the sum of two terms: d is the time associated with forming the path through the network, where T is the delay of the individual routing nodes found on the path , and d is the number of nodes traversed. - L=B is the time required for a message of length L to pass through a channel of bandwidth B. In second generation multicomputers , the network latency is dominated by the second term for all but very short messages. Another improvement in message performance", "label": ["message passing", "concurrency control", "performance", "index termsdeadlock-free adaptive routing", "wormhole networks", "telecommunication network routing", "channeldependency graph", "fault-tolerant algorithms", "graph theory", "routing algorithms", "adaptive algorithm", "fault tolerant computing"], "stemmed_label": ["messag pass", "concurr control", "perform", "index termsdeadlock-fre adapt rout", "wormhol network", "telecommun network rout", "channeldepend graph", "fault-toler algorithm", "graph theori", "rout algorithm", "adapt algorithm", "fault toler comput"]}
{"doc": "Examines how the performance of a memoryless vector quantizer changes as a function of its training set size . Specifically , the authors study how well the training set distortion predicts test distortion when the training set is a randomly drawn subset of blocks from the test or training image(s) . Using the Vapnik-Chervonenkis (VC) dimension , the authors derive formal bounds for the difference of test and training distortion of vector quantizer codebooks . The authors then describe extensive empirical simulations that test these bounds for a variety of codebook sizes and vector dimensions , and give practical suggestions for determining the training set size necessary to achieve good generalization from a codebook . The authors conclude that , by using training sets comprising only a small fraction of the available data , one can produce results that are close to the results obtainable when all available data are used . Introduction Vector quantization (VQ) 7 , 8 is a data compression technique that can be used to reduce the storage or transmission costs of binary and grayscale images . It is lossy in that the compressed/uncompressed image is a degraded copy of the original image . A major part of the computational cost in VQ is designing the codebook used to encode the image . This design is usually done by \"training\" a codebook on a set of images that is somehow representative of the images to be encoded. It is generally presumed that the more data that are used to design a VQ codebook , the better the codebook will encode its test images . The data consist of blocks of pixels extracted from a training image. We will alternatively refer to these as training blocks or training vectors . A training set of ten 512 \\Theta 512 pixel images , broken into 4 \\Theta 4 blocks , has 163,840 blocks available for training . Encoding a grayscale image at one half bit per pixel requires approximating all these 4 \\Theta 4 vectors with a codebook of 256 representative vectors . Statistically , the distribution of vectors in the image will be well represented even in a small random sub-sample of the total available training set . Since the computational cost of codebook design is heavily dependent on the size of the training set , we would like to be able to determine at what point the diminishing returns of a larger training set size are outweighed by the additional time required to train on it. The purpose of this paper is to investigate the size of training sets that are sufficient for the construction of codebooks which are nearly as good as codebooks trained on all the available data . We describe both theoretical and empirical results . In theory , we show how the VQ problem can be viewed as a learning problem . This allows us to derive upper bounds , from bounds already known in learning theory , on the size of the training set needed to build good codebooks based on the size of", "label": ["formal bounds", "vapnik-chervonenkis dimension", "training image", "training set distortion", "empirical simulations", "learning systems", "statistics", "small training sets", "memoryless vector quantizer", "vector quantisation", "image coding", "test distortion", "vector quantizer codebooks"], "stemmed_label": ["formal bound", "vapnik-chervonenki dimens", "train imag", "train set distort", "empir simul", "learn system", "statist", "small train set", "memoryless vector quantiz", "vector quantis", "imag code", "test distort", "vector quantiz codebook"]}
{"doc": "Three recent trends in database research are object-oriented and deductive databases and graph-based user interfaces . We draw these trends together in a data model we call the Hypernode Model . The single data structure of this model is the hypernode , a graph whose nodes can themselves be graphs . Hypernodes are typed , and types , too , are nested graphs . We give the theoretical foundations of hypernodes and types , and we show that type checking is tractable . We show also how conventional type-forming operators can be simulated by our graph types , including cyclic types . The Hypernode Model comes equipped with a rule-based query language called Hyperlog , which is complete with respect to computation and update . We define the operational semantics of Hyperlog and show that the evaluation can be performed efficiently . We discuss also the use of Hyperlog for supporting database browsing , an essential feature of Hypertext databases . We compare our work with other graph-based data modelsunlike previous graph-based models , the Hypernode Model provides inherent support for data abstraction via its nesting of graphs . Finally , we briefly discuss the implementation of a DBMS based on the Hypernode Model . INTRODUCTION Recent database research has focussed on deductive 7 , 14 , 26 and object-oriented 5 , 22 databases . Deductive databases extend the relational data model with rule-based computation . Rules enable the derivation of further, intentional , tuples from the stored , extensional , tuples . These derived tuples can be used purely for querying purposes or can be inserted into the database . Conversely , object-oriented databases start off with a semantic data model 16 , 20, 31 , which typically supports object identity , inheritance and complex objects , and extend it with features such as methods and encapsulation from object-oriented programming 32 , 37 . Thus , deductive and object-oriented database are largely complementary . The former support extensionally and intentionally defined relations , but not fundamental data abstraction concepts such as classification , identification , inheritance and encapsulation . Conversely , the latter do support these abstraction concepts but do not support relations natur- ally . Hence , recent research has aimed at integrating the two paradigms . The integration has generally taken the route of extending logic-based deductive database languages with features such as object identity , sets , functions , methods and inheritance 1 , 2 , 3 , 14 . In contrast , in this paper we report upon a graph-based approach to such an integration. Our use of graphs has two firstly , graphs are formally defined , well-understood structures; secondly , it is widely accepted that graph-based formalisms considerably enhance the usability of complex systems 19 . Graphs have been used in conjunction with a number of conventional data models , for example the hierarchical and network models 35 , the entity-relationship model 9 and a recent extension thereof for complex objects 27 , and various semantic data models 16 , 20 , 31 . Graphs", "label": ["object store", "rule-based query and update language", "complex object", "nested graph", "types"], "stemmed_label": ["object store", "rule-bas queri and updat languag", "complex object", "nest graph", "type"]}
{"doc": "We introduce a temporal logic for the specification of real-time systems . Our logic , TPTL , employs a novel quantifier construct for referencing time: the freeze quantifier binds a variable to the time of the local temporal context . TPTL is both a natural language for specification and a suitable formalism for verification . We present a tableau-based decision procedure and a model-checking algorithm for TPTL . Several generalizations of TPTL are shown to be highly undecidable . Introduction Linear temporal logic is a widely accepted language for specifying properties of reactive systems and their behavior over time Pnu77 , OL82 , MP92 . The tableau-based satisfiability algorithm for its propositional version , PTL , forms the basis for the automatic verification and synthesis of finite-state systems LP84 , MW84 . PTL is interpreted over models that abstract away from the actual times at which events occur , retaining only temporal ordering information about the states of a system . The analysis of systems with hard real-time requirements , such as bounded response time , calls , however , for the development of formalisms with explicit time . Several attempts have been made to introduce time explicitly in PTL , and to interpret it over models that associate a time with every system state BH81 , PH88 , Koy90 , Ost90 . While these logics allow the specification of typical real-time requirements , most of the important decidability and complexity questions have not been answered. In particular , it has not been understood which timing constraints may be permitted in PTL without sacrificing the decidability of the verification problem. Our objective is the development of a real-time extension of PTL that admits a generalization of the PTL-based tools for algorithmic verification . To begin with , a notational extension of PTL must be capable of relating the times of different system states . One commonly proposed method This research was supported in part by an IBM graduate fellowship to the second author , by the National Science Foundation under grants CCR-8812595 and CCR-9200794 , by the Defense Advanced Research Projects Agency under contract N00039-84-C-0211 , and by the United States Air Force Office of Scientific Research under contracts AFOSR- 88-0281 and F49620-93-1-0056. y A preliminary version of this paper appeared in the Proceedings of the 30th IEEE Symposium on Foundations of Computer Science (FOCS 1989) , pp . 164-169 , and an extended version appeared in The Journal of the ACM 41, 1994 , pp . 181-204. employs first-order temporal logic , with one of the state variables representing time PH88 , Ost90, LA92 . We claim that the unconstrained quantification of time variables allowed by this approach does not restrict the user to reasonable and readable specifications. Instead , we propose a novel , restricted , form of quantification - we call it freeze quantification - in which every variable is bound to the time of a particular state . Freeze quantification identifies, so we argue , precisely the subclass of \"intended\" specifications , and it leads to a concise", "label": ["discrete time", "dense time", "real-time requirements", "linear-time temporal logic", "model checking", "expspace-completeness"], "stemmed_label": ["discret time", "dens time", "real-tim requir", "linear-tim tempor logic", "model check", "expspace-complet"]}
{"doc": "We present a construction of a single-writer , multiple-reader atomic register from single-writer , single-reader atomic registers . The complexity of our construction is asymptotically optimal; O(M2 shared single-writer , single-reader safe bits are required to construct a single-writer , M-reader , N-bit atomic register . Introduction The currently accepted theory of concurrent computing is deeply rooted in the concept of atomic registers . An atomic register is a data object that is read or written by one or more processes according to the following assumption: if several read or write operations of the register are enabled simultaneously in different processes , then these operations are executed in some sequence , one after the other , and not concurrently . This assumption strongly suggests the well-known interleaving semantics of concurrent computations . The validity of this assumption is thus a cornerstone in justifying the present theory of concurrent computing. One way to check the validity of this assumption is to show that an atomic register can be constructed using a set of more realistic registers that can be read and written concurrently by different processes . In such a construction , a process reads or writes the constructed atomic register by invoking a program; within such a program , only registers of the more realistic kind are read or written . Different programs can be invoked by different processes concurrently; it is required , however , that the net effect resembles that of a serial invocation . The programs are restricted to be wait-free , i.e. , synchronization primitives, such as P , V , or await , and unbounded busy-wait loops are not allowed . This restriction guarantees that a process reads or writes the constructed atomic register in a finite amount of time , regardless of the activities of other processes . (This also means that the read or write of a process is immune to the failure of other processes that also access the register.) The wait-freedom restriction distinguishes the problem of constructing an atomic register from the classic readers-writers problem 6 . Peterson 16 was the first to suggest the problem of constructing atomic registers from safe registers . A safe register is a data object that can be read or written concurrently by different processes; if a read operation overlaps a write operation then it may return any value from the value domain of the register , and if a read operation does not overlap any operation then it obtains the most recently written value . The leap from safe registers to atomic registers is quite large; fortunately , it can be divided into a number of smaller steps. Figure 1 depicts two chains of register constructions that lead from single-writer, single-reader , single-bit safe registers to K-writer , M-reader , N -bit atomic registers . The notation K=M=N denotes a register that can be written by K processes , can be read by M processes , and can store an N -bit value . Each step in the figure is labeled by a reference to the", "label": ["wait-free synchronization", "atomic register", "linearizability"], "stemmed_label": ["wait-fre synchron", "atom regist", "lineariz"]}
{"doc": "For any fixed dimension ) time , Information Processing Letters , v.22 n.1 , p.21-24 , January 2 , 1986 Introduction The linear programming problem in fixed dimension is to maximize a linear function of a fixed number , d , of variables , subject to n linear inequality constraints , where n is not fixed . Megiddo 11 showed that for any d , this problem can be solved in O(n) time. Clarkson 4 and Dyer 7 improved the constant of proportionality . Clarkson 5 later developed linear-time probabilistic algorithms with even better complexity . The problem in fixed dimension is interesting from the point of view of parallel computation , since the general linear programming problem is known to be P-complete . The algorithm of 11 can be parallelized efficiently , but the exact parallel complexity of the problem in fixed dimension is still not known . 1 Here we develop a very efficient probabilistic parallel algorithm based on Clarkson's 5 scheme. In this paper , when we say that a sequence of events fE n g 1 occurs almost surely, we mean that there exists an ffl ? 0 such that prob(E n . A consequence of this estimate is that with probability 1 , only a finite number of the events do not occur. The main result of this paper generalizes a known fact 12; 10 that the maximum of n items can be computed almost surely in constant time. As mentioned above , the basic idea of the underlying sequential algorithm is due to Clarkson 5 . His beautiful iterative sequential algorithm uses an idea of Welzl 14 . As in Clarkson's algorithm , we also sample constraints repeatedly with variable probabilities. Several additional ideas and some modifications were , however , required in order to achieve the result of this paper . Our probabilistic analysis is also different , and focuses on probabilities of failure to meet time bounds , rather than on expected running times. In particular , a suitable sequential implementation of our algorithm can be shown to terminate almost surely within the best known asymptotic bounds on the expected time. 1 Ajtai and Megiddo recently developed deterministic algorithms which run on a linear number of processors in poly(log log n) time. In Section 2 we present a special form of the output required from a linear programming problem , which unifies the cases of problems with optimal solutions and unbounded ones . In Section 3 we describe the algorithm and provide the necessary probabilistic analysis 2 . Preliminaries The purpose of this section is to state the required form of the output of the linear programming problem , which turns out to be useful for our purposes in this paper. 2.1 A special form of the output ng and suppose the linear programming problem is given in the form Minimize c \\Delta x subject to a i where fc; a 1 ; . ; a n g ae R d and b 1 ; . ; b n are real scalars . An", "label": ["parallel computation", "probabilistic computation", "linear programming", "computational geometry", "multidimensional search"], "stemmed_label": ["parallel comput", "probabilist comput", "linear program", "comput geometri", "multidimension search"]}
{"doc": "Strongly-typed languages present programmers with compile-time feedback about the type correctness of programs . Errors during polymorphic type checking take the form of a unification failure for two types . Finding the source of the type error in the code is often difficult because the error may occur far from the spot where the inconsistency is detected . As functional languages use more and more complex type systems , the difficulty of interpreting and locating these errors will increase . To locate the source of type errors the programmer must unravel the long chain of deductions and type instantiations made during type reconstruction . This paper describes an approach that maintains the deductive steps of type inference and the reasons for type instantiations . The approach could be used in an interactive system to guide the programmer to the source of a type error or to explain why the compiler assigned a particular type to an expression . Introduction One annoying aspect of strongly-typed languages with parametric polymorphism is that it is sometimes unclear why an expression cannot be typed . Many programmers have experienced the feeling of incredulity that sometimes arises after an expression has been rejected by the compiler . There is no reason why the compiler cannot be forthcoming about the type-checking analysis . In this paper we describe a way in which the type analysis can be explained so that the programmer may be led to the source of type errors . In particular , we consider the case of type reconstruction for all the essential constructs of the programming language ML. The programming language ML 5 is a strongly-typed functional language with polymorphism . Its interesting type system , which has the property that the types of all identifiers can be deduced by their use 4 , has made it popular and the model of type systems for other languages . Not only do we focus on this language as the object of our study , but we also have implemented our approach in that language using Standard ML of New Jersey 1 . We are inspired by the paper 7 concerning the British Nationality Act . In this paper the authors described capturing the legal requirements for establishing British citizenship in a PROLOG program. Because the requirements for British citizenship are so complex it is useful to have a system that explains Appeared in ACM Letters on Programming Languages and Systems , volume 2 , numbers 1-4 , March-December 1994 , pages 17-30. the steps taken to reach a conclusion . The same idea seems appropriate for the deductions made during type reconstruction. We want to ask how the type system arrived at a particular type for an expression . Not only is the answer to this question useful when the type analysis has led to an unexpected type for an expression , but it is particularly useful in the case of type errors . In this case , type analysis has arrived at two inconsistent types and the programmer may find it difficult to understand", "label": ["polymorphic type reconstruction", "type errors"], "stemmed_label": ["polymorph type reconstruct", "type error"]}
{"doc": "The notion of a program slice , originally introduced by Mark Weiser , is useful in program debugging , automatic parallelization , program integration , and software maintenance . A slice of a program is taken with respect to a program point and a variable x; the slice consists of all statements of the program that might affect the value of x at point . An interprocedural slice is a slice of an entire program , where the slice crosses the boundaries of procedure calls . Weiser's original interprocedural-slicing algorithm produces imprecise slices that are executable programs . A recent algorithm developed by Horwitz , Reps , and Binkley produces more precise (smaller) slices by more accurately identifying those statements that might affect the values of x at point . These slices , however , are not executable . An extension to their algorithm that produces more precise executable interprocedural slices is described together with a proof of correctness for the new algorithm . INTRODUCTION The slice of a program with respect to program point and variable x consists of all statements and predicates of the program that might affect the value of x at point . This concept , originally discussed by Mark Weiser in 17 , can be used to isolate individual computation threads within a program . Slicing can help a programmer understand complicated code 17 , can aid in debugging and software maintenance 7 , 8 , 12 , and can be used for automatic parallelization 2 , 16 . Horwitz , Reps , and Binkley identify two different but related \"slicing problems\" 9 . It is important to understand the distinction between them (the names come from 15 ). This work was supported in part by a summer research grant from Loyola College. Author's address: Computer Science Department , Loyola College , 4501 North Charles Street , Baltimore Maryland 21210-2699 . binkley@cs.loyola.edu Version (1) (Closure Slice) The slice of a program with respect to program point and variable x consists of components (e.g., statements and predicates) of the program that might affect the value of x at point p. Version (2) (Executable Slice) The slice of a program with respect to program point and variable x consists of a reduced program that computes the same sequence of values for x at . That is , at point the behavior of the reduced program with respect to variable x is indistinguishable from that of the original program. For intraprocedural slicing-slicing within a single procedure where the slice does not extend across procedure boundaries-a solution to Version (1) provides a solution to Version (2) , since the \"reduced pro- gram\" required in Version (2) can be obtained by restricting the original program to just the components found in the solution for Version (1) 13 . For interprocedural slicing-generating a slice of an entire program where the slice extends across the boundaries of procedure calls-restricting the original program to just the components found for Version (1) may yield a program that is syntactically incorrect (and thus certainly not a solution", "label": ["program slicing", "program dependence graph", "control dependence", "data dependence"], "stemmed_label": ["program slice", "program depend graph", "control depend", "data depend"]}
{"doc": "We show how precise groundness information can be extracted from logic programs . The idea is to use abstract interpretation with Boolean functions as approximations to groundness dependencies between variables . This idea is not new , and different classes of Boolean functions have been used . We argue , however , that one class , the positive functions , is more suitable than others . Positive Boolean functions have a certain property which we (inspired by A . Langen) call condensation . This property allows for rapid computation of groundness information . Introduction Groundness analysis is arguably the most important dataflow analysis for logic programs . The question: \"At a given program point , is variable x always bound to a term that contains no vari- ables?\" is not only important for an optimizing compiler attempting to speed up unification , but for practically every programming tool which applies some kind of dataflow analysis . The reason is that most other analyses , such as independence analysis (whether instantiation of x indirectly instantiates other variables) or occur-check analysis (whether unification can safely be performed without the occur-check) employ groundness analysis to improve accuracy . For example , if x is ground (a terminological abuse we consistently use for \"bound to a ground term\") , then x cannot possibly share with other variables , and this is useful information for independence , occur-check, and many other dataflow analyses. Dataflow analysis of logic programs is different from the analysis of imperative or functional programming languages . This is partly because the language is nondeterministic , but , more impor- tantly , because dataflow in a sense is bidirectional , owing to the use of unification . The point is that a variable in a logic programming language is very different from a variable in the other language paradigms . It is sometimes referred to as a \"logical variable\" and characterized as \"constrain-only\" since the execution of a logic program proceeds by steps that continually narrow the set of possible values that a variable may take. While this characteristic of logic program execution makes dataflow analyses harder in some ways , it also opens up new views of some analysis problems . For example it suggests the possibility of propagating conditional invariants of the form \"From this point on , if variable x has (ever gets) property , then variable y has (will have) property r .\" In this note we show how this applies to groundness . The idea is to let the statement \"program variable x is ground\" be represented by the propositional variable x . A groundness dependency such as \"whenever y becomes ground , so does may then be represented by a Boolean function , in this case the function denoted by y ! x . If we use Boolean functions as approximations to runtime states , then abstract interpretation gives a natural way of specifying a very precise groundness analysis (Sections 2 and 3). This idea is not new , and different classes of Boolean functions have been used", "label": ["propositional logic", "condensation", "abstract interpretation", "groundness analysis"], "stemmed_label": ["proposit logic", "condens", "abstract interpret", "ground analysi"]}
{"doc": "Many applications of constraint logic programming (CLP) languages require not only testing if a set of constraints is satisfiable , but also finding the optimal solution which satisfies them . Unfortunately , the standard declarative semantics for CLP languages does not consider optimization but only constraint satisfaction . Here we give a model theoretic semantics for optimization , which is a simple extension of the standard semantics , and a corresponding operational semantics , which may be efficiently implemented . Introduction One of the most promising innovations in recent programming language design is the amalgamation of constraint programming and logic programming 8 . Constraints provide a powerful and natural programming paradigm , in which the objects of computation are not explicitly constructed but rather they are implicitly defined using constraints . Applications for constraint logic programming languages have been in many diverse areas . They include electrical circuit analysis 18 , synthesis and diagnosis 6 , options trading and financial planning 13 . Other applications are in traditional operations research problems , such as cutting stock and scheduling . Pure constraint logic programming languages only provide for testing constraint satisfaction , however , many applications desire an optimal solution . For this reason , although the standard semantics of CLP languages 8 does not include optimization operators , some existing CLP languages provide ad hoc non-logical optimization 3 and in other languages , optimization may be obtained using meta-level facilities 7 . We address the problem of giving a simple declarative semantics for optimization which has a corresponding operational semantics that allows efficient implementation. Our main contribution is a model theoretic and operational semantics for optimization in CLP languages which is a simple extension of the usual semantics . Features of the operational semantics which allow it be given a corresponding declarative semantics are that the current best optimum is used to prune the search space , allowing the operational semantics to find optimums for subgoals which ostensibly have infinite derivations and optimization subgoals are not selected until the global variables are ground . A novel feature of the operational semantics is that optimization subgoals return constraints when the optimal value occurs over a range of points . We give soundness and completeness results for this operational semantics in terms of the 3-valued completion of the program by translating optimization to negation. Example A major application of CLP languages is for constraint satisfaction problems (CSPs) . This requires constructing a set of constraints and determining whether the set is satisfiable , that is whether it has an answer . However , CSPs , contrary to their name , often include an optimization component . Not only must the answer satisfy the required constraints , it should also be the best such answer. Consider the following CLP(R) program for determining the values of stock options (adapted from 13 ). A \"call\" is a contract to allow the holder the option to buy a stock at some exercise price (X ) at some later date if desired . Obviously if later the stock price", "label": ["semantics", "constraint logic programming"], "stemmed_label": ["semant", "constraint logic program"]}
{"doc": "This article develops a dynamic generalization of the nonuniform rational B-spline (NURBS) model . NURBS have become a defacto standard in commercial modeling systems because of their power to represent free-form shapes as well as common analytic shapes . To date , however , they have been viewed as purely geometric primitives that require the user to manually adjust multiple control points and associated weights in order to design shapes . Dynamic NURBS , or D-NURBS , are physics-based models that incorporate mass distributions , internal deformation energies , and other physical quantities into the popular NURBS geometric substrate . Using D-NURBS , a modeler can interactively sculpt curves and surfaces and design complex shapes to required specifications not only in the traditional indirect fashion , by adjusting control points and weights , but also through direct physical manipulation , by applying simulated forces and local and global shape constraints . D-NURBS move and deform in a physically intuitive manner in response to the user's direct manipulations . Their dynamic behavior results from the numerical integration of a set of nonlinear differential equations that automatically evolve the control points and weights in response to the applied forces and constraints . To derive these equations , we employ Lagrangian mechanics and a finite-element-like discretization . Our approach supports the trimming of D-NURBS surfaces using D-NURBS curves . We demonstrate D-NURBS models and constraints in applications including the rounding of solids , optimal surface fitting to unstructured data , surface design from cross sections , and free-form deformation . We also introduce a new technique for 2D shape metamorphosis using constrained D-NURBS surfaces . Introduction In 1975 Versprille 40 proposed the Non-Uniform Rational B-Splines or NURBS . This shape representation for geometric design generalized Riesenfeld's B-splines . NURBS quickly gained popularity and were incorporated into several commercial modeling systems 23 . The NURBS representation has several attractive properties . It offers a unified mathematical formulation for representing not only free-form curves and surfaces , but also standard analytic shapes such as conics , quadrics , and surfaces of revolution . By adjusting the positions of control points and manipulating associated weights , one can design a large variety of shapes using NURBS 10 , 12 , 24 , 21 , 22 , 23 , 39 . Because NURBS are a purely geometric representation , however , their extraordinary flexibility has some drawbacks: ffl The designer is faced with the tedium of indirect shape manipulation through a bewildering variety of geometric parameters; i.e. , by repositioning control points , adjusting weights , and modifying knot vectors . Despite the recent prevalence of sophisticated 3D interaction devices , the indirect geometric design process remains clumsy and time consuming in general. ffl Shape design to required specifications by manual adjustment of available geometric degrees of freedom is often elusive , because relevant design tolerances are typically shape-oriented and not control point/weight oriented . The geometric \"redundancy\" of NURBS tends to make geometric shape refinement ad hoc and ambiguous; for instance , to adjust a shape should the", "label": ["finite elements", "constraints", "optimal curve and surface fitting", "shape metamorphosis", "cross-sectional shape design", "nurbs", "trimming", "free-form deformation", "dynamics", "cagd", "deformable models", "solid rounding"], "stemmed_label": ["finit element", "constraint", "optim curv and surfac fit", "shape metamorphosi", "cross-sect shape design", "nurb", "trim", "free-form deform", "dynam", "cagd", "deform model", "solid round"]}
{"doc": "3D shape modeling has received enormous attention in computer graphics and computer vision over the past decade . Several shape modeling techniques have been proposed in literature , some are local (distributed parameter) while others are global (lumped parameter) in terms of the parameters required to describe the shape . Hybrid models that combine both ends of this parameter spectrum have been in vogue only recently . However , they do not allow a smooth transition between the two extremes of this parameter spectrum . We introduce a new shape-modeling scheme that can transform smoothly from local to global models or vice versa . The modeling scheme utilizes a hybrid primitive called the deformable superquadric constructed in an orthonormal wavelet basis . The multiresolution wavelet basis provides the power to continuously transform from local to global shape deformations and thereby allow for a continuum of shape modelsfrom those with local to those with global shape descriptive powerto be created . The multiresolution wavelet basis allows us to generate fractal surfaces of arbitrary order that can be useful in describing natural detail . We embed these multiresolution shape models in a probabilistic framework and use them for recovery of anatomical structures in the human brain from MRI data . A salient feature of our modeling scheme is that it can naturally allow for the incorporation of prior statistics of a rich variety of shapes . This stems from the fact that , unlike other modeling schemes , in our modeling , we require relatively few parameters to describe a large class of shapes . Introduction Modeling shapes is an important and integral part of computer graphics as well as computer vi- sion . In computer graphics , modeling shapes is an important ingredient of shape synthesis while in computer vision , it is needed for shape reconstruction and shape recognition from sensed data. Many shape modeling schemes have been proposed in the graphics 31 , 4 , 28 , 26 , 33 , 13 , 37 , 21 as well as vision literature 6 , 43 , 29 , 2 , 41 , 9 , 44 , 45 , 42 , 14 . In this paper , we will be concerned with shape modeling with a view toward facilitation of shape recovery from 3D data for computer vision/medical imaging applications . In computer vision , the motivation for modeling shapes has been primarily driven by either shape reconstruction or shape recognition tasks . Shape reconstruction from sensed data requires a broad geometric coverage . The models must recover detailed structure from noisy data using only the weakest of the possible assumptions about the observed shapes . Generalized spline models with continuity constraints are well suited for fulfilling the goals of shape reconstruction 38 , 43 , 8 . Generalized splines are the key ingredient of the dynamic shape modeling paradigm introduced by Terzopoulos et . al. , 40 , 41 . Incorporating dynamics into shape modeling with generalized splines , allows for creating realistic animation for computer graphics applications and also for tracking", "label": ["surface fitting", "multiresolution representation", "stiffness matrix", "fractal surfaces", "superquadrics", "orthonormal wavelet basis", "deformable surfaces", "bayesian estimation"], "stemmed_label": ["surfac fit", "multiresolut represent", "stiff matrix", "fractal surfac", "superquadr", "orthonorm wavelet basi", "deform surfac", "bayesian estim"]}
{"doc": "The authors consider uniform subclasses of the nonuniform complexity classes defined by Karp and Lipton L'Enseign . Math. , 28 (1982) via the notion of advice functions . These subclasses are obtained by restricting the complexity of computing correct advice . Also , the effect of allowing advice functions of limited complexity to depend on the input rather than on the input's length is investigated . Among other results , using the notions described above , new characterizations of (a) $NP^ NP\\cap SPARSE $ , (b) $\\NP$ with a restricted access to an $\\NP$ oracle , and (c) the odd levels of the boolean hierarchy are given . As a consequence , it is shown that every set that is nondeterministically truth-table reducible to SAT in the sense of Rich J . Comput . System Sci. , 38 (1989) , pp . 511--523 is already deterministically truth-table reducible to SAT . Furthermore , it turns out that the $\\NP$ reduction classes of bounded versions of this reducibility coincide with the odd levels of the boolean hierarchy . Introduction . In their fundamental paper , Karp and Lipton 23 introduced the notion of advice functions and investigated nonuniform complexity classes which they denoted by C=F , where C is a class of sets and F is a class of (advice) functions . A typical class is P=poly , where poly is the set of polynomially length bounded functions . The interest in P=poly stems from the fact that it consists exactly of the languages that can be computed by polynomially size-bounded circuits 34 . Intuitively , a set A is in C=F , if A can be solved by a machine of type C that gets , in addition to the input x , the advice f(x) , where f is a function in F depending only on the length of x . Many researchers have considered nonuniform classes where the function class F is defined by a quantitative length restriction such as poly and log (see , for example , 3 , 5 , 23 , 36 ) . Note that for such F there are nonrecursive functions in F , and therefore C=F contains nonrecursive languages. Here , we consider uniform language classes obtained by imposing complexity bounds on the advice functions . Note that K-amper 22 investigates refinements of the original C=F definition by delimiting the complexity of proof sets , i.e. , special Abteilung f?r Theoretische Informatik , Universit?t Ulm , Oberer Eselsberg , D-W-7900 Ulm, Germany . Supported in part by the DAAD through Acciones Integradas 1991 , 313-AI-e-es/zk. y Abteilung f?r Theoretische Informatik , Universit?t Ulm , Oberer Eselsberg , D-W-7900 Ulm, Germany . Work done in part while visiting the University of Rochester . Supported in part by DFG Postdoctoral Stipend Th 472/1-1 , NSF Grant CCR-8957604 , and by the DAAD through Acciones Integradas 1991 , 313-AI-e-es/zk. sets of correct advice . In contrast to this , we directly bound the complexity of computing correct advice . With this concept , we are able to", "label": ["nonuniform complexity classes", "truth-table reducibility", "relativization", "boolean hierarchy", "restricted oracle access", "sparse np sets", "advice classes", "optimization functions"], "stemmed_label": ["nonuniform complex class", "truth-tabl reduc", "relativ", "boolean hierarchi", "restrict oracl access", "spars np set", "advic class", "optim function"]}
{"doc": "One of the most important sets associated with a poset $ \\cal P $ is its set of linear extensions , $E( \\cal P )$ . This paper presents an algorithm to generate all of the linear extensions of a poset in constant amortized time , that is , in time $O(e(\\cP))$ , where |E(\\cP)|$ . The fastest previously known algorithm for generating the linear extensions of a poset runs in time $O(n \\! \\cdot \\! e(\\cP))$ , where $n$ is the number of elements of the poset . The algorithm presented here is the first constant amortized time algorithm for generating a \"naturally defined\" class of combinatorial objects for which the corresponding counting problem is #P-complete . Furthermore , it is shown that linear extensions can be generated in constant amortized time where each extension differs from its predecessor by one or two adjacent transpositions . The algorithm is practical and can be modified to count linear extensions efficiently and to compute $P (x y)$ , for all pairs $x,y$ , in time $O(n^2 e( \\cal P ))$ . Introduction . One definition of the adverb \"fast\" is \"in quick succession\" (Webster's Collegiate Dictionary 1 ) . The purpose of this paper is to show that the linear extensions of a partially ordered set (poset) can be generated fast; so fast, in fact , that no algorithm can be faster , up to constant factors . Furthermore , the constants involved are very small and our algorithms extend the practical range of posets for which extensions can be generated and counted. Linear extensions are of great interest to computer scientists because of their relation to sorting and scheduling problems . For example , there are many NP-complete one-processor scheduling problems with precedence constraints ( 13 ) , and one obvious way of solving such problems is by generating all linear extensions of the precedence constraints and picking the best extension . Linear extensions are also of interest to combinatorists because of their relation to counting problems ( 2 , 21 ) . Our results can be used to efficiently generate standard Young Tableau of a given shape , alternating permutations , and any of the many other combinatorial objects that can be viewed as linear extensions of particular posets. Given a poset P , two questions naturally arise . The generation question asks whether the linear extensions , E(P) , of P be efficiently generated . The counting question asks whether e(P) , the size of the set E(P) , can be efficiently determined. The recent result of Brightwell and Winkler 4 that the counting question is #P- complete indicates that the counting question may be no easier than the generation question . We give the best possible answer to the generation question in the sense that our algorithm generates E(P) in time complexity O(e(P)) (aside from a small amount of preprocessing). We say that a generation algorithm runs in constant amortized time if it runs in time O(N ) , where N is the number of objects generated . In", "label": ["transposition", "poset", "combinatorial gray code", "linear extension"], "stemmed_label": ["transposit", "poset", "combinatori gray code", "linear extens"]}
{"doc": "The authors analyze the computational complexity of sparse rational interpolation , and give the first deterministic algorithm for this problem with singly exponential bounds on the number of arithmetic operations . Introduction In this paper we present an algorithm which , given a black box to evaluate a t-sparse (a quotient of two t-sparse polynomials) n-variable rational function f with integer coefficients, can find the coefficients and exponents appearing in a t-sparse representation of f using t (nt) log d black box evaluations and arithmetic operations and with arithmetic depth (nt log d) O(1) , where d denotes the degree of t-sparse representation of f (see the Theorem at the end of section 4 for an exact statement of this result) . Although these bounds involve the size of the exponents , this dependency only arises at the end of our algorithm . The algorithm genuinely produces (that is produces in a way whose arithmetic complexity does not depend on the size of the coefficients of f or on the degree of f , 19 ) a polynomial whose roots are p-powers (for some small p) of the exponents appearing in a t-sparse representation of f . All known algorithms to find the roots of this polynomial (even knowing that they are p-powers) have complexity that depend on the size of the roots . This dependency also occurs in algorithms for interpolating t-sparse polynomials (c.f., 1 ) for the same reason. To find the exponents appearing in some t-sparse representation of a t-sparse univariate rational function f(X) we proceed as follows: We consider representations of f(X) of the are real numbers . Such a function is called a real quasirational function . Furthermore , we call such a representation minimal if it has a minimal number of nonzero terms in the numerator and denominator and is called normalized if some term is 1 . We show that there are only a finite number of minimal normalized representations and that the exponents must be integers . We are able to produce a system T of polynomial equalities and inequalities (whose coefficients depend on the values of f(X) at t O(t) points) that determine all the possible values of any such ff i and fi i . Using the methods of 13 , we can then find all ff i and fi i . To find the exponents when multivariate polynomial , we show how to produce sufficiently many n-tuples of integers (- such that the exponents of f can be recovered from the exponents of all the f(X - Complexity issues for t-sparse polynomial and rational function interpolation have been dealt with in several papers . Polynomial (black box) interpolation was studied in 1 , 2 , 9 , 12 , 17 , 19 , 27 , 28 . For bounded degree rational interpolation (when the bound on the degree is part of the input) see 15 , 16 , 25 . Approximative unbound interpolation arises also naturally in issues of computational learnability of sparse rational functions (cf . 21 ) . The", "label": ["interpolation", "sparse rational functions", "arithmetic operations", "computational complexity"], "stemmed_label": ["interpol", "spars ration function", "arithmet oper", "comput complex"]}
{"doc": "The external path length of a tree $T$ is the sum of the lengths of the paths from the root to each external node . The maximal path length difference , $\\Delta$ , is the difference between the lengths of the longest and shortest such paths . Tight lower and upper bounds are proved on the external path length of binary trees with $N$ external nodes and maximal path length difference $\\Delta$ is prescribed . In particular , an upper bound is given that , for each value of $\\Delta$ , can be exactly achieved for infinitely many values of $N$ . This improves on the previously known upper bound that could only be achieved up to a factor proportional to $N$ . An elementary proof of the known upper bound is also presented as a preliminary result . Moreover , a lower bound is proved that can be exactly achieved for each value of $N$ and $\\Delta\\leq N/2$ . Introduction . Binary trees constitute the most important and widely used data structure for the storage and retrieval of information . The cost of accessing information stored in a node is proportional to the distance of the node from the root. An important measure of efficiency , often considered with respect to a binary tree T , is its external path length External(T ) , that is the sum of the distances of the external nodes from the root as this is related to the average cost of an unsuccessful search in the tree T . Moreover , the external path length of T is related to the internal path length that is the sum of the distances of the internal nodes from the root and corresponds to the average cost of a successful search in the tree T . It is well known that the external path length of a binary tree with N external nodes is \\Theta(N lg N) in the best case while in the worst case can be as bad as \\Theta(N 2 ). The large gap between the best and the worst case motivates the study of this important quantity when some additional information about the tree is available . Nievergelt and Wong 7 proposed an upper bound for the external path length of a tree T in term of the number of external nodes and the maximum weight balance of all its subtrees. More recently , Klein and Wood 5 obtained an upper bound that requires much less information about the tree . Namely , they derived an upper bound on the external path length of a T in terms of N , the number of external nodes , and \\Delta , the maximum of the differences of the lengths of the paths from the root to each external node . In the case Dipartimento di Informatica ed Applicazioni , Universit'a di Salerno , 84081 Baronissi (Salerno), Italy . Part of this work was done while the author was visiting IBM Research Division , T . J . Watson Research Ctr , Yorktown Heights , NY", "label": ["binary search trees", "path length"], "stemmed_label": ["binari search tree", "path length"]}
{"doc": "A basic question about NP is whether or not search reduces in polynomial time to decision . This paper indicates that the answer is negative: Under a complexity assumption (that deterministic and nondeterministic double-exponential time are unequal) a language in NP for which search does not reduce to decision is constructed . These ideas extend in a natural way to interactive proofs and program checking . Under similar assumptions , the authors present languages in NP for which it is harder to prove membership interactively than it is to decide this membership , and languages in NP that are not checkable . Summary . We summarize relationships amongst the various complexity classes wehave discussed. First , some notation . We de ne the triple exponential time class Similarly,we let BPEEE denote the class of languages recognized with bounded error by a probabilistic nTM running in time 222 for some constant c 0. The following inclusions are known , or easily derived from known techniques: 3 compIP Check frIP MIP Coh. Under the assumption NEE BPEE we establish the following:4 NP is not contained in any of the following: compNP; compIP; Check; frIP. 5 NP Coh is not contained in any of the following: compNP; compIP; Check; frIP. For the results of line 4 , see Theorems 2.9 , 4.4 , 5.3 and 3.6 . For those of line 5 , see the theorem and discussion at the end of Section 5 . Finally , under the assumption NEEE BPEEE , BFestablish the following: 6 NP Coh.2 Decision versus SearchinNP In this section we present a simple construction of a language in NP for which searchdoesnot reduce to decision , assuming that EE NEE . In later sections we will extend the argumenttointeractive proofs and program checking . Let us begin with the de nitions. 2.1 De nitions The goal of this section is to make precise what we mean by search reduces to decision for an NP language L.\" Since the issues were discussed at length in Section 1.1,we will here be brief , stating the formal de nitions and limiting the discussion to essentials. It is convenient to proceed in steps . We begin by de ning NP-relations and saying what it means for search to reduce to decision for them . We then use this this to say what it means for search to reduce to decision for a NP language. De nition 2.1 Let ; beapolynomial time computable binary relation , and let x 2f0; 1g . We let x f w and call the members of this set -witnesses for x.We say that is an NP-relation if there exists a constant c 2 N such that for all x 2f0; 1g it is the case that x f0; 1gjxjc . The language de ned by is f x 2f0; 1g : x ;gand is denotedL . Note that if is an NP-relation then L 2 NP. Notation: If W is an oracle machine , then WL x denotes the output of W with oracle L f0; 1g and", "label": ["sparse sets", "interactive proofs", "quadratic residuosity", "np-completeness", "program checking", "self-reducibility"], "stemmed_label": ["spars set", "interact proof", "quadrat residuos", "np-complet", "program check", "self-reduc"]}
{"doc": "In this paper we present a new technique for piecewise-linear surface reconstruction from a series of parallel polygonal cross-sections . This is an important problem in medical imaging , surface reconstruction from topographic data , and other applications . We reduce the problem , as in most previous works , to a series of problems of piecewise-linear interpolation between each pair of successive slices . Our algorithm uses a partial curve matching technique for matching parts of the contours , an optimal triangulation of 3-D polygons for resolving the unmatched parts , and a minimum spanning tree heuristic for interpolating between non simply connected regions . Unlike previous attempts at solving this problem , our algorithm seems to handle successfully any kind of data . It allows multiple contours in each slice , with any hierarchy of contour nesting , and avoids the introduction of counter-intuitive bridges between contours , proposed in some earlier papers to handle interpolation between multiply connected regions . Experimental results on various complex examples , involving actual medical imaging data , are presented , and show the good and robust performance of our algorithm . Introduction The problem of reconstructing the boundary of a solid object from a series of parallel planar cross-sections has attracted much attention in the literature during the past two decades . The main motivation for this problem comes from medical imaging applications , where cross-sections of human organs , such as bones , tumors and tissues , are obtained by CT (Computerized Tomog- raphy) or MRI (Magnetic Resonance Imaging) appa- Work on this paper by both authors has been supported by a grant from the G.I.F. , the German-Israeli Foundation for Scientific Research and Development . Work on this paper by the second author has also been supported by National Science Foundation Grant CCR-91-22103 , and by grants from the U.S.-Israeli Binational Science Foundation , and the Israel Science Fund administered by the Israeli Academy of Sciences. y School of Mathematical Sciences , Tel-Aviv University , Tel-Aviv 69978 , Israel , and Algotec Systems Ltd. , Raanana , Israel. z School of Mathematical Sciences , Tel-Aviv University , Tel-Aviv 69978 , Israel , and Courant Institute of Mathematical Sci- ences , New York University , New York , NY 10012 , USA rata . These cross-sections , hereafter called slices , are the basis for interpolating the boundary surface of the organ . The interpolated object can then be displayed in graphics applications , or (more recently) even manufactured by an NC (Numerically Controlled) or an RP (Rapid Prototyping) machine . Another motivation for this problem is the non-destructive digitization of ob- jects: after an object is scanned by an echo-graphic or an X-ray apparatus , the obtained slices are used for the reconstruction of the original object . Yet another motivation is the reconstruction of a 3-dimensional model of a terrain from topographic elevation contours. Many solutions were suggested for the pure raster in- terpolation . These usually handle two raster images, where each pixel is either white or black ,", "label": ["slice interpolation", "branching surfaces", "surface fitting", "polyhedra", "geometric hashing", "curve matching", "tiling", "dynamic programming", "surface reconstruction", "triangulation"], "stemmed_label": ["slice interpol", "branch surfac", "surfac fit", "polyhedra", "geometr hash", "curv match", "tile", "dynam program", "surfac reconstruct", "triangul"]}
{"doc": "We describe two improvements to Chaitin-style graph coloring register allocators . The first , optimistic coloring , uses a stronger heuristic to find a k-coloring for the interference graph . The second extends Chaitin's treatment of rematerialization to handle a larger class of values . These techniques are complementary . Optimistic coloring decreases the number of procedures that require spill code and reduces the amount of spill code when spilling is unavoidable . Rematerialization lowers the cost of spilling some values . This paper describes both of the techniques and our experience building and using register allocators that incorporate them . It provides a detailed description of optimistic coloring and rematerialization . It presents experimental data to show the performance of several versions of the register allocator on a suite of FORTRAN programs . It discusses several insights that we discovered only after repeated implementation of these allocators . INTRODUCTION The relationship between run-time performance and effective use of a machine's register set is well understood. In a compiler , the process of deciding which values to keep in registers at each point in the generated code is called register allocation . Values in registers can be accessed more quickly than values in memory - on high- performance , microprocessor-based machines , the difference in access time can be an order of magnitude. Thus , register allocation has a strong impact on the run-time performance of the code that a compiler generates . Because memory latencies are rising while register latencies are not , the impact of allocation on performance is increasing . In addition , features like superscalar instruction issue increase a program's absolute demand for registers - if the machine issues two instructions in a single cycle , it must have two sets of operands ready and in place at the start of the cycle . This naturally increases the demand for registers. Popular techniques for performing register allocation are based on a graph coloring paradigm . These allocators construct a graph representing the constraints that the allocator must preserve . Using graph coloring techniques , they discover a mapping from values in the procedure to registers in the target machine; the mapping must observe the constraints . The first graph coloring allocator was built by Chaitin and his colleagues 8 . Another approach , called priority-based coloring , was described by Chow and Hennessy 10, 11 . These two techniques have formed the core around which a rich literature has emerged (see Section 7). The techniques used in building graph coloring allocators can be improved . In recent years , several important extensions to Chaitin's basic techniques have appeared 2 , 28 . Nevertheless , problems remain . In practice , most of these problems appear as either over-spilling or a poor spill choice . In the former case , the allocator fails to keep some value in a register , even though a register is available throughout its lifetime . In the latter case , the allocator chooses the \"wrong\" value to keep in a register at some", "label": ["graph coloring", "register allocation", "code generation"], "stemmed_label": ["graph color", "regist alloc", "code gener"]}
{"doc": "We describe a framework for compositional verification of finite-state processes . The framework is based on two ideas: a subset of the logic CTL for which satisfaction is preserved under composition , and a preorder on structures which captures the relation between a component and a system containing the component . Satisfaction of a formula in the logic corresponds to being below a particular structure (a tableau for the formula) in the preorder . We show how to do assume-guarantee-style reasoning within this framework . Additionally , we demonstrate efficient methods for model checking in the logic and for checking the preorder in several special cases . We have implemented a system based on these methods , and we use it to give a compositional verification of a CPU controller . Introduction Temporal logic model checking procedures are useful tools for the verification of finite state systems 3 , 12 , 20 . However , these procedures have traditionally suffered from the state explosion problem . This problem arises in systems which are composed of many parallel processes; in general , the size of the state space grows exponentially with the number of processes . By introducing symbolic representations for sets of states and transition relations and using a symbolic model checking procedure , systems with very large state spaces (10 100 or more states) can be verified 1 , 8 . Further , the time and space requirements with these techniques may in practice be polynomial in the number of components of the system. This research was sponsored in part by the Avionics Laboratory , Wright Research and Development Center , Aeronautical Systems Division (AFSC) , U.S . Air Force , Wright-Patterson AFB , Ohio 45433-6543 under Contract F33615-90-C-1465 , ARPA Order No . 7597 and in part by the National Science Foundation under Contract No . CCR-9005992 and in part by the U.S.-Israeli Binational Science Foundation. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the U.S . government. Unfortunately , the symbolic procedures still have limits , and many realistic problems are not tractable due to their size . Thus , we are motivated to search for additional methods of handling the state explosion problem , methods which work well in conjunction with the techniques. An obvious method for trying to avoid the state explosion problem is to use the natural decomposition of the system . The goal is to verify properties of individual components, infer that these hold in the complete system , and use them to deduce additional properties of the system . When verifying properties of the components , it may also be necessary to make assumptions about the environment . This approach is exemplified by Pnueli's assume-guarantee paradigm 23 . A formula in his logic is a triple h'iM h/i where ' and / are temporal formulas and M is a program . The formula is true if whenever M is part of a", "label": ["temporal logics", "formal verification", "computer-aided verification", "ctl", "moore machines", "model checking"], "stemmed_label": ["tempor logic", "formal verif", "computer-aid verif", "ctl", "moor machin", "model check"]}
{"doc": "A first-order multiparty interaction is an abstraction mechanism that defines communication among a set of formal process roles . Actual processes participate in a first-order interaction by enroling into roles , and execution of the interaction can proceed when all roles are filled by distinct processes . As in CSP , enrolement statements can serve as guards in alternative commands . The enrolement guard-scheduling problem then is to enable the execution of first-order interactions through the judicious scheduling of roles to processes that are currently ready to execute enrolement guards . We present a fully distributed and message-efficient algorithm for the enrolement guard-scheduling problem , the first such solution of which we are aware . We also describe several extensions of the algorithm , including: generic roles; dynamically changing environments , where processes can be created and destroyed at run time; and nested-enrolement , which allows interactions to be nested . Introduction A multiparty interaction is a set of I/O actions executed jointly by a number of processes , each of which must be ready to execute its own action for any of the actions in the set to occur . An attempt to participate in an interaction delays a process until all other participants are available. After the actions are executed , the participating processes continue their local computation , usually asynchronously . Languages like CSP and Ada support interaction only between two processes . How- ever , for many applications a higher level of abstraction can be obtained by permitting interaction among an arbitrary number of processes . For example , consider the well-known dining philosophers problem . The natural unit of process inter-action in this setting is between a philosopher and its two neighboring forks; i.e. , a multiparty synchronization involving three processes. It is useful to distinguish between zeroth-order multiparty interactions where the participants are fixed in advance , and first-order multiparty interactions where the participants may vary dynami- cally . For example , a zeroth-order multicast inter-action in which process P sends a message m to Q and R is captured by the code: Research supported by the National Science Foundation under Grant CCR-8704309.R :: B y := m The notation we use is based on IP 7 , 8 : B is the interaction name and m , x , and y are variables local to P , Q , and R , respectively . An interaction describes the action taken by a process engaged in the interaction; e.g. , x := m means that assigns x the non-local value of m . Many of the existing constructs for multiparty interaction are zeroth-order , including shared actions 16 , joint actions 1 , interactions in Raddle 4 , interactions in IP , and interaction types 13 . A first-order multiparty interaction is an abstraction mechanism that defines activities among a set of roles , which serve as formal process param- eters . Actual processes participate in an interaction by enroling 1 into the roles . We first consider partners-unnamed enrolement 9 where a process is not", "label": ["multiparty interaction", "rendezvous", "interaction scheduling", "distributed languages", "committee coordination", "distributed algorithms", "first-order interaction"], "stemmed_label": ["multiparti interact", "rendezv", "interact schedul", "distribut languag", "committe coordin", "distribut algorithm", "first-ord interact"]}
{"doc": "A new approach to ambiguity of context-free grammars is presented , and within this approach the LL and LR techniques are generalized to solve the following problems for large classes of ambiguous grammars: Construction of a parser that accepts all sentences generated by the grammar , and which always terminates in linear time . Identification of the structural ambiguity: a finite set of pairs of partial parse trees is constructed; if for each pair the two partial parse trees are semantically equivalent , the ambiguity of the grammar is semantically irrelevant . The user may control the parser generation so as to get a parser which finds some specific parse trees for the sentences . The generalized LL and LR techniques will still guarantee that the resulting parser accepts all sentences and terminates in linear time on all input . INTRODUCTION For unambiguous grammars we have the powerful LL and LR techniques that for large classes can verify their unambiguity and construct complete linear time parsers , i.e . parsers that accept the full languages and terminate in linear time on all inputs . With a new approach to ambiguity we generalize the LL and LR techniques to deal with large classes of ambiguous grammars as well; thus characterizing the ambiguity and constructing complete linear time parsers. This homemade reprent is typeset using the L A T E X document style acmtrans . It shows how the published version was intended: the page references are still intact , figures and text are with the same fonts , and theoretically important material has not been deferred to an electronic appendix. Most of this work was done while the author was at Oxford University and DIMACS supported, mainly , by a NATO grant from the Danish Research Council , partly , by the Danish Research Academy. Author's address: University of Copenhagen , Department of Computer Science , Univer- sitetsparken 1 , 2100 Kbenhavn , Denmark; e-mail: mthorup@diku.dk. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copying is by permission of the Association for Computing Machinery . To copy otherwise , or to republish , requires a fee and/or specific permission. c Ambiguous grammars have long been considered relevant in connection with programming languages , for as noticed in Aho , Johnson , and Ullman 1975 ambiguous grammars are often simpler and more natural than their unambiguous counterparts. Moreover , they can often be parsed more efficiently due to their having smaller parse trees . In Aho , Johnson , and Ullman 1975 , and independently in Earley 1975 , the now standard approach was developed for construction of linear time parsers for ambiguous grammars . The approach starts by applying an LL or LR technique. As the grammar is ambiguous the resulting parser will be non-deterministic due to conflicts in the action table . A", "label": ["grammatic ambiguity", "semantic unambiguity"], "stemmed_label": ["grammat ambigu", "semant unambigu"]}
{"doc": "Modern computer architectures increasingly depend on mechanisms that estimate future control flow decisions to increase performance . Mechanisms such as speculative execution and prefetching are becoming standard architectural mechanisms that rely on control flow prediction to prefetch and speculatively execute future instructions . At the same time , computer programmers are increasingly turning to object-oriented languages to increase their productivity . These languages commonly use run time dispatching to implement object polymorphism . Dispatching is usually implemented using an indirect function call , which presents challenges to existing control flow prediction techniques . We have measured the occurrence of indirect function calls in a collection of C++ programs . We show that , although it is more important to predict branches accurately , indirect call prediction is also an important factor in some programs and will grow in importance with the growth of object-oriented programming . We examine the improvement offered by compile-time optimizations and static and dynamic prediction techniques , and demonstrate how compilers can use existing branch prediction mechanisms to improve performance in C++ programs . Using these methods with the programs we examined , the number of instructions between mispredicted breaks in control can be doubled on existing computers . Introduction The design of computer architectures and languages are tightly en- twined . For example , the advent of register displacement addressing enabled efficient implementation of Algol and the increased use of COBOL emphasized the use of BCD arithmetic . Likewise , the C This paper appeared in the ACM Principles and Practice of Programming Lan- guages , Portland , Oregon 1994. and FORTRAN languages have become ubiquitous , strongly influenced RISC processor design . Object-oriented programming has recently gained popularity , illustrated by the wide-spread popularity of C++ . Object-oriented languages exercise different aspects of computer architectures to support the object-oriented programming style . In this paper , we examine how indirect function calls, used to support object polymorphism , influence the performance of an efficient object oriented language . Modern architectures using deep instruction pipelines and speculative execution rely on predictable control flow changes , and indirect function calls cause unpredictable changes in program control flow . For example , the DEC Alpha AXP 21064 processor , one of the first widely-available deeply pipelined superscalar microprocessors , stalls for 10 instructions if the processor mispredicts the flow of control . This increases if the mispredicted target is not in the instruction cache and must be fetched . As systems increasingly rely on speculative execution 19 , 16 , the importance of control flow prediction will increase. In most programs , conditional branches introduce the main uncertainty in program flow , and architectures use a variety of branch prediction techniques to reduce instruction cache misses and to insure instructions are available for the processor pipeline . Most function calls specify explicit call targets , and thus most function calls can be trivially predicted . Control flow prediction is just as important in object-oriented programs , but these languages tend to use indirect function calls , where the address", "label": ["profile-based optimization", "customization", "optimization", "object oriented programming"], "stemmed_label": ["profile-bas optim", "custom", "optim", "object orient program"]}
{"doc": "This paper describes new algorithms for approximately solving the concurrent multicommodity flow problem with uniform capacities . These algorithms are much faster than algorithms discovered previously . Besides being an important problem in its own right , the uniform-capacity concurrent flow problem has many interesting applications . Leighton and Rao used uniform-capacity concurrent flow to find an approximately \"sparsest cut\" in a graph and thereby approximately solve a wide variety of graph problems , including minimum feedback arc set , minimum cut linear arrangement , and minimum area layout . However , their method appeared to be impractical as it required solving a large linear program . This paper shows that their method might be practical by giving an $O(m^2 \\log m)$ expected-time randomized algorithm for their concurrent flow problem on an $m$-edge graph . Raghavan and Thompson used uniform-capacity concurrent flow to solve approximately a channel width minimization problem in very large scale integration . An randomized algorithm and an $O(k\\min n,k (m+n\\log n)\\log k)$ deterministic algorithm is given for this problem when the channel width is $\\Omega(\\log n)$ , where $k$ denotes the number of wires to be routed in an $n$-node , $m$-edge network . Introduction The multicommodity flow problem involves shipping several different commodities from their respective sources to their sinks in a single network with the total amount of flow going through an edge limited by its capacity . The amount of each commodity we wish to ship is called the demand for that commodity . An optimization version of this problem is the concurrent flow problem in which the goal is to find the maximum percentage z such that at least z percent of each demand can be shipped without violating the capacity constraints . Here we consider the concurrent flow problem with unit capacities . Observe that in this case , the problem is equivalent to the problem of finding a flow (disregarding capacities) that minimizes the maximum total flow on any edge (the congestion). Let m , n , and k be , respectively , the number of edges , nodes , and commodities for the input network. In this paper , we give algorithms that , for any positive ffl , find a solution whose congestion is no more than (1 times the minimum congestion . Our algorithms significantly improve the time required for finding such approximately optimal solutions. One contribution of this paper is the introduction of a randomization technique useful in iterative approximation algorithms . This technique enables each iteration to be carried out much more quickly than by using known deterministic methods. Part of our motivation in developing algorithms for concurrent flow derives from two important applications , finding sparsest cuts and finding a VLSI routing that minimizes channel width. Leighton and Rao 11 showed how to use the solution to a unit-capacity concurrent flow problem to find an approximate \"sparsest cut\" of a graph . As a consequence , they and other researchers have developed polylog-times-optimal approximation algorithms for a wide variety of graph problems, including minimum area VLSI", "label": ["approximation", "multicommodity flow", "vlsi routing", "concurrent flow", "graph separators"], "stemmed_label": ["approxim", "multicommod flow", "vlsi rout", "concurr flow", "graph separ"]}
{"doc": "Algorithms are developed for reliable and accurate evaluations of the complex elementary functions required in FORTRAN 77 and FORTRAN 9 , namely , cabs , csqrt , cexp , clog , csin , and ccos . The algorithms are presented in a pseudocode that has a convenient exception-handling facility . A tight error bound is derived for each algorithm . Corresponding FORTRAN programs for an IEEE environment have also been developed to illustrate the practicality of the algorithms , and these programs have been tested very carefully to help confirm the correctness of the algorithms and their error bounds . The results of these tests are included in the paper , but the FORTRAN programs are not . INTRODUCTION Our purpose is to develop algorithms , along with error bounds , for reliable and accurate evaluations of the complex elementary functions required in Fortran 77 1 and Fortran 90 4 , namely cabs , csqrt , cexp , clog , csin , and ccos . These (seemingly oxy- moronic) complex elementary functions can be expressed in terms of formulas involving only real arithmetic and real elementary functions . Complex arithmetic is not needed. If care is taken these formulas can usually be arranged so that serious numerical cancellation will not occur during their evaluation . (If this cannot be arranged , higher precision may be necessary at such critical points in the calculations.) This work was supported by the Natural Sciences and Engineering Research Council of Canada and the Information Technology Research Centre of Ontario , as well as by the Applied Mathematical Sciences subprogram of the Office of Energy Research , U . S . Department of Energy , under Contract W-31-109-Eng-38 , and by the STARS Program Office , under AF Order RESD-632. Authors' addresses: T . E . Hull and T . F . Fairgrieve , Department of Computer Science , University of Toronto , Toronto , Ontario , Canada M5S 1A4 (e-mail: ftehull,tffg@cs.utoronto.ca); Ping Tak Peter Tang , Mathematics and Computer Science Division , Argonne National Laboratory , 9700 South Cass Ave. , Argonne , IL U.S.A . 60439-4801 (e-mail: tang@antares.mcs.anl.gov) The main difficulty that remains in such evaluations is the possibility that overflow or underflow might occur at some intermediate stages in the calculation . Such exceptions are often \"spurious\" , in the sense that the final mathematical result is within the range of machine representable numbers . In these circumstances , which normally occur only rarely , the algorithms must provide for alternative calculations , which may be more lengthy , but which are able to circumvent the spurious exceptional situations. All of this suggests designing the algorithms with the help of exception handling facilities . Each algorithm would then begin with a direct evaluation of the original carefully arranged formulas . This would be efficient , and almost always successful . But if an exception should occur during such a calculation , it would cause control of the calculations to be transferred to an exception handler that would do what was needed to circumvent the", "label": ["implementation", "complex elementary functions"], "stemmed_label": ["implement", "complex elementari function"]}
{"doc": "In this article , we explore the use of genetic algorithms (GAs) as a key element in the design and implementation of robust concept learning systems . We describe and evaluate a GA-based system called GABIL that continually learns and refines concept classification rules from its interaction with the environment . The use of GAs is motivated by recent studies showing the effects of various forms of bias built into different concept learning systems , resulting in systems that perform well on certain concept classes (generally , those well matched to the biases) and poorly on others . By incorporating a GA as the underlying adaptive search mechanism , we are able to construct a concept learning system that has a simple , unified architecture with several important features . First , the system is surprisingly robust even with minimal bias . Second , the system can be easily extended to incorporate traditional forms of bias found in other concept learning systems . Finally , the architecture of the system encourages explicit representation of such biases and , as a result , provides for an important additional feature: the ability to dynamically adjust system bias . The viability of this approach is illustrated by comparing the performance of GABIL with that of four other more traditional concept learners (AQ14 , C4.5 , ID5R , and IACL) on a variety of target concepts . We conclude with some observations about the merits of this approach and about possible extensions . Introduction An important requirement for both natural and artificial organisms is the ability to acquire concept classification rules from interactions with their environment . In this paper , we explore the use of an adaptive search technique , namely , genetic algorithms (GAs) , as the central mechanism for designing such systems . The motivation for this approach comes from an accumulating body of evidence that suggests that , although concept learners require fairly strong biases to induce classification rules efficiently , no a priori set of biases is appropriate for all concept learning tasks . We have been exploring the design and implementation of more robust concept learning systems which are capable of adaptively shifting their biases when appropriate . What we find particularly intriguing is the natural way GA-based concept learners can provide this capability. As proof of concept we have implemented a system called GABIL with these features and have compared its performance with four more traditional concept learning systems (AQ14 , C4.5 , ID5R , and IACL) on a set of target concepts of varying complexity We present these results in the following manner . We begin by showing how concept learning tasks can be represented and solved by traditional GAs with minimal implicit bias . We illustrate this by explaining the GABIL system architecture in some detail. We then compare the performance of this minimalist GABIL system with AQ14, C4.5 , ID5R , and IACL on a set of target concepts of varying complexity . As expected, no single system is best for all of the presented concepts", "label": ["genetic algorithms", "bias adjustment", "concept learning"], "stemmed_label": ["genet algorithm", "bia adjust", "concept learn"]}
{"doc": "Neural networks , despite their empirically proven abilities , have been little used for the refinement of existing knowledge because this task requires a three-step process . First , knowledge must be inserted into a neural network . Second , the network must be refined . Third , the refined knowledge must be extracted from the network . We have previously described a method for the first step of this process . Standard neural learning techniques can accomplish the second step . In this article , we propose and empirically evaluate a method for the final , and possibly most difficult , step . Our method efficiently extracts symbolic rules from trained neural networks . The four major results of empirical tests of this method are that the extracted rules 1) closely reproduce the accuracy of the network from which they are extracted&semi; 2) are superior to the rules produced by methods that directly refine symbolic rules&semi; are superior to those produced by previous techniques for extracting rules from trained neural networks&semi; and are human comprehensible . Thus , this method demonstrates that neural networks can be used to effectively refine symbolic knowledge . Moreover , the rule-extraction technique developed herein contributes to the understanding of how symbolic and connectionist approaches to artificial intelligence can be profitably integrated . Introduction Artificial neural networks (ANNs) have proven to be a powerful and general technique for machine learning (Fisher & McKusick , 1989; Shavlik et al. , 1991) . However , ANNs have several well-known shortcomings; perhaps the most significant of which is that a trained ANN is essentially a \"black box.\" That is , determining exactly why an ANN makes a particular decision is a daunting task . This is a significant shortcoming , for without the ability to produce understandable decisions , it is hard to be confident in the reliability of networks that address real-world problems . Also , the fruits of training neural networks are difficult to transfer to other neural networks (Pratt et al . (1991) ameliorate this problem) , and all but impossible to directly transfer to non-neural learning systems. Hence , a trained neural network is analogous to Pierre de Fermat's comment about his last theorem . Like Fermat , the network tells you that it is has discovered something \"wonderful\" , but then does not tell you what it discovered. This paper sheds light into the neural-network black box by combining symbolic, rule-based reasoning with neural learning . Our approach is to form the three-link chain illustrated by Figure 1 in which symbolic knowledge is revised and corrected using neural networks . Thus , the approach we present makes possible the use of neural networks as the empirical learning algorithm underlying a rule-refinement system. Figure approximately here. The first link of our three-link chain is to insert knowledge , which need be neither complete nor correct , into a neural network using Kbann (Towell et al. , 1990) . (Here- after , networks created using Kbann will be referred to as Knowledge-based Neural Networks - KNNs.)", "label": ["representational shift", "rule extraction from neural networks", "integrated learning", "theory refinement"], "stemmed_label": ["represent shift", "rule extract from neural network", "integr learn", "theori refin"]}
{"doc": "An $n \\times n$ matrix polynomial $L(\\lambda)$ (with real or complex coefficients) is called self-adjoint if Factorizations of selfadjoint and symmetric matrix polynomials of the form are studied , where $D$ is a constant matrix and $M(\\lambda)$ is a matrix polynomial . In particular , the minimal possible size of $D$ is described in terms of the elementary divisors of $L(\\lambda)$ and (sometimes) signature of the Hermitian values of $L(\\lambda)$ . Introduction . Let be a matrix polynomial , where A j (j = are complex n \\Theta n matrices and - is a complex parameter . The polynomial L(-) is called selfadjoint if Factorizations of the form is a constant matrix (not necessarily of the same size as L(-) and M(-) is a matrix polynomial , have been studied in the literature , under various additional hypotheses (see Ja , Co , GLR1 , GLR2 ) . The study of factorizations (1.1) is motivated by several applied problems , such as filtering (Chapter 9 of AM ) . Factorizations of matrix polynomial L(-) having other types of symmetries , such as been studied in the literature as well (see , e.g. , Lyu1 , Lyu2 ) . For such polynomials , it is natural to seek factorizations of type is a constant matrix (not necessarily of the same size as L(-)); M(-) is a matrix polynomial , and In this paper we identify the minimal possible size of the matrix D in factorization of types (1.1) and (1.2) , where L(-) has the appropriate symmetry . The cases when L(-) has complex coefficients or real coefficients are studied (if L(-) is assumed to be real , then in (1.1) and (1.2) M(-) and D are assumed to be real as well) . Our result concerning *Faculteit Wiskunde en Informatica , Vrije Universiteit , De Boelelaan 1081 , 1081 HV Amsterdam , The Netherlands yDepartment of Mathematics , College of William and Mary Williamsburg , VA 23187-8795 , USA . Partially supported by NSF Grant DMS-9000839 and by the NSF International Cooperation Grant with the Netherlands. factorization (1.1) is a generalization of the main result of GLR2 where only the case of constant signature was considered under the additional hypothesis that det L(-) 6j 0 We present also (in Section 2) general factorization results in an abstract framework, for matrix polynomials over a field having suitable symmetries . These results , although independently interesting , play an auxiliary role in this paper , serving as essential ingredients in the proofs of the main results given in Sections 3-6. The following notation will be used throughout the paper . Standard notation R(C) to denote the real (complex) field , and I k for the k \\Theta k unit matrix . A T (resp. for the transpose (resp . conjugate transpose) of a matrix A , and abbreviated to A \\GammaT (resp . A \\Gamma ) . Block diagonal matrix with the blocks Z 1 ; . ; Zm on the main diagonal will be denoted Z 1 \\Phi \\Delta \\Delta \\Delta \\Phi Zm", "label": ["factorization", "matrix polynomials", "symmetries"], "stemmed_label": ["factor", "matrix polynomi", "symmetri"]}
{"doc": "Loops are a large source of parallelism for many numerical applications . An important issue in the parallel execution of loops is how to schedule them so that the workload is well balanced among the processors . Most existing loop scheduling algorithms were designed for shared-memory multiprocessors , with uniform memory access costs . These approaches are not suitable for distributed-memory multiprocessors where data locality is a major concern and communication costs are high . This paper presents a new scheduling algorithm in which data locality is taken into account . Our approach combines both worlds , static and dynamic scheduling , in a two-level (overlapped) fashion . This way data locality is considered and communication costs are limited . The performance of the new algorithm is evaluated on a CM-5 message-passing distributed-memory multiprocessor . Introduction Loops exhibit most of the parallelism present in numerical programs . Therefore , distributing the workload of a loop evenly among the processors is a critical factor in the efficient execution of this kind of parallel programs . A loop scheduling strategy assigns iterations to the processors of the machine in such a way that all of them finish their work-load at more or less the same time . A simple strategy is static scheduling , which determines the assignment of iterations to processors at compile-time . But in many situations, the workload of the iterations is unpredictable at compile- time . Dynamic scheduling strategies have been developed to handle such situations , solving the assignment problem at run-time. When considering cross-iteration data dependencies we can classify the loops into three major types , doserial , doall and doacross Pol88 . In this paper we are primarily concerned with doall or parallel loops , in which there is no data dependence between any pair of their iterations . Otherwise, Published in Proc . ACM Int'l Conf . on Supercomputing, Manchester , UK , July 11-15 , 1994 the loop is taken as serial . From the point of view of the scheduling a loop is uniform if the execution times of different iterations are the same (e.g . matrix multiplication), semi-uniform , if they depend on the index of the loop (e.g. adjoint convolution) , or non-uniform , if they depend on the data (e.g . transitive closure). We can always obtain an optimal (or near optimal) static schedule for uniform loops . If we have a parallel machine with P processors , we must simply partition the set of iterations of the loop into P chunks of dP=Ne iterations each, where N is the length of the loop . Now we assign each of the chunks to each of the processors . We can still obtain an (near) optimal static schedule for semi-uniform loops . For example , consider the parallelized adjoint convolution algorithm which exhibits a triangular iteration space, We can establish a (near) optimal static schedule using a kind of cyclic loop distribution scheme . We assign the iteration rP (i from 1 to P and .) to processor or to processor Clearly", "label": ["distributed-memory multiprocessors", "dynamic and static scheduling", "loop scheduling", "load balancing", "message-passing"], "stemmed_label": ["distributed-memori multiprocessor", "dynam and static schedul", "loop schedul", "load balanc", "message-pass"]}
{"doc": "Because the spatial locality of numerical codes is significant , the potential for performance improvements is important . However , large cache lines cannot be used in current on-chip data caches because of the important pollution they breed . In this paper , we propose a hardware design , called the Virtual Line Scheme , that allows the utilization of large virtual cache lines when fetching data from memory for better exploitation of spatial locality , while the actual physical cache line is smaller than currently found cache lines for better exploitation of temporal locality . Simulations show that a 17% to 64% reduction of the average memory access time can be obtained for a 20-cycle memory latency . It is also shown how simple software informations can be used to significantly decrease memory traffic , a flaw associated with the utilization of large cache lines . Introduction Due to the constantly decreasing processor cycle time , the average memory access time observed by processors is rapidly increasing , because of high network or memory latency . Consequently , the cost of a cache miss can become prohibitive for monoprocessor and multi- processors , urging for the development of hardware or software solutions. Numerical codes can be particularly sensitive to cache performance because their working set is usually large , resulting in numerous memory accesses . Because of array references , numerical codes generally have strong spatial and temporal locality properties. While temporal locality can be exploited with loop blocking 2 , 12 , 16 , little support (except for the cache line) or flexibility is available for the exploitation of spatial locality . However , experiments 15 , tend to show that the optimal cache line is not the same for all codes , depending on whether spatial or temporal locality should be preferably exploited. Small direct-mapped caches are now popular 13, 4 because the on-chip space used and the cache hit time can be minimized (the cache hit time should be minimized if it determines the processor cycle time). This work was funded by the BRA Esprit III Projet AP- PART , European agency DGXIII. y High Performance Computing Division , Department of Computer Science , University of Leiden , The Netherlands. However , such caches can be very sensitive to cache conflicts and pollution phenomena , preventing the use of large cache lines. In this paper , we propose a cache design , called the Virtual Line Scheme (VLS) that allows the utilization of large cache lines in small direct-mapped caches, while avoiding most of the flaws associated with large cache lines: increased cache conflicts and cache pollu- tion . The scheme proposed gives the illusion that a variable line size can be used for each reference within a code . The actual physical cache line size is smaller than usual cache line sizes in order to better exploit temporal locality , while large virtual cache lines are used in order to better exploit spatial locality . Simulations show that the mean average memory access time observed over all", "label": ["numerical codes", "memory hierarchy", "temporal locality", "spatial locality", "cache architecture"], "stemmed_label": ["numer code", "memori hierarchi", "tempor local", "spatial local", "cach architectur"]}
{"doc": "We address the development of efficient methods for performing data redistribution of arrays on distributed-memory machines . Data redistribution is important for the distributed-memory implementation of data parallel languages such as High Performance Fortran . An algebraic representation of regular data distributions is used to develop an analytical model for evaluating the communication cost of data redistribution . Using this algebraic representation and the analytical model , an approach to communication-efficient data redistribution is developed . Implementation results on the Intel iPSC/860 are reported . Introduction Distributed-memory machines have demonstrated a potential for high performance . However , their use has been restricted due to the difficulty of programming these comput- ers . A programming model based on a single address space with provisions for explicit specification of data distributions for shared arrays has recently gained popularity 1 , 3, 13 . High Performance Fortran (HPF) 6 , a Fortran-90 ex- tension , provides programmers with directives , that specify alignment of arrays with one another and distribute these aligned arrays on a user-defined virtual processor mesh . Directives to dynamically change the distribution of arrays during program execution are provided . Redistribution of data arrays is used under the following circumstances. This work was supported in part by ARPA , order number 7898 , monitored by NIST under grant number 60NANB1D1151 , and DARPA , order number 7899 , monitored by NIST under grant number To appear in the 8th ACM International Conference on July 1994 , Manchester , England. ffl Different phases of a program vary in their access patterns to a shared array and a different data distribution of the array is often best suited for each phase . For instance , the alternate direction implicit method 12 consists of two phases - the first phase accesses a two-dimensional array along the rows and the second phase along the columns . A distribution in which the array rows are local to a processor and the columns are dis- tributed , eliminates communication for the first phase. Similarly , a distribution in which the array columns are local and the rows are distributed , eliminates communication for the second phase . The need to explicitly redistribute the array between the two phases arises. ffl Scientific libraries are tuned to provide peak performance for a fixed set of distributions for the input arrays . These distributions may not conform with the distributions of the actual parameters , leading to performance degradation . Developing library routines for all possible input distributions is not practical . Hence the actual array parameters must be explicitly redistributed ffl Data redistribution is implicitly required in the execution of array statements , where the array sections in the statement are the entire arrays and have different distributions. Thus efficient methods for performing data redistribution are of great importance in the distributed-memory implementations of HPF. Some data redistribution strategies have been presented in the literature . The issue of reshaping perfect power-of-two sized data arrays on hypercubes is addressed in 15 . Closed form expressions for the processor", "label": ["tensor products", "data distribution", "high performance fortran", "data communication", "distributed-memory machine"], "stemmed_label": ["tensor product", "data distribut", "high perform fortran", "data commun", "distributed-memori machin"]}
{"doc": "The main theorem of this paper is that , for every real number $\\alpha 1$ (e.g. , $\\alpha=0.99$) , only a measure 0 subset of the languages decidable in exponential time are $\\leq^ P _ n^ \\alpha - tt $-reducible to languages that are not exponentially dense . Thus every $\\leq^ P _ n^ \\alpha - tt $-hard language for E is exponentially dense . This strengthens Watanabe's 1987 result , that every $\\leq^ P _ (O \\log n)-tt $-hard language for E is exponentially dense . The combinatorial technique used here , the sequentially most frequent query selection , also gives a new , simpler proof of Watanabe's result . The main theorem also has implications for the structure of NP under strong hypotheses . Ogiwara and Watanabe (1991) have shown that the hypothesis $\\p\\ne\\NP$ implies that every $\\leq^ P _ btt $-hard language for NP is nonsparse (i.e. , not polynomially sparse) . Their technique does not appear to allow significant relaxation of either the query bound or the sparseness criterion . It is shown here that a stronger hypothesis---namely , that NP does not have measure 0 in exponential time---implies the stronger conclusion that , for every real $\\alpha 1$ , every $\\leq^ P _ n^ \\alpha - tt $-hard language for NP is exponentially dense . Evidence is presented that this stronger hypothesis is reasonable . The proof of the main theorem uses a new , very general weak stochasticity theorem , ensuring that almost every language in E is statistically unpredictable by feasible deterministic algorithms , even with linear nonuniform advice . Introduction How dense must a language A ' f0; 1g be in order to be hard for a complexity class C? The ongoing investigation of this question , especially important when has yielded several significant results 3 , 11 , 19 , 21 , 22 , 29 , 30 over the past 15 years. Any formalization of this question must specify the class C and give precise meanings to \"hard\" and \"how dense.\" The results of this paper concern the polynomial ) , and all subclasses C of these classes , though we are particularly interested in the case We will consider the polynomial-time reducibilities - P (Turing reducibility) , - P btt (bounded truth-table reducibility), q\\Gammatt (truth-table reducibility with q(n) queries on inputs of length r is any of these reducibilities , we say that a language A is - P r -hard for a class C of languages if C ' P r (A) , where r Ag. Two criteria for \"how dense\" a language A is have been widely used . A language A is (polynomially) sparse , and we write A 2 SPARSE , if there is a polynomial such that jA-n j - p(n) for all n 2 N , where A language A is (exponentially) dense , and we write A 2 DENSE , if there is a real number ffl ? 0 such that jA-n j - 2 n ffl for all sufficiently large n 2 N .", "label": ["dense languages", "resource-bounded measure", "complexity classes", "computational complexity", "sparse languages", "weak stochasticity", "polynomial reductions"], "stemmed_label": ["dens languag", "resource-bound measur", "complex class", "comput complex", "spars languag", "weak stochast", "polynomi reduct"]}
{"doc": "The impact of cache interferences on program performance (particularly numerical codes , which heavily use the memory hierarchy) remains unknown . The general knowledge is that cache interferences are highly irregular , in terms of occurrence and intensity . In this paper , the different types of cache interferences that can occur in numerical loop nests are identified . An analytical method is developed for detecting the occurrence of interferences and , more important , for computing the number of cache misses due to interferences . Simulations and experiments on real machines show that the model is generally accurate and that most interference phenomena are captured . Experiments also show that cache interferences can be intense and frequent . Certain parameters such as array base addresses or dimensions can have a strong impact on the occurrence of interferences . Modifying these parameters only can induce global execution time variations of 30% and more . Applications of these modeling techniques are numerous and range from performance evaluation and prediction to enhancement of data locality optimizations techniques . Introduction Three types of cache misses can be distinguished 6 , 7 : cold-start misses which are compulsory , capacity misses and interference (or conflict) misses . Capacity occur when cache space is unsufficient to store all data to be reused . Interference misses occur when two data are mapped to the same cache location . Typi- cally , fully-associative caches do not exhibit interference misses. This work was supportedby the Esprit Agency DG XIII under Grant No . APPARC 6634 BRA III.Capacity misses in numerical codes have been studied to a great extent 2 , 9 , 16 , and can be relatively easily predicted and estimated . Most of these studies also attempt to take into account the impact of the cache line size . But , there are few studies on interference misses, though several case-studies report that cache interferences can severely affect cache behavior 6 , 8 . Also, in 3 , suggestions are provided on how to consider interferences for cache performance evaluation and optimization Cache interferences are difficult to predict and esti- mate , because it is necessary to know where data are mapped in cache and when data are referenced . For in- stance , consider addresses A and B that are mapped to the same cache location and reused 3 times . Whether the reference sequence is AAABBB or ABABAB , interference are equal to respectively 0 or 4. Nevertheless , several reasons press for the study of cache interferences . First of all , cache tends to be a performance bottleneck because of high network and memory latencies , so that significant performance improvements can be obtained through a slight reduction of cache misses . Besides , several on-chip data caches are direct-mapped in order to achieve a low hit time. Such caches are considered to be more sensitive to interferences 8 , especially when they are small , which is currently the case because of on-chip space constraints kbytes in the DEC Alpha 11 , MIPS", "label": ["numerical codes", "performance evaluation", "data locality", "cache interferences or conflicts", "modeling"], "stemmed_label": ["numer code", "perform evalu", "data local", "cach interfer or conflict", "model"]}
{"doc": "Three different interfaces were used to browse a large (1296 items) table of contents . A fully expanded stable interface , expand/contract interface , and multipane interface were studied in a between-groups experiment with 41 novice participants . Nine timed fact retrieval tasks were performed; each task is analyzed and discussed separately . We found that both the expand/contract and multipane interfaces produced significantly faster times than the stable interface for many tasks using this large hierarchy; other advantages of the expand/contract and multipane interfaces over the stable interface are discussed . The animation characteristics of the expand/contract interface appear to play a major role . Refinements to the multipane and expand/contract interfaces are suggested . A predictive model for measuring navigation effort of each interface is presented . Introduction Although only a few studies have shown the superiority of online texts when compared to paper documents , the increasing requirement for electronic access to voluminous data dictates improved methods for browsing online information . Several studies have shown that a hierarchical representation with associated browser is an effective approach 1 , 19 . Recent studies have shown that browsing through a table of contents is a preferred method over more analytical methods such as query formulation 2 , 4 , 14 . Benefits of online information include geographically distributed high speed access to data; faster , more complete updates to information 20 ; the capability for string searching; and inclusion of animation 16 , sound , and video. Figure 1a . Stable interface in initial state. Figure 1b . Stable interface viewing section 2.6 . Scrolling is the only navigation technique. There are three generally used interface methods for browsing online , hierarchical information . One type of interface which we call stable (Figures 1a-1b) uses a fully expanded, stable screen layout , much like a table of contents for a printed book . These interfaces are quite widely used for viewing online hierarchies 11 . Another interface , expand/contract (Figures 2a- 2c) , is employed by many outline programs available for PCs (e.g. , PC Outline , GrandView, etc . A third interface , multi-pane (Figures 3a-3c) , usually consists of a predetermined number of separate panes , each pane containing contents for a separate level of the hierarchy (e.g. , Smalltalk browser) . There are variations to what the behavior can be when the number of levels of the hierarchy is more than the number of panes. Figure 2a . Expand/Contract interface in initial state . Only highest level (chapter) items are visible. Figure 2b . Expand/Contract interface viewing chapter 2 , produced by clicking the mouse on the title . Only items in the immediately next lower level (sections) appear via line-at-a-time animation. Figure 2c . Expand/Contract interface viewing section 2.6 and section 2.3. Figure 3a . Multi-pane interface in initial state . Chapter items appear in the top pane , section items in the middle pane , and subsection items appear in the bottom pane. Figure 3b . Multi-pane interface viewing chapter 2 , produced by clicking", "label": ["user interfaces", "browsing", "table of contents", "hierarchies"], "stemmed_label": ["user interfac", "brows", "tabl of content", "hierarchi"]}
{"doc": "This paper presents an optimized general-purpose algorithm for polyvariant , static analyses of higher-order applicative programs . A polyvariant analysis is a very accurate form of analysis that produces many more abstract descriptions for a program than does a conventional analysis . It may also compute intermediate abstract descriptions that are irrelevant to the final result of the analysis . The optimized algorithm addresses this overhead while preserving the accuracy of the analysis . The algorithm is also parameterized over both the abstract domain and degree of polyvariance . We have implemented an instance of our algorithm and evaluated its performance compared to the unoptimized algorithm . Our implementation runs significantly faster on average than the other algorithm for benchmarks reported here . INTRODUCTION Abstract interpretation Abramsky and Hankin 1987; Cousot 1981; Jones and Nielson 1990 has been used to formulate a wide variety of static analyses aimed at optimizing programs in practical programming languages . Research in the area has been focusing on the conceptual and formal aspects of the topic . Special emphasis has been put on such issues as accuracy , termination , and relating non-standard and standard semantic definitions . However , the practical aspects involved in implementing an abstract interpreter have not received as much attention . This situation is even more pronounced for analyses of languages with higher-order functions. A static analysis includes a critical phase that consists of finding a fixpoint to a set of (possibly) recursive abstract functions derived from the analyzed program. To be of any practical use , an analysis should include an efficient and accurate fixpoint algorithm . The efficiency depends mostly on this accuracy . For exam- ple , some analyses only determine one abstract description for each object (e.g., functions and data structures) in the program . By analogy with partial evaluation Consel and Danvy 1993 , they are said to be monovariant . Other analyses are more accurate . They determine multiple abstract descriptions for each object in a This research was partially supported by NSF grant CCR-9224375. Authors' addresses: J . Michael Ashley , Computer Science Department , Lindley Hall 215 , Bloom- ington , Indiana 47405 . email: jashley@cs.indiana.edu; Charles Consel , Oregon Graduate Insti- tute , Department of Computer Science , PO Box 91000 , Portland , Oregon 97291 . email: con- sel@cse.ogi.edu M . Ashley and C . Consel program depending on the context in which these objects are used . Again , by analogy with partial evaluation , these analyses are said to be polyvariant . They make the fixpoint computation expensive because they yield more abstract descriptions. Unlike first-order programs , higher-order programs do not have a static control flow graph since higher-order languages treat procedures as values . As a consequence control-flow and data-flow aspects of higher-order programs are intertwined. In fact , a control-flow analysis for higher-order programs (also called closure analysis Sestoft 1989 ) includes data-flow aspects. In a polyvariant analysis , separating control-flow and data-flow analyses is not desirable since both first-order and higher-order values are used to", "label": ["program analysis", "fixpoint algorithm", "abstract interpretation"], "stemmed_label": ["program analysi", "fixpoint algorithm", "abstract interpret"]}
{"doc": "Composite systems are generally comprised of heterogeneous components whose specifications are developed by many development participants . The requirements of such systems are invariably elicited from multiple perspectives that overlap , complement , and contradict each other . Furthermore , these requirements are generally developed and specified using multiple methods and notations , respectively . It is therefore necessary to express and check the relationships between the resultant specification fragments . We deploy multiple ViewPoints that hold partial requirements specifications , described and developed using different representation schemes and development strategies . We discuss the notion of inter-ViewPoint communication in the context of this ViewPoints framework , and propose a general model for ViewPoint interaction and integration . We elaborate on some of the requirements for expressing and enacting inter-ViewPoint relationships-the vehicles for consistency checking and inconsistency management . Finally , though we use simple fragments of the requirements specification method CORE to illustrate various components of our work , we also outline a number of larger case studies that we have used to validate our framework . Our computer-based ViewPoints support environment , The Viewer , is also briefly described . Introduction 1.1 . Motivation Heterogeneity is inevitable in most composite systems of significant size , and no single development process and representation will be IEEE Transactions on Software Engineering , October 1994. sufficient for their development . This is particularly true of the requirements engineering phase of the software development life-cycle. Requirements engineering encompasses activities ranging from requirements analysis and elicitation to specification , conflict resolution and validation. Even a single activity such as requirements elicitation , is likely to involve multiple development participants who will hold multiple perspectives on a single domain. This heterogeneity of representations and processes poses challenging research problems of integration: (1) the integration of the methods used to specify system requirements , (2) the integration of the tools that support these methods, and (3) the integration of the multiple specification fragments produced by applying these methods and tools . By explicitly deploying \"views\" that encapsulate partial specifications together with the development techniques by which they are produced , a framework is in place within which the problems of integration outlined above may be addressed . However , the difficulties of expressing , invoking and applying the relationships between multiple views need to be resolved , before integration in this setting may be achieved. 1.2 . Views in Requirements Engineering Views are vehicles for separation of concerns. They allow development participants to address only those concerns or criteria that are of interest, ignoring others that are unrelated . In our earlier work 23 , we have used the term \"multiple perspectives problem\" to describe the class of problems surrounding the development of composite systems 18 by many development participants who deploy sundry representation schemes , use a variety of development strategies and hold diverse domain knowledge . We have also proposed an object-based framework deploying \"ViewPoints\" within which the above problems may be tackled . ViewPoints in our framework serve to separate the concerns of different", "label": ["core", "requirements specification method", "viewpoints framework", "inconsistency management", "requirements specification", "inter-viewpoint communication", "the viewer", "multiple viewpoints", "consistency checking", "heterogeneous components", "computer-based viewpoints support", "formal specification", "multiple views", "partial requirements specifications"], "stemmed_label": ["core", "requir specif method", "viewpoint framework", "inconsist manag", "requir specif", "inter-viewpoint commun", "the viewer", "multipl viewpoint", "consist check", "heterogen compon", "computer-bas viewpoint support", "formal specif", "multipl view", "partial requir specif"]}
{"doc": "Features are often the basic unit of development for a very large software system and represent long-term efforts , spanning up to several years from inception to actual use . Developing an experiment to monitor (by means of sampling) such lengthy processes requires a great deal of care in order to minimize casts and to maximize benefits . Just as prototyping is often a necessary auxiliary step in a large-scale , long-term development effort , so , too , is prototyping a necessary step in the development of a large-scale , long-term process monitoring experiment . Therefore , we have prototyped our experiment using a representative process and reconstructed data from a large and rich feature development . This approach has yielded three interesting sets of results . First , we reconstructed a 30-month time diary for the lead engineer of a feature composed of both hardware and software . These data represent the daily state (where the lead engineer spent the majority of his time) for a complete cycle of the development process . Second , we found that we needed to modify our experimental design . Our initial set of states did not represent the data as well as we had hoped . This is exemplified by the fact that the \"Other\" category is too large . Finally , the data provide evidence for both a waterfall view and an interactive , cyclic view of software development . We conclude that the prototyping effort is a necessary part of developing and installing any large-scale process monitoring experiment . Introduction Features are often the basic unit of development for very large software systems and represent long-term efforts, spanning several years from inception to actual use . Thus , monitoring these lengthy processes is a long-term effort as well . We report here an initial step in the development of an experiment to monitor such processes: that of prototyping the experimental design to monitor a representative process used in developing such features. In the remainder of Section 1 , we provide background information relevant to the general goals of our experiment, present our motivations for both the experiment and our prototype , and discuss related work . In Section 2 , we present our experimental design and discuss issues in instrumenting the experiment . In Section 3 , we describe our method of prototyping the process monitoring experiment and evaluate the results of the prototype experiment . In Section 4 , we discuss the results of our prototype analyses and indicate some interesting aspects of the prototype data . Finally , in Section 5 , we present our conclusions. 1.1 Background like costs , can be viewed as a unit of optimization in improving software development processes . In particular, processes and artifacts that have evolved over time have accreted a variety of inefficiencies . Optimizing the development interval is one way of exposing many of these inefficiencies and reducing costs . While the general goal of most organizations is to maintain or increase the level of quality while reducing costs ,", "label": ["process computer control", "interactive cyclic view", "process monitoring experiment", "large-scale long-term development", "software", "very large software system", "software development", "computerised monitoring", "experimental design", "long-term process monitoring", "software prototyping", "large-scale process monitoring experiment", "waterfall view", "prototyping", "hardware"], "stemmed_label": ["process comput control", "interact cyclic view", "process monitor experi", "large-scal long-term develop", "softwar", "veri larg softwar system", "softwar develop", "computeris monitor", "experiment design", "long-term process monitor", "softwar prototyp", "large-scal process monitor experi", "waterfal view", "prototyp", "hardwar"]}
{"doc": "We consider time slot interchangers (TSIs) which are built from 2/spl times/2 exchange switches and delays and which are useful for time division multiplexed (TDM) systems in telecommunications and pipelined systems such as time multiplexed optical multiprocessors . We formulate a general method for constructing TSIs based on multistage interconnection networks in the space domain via space-to-time mapping . Two types of TSIs , time slot permuters and time slot sorters , are considered . We review the time slot permuter based on the Benes network , and obtain the /spl Lambdaspl tilde/ time slot permuter based on the bit-controlled , self-routing /spl Lambda/ permutation network . The time slot sorter , S/sub N/ , is obtained from the Batcher spatial sorting network . The generalized Lambda time slot permuter /spl Lambdasub Nsup q/ is obtained , in an algorithmic approach , by combining the idea of the /spl Lambdaspl tilde/ time slot permuter and Q-way bitonic decomposition (Q=2/sup q/) . The numbers of switches , control complexities , and frame delays of these architectures are compared , and the problem of crosstalk in optical implementation is discussed . It is shown that control complexity can be traded against the number of switches . Introduction The need to reorder data transmitted serially in time appears in nearly every complex serial digital system . The most extensive use is probably in time division multiplexed (TDM) communications . Using TDM terminology , a frame consisting of N time slots identifies an data packet contained in a slot by its sequential position with respect to the start of the frame . Switching among communications channels corresponds to changing the relative order of time slots in the frame . With the increasing use of optics in com- munications , photonic techniques for TDM switching have attracted a great deal of interest 1 . Additional interest comes from the design of a serial optical computer 2 , in which words in a serial memory 3 can be considered as time slots in a fixed length frame . Time multiplexing multiple computers on the same serial hardware , as proposed in 4 , establishes a correspondence between time slot interchange and multiprocessor interconnection networks . The availability of optical exchange switches and the ease of implementing optical delay by fiber encourages the study of time slot interchangers built from 2-2 exchange switches and delays. We take a time slot interchanger (TSI) to be a system with one serial input consisting of a fixed length frame of N time slots and producing one serial output frame of the same time slots in a permuted order . We consider only systems with frame integrity , so output slots for a given input frame are adjacent , with no intervening gaps . Any such system performing a non-trivial permutation must have an associated frame delay , since a slot can only move toward the beginning of the frame without violating input before output ordering if the beginning of the frame is delayed . The maximum required frame delay is N -1", "label": ["benes network", "time slot sorters", "telecommunications", "time division multiplexing", "multiprocessor interconnection networks", "optical implementations", "optical information processing", "serial array time slot interchangers", "bitonic decomposition", "crosstalk", "time division multiplexed systems", "multistage interconnection networks", "control complexity", "exchange switches", "space-to-time mapping", "pipelined systems", "logic arrays", "optical interconnections", "time multiplexed optical multiprocessors", "batcher spatial sorting network", "self-routing /spl lambda/ permutation network", "time slot permuters"], "stemmed_label": ["bene network", "time slot sorter", "telecommun", "time divis multiplex", "multiprocessor interconnect network", "optic implement", "optic inform process", "serial array time slot interchang", "biton decomposit", "crosstalk", "time divis multiplex system", "multistag interconnect network", "control complex", "exchang switch", "space-to-tim map", "pipelin system", "logic array", "optic interconnect", "time multiplex optic multiprocessor", "batcher spatial sort network", "self-rout /spl lambda/ permut network", "time slot permut"]}
{"doc": "Several techniques have been proposed to allow parallel access to a shared memorylocation by combining requests . They have one or more of the following attributes:requirements for a priori knowledge of the request to combine , restrictions on the routingof messages in the network , or the use of sophisticated interconnection network nodes.We present a new method of combining requests that does not have the aboverequirements . We obtain this new method for request combining by developing aclassification scheme for the existing methods of request combining . This classificationscheme is facilitated by separating the request combining process into a two partoperation: determining the combining set , which is the set of requests that participate ina combined access; and distributing the results of the combined access to the membersof the combining set . The classification of combining strategies is based upon whichsystem component , processor elements , or interconnection network performs each ofthese tasks . Our approach , which uses the interconnection network to establish thecombining set and the processor elements to distribute the results , lies in an unexploredarea of the design space . We also present simulation results to assess the benefits of theproposed approach . Introduction Arvind and Iannucci state that the design of a large-scale , shared memory multiprocessor must address two basic issues 2 : (1) it must tolerate long latencies for memory requests, (2) it must achieve unconstrained , yet synchronized , access to shared data. While several techniques , for example caches and prefetching 24 , and low level context switching 25 , have been proposed to tolerate the latency of memory requests , heretofore the only known methods of allowing unconstrained, yet synchronized , access to shared data are implementations of request combining . The earliest published proposal for request combining was in the CHoPP system 28 , where several read requests to a common memory location are combined in the interconnection network and are satisfied with only a single access of the memory location. When two read requests destined for the same memory location meet at a node of the network , the source of one of the requests is saved and only one read request is forwarded to memory . When the response of the read request arrives at the node where combining took place , two responses are sent back toward the processors. The idea of combining read requests , or read combining in CHoPP was extended in the NYU Ultracomputer to allow several types of requests to combine 6 . The Ultracomputer uses the Fetch&F primitive , where F is any associative and commutative operator . An enhanced interconnection network with the topology of an Omega net-work is proposed to perform combining on the Fetch&F primitive. The Ultracomputer style of request combining is illustrated in Figure 1 . When a Fetch&F(X , e) request meets a Fetch&F(X , j) request at a network node , combining takes place: e is saved in a wait buffer , an ALU in the node computes eFj , and the request Fetch&F(X , eFj) is", "label": ["message passing", "parallel architectures", "multiprocessors", "index termsmultiprocessor interconnection networks", "combining strategies", "message routing", "hot spots", "arbitrary interconnection networks", "design space", "combining set", "simulationresults", "shared memory systems", "parallel access", "shared memory location", "classification scheme", "virtual machines", "processor elements"], "stemmed_label": ["messag pass", "parallel architectur", "multiprocessor", "index termsmultiprocessor interconnect network", "combin strategi", "messag rout", "hot spot", "arbitrari interconnect network", "design space", "combin set", "simulationresult", "share memori system", "parallel access", "share memori locat", "classif scheme", "virtual machin", "processor element"]}
{"doc": "It is important for a distributed computing system to be able to route messages aroundwhatever faulty links or nodes may be present . We present a fault-tolerant routingalgorithm that assures the delivery of every message as long as there is a path betweenits source and destination . The algorithm works on many common mesh architecturessuch as the torus and hexagonal mesh . The proposed scheme can also detect thenonexistence of a path between a pair of nodes in a finite amount of time . Moreover , thescheme requires each node in the system to know only the state (faulty or not) of eachof its own links . The performance of the routing scheme is simulated for both square andhexagonal meshes while varying the physical distribution of faulty components . It isshown that a shortest path between the source and destination of each message istaken with a high probability , and , if a path exists , it is usually found very quickly . Introduction The processors of a distributed computing system communicate by sending messages over a network . Faults in the network can prevent the delivery of messages unless the network provides fault-tolerant routing . However , most distributed systems pay little attention to this potential problem . While they provide simple and efficient routing algorithms , the algorithms usually will not work properly if faults are present in the network . In this paper , we propose a simple and efficient fault-tolerant routing algorithm which can be used for many mesh-type distributed system architectures. An obvious way to handle fault-tolerant routing is for each node to keep track of all faults in the system . A node can be expected to know the state (failed or not) of its own links , and some algorithms are proposed in 6 to broadcast information about faulty components to all other nodes in the system . With this information messages can always be routed by shortest paths. There are two main problems with this approach . First is the amount of memory that may be needed to store all this information , especially if the system is large . Second is the overhead it induces . The standard routing algorithms of most systems allow routing decisions to be made by simple circuitry using only information on the message header . This allows optimizations like virtual cut-through 4 , which speed up message delivery by avoiding buffering at intermediate nodes . If other information must be consulted , the message must be buffered , and message delivery is delayed . We therefore restrict ourselves to the situation where each node knows only the state of its own links. Some work has already been done on fault-tolerant routing in the hypercube 1 , 3 , 5 , 7 . These algorithms either take advantage of the specific mathematical properties of the hypercube and are therefore inapplicable to meshes , or use some form of global information , which we want to avoid . The authors of 1 present an algorithm which does not use global", "label": ["software reliability", "parallel architectures", "torus", "message routing", "hexagonal meshes", "parallelalgorithms", "fault-tolerant routing", "square meshes", "mesh architectures", "source", "destination", "fault-tolerant routing algorithm", "index termsmessage passing", "distributedcomputing system", "hexagonal mesh", "routing scheme performance", "network routing", "fault tolerant computing", "high probability"], "stemmed_label": ["softwar reliabl", "parallel architectur", "toru", "messag rout", "hexagon mesh", "parallelalgorithm", "fault-toler rout", "squar mesh", "mesh architectur", "sourc", "destin", "fault-toler rout algorithm", "index termsmessag pass", "distributedcomput system", "hexagon mesh", "rout scheme perform", "network rout", "fault toler comput", "high probabl"]}
{"doc": "Active learning differs from learning from examples in that the learning algorithm assumes at least some control over what part of the input domain it receives information about . In some situations , active learning is provably more powerful than learning from examples alone , giving better generalization for a fixed number of training examples.In this article , we consider the problem of learning a binary concept in the absence of noise . We describe a formalism for active concept learning called selective sampling and show how it may be approximately implemented by a neural network . In selective sampling , a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers useful . We test our implementation , called an SG-network , on three domains and observe significant improvement in generalization . Introduction vs . Active Learning Most neural network generalization problems are studied only with respect to random sampling: the training examples are chosen at random , and the network is simply a passive learner . This approach is generally referred to as \"learning from examples.\" Baum and Haussler (1989) , examine the problem analytically for neural networks; Cohn and Tesauro (1992) provide an empirical study of neural network generalization when learning from examples . There have also been a number of empirical efforts , such as Le Cun et al . (1990), aimed at improving neural network generalization when learning from examples. Learning from examples is not , however , a universally applicable paradigm . Many natural learning systems are not simply passive , but instead make use of at least some form of active learning to examine the problem domain . By active learning , we mean any form of learning in which the learning program has some control over the inputs it trains on . In natural systems (such as humans) , this phenomenon is exhibited at both high levels (e.g . active examination of objects) and low , subconscious levels (e.g . Fernald and Kuhl's (1987) work on infant reactions to \"Motherese\" speech). Within the broad definition of active learning , we will restrict our attention to the simple and intuitive form of concept learning via membership queries . In a membership query , the learner queries a point in the input domain and an oracle returns the classification of that point . Much work in formal learning theory has been directed to the study of queries (see e.g.: Angluin 1986 , Valiant 1984) , but only very recently have queries been examined with respect to their role in improving generalization behavior. In many formal problems , active learning is provably more powerful than passively learning from randomly given examples . A simple example is that of locating a boundary on the unit line interval . In order to achieve an expected position error of less than ffl , one would need to draw O( 1 training examples . If As published in Machine Learning 15(2):201-221 , 1994 . A preliminary version of this paper appears as (Cohn", "label": ["active learning", "version space", "neural networks", "queries", "generalization"], "stemmed_label": ["activ learn", "version space", "neural network", "queri", "gener"]}
{"doc": "We present a linear algebraic formulation for a class of index transformations such asGray code encoding and decoding , matrix transpose , bit reversal , vector reversal,shuffles , and other index or dimension permutations . This formulation unifies , simplifies,and can be used to derive algorithms for hypercube multiprocessors . We show how all the widely known properties of Gray codes , and some not so well-known properties as well , can be derived using this framework . Using this framework , we relate hypercube communications algorithms to Gauss-Jordan elimination on a matrix of 0's and 1's . Introduction We present a theory for a class of index transformation algorithms that should be properly thought of as a matrix-vector product , though they rarely are . This class is strictly a superset of the class known as BCP (bit-permute/complement) 20 , 21 . In spirit this theory is linked with the ideas in Van Loan's new book 26 , particularly the notion that matrix factorizations can define algorithms . The principal idea is not the discussion of matrix factorization algorithms , per se . The idea is a different way of viewing and generating algorithms. Loan 26 covers computational frameworks for the Fast Fourier Transform . Despite differences in our approach , on this quote we firmly agree: The proper way to discuss a matrix-vector product such as the discrete Fourier transform is with matrix-vector notation , not with vectors of subscripts and multiple summations . We should be as repelled by scalar notation as we are by assembly language coding for both retard algorithmic development. Although it has always been clear that BCP and larger classes of communications problems can be formulated as matrix-vector products , they rarely have been . Keohane and Stearns address a similar class of permutations 19 , but do not formulate the problem as a matrix-vector product . A notable exception is the contemporaneous work of Cormen 2 for permuting data on disk arrays. Our motivation stems from communications algorithms for real applications on hypercube multiprocessors such as the Connection Machine model CM-2 multiprocessor , though we believe these ideas to have wider applicability . Our matrices only contain 0's and 1's: they describe transformations on a vector of length 2 n indirectly through binary encodings . The most familiar example is bit reversal , an operation used in conjunction with FFT's . Bit reversal is a permutation of a vector of length 2 n induced by a permutation on n objects: the n bits of the vector's indices . One can represent this transformation as a 2 n \\Theta 2 n permutation matrix on the components of the vector 11 , 26 . For our purposes it is more convenient to consider the more compact representation of the n \\Theta n matrix describing the index transformation , which in the bit reversal case has 1's on the northeast-southwest diagonal and is otherwise 0 . Also familiar are so-called dimension transformations or index permutations . These are arbitrary permutations of the n bit indices , which", "label": ["gray code encoding", "matrix transpose", "hypercube communications algorithms", "index termslinear algebra", "shuffles", "bit reversal", "encoding", "hypercube multiprocessors", "linear algebra framework", "gray codes", "indextransformation algorithms", "vector reversal", "gauss-jordan elimination", "decoding", "hypercube networks"], "stemmed_label": ["gray code encod", "matrix transpos", "hypercub commun algorithm", "index termslinear algebra", "shuffl", "bit revers", "encod", "hypercub multiprocessor", "linear algebra framework", "gray code", "indextransform algorithm", "vector revers", "gauss-jordan elimin", "decod", "hypercub network"]}
{"doc": "It is expected that in the near future , tens of millions of users will have access to distributed information systems through wireless connections . The technical characteristics of the wireless medium and the resulting mobility of both data resources and data consumers raise new challenging questions regarding the development of information systems appropriate for mobile environments . In this paper , we report on the development of such a system . First , we describe the general architecture of the information system and the main considerations of our design . Then , based on these considerations , we present our system support for maintaining the consistency of replicated data and for providing transaction schemas that account for the frequent but predictable disconnections , the mobility , and the vulnerability of the wireless environment . Introduction In the recent past , technical advances in the development of portable computers and the rapidly expanding cordless technology have provided the basis for accessing information systems through wireless connections . Today , when users move , unplug their computer from some local area network, transport it , and plug it back to the local area network at their destination . Wireless technology provides users with the ability to retain their network connection even while moving . This new computing paradigm is called mobile or nomadic computing . Mobile computing can be viewed as adding a new dimension to the broader vision of universal access to information that allows the mobility of data consumers and data resources. In Proceedings of the 3rd International Conference on Information and Knowledge Management , Gaithesburg , MD , Nov 1994 , pp This and related reports are available through www , URL address: http://www.cs.purdue.edu/people/pitoura Until recently , infrastructure research pertaining to mobile computing has mostly focused on networking and operating systems 18 , 8 , 17 , 25 , 4 , 23 . Research in networking and communications includes new addressing and routing schemas , support for efficient multicasting and broadcast- ing , data compression , and relocation transparency . Re-search in operating system addresses security issues , file systems that support disconnected operation , and caching techniques . However , the issues introduced go beyond those areas and directly affect information management systems 3 , 15 , 20 . Mobile computing introduces new challenging problems concerning resource management , information acquisition 16 , and data distribution 13 . In this paper , we report on the design of an information system for a mobile environment . The goal of this paper is twofold . First , we give a general overview of the organization of the system and of the important concerns of our design. Second , we focus on our system support for consistency and transactions and show how our schema is in compliance with the general architecture and design concerns. The structure of this paper is as follows . In Section 2 , we introduce the physical architecture , and identify the characteristics of both the wireless medium and the mobile hosts. In Section 3 , we", "label": ["mobile computing", "new applications", "information systems", "consistency", "transaction management"], "stemmed_label": ["mobil comput", "new applic", "inform system", "consist", "transact manag"]}
{"doc": "The development of software for minimization problems is often based on a line search method . We consider line search methods that satisfy sufficient decrease and curvature conditions , and formulate the problem of determining a point that satisfies these two conditions in terms of finding a point in a set T(&mgr;) . We describe a search algorithm for this problem that produces a sequence of iterates that converge to a point in T(&mgr;) and that , except for pathological cases , terminates in a finite number of steps . Numerical results for an implementation of the search algorithm on a set of test functions show that the algorithm terminates within a small number of iterations . Introduction Given a continuously differentiable function OE defined on 0; 1) with OE 0 and constants - and j in (0; 1) , we are interested in finding an ff ? 0 such that and The development of a search procedure that satisfies these conditions is a crucial ingredient in a line search method for minimization . The search algorithm described in this paper has been used by several authors , for example , Liu and Nocedal 10 , O'Leary 12 , Schlick and Fogelson 14 , 15 , and Gilbert and Nocedal 7 . This paper describes this search procedure and the associated convergence theory. In a line search method we are given a continuously differentiable function f : and a descent direction for f at a given point x 2 IR n . Thus , if then (1.1) and (1.2) define an acceptable step . The motivation for requiring conditions (1.1) and (1.2) in a line search method should be clear . If ff is not too small , condition (1.1) forces a sufficient decrease in the function . However , this condition is not sufficient to guarantee convergence , because it allows arbitrarily small choices of ff ? 0 . Condition (1.2) rules out arbitrarily small choices of ff and usually guarantees that ff is near a local minimizer of OE. Condition (1.2) is a curvature condition because it implies that and thus the average curvature of OE on (0; ff) is positive . The curvature condition (1.2) is particularly important in a quasi-Newton method because it guarantees that a positive definite quasi-Newton update is possible . See , for example , Dennis and Schnabel 4 and Fletcher 6 . Work supported in part by the Applied Mathematical Sciences subprogram of the Office of Energy Research of the U.S . Department of Energy under Contract W-31-109-Eng-38. Permanent address: Department of Mathematical Sciences , Indiana-Purdue University , Fort Wayne, Indiana 46805. As final motivation for the solution of (1.1) and (1.2) , we mention that if a step satisfies these conditions , then the line search method is convergent for reasonable choices of direction . See , for example , Dennis and Schnabel 4 and Fletcher 6 for gradient-related methods; Powell 13 and Byrd , Nocedal , and Yuan 3 for quasi-Newton methods; and Al- Baali 1 , Liu and Nocedal 10 ,", "label": ["variable metric algorithms", "line search algorithms", "conjugate gradient algorithms", "nonlinear optimization", "truncated newton algorithms"], "stemmed_label": ["variabl metric algorithm", "line search algorithm", "conjug gradient algorithm", "nonlinear optim", "truncat newton algorithm"]}
{"doc": "We present a method for determining a posteriori bounds and estimates for local and total errors in radiosity solutions . The ability to obtain bounds and estimates for the total error is crucial fro reliably judging the acceptability of a solution . Realistic estimates of the local error improve the efficiency of adaptive radiosity algorithms , such as hierarchical radiosity , by indicating where adaptive refinement is necessary.First , we describe a hierarchical radiosity algorithm that computes conservative lower and upper bounds on the exact radiosity function , as well as on the approximate solution . These bounds account for the propagation of errors due to interreflections , and provide a conservative upper bound on the error . We also describe a non-conservative version of the same algorithm that is capable of computing tighter bounds , from which more realistic error estimates can be obtained . Finally , we derive an expression for the effect of a particular interaction on the total error . This yields a new error-driven refinement strategy for hierarchical radiosity , which is shown to be superior to brightness-weighted refinement . INTRODUCTION During the past decade , radiosity has become the method of choice for simulating global illumination in environments consisting entirely of Lambertian (ideal diffuse) reflectors and emitters . Global illumination in such environments is governed by a Fredholm integral equation of the second kind: Z k(x , y)B(y) dy , (1) E-mail: danix | bes | dpg @graphics.cornell.edu where B(x) is the total radiosity at point x , E(x) is the emission , and ae(x) is the reflectivity 1 . The kernel of the integral operator xy describes the point-to-point transfer from y to x: ' x and ' y are the angles between the surface normals and the line connecting x and y , r xy is the distance between the two points , and V(x , y) is 1 if y is visible to x and 0 otherwise. Radiosity algorithms compute an approximate solution b B(x) to equation (1) by projecting the continuous integral equation into a finite dimensional function space . Most radiosity algorithms use spaces of piecewise constant functions , although recently several investigators described radiosity algorithms that use higher order basis functions 12 , 21 , 22 . The projection of the continuous equation results in a discrete system of n linear equations , where n is the dimension of the finite dimensional space: Since radiosity algorithms produce only approximate results , reliable error bounds and realistic error estimates are crucial for assessing the acceptability of a particular solution , as well as for automatic adaptive refinement. The theory of integral equations 1 , 10 provides an a priori error analysis of computational methods for Fredholm equations of the second kind . This general framework is valuable for analyzing convergencerates 10 , and for boundingvarious components of the error in terms of the corresponding operator norms 3 . However, a priori error bounds are typically pessimistic and often difficult to evaluate , requiring information about the operators or the exact solution", "label": ["adaptive refinement", "a posteriori error bounds and estimates", "importance", "hierarchical radiosity", "global illumination"], "stemmed_label": ["adapt refin", "a posteriori error bound and estim", "import", "hierarch radios", "global illumin"]}
{"doc": "In this paper we identify sources of error in global illumination algorithms and derive bounds for each distinct category . Errors arise from three sources: inaccuracies in the boundary data , discretization , and computation . Boundary data consists of surface geometry , reflectance functions , and emission functions , all of which may be perturbed by errors in measurement or simulation , or by simplifications made for computational efficiency . Discretization error is introduced by replacing the continuous radiative transfer equation with a finite-dimensional linear system , usually by means of boundary elements and a corresponding projection method . Finally , computational errors perturb the finite-dimensional linear system through imprecise form factors , inner products , visibility , etc. , as well as by halting iterative solvers after a finite number of steps . Using the error taxonomy introduced in the paper we examine existing global illumination algorithms and suggest new avenues of research . Introduction The role of global illumination algorithms is to simulate the inter-action of light with large-scale geometry for the purpose of image synthesis . The greatest challenges in this endeavor have been those of accuracy and efficiency . While issues of efficiency have been addressed frequently in computer graphics , error analysis has received comparatively little attention . Indeed , the subject is difficult to even approach for several reasons . First , there is no universally accepted definition of accuracy for global illumination . Although accuracy connotes a quantitative comparison with some ideal , the ideal may be either empirical or theoretical , and the comparison may assume a range of forms from purely mathematical to percep- tual . A second obstacle has been a lack of mathematical formalisms 580 Engineering and Theory Center Building , Ithaca , New York 14853 for global error analysis . Thus far , analysis has been confined to specific sub-problems , and no systematic treatment of the subject has been presented. In this paper we attempt to establish a framework for error analysis within a well-defined class of global illumination problems. Specifically , we address the problem of approximating solutions to a form of the rendering equation 18 given imprecise data for ge- reflectance functions , and emission functions . We further assume that the approximation is to be assessed quantitatively by its distance from the theoretical solution . By employing radiometric quantities and physically-motivated measures of error we temporarily sidestep the difficult issues of display and perception . Moreover, in the present work we exclude participating media , transparent sur- faces , and probabilistic solution methods . The problem domain that we address can be summarized as follows: ffl Radiometric quantities (radiance , reflectivities , emission) ffl A linear model of radiative transfer ffl Direct radiative exchange among opaque surfaces ffl Deterministic boundary element formulations Given these restrictions , we derive error bounds in terms of potentially known quantities , such as bounds on emission , reflectivity, and measurement error . To obtain these error bounds , we draw upon the general theory of integral equations 2 as", "label": ["discretization", "linear operators", "boundary elements", "radiosity", "error bounds", "global illumination", "projection methods", "reflectance functions"], "stemmed_label": ["discret", "linear oper", "boundari element", "radios", "error bound", "global illumin", "project method", "reflect function"]}
{"doc": "We describe a data visualization system based on spreadsheets . Cells in our spreadsheet contain graphical objects such as images , volumes , or movies . Cells may also contain widgets such as buttons , sliders , or curve editors . Objects are displayed in miniature inside each cell . Formulas for cells are written in a general-purpose programming language (Tcl) augmented with operators for array manipulation , image processing , and rendering.Compared to flow chart visualization systems , spreadsheets are more expressive , morescalable , and easier to program . Compared to conventional numerical spreadsheets , spreadsheets for images pose several unique design problems: larger formulas , longer computation times , and more complicated intercelldependencies . In response to these problems , we have extended the spreadsheet paradigm in three ways: formulas can display their results anywhere in the spreadsheet , cells can be selectively disabled , and multiple cells can be edited at once . We discuss these extensions and their implications , and we also point out some unexpected uses for our spreadsheets: as a visual database browser , as a graphical user interface builder , as a smart clipboard for the desktop , and as a presentation tool . Introduction The majority of commercially available image processing and data visualization systems employ a flow chart paradigm. Users select processing modules from a menu and wire them together using a mouse . Although elegant in principle , flow charts are limited in expressiveness and scalability . Useful programming constructs like procedure calls and variable substitution cannot be conveniently expressed in these systems . Flow charts spend their screen real estate on operators and their interconnec- tions , which becomes uninteresting once the flow chart has been Address: Center for Integrated Systems Email: levoy@cs.stanford.edu Stanford University Web: http://www-graphics.stanford.edu Stanford , CA 94305-4070 specified , and they run out of screen space if the chart exceeds a few dozen operators . Flow charts also provide no convenient mechanism for managing multiple datasets. We propose an alternative paradigm based on spreadsheets. Broadly speaking , a spreadsheet is a system for specifying constraints among cells arranged in a grid . Cells may contain a constant data value or a formula that evaluates to a data value . Formulas may reference the value of other cells , but they may not alter the value of other cells . Formulas are typically written in a simple , interpreted language . Examples of spreadsheet systems are Microsoft's Excel , Lotus's 1-2-3 , and Borland's Quattro. We have implemented a spreadsheet for images (hen- ceforth denoted SI) in which we extend the notion of a data value to include graphical objects such as images . These objects are displayed in miniature inside each cell . Double clicking on a cell brings up the full-size object . Cells may also contain interactive widgets . Manipulating a widget modifies the data associated with the cell . If formulas in other cells reference the modified cell, they are recomputed as well. Formulas in our spreadsheet are written in Tcl ,", "label": ["visual programming languages", "user interfaces", "flow charts", "data visualization", "spreadsheets"], "stemmed_label": ["visual program languag", "user interfac", "flow chart", "data visual", "spreadsheet"]}
{"doc": "Lambert's model for body reflection is widely used in computer graphics . It is used extensively by rendering techniques such as radiosity and ray tracing . For several real-world objects , however , Lambert's model can prove to be a very inaccurate approximation to the body reflectance . While the brightness of a Lambertian surface is independent of viewing direction , that of a rough surface increases as the viewing direction approaches the light source direction . In this paper , a comprehensive model is developed that predicts body reflectance from rough surfaces . The surface is modeled as a collection of Lambertian facets . It is shown that such a surface is inherently non-Lambertian due to the foreshortening of the surface facets . Further , the model accounts for complex geometric and radiometric phenomena such as masking , shadowing , and interreflections between facets . Several experiments have been conducted on samples of rough diffuse surfaces , such as , plaster , sand , clay , and cloth . All these surface demonstrate significant deviation from Lambertian behavior . The reflectance measurements obtained are in strong agreement with the reflectance predicted by the model . Introduction An active area of research in computer graphics involves the creation of realistic images . Images are rendered using one of two well-known techniques , namely , ray tracing 34 or radiosity 6 . The quality of a rendered image depends to a great extent on the accuracy of the reflectance model used. In the past decade , computer graphics has witnessed the application of several physically-based reflectance models for image rendering (see 7 , 16 , 9 , 13 ) . Reflection from a surface can be broadly classified into two categories: surface reflectance which takes place at the interface between two media with different refractive indices and body reflectance which is due to subsurface scattering . Most of the previous work on physically-based rendering has focused on accurate modeling of surface reflectance . They predict ideal specular reflection from smooth surfaces as well as wide directional lobes from rougher surfaces 13 . In contrast , the body component has most often been assumed to be Lambertian . A Lambertian surface appears equally bright from all direc- tions . This model was advanced by Lambert 18 more than 200 years ago and remains one of the most widely used models in computer graphics. For several real-world objects , however , the Lambertian model can prove to be a poor and inadequate approximation to body reflection . Figure 1(a) shows a real image of a clay vase obtained using a CCD camera . The vase is illuminated by a single distant light source in the same direction as the sensor . Figure 1(b) shows a rendered image of a vase with the same shape as the one shown in Figure 1(a) . This image is rendered using Lambert's model , and the same illumination direction as in the case of the real vase. As expected , Lambert's model predicts that the brightness (a) (b) Figure", "label": ["moon reflectance", "brdf", "reflection models", "rough surfaces", "lambert's model"], "stemmed_label": ["moon reflect", "brdf", "reflect model", "rough surfac", "lambert' model"]}
{"doc": "We present an approach to modeling with truly mutable yet completely controllable free-form surfaces of arbitrary topology . Surfaces may be pinned down at points and along curves , cut up and smoothly welded back together , and faired and reshaped in the large . This style of control is formulated as a constrained shape optimization , with minimization of squared principal curvatures yielding graceful shapes that are free of the parameterization worries accompanying many patch-based approaches . Triangulated point sets are used to approximate these smooth variational surfaces , bridging the gap between patch-based and particle-based representations . Automatic refinement , mesh smoothing , and re-triangulation maintain a good computational mesh as the surface shape evolves , and give sample points and surface features much of the freedom to slide around in the surface that oriented particles enjoy . The resulting surface triangulations are constructed and maintained in real time . Introduction One of the fundamental goals in computer-aided free-form shape design is to offer convenient ways to specify shape and topology. We are concerned here with a truly broad class of surfaces: smooth, doubly curved surfaces , of arbitrary topology (closed or bordered). This generality is what makes representing and controlling such shapes on a computer a difficult problem. 1.1 Functional minimization for shape design Optimization has long been used as a way of describing fair free-form shapes (a good survey is Moreton 23 ) . More recently , it has come to be used in interactive modelers 4,5,41,18 . Though such approaches are computationally complex , their intent is to create an illusion of simplicity for the designer . Ideally , the designer sees a surface having no particular fixed controls or other representation- specific parameters . Instead , the surface can be directly manipu- lated , pinned down at points and along curves , and will behave as if made of some infinitely stretchy material . This lets us mimic a style of pen-and-paper design in which important contours of a shape are sketched out as \"character lines\" , with the understanding that a surface passes through them in a fair way 4 . Such shapes are ultimately realized as solutions to constrained functional minimization problems - globally fair surfaces that satisfy geometric interpolation constraints . This approach allows concise descriptions of a useful class of free-form shapes. Unfortunately , these approaches have only allowed a designer to interact with pre-fabricated families of shapes , in which the topology remains fixed and surfaces do not stray far from their initial configurations . More drastic , nonuniform deformations are not handled well by the linearized thin plate functional 30 used to fair the piecewise smooth patches making up these surfaces . Further , no real consideration has been given to the problem of creating non-trivial smooth surface topologies interactively . The one approach to fair shape design that has allowed large-scale changes in shape and topology during sculpting is the oriented particle system of Szeliski and Tonnesin 34 . The drawback of this approach is that there is no", "label": ["delaunay triangulation", "functional minimization", "adaptive meshing", "fair surface design", "polygonal models"], "stemmed_label": ["delaunay triangul", "function minim", "adapt mesh", "fair surfac design", "polygon model"]}
{"doc": "This article describes a new approach to the unit testing of object-oriented programs , a set of tools based on this approach , and two case studies . In this approach , each test case consists of a tuple of sequences of messages , along with tags indicating whether these sequences should put objects of the class under test into equivalent states and/or return objects that are in equivalent states . Tests are executed by sending the sequences to objects of the class under test , then invoking a user-supplied equivalence-checking mechanism . This approach allows for substantial automation of many aspects of testing , including test case generation , test driver generation , test execution , and test checking . Experimental prototypes of tools for test generation and test execution are described . The test generation tool requires the availability of an algebraic specification of the abstract data type being tested , but the test execution tool can be used when no formal specification is available . Using the test execution tools , case studies involving execution of tens of thousands of test cases , with various sequence lengths , parameters , and combinations of operations were performed . The relationships among likelihood of detecting an error and sequence length , range of parameters , and relative frequency of various operations were investigated for priority queue and sorted-list implementations having subtle errors . In each case , long sequences tended to be more likely to detect the error , provided that the range of parameters was sufficiently large and likelihood of detecting an error tended to increase up to a threshold value as the parameter range increased . Introduction Object-oriented programming , based on the concepts of data abstraction , inheritance , and dynamic binding , is becoming an increasingly popular software development methodology. Much research has been done on developing object-oriented analysis and design techniques, developing object-oriented programming languages , and exploring how the methodology This research was supported in part by NSF grants CCR-8810287 and CCR-9003006 and by the New York State Science and Technology Foundation and was performed while the first author was at Polytechnic University . Authors' address: Department of Computer Science , Polytechnic University , 6 Metrotech Center, Brooklyn , NY 11201 . e-mail: phyllis@morph.poly.edu. changes the software development process . Yet relatively little research has addressed the question of how object-oriented programs should be tested. We have developed a new approach to unit testing object-oriented programs , which is based on the ideas that the natural units to test are classes , and that in testing classes, one should focus on the question of whether a sequence of messages puts an object of the class under test into the \"correct\" state . In this approach , roughly speaking , each test case consists of a pair of sequences of messages , along with a tag indicating whether these sequences should result in objects that are in the same \"abstract state\" . A test case is executed by sending each sequence of messages to an object", "label": ["abstract data types", "software testing", "object-oriented programming", "algebraic specification"], "stemmed_label": ["abstract data type", "softwar test", "object-ori program", "algebra specif"]}
{"doc": "We describe a multiresolution curve representation , based on wavelets , that conveniently supports a variety of operations: smoothing a curve; editing the overall form of a curve while preserving its details; and approximating a curve within any given error tolerance for scan conversion . We present methods to support continuous levels of smoothing as well as direct manipulation of an arbitrary portion of the curve; the control points , as well as the discrete nature of the underlying hierarchical representation , can be hidden from the user . The multiresolution representation requires no extra storage beyond that of the original control points , and the algorithms using the representation are both simple and fast . Introduction A good representation for curves should allow for flexible editing , smooth- ing , and scan conversion . In particular , a representation for curves should support: ffl the ability to change the overall \"sweep\" of a curve while maintaining its fine details , or \"character\" (Figure 3); ffl the ability to change a curve's ``character'' without affecting its overall Figure ffl the ability to edit a curve at any continuous level of detail , allowing an arbitrary portion of the curve to be affected through direct manipulation Figure ffl continuous levels of smoothing , in which undesirable features are removed from a curve (Figure 2); ffl curve approximation , or \"fitting,\" within a guaranteedmaximum error tol- erance , for scan conversion and other applications (Figures 8 and 9). In this paper , we show how a multiresolution curve representation can provide a single , unified framework for addressing all of these issues . It requires no extra storage beyond that of the original m control points , and the algorithms that use it are both simple and fast , typically linear in m. There are many applications of multiresolution curves , including computer-aided design , in which cross-sectional curves are frequently used in the specification of surfaces; keyframeanimation , in which curves are used to control parameter interpolation; 3D modeling and animation , in which \"backbone\" curves are manipulated to specify object deformations; graphic design , in which curves are used to describe regions of constant color or texture; font design , in which curves represent the outlines of characters; and pen-and-ink illustration , in which curves are the basic elements of the finished piece . In all of these situations , the editing , smoothing , and approximation techniques we describe can be powerful tools. 1.1 Related work Some of the algorithms supported by multiresolution curves are completely new , to our knowledge , such as the ability to edit a curve at any continuous level of detail , and the ability to change a curve's character without affecting its overall sweep . However , the majority of applications described in this paper have already been addressed in one form or another . Although the algorithms we describe compare favorably , in and of themselves , with most of this previous work , it is the convenience with which the multiresolution representation supports", "label": ["curve fitting", "curve smoothing", "direct manipulation", "curve compression", "scan conversion", "wavelets", "curve editing"], "stemmed_label": ["curv fit", "curv smooth", "direct manipul", "curv compress", "scan convers", "wavelet", "curv edit"]}
{"doc": "This article describes a graphical interval logic that is the foundation of a tool set supporting formal specification and verification of concurrent software systems . Experience has shown that most software engineers find standard temporal logics difficult to understand and use . The objective of this article is to enable software engineers to specify and reason about temporal properties of concurrent systems more easily by providing them with a logic that has an intuitive graphical representation and with tools that support its use . To illustrate the use of the graphical logic , the article provides some specifications for an elevator system and proves several properties of the specifications . The article also describes the tool set and the implementation . Introduction One of the great challenges facing today's software engineers is the development of correct programs for real applications . Recent advances in hardware reliability and fault tolerance technology can assure extremely low hardware failure rates for devices . Unfortunately , technologies for digital hardware design and software engineering have not matched this advance . The use of computers in many critical applications is now primarily limited by the reliability of system designs and implementations. Research partially supported by NSF grant CCR-9014382 with cooperation from DARPA . An early version of the paper was presented at 14th Inter . Conf . Software Engineering , May 1992 (Institution of Engineers Australia , IEEE Computer Society , Association of Computing Machinery , Institution of Radio and Electronic Engineers Australia , and Australian Computer Society) . Copyright 1995 c by ACM , Inc . Permission to copy and distribute this document is hereby granted provided that this notice is retained on all copies , that copies are not altered , and that ACM is credited when the material is used to form other copyright policies The most critical real applications often involve concurrency , which increases the difficulty of system development and validation . Modern methods of structured programming , which are quite effective for sequential programs , are notoriously inadequate for concurrent ones . Moreover , the nondeterminism inherent in applications that involve concurrency and the reactive character of those applications makes them hard to test . Aggravating these problems is the need to explore large spaces of possible executions , which grow exponentially with the number of independent threads of control. Formal methods for specifying and verifying systems can , in principle , offer a greater assurance of correctness than informal design/code checks or testing . Formal verification methods can demonstrate that a high-level design meets formally specified correctness requirements , thereby reducing the risk that faulty designs will be used as the basis for system development . Formal specifications are valuable for defining interfaces between independently developed software modules and for establishing software and interface standards . Because they provide a succinct and unambiguous statement of system requirements , formal specifications can potentially be analyzed for consistency, a particularly difficult and important problem for concurrent systems . Formal specifications can also be used during the selection of test data to suggest", "label": ["concurrent systems", "visual languages", "timing diagrams", "automated proof-checking", "formal specifications", "temporal logic", "graphical interval logic"], "stemmed_label": ["concurr system", "visual languag", "time diagram", "autom proof-check", "formal specif", "tempor logic", "graphic interv logic"]}
{"doc": "We present a new particle-based approach to sampling and controlling implicit surfaces . A simple constraint locks a set of particles onto a surface while the particles and the surface move . We use the constraint to make surfaces follow particles , and to make particles follow surfaces . We implement control points for direct manipulation by specifying particle motions , then solving for surface motion that maintains the constraint . For sampling and rendering , we run the constraint in the order direction , creating floater particles that roam freely over the surface . Local repulsion is used to make floaters spread evenly across the surface . By varying the radius of repulsion adaptively , and fissioning or killing particles based on the local density , we can achieve good sampling distributions very rapidly , and maintain them even in the face of rapid and extreme deformations and changes in surface topology . Introduction Implicit surfaces have proven to be useful for modeling , ani- mation , and visualization . One appeal of implicit models is that new surfaces can be created by adding or otherwise combining the functions that define them , producing a variety of subtle and interesting shape effects . Another is their role in the visualization of volume data . In addition , the implicit representation lends itself to such calculations as ray/surface intersection and inside/outside test. However , implicit surfaces suffer from two serious drawbacks: first, although well suited to ray tracing , they are not easily rendered at interactive speeds , reflecting the underlying problem that it is difficult to sample them systematically . This is particularly a problem if we wish to render time-varying surfaces in real time , which is vital for interactive sculpting . Second , the shapes of implicit surfaces have proven to be more difficult to specify and control than those of their parametric counterparts. Mail to the authors should be addressed to the Department of Computer Science , Carnegie Mellon University , 5000Forbes Ave , Pittsburgh PA 15213, USA . Email should be addressed to Andrew Witkin as aw@cs.cmu.edu , and to Paul Heckbert as ph@cs.cmu.edu. c ACM . Reprinted from Computer Graphics , Proc . SIGGRPAH '94. In this paper , we present a new particle-based approach to sampling and shape control of implicit surfaces that addresses these problems . At the heart of our approach is a simple constraint that locks a collection of particles onto an implicit surface while both the particles and the surface move . We can use the constraint to make the surface follow the particles , or to make the particles follow the surface . Our formulation is differential: we specify and solve for velocities rather than positions , and the behavior of the system is governed by differential equations that integrate these velocities over time. We control surface shape by moving particles interactively , solving for surface motion that keeps the particles on the surface . This technique lets us pin down the surface at some points while interactively dragging others", "label": ["constrained optimization", "physically based modeling", "interaction", "adaptive sampling"], "stemmed_label": ["constrain optim", "physic base model", "interact", "adapt sampl"]}
{"doc": "We present a general method for automatic reconstruction of accurate , concise , piecewise smooth surface models from scattered range data . The method can be used in a variety of applications such as reverse engineeringthe automatic generation of CAD models from physical objects . Novel aspects of the method are its ability to model surfaces of arbitrary topological type and to recover sharp features such as creases and corners . The method has proven to be effective , as demonstrated by a number of examples using both simulated and real data.A key ingredient in the method , and a principal contribution of this paper , is the introduction of a new class of piecewise smooth surface representations based on subdivision . These surfaces have a number of properties that make them ideal for use in surface reconstruction: they are simple to implement , they can model sharp features concisely , and they can be fit to scattered range data using an unconstrained optimization procedure . Introduction In this paper , we present a new representation for piecewise smooth surfaces of arbitrary topological type , 1 and a method for fitting such surface models to scattered range data , where neither the topological type of the surface , its geometry , nor the location of its sharp features are known in advance . We also present examples showing that the surface representation and fitting method are useful for im- 3 Department of Computer Science and Engineering , FR-35 y Department of Mathematics , GN-50 z Apple Computer x Department of Statistics , GN-22 This work was supported in part by IBM , Silicon Graphics Inc. , the Xerox Corporation , and the National Science Foundation under grants CCR- 8957323 and DMS-9103002. 1 The topological type of a surface refers to its genus , the presence of boundaries , etc. portant applications such as reverse engineering - the automatic generation of CAD models from laser range data. In previous work 4 , 10 , 11 , we developed a method for fitting compact , accurate piecewise linear surfaces to scattered range data. The generalization to piecewise smooth surfaces is a natural and necessary extension . Many objects of interest are piecewise smooth; their surfaces consist of smoothly curved regions that meet along sharp curves and at sharp corners . Modeling such objects as piece-wise linear surfaces requires a large number of triangles , whereas curved surface models can provide both a more accurate and a more compact representation of the true surface . It is critical , however , to use a surface representation that is capable of explicitly modeling sharp features . Using an everywhere smooth surface representation to model sharp features either results in a large number of surface elements , or in a poor geometric fit , as illustrated in Color Plate 1m. Additionally , the surface representation should be capable of modeling surfaces of arbitrary topological type. The most popular smooth surface representations are tensor product NURBS . However , NURBS can only represent surfaces of arbitrary topological type", "label": ["subdivision surfaces", "surface fitting", "shape recovery", "geometric modeling", "range data analysis"], "stemmed_label": ["subdivis surfac", "surfac fit", "shape recoveri", "geometr model", "rang data analysi"]}
{"doc": "We present an approach for accelerating hierarchical radiosity by clustering objects . Previous approaches constructed effective hierarchies by subdividing surfaces , but could not exploit a hierarchical grouping on existing surfaces . This limitation resulted in an excessive number of initial links in complex environments . Initial linking is potentially the most expensive portion of hierarchical radiosity algorithms , and constrains the complexity of the environments that can be simulated . The clustering algorithm presented here operates by estimating energy transfer between collections of objects while maintaining reliable error bounds on each transfer . Two methods of bounding the transfers are employed with different tradeoffs between accuracy and time . In contrast with the O(s2) time and space complexity of the initial linking in previous hierarchical radiosity algorithms , the new methods have complexities of O(slogs) and O(s) for both time and space . Using these methods we have obtained speedups of two orders of magnitude for environments of moderate complexity while maintaining comparable accuracy . Introduction Recent trends in realistic image synthesis have been towards a separation of the rendering process into two or more stages 10 , 2 , 9 . One of these stages solves for the global energy equilibrium throughout the environment . This process can be very expensive and its complexity grows rapidly with the number of objects in the environment. These computational demands generally limit the level of detail of environments that can be simulated . Furthermore , a solution to this problem must be computed before anything useful can be displayed. Radiosity algorithms attempt to solve the global illumination problem by discretizing the environmentand solving a linear system to approximate the transfer of energy between the elements 5 . For complex environments,the large number of interactions is expensive E-mail: bes arvo | dpg @graphics.cornell.edu to compute , as each requires form factor and visibility calculations. The challenge is to reduce the computational complexity of this process . In one of the early approaches , Cohen et al . 3 reduced the number of interactions by imposing a two-level hierarchy of patches and elements on the environment . Although the number of interactions was reduced , the approachwas still O(p 2 ) in the number of elements in the environment. Currently , the best radiosity algorithms are analogous to linear-time algorithms for charged particle simulation 6 . These algorithms work by clustering particles together so that the mutual effect of well-separated collections can be approximated with a single interaction . Hanrahan et al . 7 used a similar strategy to reduce the number of interactions needed for a radiosity solution . A hierarchical structure was imposed on each surface in an environment and interactions were allowed to occur between the appropriate levels on each . This approach works well when the number of initial surfaces is small , as hierarchical radiosity (HR) algorithms can \"sub- divide\" large surfaces into smaller ones , but cannot \"group\" smaller elements into larger ones . The initial linking phase of HR must check all pairs of initial surfaces for potential", "label": ["hierarchical radiosity", "error bounds", "clustering", "global illumination"], "stemmed_label": ["hierarch radios", "error bound", "cluster", "global illumin"]}
{"doc": "Character User Interfaces (CUI) generally display only pieces of text and semi-graphical objects , whereas Graphical User Interfaces (GUI) display interaction objects (IO) such as icons , check boxes , list boxes , radio buttons and push buttons . Traditional GUI do not often go beyond such existing IO . Multimedia GUI add interactive objects such as pictures , images , video sequences that could serve as a base for sophisticated user interaction . All these types of user interfaces have in common the problem of determining a basic layout of IO . The complexity of this problem is proportional to the variety of IO accessible for the designer . This paper summarises visual techniques exported from the area of visual design to be further exploited for user interface . These visual techniques provide the designer a wide range of means for laying out IO . A small set of guidelines for effectively applying these visual techniques is given . INTRODUCTION When the designer sketches the components of a user inter- face , the first thing to do is to select appropriate interaction and interactive objects according to the user's task . The second responsibility is to determine the basic layout of these selected objects ranging from the most important to the least important: e.g . the main application window , the title and menu bars , if any , the functional areas of the application window (e.g . the status bar , the toolbar) , all child windows , dialog boxes and panels with their contents . This layout consists of interaction objects and interactive objects 11 . Interaction objects , also called widgets or controls, encompass static objects (e.g . labels , separators , group boxes) and dynamic objects (e.g . edit boxes , radio boxes, option boxes) . Interactive objects cover every other kind of object that a multimedia user interface could virtually dis- Today , one problem arises in modern user interfaces (especially multimedia interfaces) where layout grids are no longer valid since the layout no longer consists of vertical and horizontal lines . Instead , the layout may be based on other lines (e.g . oblique lines , discontinuous lines), convex shapes (e.g . lozenge) , planes (e.g . planes with a vanishing point) , and volumes (e.g . cylinder) . Therefore, the concept of layout grid should be extended to the concept of layout frame . A layout frame consists of dots , lines, shapes and volumes that constraint the localisation of IO 2 . In the rest of this paper , the term \"layout\" will be used for short . To help the designer deciding such a layout , several visual techniques are now introduced and exemplified immediately countered by adding an IO if the same weight to the right of the vertical axis. Fig . 3 . Symmetrically and asymmetrically balanced layouts. DEFINITION OF VISUAL TECHNIQUES A visual technique relies on a commonly accepted visual principle to suggest the arrangement of the layout compo- nents . The visual techniques listed in this section are", "label": ["layout", "interactive objects", "graphical applications", "visual interaction", "multimedia applications", "visual techniques", "visual placement", "interaction objects", "visual interface design and management"], "stemmed_label": ["layout", "interact object", "graphic applic", "visual interact", "multimedia applic", "visual techniqu", "visual placement", "interact object", "visual interfac design and manag"]}
{"doc": "This paper presents the architecture for an extensible toolkit used in construction and rapid prototyping of three dimensional interfaces , interactive illustrations , and three dimensional widgets . The toolkit provides methods for the direct manipulation of 3D primitives which can be linked together through a visual programming language to create complex constrained behavior . Features of the toolkit include the ability to visually build , encapsulate , and parameterize complex models , and impose limits on the models . The toolkit's constraint resolution technique is based on a dynamic object model similar to those in prototype delegation object systems . The toolkit has been used to rapidly prototype tools for mechanical modelling , scientific visualization , construct 3D widgets , and build mathematical illustrations . Introduction There have been many advances in 2D user interface toolkits 8 10 11 12 which allow developers to rapidly prototype 2D interfaces . Recent attempts have been made to advance user interfaces into 3D 3 4 5 7 13 15 and it is natural to develop a toolkit that aids in the rapid prototyping and construction of 3D interfaces . Visual toolkits have the added benefit that non-programmers can also be interface developers . Due to the difficulty in specifying complex behavior in 3 dimensions , the task of specifying interfaces in 3D is difficult and time consuming , but a visual 3D toolkit provides the means to make interface construction in 3D feasible for both programmers and non-programmers. In this paper , we present an architecture for a toolkit used in constructing three dimensional widgets , interactive illustrations , and three dimensional interfaces 5 . The toolkit provides direct manipulation of 3D primitives through a visual language . These primitives are used to construct widgets, interface objects , and application objects whose geometry is affinely constrained . Constraints can apply not only to the geometry but also to other non-geometric attributes such as color , visibility , and transparency . The toolkit has been improved over the prototype (described in 18 ) by enhancing the visual language to support parametrized procedures through encapsulation , inequality relationships through limits , and constraints of non-geometric attributes . We have also enhanced the interface for specifying relationships between primitives in three ways . First , we have provided options for linking behaviors . Second , we included mechanisms for breaking constraint relations . Finally , we added visual feedback for displaying constraint relations . This paper presents the underlying architecture of the toolkit . For further information on the UI see 22 . The visual programming paradigm of our toolkit has significant advantages over methods used by other toolkits , such as libraries 12 15 and graphical networks 1 8 10 . The traditional approach to designing user interface toolkits is to use libraries of software objects which are created using standard programming languages . This makes the task of visualizing the complex relationships between these objects difficult . It also rules out the possibility of non-programmers using them to do interface prototyping . The second paradigm", "label": ["constraints", "delegation", "visual programming", "user interface toolkits", "direct manipulation", "interaction techniques"], "stemmed_label": ["constraint", "deleg", "visual program", "user interfac toolkit", "direct manipul", "interact techniqu"]}
{"doc": "Multimodal interaction combines input from multiple sensors such as pointing devices or speech recognition systems , in order to achieve more fluid and natural interaction . Two-handed interaction has been used recently to enrich graphical interaction . Building applications that use such combined interaction requires new software techniques and frameworks . Using additional devices means that user interface toolkits must be more flexible with regard to input devices and event types . The possibility of parallel interactions must also be taken into account , with consequences on the structure of toolkits . Finally , frameworks must be provided for the combination of events and status of several devices . This paper reports on the extensions we made to the direct manipulation interface toolkit Whizz in order to experiment two-handed interaction . These extensions range from structural adaptations of the toolkit to new techniques for specifying the time-dependent fusion of events . INTRODUCTION Though many aspects of their construction are still a matter of research , graphical interfaces are now well known . Most of them make use of a pointing device that users manipulate with their dominant hand . This has led to the introduction of a number of interaction styles centered around that pointing device: buttons , menus , point-and-click , drag-and-drop , and so on . Such interaction styles enable interface designers to build systems that are fairly efficient and easy to use . However , the efficiency of such interfaces can probably be improved . In the real world, we perform many tasks with both hands , because it is more efficient . Because of these natural skills , drawing pictures with a MacDraw-like tool is sometimes frustrating: a significant part of the time is spent in moving the mouse around to select tools , locking objects so that they do not move when working on them , and so on . This is very similar to handcrafting with one's hand behind one's back: tools make it possible , but at the cost of a considerable waste of time . When considering graphical software , it is interesting to note that keyboard short-cuts are a way for us to use our non-dominant hand when drawing , and to avoid unnecessary movements with the dominant one . A recent study shows that carefully designed two-handed graphical interaction can improve the efficiency of interfaces 11 . Apart from drawing tools , a number of application domains could benefit from such interfaces. Among these are the domains where users are well-trained professionals , whose attention is focused on the task they are performing . We believe that air-traffic control is a good example of such a domain . The interfaces provided to air-traffic controllers essentially consist of a presentation of the situation in air-space: it is the so-called \"radar image\" , which is composed of maps and a number of symbols representing way-points , aircraft , and other useful information. Many countries are currently working on new interfaces that allow controllers to manipulate these representations with modern interaction techniques . At CENA", "label": ["interaction styles", "graphical toolkit", "direct manipulation", "two-handed interaction", "multimodal interaction"], "stemmed_label": ["interact style", "graphic toolkit", "direct manipul", "two-hand interact", "multimod interact"]}
{"doc": "Array and pointer references are often ambiguous in that compile time analysis cannot always determine if distinct references are to the same object . Ambiguously aliased objects are not allocated to registers by conventional compilers due to the cost of the loads and stores required to keep register copies consistent with memory and each other . There are several hardware and software strategies that can be used to solve the ambiguous alias problem: we have implemented one such scheme called CRegs in a compiler and instruction level simulator . We present a modification to Briggs' Optimistic Coloring Algorithm that allows us to allocate local and parameter arrays to CRegs . The CRegs register file operation and instruction set modifications required to implement this scheme are discussed . Underlying hardware issues such as pipeline impact and chip area are briefly discussed . Several benchmarks are compared in terms of dynamic instructions executed for two CReg set sizes . The measured reduction in memory operations is significant , averaging 23% for the benchmarks shown . Introduction In most programs , memory references are a significant fraction of both the total number of instructions executed and the total run time . A recent study of the SPEC benchmark suite showed that an average of one-third of the dynamic instructions executed were loads and stores BYP91 . In this paper , we show how a simple hardware scheme combined with small changes to current compiler technology can improve performance by reducing memory traffic . We show how these techniques can be cleanly integrated into a current instruction set architecture and implementation , retaining object-code compatibility while providing a register file to which aliased objects can be efficiently allocated. An ambiguous alias occurs when two names may or may not refer to the same memory location. In the example shown in Figure 1 , if the relationship between i and j is not known at compile time or varies (denoted i ? j) , the references may depend on each other and the load in line 3 is required . If the relationship between i and j can be determined a load can be load r2/a i load r2/a i load r2/a i store a j /r3 store a j /r3 store a j /r3 load r4/a i use r2 use r3 Figure 1: Ambiguous Alias Example eliminated because a i can be allocated to a register . In general , ambiguously aliased objects are not allocated to the register file because of the loads and stores required to maintain correctness. CRegs is a hardware scheme that performs a run time consistency check of effective addresses 1 , in this manner aliases are detected and values are propagated to ambiguously aliased objects in other CRegs DiC88 . With CReg hardware maintaining addresses in the register file , the compiler can allocate pointer values and arrays to CRegs safely without fear of using stale data , reaping the benefits of fast local memory for these objects . A performance gain is expected due to the associated reduction in", "label": ["cregs", "register allocation", "ambiguous alias", "live range", "graph coloring"], "stemmed_label": ["creg", "regist alloc", "ambigu alia", "live rang", "graph color"]}
{"doc": "Numerical applications frequently contain nested loop structures that process large arrays of data . The execution of these loop structures often produces memory reference patterns that poorly utilize data caches . Limited associativity and cache capacity result in cache conflict misses . Also , non-unit stride access patterns can cause low utilization of cache lines . Data copying has been proposed and investigated in order to reduce cache conflict misses , but this technique has a high execution overhead since it performs the copy operations entirely in software.We propose a combined hardware and software technique called data relocation and prefetching which eliminates much of the overhead of data copying through the use of special hardware . Furthermore , by relocating the data while performing software prefetching , the overhead of copying the data can be reduced further . Experimental results for data relocation and prefetching are encouraging and show a large improvement in cache performance . Introduction Numerical applications frequently contain nested loop structures that process large arrays . The execution of these loop structures has been shown to produce memory preference patterns that poorly utilize data caches 3 4 . The first of three problems involves an insufficient capacity of the cache: The data accessed by each loop may exceed the cache size , resulting in cache misses . Limited associativity of the cache presents a second problem: accesses to different arrays , or even to different elements of a single array , may conflict. The final problem involves non-unit stride access patterns that can cause low utilization of cache lines and wasted bus and memory cycles 5 . Potentially , one could use a larger cache size and higher cache associativity to eliminate cache capacity misses and cache conflict misses . This brute force approach , however , does not scale well with the rapidly increasing amount of data used in sophisticated numerical applications . Moreover , it would result in significant hardware cost and increased cache access latency , both of which could be avoided via the more cost-effective approach proposed in this paper. The use of blocking transformations could reduce the working-set size of of data accessed in loop nests 4 1 6 . By reordering the execution of iterations , blocking transformations reduce the amount of data referenced between two references to the same data . Once the data accessed between two references to the same data is reduced to an amount smaller than the cache size , capacity misses are eliminated . In practice , however , blocking transformations may not reduce cache misses because of cache mapping conflicts. Additionally , blocking alone does not reduce the working-set size of data accessed in single loops since the data accesses are not reordered. Data prefetching has also been proposed to reduce cache misses by fetching data into the cache before it is referenced 7 8 . When used in conjunction with small cache-block sizes , one can potentially eliminate the problem of low utilization of cache blocks and wasted bus cycles 5 . However , data prefetching", "label": ["cache conflicts", "data relocation", "software prefetching", "program optimization", "data copying"], "stemmed_label": ["cach conflict", "data reloc", "softwar prefetch", "program optim", "data copi"]}
{"doc": "This paper explores a novel way to incorporate hardware-programmable resources into a processor microarchitecture to improve the performance of general-purpose applications . Through a coupling of compile-time analysis routines and hardware synthesis tools , we automatically configure a given set of the hardware-programmable functional units (PFUs) and thus augment the base instruction set architecture so that it better meets the instruction set needs of each application . We refer to this new class of general-purpose computers as PRogrammable Instruction Set Computers (PRISC) . Although similar in concept , the PRISC approach differs from dynamically programmable microcode because in PRISC we define entirely-new primitive datapath operations . In this paper , we concentrate on the microarchitectural design of the simplest form of PRISCa RISC microprocessor with a single PFU that only evaluates combinational functions . We briefly discuss the operating system and the programming language compilation techniques that are needed to successfully build PRISC and , we present performance results from a proof-of-concept study . With the inclusion of a single 32-bit-wide PFU whose hardware cost is less than that of a 1 kilobyte SRAM , our study shows a 22% improvement in processor performance on the SPECint92 benchmarks . Introduction A number of studies have shown that the use of hardware-pro- grammable logic , such as FPGAs , can improve application performance by tailoring hardware paths to match the particular characteristics of the individual application 4,5,6,17 . Overall , the architectures in these studies only work well for special-purpose domains such as logic simulation and large number multiplication. To effectively use hardware-programmable resources in general-purpose environment , we must develop a new approach that is cost-effective , automatic , and applicable to the vast majority of applications. Our architectural approach to achieve these goals is called PRogrammable Instruction Set Computers (PRISC) . To be cost effec- tive , we implement PRISC on top of an existing high-performance processor microarchitecture . For this paper , we use a RISC architecture as our base , though our PRISC techniques are equally applicable to a CISC architecture . PRISC augments the conventional set of RISC instructions with application-specific instructions that are implemented in hardware-programmable functional units (PFUs) . These PFUs are carefully added to the microarchitecture so we maintain the benefits of high-performance RISC techniques (e.g . fixed instruction formats) and we minimally impact the processor's cycle time. To generate these application-specific PFU instructions in an automated fashion , we have developed compilation routines that analyze the hardware complexity of individual instructions . Using this information , the compiler interacts with sophisticated logic synthesis programs to select sequences of instructions that will execute faster if implemented in PFU hardware . Since the PFU instruction generation process is driven by the specific computations found in each application , our PRISC approach avoids the semantics gap problems of CISC architectures 14 . Furthermore , the complexity of our approach is completely hidden from the user/programmer. The most general computational model for a PFU is a multi-cycle sequential state machine . Iterative hardware solutions for square-root or transcendental", "label": ["compile-time optimization", "general-purpose microarchitectures", "logic synthesis", "automatic instruction set design", "programmable logic"], "stemmed_label": ["compile-tim optim", "general-purpos microarchitectur", "logic synthesi", "automat instruct set design", "programm logic"]}
{"doc": "We propose a new navigation paradigm based on a spatial metaphor to help users access and navigate within large sets of documents . This metaphor is implemented by a computer artifact called an Interactive Dynamic Map (IDM) . An IDM plays a role similar to the role of a real map with respect to physical space . Two types of IDMs are computed from the documents: Topic IDMs represent the semantic contents of a set of documents while Document IDMs visualize a subset of documents such as those resulting from a query . IDMs can be used for navigating , browsing , and querying . They can be made active , they can be customized and they can be shared among users . The article presents the SHADOCS document retrieval system and describes the role , use and generation of IDMs in SHADOCS . INTRODUCTION According to many authors , disorientation is a major problem in hypertext systems: -The biggest problem in hypertext , which most of us admit in footnotes toward the end of papers extolling the virtues of our systems , is of getting lost.- Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copyright is by permission of the Association for Computing Machinery . To copy otherwise , or to republish, requires a fee and/or specific permission. One reason for getting lost in a hypertext system is the large quantity of information that is accessible . Another reason is the complexity of the graph that links the different documents . One can get lost in a small hypertext system if the number of links is large. In the results of a user study , Nielsen90 reports : -56% of the users agreed fully or partly with the statement: when reading the report I was often confused about where I was . 44% agreed with the statement: when reading the report I was often confused about how to get back where I came from.- In this paper , we propose a new paradigm based on a spatial metaphor to help users access and navigate within large sets of documents . We use an Interactive Dynamic Map (IDM) to implement this metaphor . Just as a real map is a concise , abstract representation of a large territory , an IDM is a concise , abstract representation of a large set of documents . Real maps take advantage of the ability of the human brain to memorize and manage spatial information . Similarly , we expect IDMs to facilitate the navigation in a large set of documents and reduce the \"lost in hyperspace\" syndrome. The paper is organized as follows . We first describe previous work on this topic . We then present the rationale for our approach , give an overview of the prototype system we are developing and describe the various", "label": ["visualization", "navigation", "information retrieval", "interaction paradigm"], "stemmed_label": ["visual", "navig", "inform retriev", "interact paradigm"]}
{"doc": "In semantically rich hypertexts it is attractive to enable presentation of a network of nodes and link at different levels of abstraction . It is also important that the user can interact with the hypertext using a command repertoire that reflects the chosen abstraction level . Based on a characterization of rich hypertext we introduce the concept of an interaction engine that governs the separation between internal hypertext representation and external screen presentation . This separation is the key principle of the HyperPro system . The HyperPro interaction engine is based on simple rules for presentation , interpretation of events , and menu set up . Much of the power of the interaction engine framework comes from the organization of these rules relative to the type of hierarchy of nodes and links , and relative to a hierarchy of so-called interaction schemes . The primary application domain discussed in the paper is program development and program documentation . Introduction The topic of this paper is development of interaction techniques on hypertexts that represent information from regular and structured domains . Our primary interest is hypertexts which represent source programs , program documentation, and similar information captured during program development or maintenance . However , the interaction techniques we have developed are of interest to developers of a much broader set of hypertexts , which we will call \"rich hyper- texts\". In rich hypertexts all the nodes have types . The type of a node may reflect its role in the hypertext , e.g . its syntactic Department of Mathematics and Computer Science , Fredrik Bajers Vej 7E , 9220 Aalborg , Denmark . (Internet: kasper@iesd.auc.dk and nor- mark@iesd.auc.dk) . This research was supported in part by the Danish Natural Science Research Council , No . 11-0061. category . The nodes in rich hypertexts are connected by typed links . In many application domains it may in addition be important to ensure that a rich hypertext obeys a set of topological constraints . A structure may be imposed on the contents of nodes as well . Thus , the \"richness\" stems from the typing of both nodes and links and from the degree of structuring at the microscopic level 1 (inside nodes and links) as well as at the macroscopic level (among nodes and links). Rich hypertexts may appear in a variety of different application domains . One such domain is engineering as discussed by Malcolm et al . in 14 , and illustrated by the systems Dynamic Design 1 , Ishys 8 , and the present paper . Another domain is structured argumentation , as represented by gIBIS 4 , Authors Argumentation Assistant 22 , and AquaNet 15 . In 16 Nanard and Nanard use the term rich hypertext structure model to cover essentially the same notion. In most hypertext systems it is satisfactory to show only one node in one window . In our work , however , we emphasize the creation of coherent , textual views on several nodes and links . Such views typically consist of aggregation of text", "label": ["program development", "event control", "interaction engine", "tailorability", "aggregated views"], "stemmed_label": ["program develop", "event control", "interact engin", "tailor", "aggreg view"]}
{"doc": "The correct and timely creation of systems for coordination of group work depends on the ability to express , analyze , and experiment with protocols for managing multiple work threads . We present an evolution of the Trellis model that provides a formal basis for prototyping the coordination structure of a collaboration system . In Trellis , group interaction protocols are represented separately from the interface processes that use them for coordination . Protocols are interpreted (rather than compiled into applications) so group interactions can be changed as a collaborative task progresses . Changes can be made either by a person editing the protocol specification on the fly or by a silent observation process that participates in an application solely to perform behavioral adaptations.Trellis uniquely mixes hypermedia browsing with collaboration support . We term this combination a hyperprogram , and we say that a hyperprogram integrates the description of a collaborative task with the information required for that task . As illustration , we describe a protocol for a moderated meeting and show a Trellis prototype conference tool controlled by this protocol . protocol for a moderated meeting and show a Trellis prototype conference tool controlled by this protocol. This work is partially supported by the National Science Foundation under grant numbers IRI-9007746 , IRI- 9015439 , and IRI-9496187 , by the Software Engineering Research Center (University of Florida and Purdue Uni- versity) , and by the Texas Advanced Research Program under Grant No . 999903-155. (copyright notice here) We present a technology , collectively called Trellis , for modeling , and analysis of coordination structures , and for prototyping CSCW system based on such coordination structures . Our method separates the collaboration protocol guiding the behavior of a CSCW system out from the code for the system implementation . The collaboration protocol is interpreted and serves as a central information engine in a CSCW system. Some CSCW systems already provide \"parameterized\" access to the underlying protocol . For example , the Suite system 2 allows users to set and change the granularity of text exchange , from character level up to paragraph level . Our approach takes this ability to customize a protocol a step further , allowing dynamic alteration of any aspect of a protocol , even aspects that system designers do not (or cannot) anticipate . This capability is useful for very long-lived interactions , ones in which the nature of the shared tasks might evolve based on the outcomes of earlier actions or decisions. It is difficult to anticipate in detail all the behaviors of CSCW systems , especially when parallel activities are involved . Our method of separating out the protocol and expressing it in a form different from the code gives support for examining formally and informally the interaction of parallel tasks and concurrent users . The graphical notation of a network is no more difficult to understand than direct code , and some researchers in visual languages have found that graphical notations enhance human ability to understand parallel computation threads . We exploit this informal", "label": ["dynamic protocol", "coordination structure", "formal methods", "moderated meeting", "process-based hypertext/hypermedia", "colored petri net", "trellis"], "stemmed_label": ["dynam protocol", "coordin structur", "formal method", "moder meet", "process-bas hypertext/hypermedia", "color petri net", "trelli"]}
{"doc": "The need to merge different versions of an object to a common state arises in collaborative computing due to several reasons including optimistic concurrency control , asynchronous coupling , and absence of access control . We have developed a flexible object merging framework that allows definition of the merge policy based on the particular application and the context of the collaborative activity . It performs automatic , semi-automatic , and interactive merges , supports semantics-determined merges , operates on objects with arbitrary structure and semantics , and allows fine-grained specification of merge policies . It is based on an existing collaborative applications framework and consists of a merge matrix , which defines merge functions and their parameters and allows definition of multiple merge policies , and a merge algorithm , which performs the merge based on the results computed by the merge functions . In conjunction with our framework we introduce a set of merge policies for several useful kinds of merges we have identified . This paper motivates the need for a general approach to merging , identifies some important merging issues , surveys previous research in merging , identifies a list of merge requirements , describes our merging framework and illustrates it with examples , and evaluates the framework with respect to the requirements and other research efforts in merging objects . INTRODUCTION In the course of collaboratively producing a document or some other artifact , collaborators often find that they have created two versions , each containing revisions that they wish to have in a single version . It then becomes a task to take the set of revisions from one version and re-apply them to the other version of the object . A tool that points out the differences between the versions may be employed to ease the task,if such a tool is available , but merging the versions remains essentially a manual process . This situation is objectionable on two counts: first , the needed differencing tools may be unsatisfactory or unavailable , and second , the process of re-applying one set of changes to an object to another version of the object is error-prone and time-consuming . A tool that performs the merge automatically , responding appropriately to conflicting changes , would be highly useful. A number of merge tools already exist . Tools for merging plain-text files include the UNIX diff3 tool , the RCS rcsmerge tool 11 , and the fileresolve tool in Sun's Network Software Environment 1 . Research efforts include the work of Horwitz , Prins , and Reps with a program merging tool that detects an inconsistent merge through the use of program dependency graphs 6 , and the GINA collaborative application framework 2 , which allows users to merge revised versions by merging command histories . Work related to object merging includes the PREP flexible diff tool 9 , which gives users flexibility in finding and pinpointing differences, and the concurrency control model of Ellis and Gibbs 4 , which determines a consistent ordering of operations at all sites in", "label": ["optimistic concurrency control", "merging", "flexible coupling", "versions"], "stemmed_label": ["optimist concurr control", "merg", "flexibl coupl", "version"]}
{"doc": "Computer technology is available to build video-based tools for supporting presentations to distributed audiences , but it is unclear how such an environment affects participants' ability to interact and to learn . We built and tested a tool called Forum that broadcasts live audio , video and slides from a speaker , and enables audiences to interact with the speaker and other audience members in a variety of ways . The challenge was to enable effective interactions while overcoming obstacles introduced by the distributed nature of the environment , the large size of the group , and the asymmetric roles of the participants . Forum was most successful in enabling effective presentations in cases when the topic sparked a great deal of audience participation or when the purpose of the talk was mostly informational and did not require a great deal of interaction . We are exploring ways to enhance Forum to expand the effectiveness of this technology . INTRODUCTION Over the last few years , the multimedia community has been exploring ways to use distributed , interactive audio and video . Point-to-point desktop video conferencing and multi-way \"video spaces\" are two of the applications that have received attention Bly , et . al. , 1993; Tang and Isaacs , 1993; Root , 1988 . Another obvious application is to enable people to broadcast live presentations to audiences that are distributed across many locations. There has been a growing interest in such one-to-many technology . Politicians have recently made popular the idea of an \"electronic town hall\" meeting in which voters all around a nation could not only watch but also interact with policy makers . And at a time when many institutions are struggling with budget cuts , both universities and companies have shown interest in providing live training over a computer network . By broadcasting courses , schools can reach a wider set of potential students and companies can train more of their work force while reducing travel costs. The distance learning industry has been using technologies that provide one-to-many communication for quite some time . The Open University , for example , has been airing courses over British television for many years, and , more recently , such programs as Stanford Univer- sity's Instructional Television Network and the Chicago College have enabled remote students to not only watch but also phone in questions to the speaker Gib- bons , et . al. , 1977 . These environments , although quite successful , represent only a step toward supporting fully interactive presentations . What they lack is a rich channel for audiences to interact with speakers and with each other . Although the phone does provide some audience- to-speaker communication , it is a cumbersome mechanism that does not allow for quick , spontaneous questions and discussion . It also does not support audience- to-audience interaction . With the development of technology to support distributed video and audio over existing computer networks , we are now in a better position to support more fully interactive presentations. One might question how", "label": ["remote collaboration", "multimedia", "distance learning", "distributed presentations", "user interface design", "broadcast video"], "stemmed_label": ["remot collabor", "multimedia", "distanc learn", "distribut present", "user interfac design", "broadcast video"]}
{"doc": "The chaining problem is defined as follows . Given values The chaining problem appears as a subproblem in many contexts . There are known algorithms that solve the chaining problem on CRCW PRAMs in $O(\\alpha(n))$ time , where $\\alpha(n)$ is the inverse of Ackerman's function , and is a very slowly growing function . The author studies a class of algorithms (called oblivious algorithms) for this problem . A simple oblivious chaining algorithm running in $O(\\alpha(n))$ time is presented . More importantly , the optimality of the algorithm is demonstrated by showing a matching lower bound for oblivious algorithms using $n$ processors . The first steps toward a lower bound for all chaining algorithms are also provided by showing that any chaining algorithm that runs in two steps must use a superlinear number of processors . The proofs use prefix graphs and weak superconcentrators . An interesting connection between the two is demonstrated and this idea is used to obtain improved bounds on the size of prefix graphs . Introduction Consider the following problem called chaining . Given values a 1 ; :::; an ; a ig . (Define The output can be viewed as pointers that chain the 1's into a linked list . The chaining problem is a natural problem to consider in the context of database retreival operations; all the records that satisfy a particular predicate correspond to the input bits that have value 1 . Chaining the 1's then corresponds to making a linked list of these records for future processing . Apart from this it appears as a subproblem in many contexts and has been studied before in 16 , 17 . Parallel integer sorting 2 , 14 , parallel merging of integers drawn from a restricted domain 3 , parallel subset compaction 18 , 13 , 16 and circuits for computing threshold functions 15 are examples . It is easy to solve the problem in O(n) time using one processor . Using processors , very fast parallel algorithms exist , with running times close to constant . For this reason, and because of its simplicity , it is an open question of theoretical interest 3 , 16 , 17 whether constant time parallel algorithms exist. Berkman and Vishkin 4 and independently , Ragde 16 have given parallel algorithms that solve the chaining problem in O(ff(n)) time using n processors , where ff(n) is the inverse of Ackerman's function, and is a very slowly growing function . Using algorithms similar to the chaining algorithm , Berkman and Vishkin 5 give algorithms achieving the same bounds for other problems : the lowest-common-ancestor problem and a parenthesis matching problem. We study oblivious algorithms for the chaining problem . Informally , an oblivious algorithm is one in which the pattern of memory access depends only on n (the size of the problem) , and not on the specific input . This class of algorithms is of interest because the algorithms of Berkman and Vishkin and Ragde can be modified to be oblivious . We present a simple oblivious algorithm for", "label": ["ackerman's function", "parallel", "superconcentrators", "lower bound", "prefix graphs", "chaining"], "stemmed_label": ["ackerman' function", "parallel", "superconcentr", "lower bound", "prefix graph", "chain"]}
{"doc": "Managing tradeoffs between program structure and program efficiency is one of the most difficult problems facing software engineers . Decomposing programs into abstractions simplifies the construction and maintenance of software and results in fewer errors . However , the introduction of these abstractions often introduces significant inefficiencies.This paper describes a strategy for eliminating many of these inefficiencies . It is based upon providing alternative implementations of the same abstraction , and using information contained in formal specifications to allow a compiler to choose the appropriate one . The strategy has been implemented in a prototype compiler that incorporates theorem proving technology . INTRODUCTION Many approaches to programming emphasize the use of specifications of interfaces . The basic idea is to achieve a separation of concerns . The client of an interface looks at the specification and writes code that uses the inter- He need not concern himself with how the specified behavior is achieved . The implementor's job is to provide an implementation that satisfies the specification and is efficient in the contexts in which it is used . In practice what often happens is that the first implementation proves unacceptably inefficient and must be tuned . Changing the implementation may necessitate re-compiling the client , but the client source code should not have to be changed. Unfortunately , what often occurs in practice is that achieving the desired efficiency requires changing the inter- Supported in part by the Advanced Research Projects Agency of the Department of Defense , monitored by the Office of Naval Research Research under contract N00014-92-J-1795 , and in part by the National Science Foundation under grant 9115797-CCR . Authors' address: MIT Lab for Computer Science , 545 Technology Square, Cambridge , MA 02139 . Internet: fmtv,guttagg@lcs.mit.edu Appeared in Proceedings of the 1994 ACM/SIGSOFT Foundations of Software Engineering Conference. Map-Define (Map *m , Dom d , Ran r) Modifies: *m Ensures: Defines r as the image of d in *m . If d is already defined in *m , changes the image of d to r. Ran Map-Lookup (Map *m , Dom d) Modifies nothing. Ensures: If d is undefined in *m , returns NULL-RAN. Otherwise , returns the image of d in *m. Figure 1: Interface for Maps if (r == NULL-RAN) - Map Figure 2: An Opportunity to Optimize Map Define then all bets about the client code are off . Consider the following scenario . Suppose that the specifications in Figure are implemented by an unsorted list of do- main/range pairs with the invariant that no domain element appears more than once . To maintain this invariant , the implementation of Map Define must , at each invocation, search the list to find out if domain element being defined is already there . If clients of map have code that looks like that in Figure 2 , they will run unnecessarily slowly , because time will be spent in the implementation of Map Define checking if a domain element is in the list-when the calling context guarantees that it isn't. One conventional solution to this", "label": ["compilers", "program optimization", "program modularity", "formal specifications", "software interfaces"], "stemmed_label": ["compil", "program optim", "program modular", "formal specif", "softwar interfac"]}
{"doc": "Tapeworm II is a software-based simulation tool that evaluates the cache and TLB performance of multiple-task and operating system intensive workloads . Tapeworm resides in an OS kernel and causes a host machine's hardware to drive simulations with kernel traps instead of with address traces , as is conventionally done . This allows Tapeworm to quickly and accurately capture complete memory referencing behavior with a limited degradation in overall system performance . This paper compares trap-driven simulation , as implemented in Tapeworm , with the more common technique of trace-driven memory simulation with respect to speed , accuracy , portability and flexibility . Introduction Trace-driven simulation is probably the most popular method for evaluating memory system architectures consisting of caches and TLBs Smith82 , Holliday91 . This technique has worked well in the design of memory systems supporting single-task , user- intensive applications such as those found in the SPEC benchmark suite Gee93 , SPEC91 . However , there is a growing body of work showing that memory systems tuned to this type of work- Trap-driven Simulation with Tapeworm II Richard Uhlig , David Nagle , Trevor Mudge & Stuart Sechrest Department of Electrical Engineering and Computer Science University of Michigan e-mail: uhlig@eecs.umich.edu , bassoon@eecs.umich.edu This work was supported by Defense Advanced Research Projects Agency under DARPA/ARO Contract Number DAAL03-90-C-0028 , by a National Science Foundation CISE Research Instrumentation Grant No . CDA- 9121887 , by a Digital Equipment Corporation Grant , and by a National Science Foundation Graduate Fellowship. load do not perform as well on interactive and digital-media appli- cations , or with distributed file systems and databases , all of which require frequent interaction with the operating system or other tasks Agarwal88 , Anderson91 , Chen93a , Cvetanovic94 , Mogul91, Nagle93 , Nagle94 , Uhlig94b , Ousterhout89 . Unfortunately , most trace-driven simulation tools are limited to single user-mode tasks and thus cannot capture a significant portion of the memory system activity of these applications . Those trace-driven simulators that are OS-capable tend to rely on expensive hardware monitoring equipment and are generally not very portable. We have developed a software-based tool , called Tapeworm II, that attempts to overcome some of these limitations . Tapeworm simulations are driven not by traces , but by traps into the operating system kernel where Tapeworm resides . Each kernel trap corresponds to a simulated TLB or cache miss . This approach has three principal advantages: (1) Completeness , (2) Speed and (3) Portabil- ity . Tapeworm simulations are complete because traps can originate from any user task , or even the OS kernel itself . Tapeworm is fast because the simulator is invoked only in the uncommon case of TLB or cache misses . Finally , because Tapeworm is software- based , it can be ported to any system that provides support for certain primitives. Despite these advantages , this method does suffer from certain drawbacks . Although capable of simulating TLBs and caches with different sizes and associativities , trap-driven simulation is generally less flexible than trace-driven approaches with respect", "label": ["trap-driven simulation", "trace-driven simulation", "cache", "tlb", "memory system"], "stemmed_label": ["trap-driven simul", "trace-driven simul", "cach", "tlb", "memori system"]}
{"doc": "Several researchers have proposed algorithms for basic block reordering . We call these branch alignment algorithms . The primary emphasis of these algorithms has been on improving instruction cache locality , and the few studies concerned with branch prediction reported small or minimal improvements . As wide-issue architectures become increasingly popular the importance of reducing branch costs will increase , and branch alignment is one mechanism which can effectively reduce these costs.In this paper , we propose an improved branch alignment algorithm that takes into consideration the architectural cost model and the branch prediction architecture when performing the basic block reordering . We show that branch alignment algorithms can improve a broad range of static and dynamic branch prediction architectures . We also show that a program performance can be improved by approximately 5% even when using recently proposed , highly accurate branch prediction architectures . The programs are compiled by any existing compiler and then transformed via binary transformations . When implementing these algorithms on a Alpha AXP 21604 up to a 16% reduction in total execution time is achieved . Introduction Conventional processor architectures , particularly modern super-scalar designs , are extremely sensitive to control flow changes. Changes in control flow , be they conditional or unconditional branches , direct or indirect function calls or returns , are not detected until those instructions are decoded . To keep the pipeline fully utilized , processors typically fetch the address following the To appear in the 6th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS-VI) , San Jose , California. October 1994. most recent address . If the decoded instruction breaks the control flow , the previously fetched instruction can not be used , and a new instruction must be fetched , introducing a \"pipeline bubble\" or unused pipeline step . This is called an instruction misfetch penalty. The final destination for conditional branches , indirect function calls and returns are typically not available until a latter stage of the pipeline . At this point the branch has been completely eval- uated . The processor may elect to fetch and decode instructions on the assumption that the eventual branch target can be accurately predicted . If the processor mispredicts the branch destination , the instructions fetched from the incorrect instruction stream must be discarded , leading to several \"pipeline bubbles\" and causing a mispredict penalty . In practice , pipeline bubbles due to mispredicted breaks in control flow degrade a programs performance more than the misfetch penalty . For example , the combined branch mispredict penalty for the Digital Alpha AXP 21064 processor is ten instructions . By comparison , the AXP 21064 would lose only two instructions from instruction misfetches. Almost all modern architectures use some form of branch pre- diction , and reducing the number of misfetch and misprediction penalties will be increasingly important for wide-issue architec- tures . In this paper , we examine algorithms that reorder the structure of a program to improve the accuracy of the branch fetch and prediction architectures . Our", "label": ["profile-based optimization", "trace scheduling", "branch target buffers", "branch prediction"], "stemmed_label": ["profile-bas optim", "trace schedul", "branch target buffer", "branch predict"]}
{"doc": "An articulated figure is often modeled as a set of rigid segments connected with joints . Its configuration can be altered by varying the joint angles . Although it is straight forward to compute figure configurations given joint angles (forward kinematics) , it is more difficult to find the joint angles for a desired configuration (inverse kinematics) . Since the inverse kinematics problem is of special importance to an animator wishing to set a figure to a posture satisfying a set of positioning constraints , researchers have proposed several different approaches . However , when we try to follow these approaches in an interactive animation system where the object on which to operate is as highly articulated as a realistic human figure , they fail in either generality or performance . So , we approach this problem through nonlinear programming techniques . It has been successfully used since 1988 in the spatial constraint system within Jack , a human figure simulation system developed at the University of Pennsylvania , and proves to be satisfactorily efficient , controllable , and robust . A spatial constraint in our system involves two parts: one constraint on the figure , the end-effector , and one on the spatial environment , the goal . These two parts are dealt with separately , so that we can achieve a neat modular implementation . Constraints can be added one at a time with appropriate weights designating the importance of this constraint relative to the others and are always solved as a group . If physical limits prevent satisfaction of all the constraints , the system stops with the (possibly local) optimal solution for the given weights . Also , the rigidity of each joint angle can be controlled , which is useful for redundant degrees of freedom . Introduction In computer animation , an articulated figure is often modeled as a set of rigid segments connected by joints. A joint is , abstractly , a constraint on the geometric relationship between two adjacent segments . This \"relationship\" is expressed by a number of parameters called joint angles . With judicious selection of joints, so that , e.g. , segments are connected to form a tree structure , a collection of the joint angles of all the joints corresponds one-on-one to a configuration of the figure . While this correspondence provides an immediate computer representation of articulated figure configurations in the sense that given a set of joint angles it is straightforward to compute the corresponding configuration , the problem of finding a set of joint angles that corresponds to a given configuration , the inverse kinematics problem , persists in practice. The inverse kinematics problem , however , is extremely important in computer animation , since it is often the spatial appearance , rather than the joint angles , that an animator is interested in . Naturally , the problem has received attention of many researchers in computer animation , as well as in robotics (see the next section) , but the various algorithms reflect particular aspects of the", "label": ["nonlinear programming", "articulated figures", "inverse kinematics"], "stemmed_label": ["nonlinear program", "articul figur", "invers kinemat"]}
{"doc": "Perturbed nonlinear control problems with data depending on a vector parameter are considered . Using second-order sufficient optimality conditions , it is shown that the optimal solution and the adjoint multipliers are differentiable functions of the parameter . The proof exploits the close connections between solutions of a Riccati differential equation and shooting methods for solving the associated boundary value problem . Solution differentiability provides a firm theoretical basis for numerical feedback schemes that have been developed for computing neighbouring extremals . The results are illustrated by an example that admits two extremal solutions . Second-order sufficient conditions single out one optimal solution for which a sensitivity analysis is carried out . Introduction This paper is concerned with parametric nonlinear control problems where all data depend on a vector parameter 2 IR k . In order to make the main ideas more transparent we restrict the discussion to the following simple prototype: Minimize J(x; u; R a subject to - The problem P (p 0 ) corresponding to a fixed parameter 0 2 IR k is considered as the unperturbed problem . Assume that a local minimum (optimal problem in sensitivity analysis is the following: find conditions for the unperturbed optimal solution x such that the perturbed problem P (p) admits an optimal solution x(p) , u(p) near x 0 , u 0 which is a differentiable function of the parameter near 0 . Comparing sensitivity approaches in optimization and optimal control it is apparent that second-order sufficient optimality conditions (SSCs) are a crucial assumption for this type of sensitivity result . Let us briefly review existing papers in this regard. In finite-dimensional nonlinear programming we have the famous second-order sensitivity result of Fiacco and McCormick 13 , 14 . This basic sensitivity result has been extended under milder assumptions in 15 17 , 18 , 21 , 25 , 26 , 46 , 48 , 49 and by other authors cited in these papers. Semi-infinite programming problems under SSCs are treated by Rupp 47 . A direct generalization of the Fiacco and McCormick result to optimization problems in Hilbert spaces may be found in Wiercbicki and Kurcyusz 52 , Theorem 8.6 . These authors consider optimization problems with equality constraints and finitely many inequality constraints . For Hilbert space optimization problems including infinite-dimensional inequality constraints , Alt 1 and Malanowski 32 have shown that the optimal solution is directionally differentiable with respect to the parameter . These results have recently been extended by Colonius and Kunisch 8 . The setting in Alt 1 and Malanowski 32 allows for applications to convex control problems . A direct treatment of convex control problems with control appearing linearly has been performed earlier by Dontchev 11 and Malanowski 29 - 31 . Elliptic control problems have been considered in Malanowski and Sokolowski 33 . In the framework of nonlinear control problems the second-order sensitivity analysis goes back as far as to the ingenious papers of Breakwell and Ho 4 , Breakwell , Speyer and Bryson 5 and Kelley 19 , 20 . This approach is", "label": ["parametric control problems", "solution differentiability", "feedback controls", "shooting methods", "second-order sufficient conditions"], "stemmed_label": ["parametr control problem", "solut differenti", "feedback control", "shoot method", "second-ord suffici condit"]}
{"doc": "It is shown that indirect pole-zero placement adaptive controllers are robust for systems with time-varying parameters as well as unmodeled dynamics and disturbances . A parameter estimator with projection is used . No special signal normalization is employed to ensure robustness . The nominal system parameters need only be bounded , and their variations need only be small in an average sense . This allows them to vary slowly with time , as well as to take large jumps occasionally . The adaptive controllers can also simultaneously tolerate small unmodeled dynamics , as well as bounded disturbances , with no restriction on the magnitude of the bound . Introduction In 1 , Astrom and Wittenmark have proposed the use of indirect , certainty-equivalent self-tuning controllers based on pole-zero placement for the servo-problem . Thus , if the goal is to enforce a response A (q to a command signal fr k g , then one first estimates system polynomials b A at each time instant k by fitting a model, to the available data fy t ; u kg , at time k . Then , the control input u k is chosen such that, where the polynomials b R k and b S k are obtained by solving the Diophantine equation, at each time instant . To estimate the parameter vector b may use a recursive algorithm of the form where The choice of the \"gain\" matrix I yields a gradient update law . Control schemes of this nature have proven popular in practice , and many successful implementations have been reported; see 2 , 3 , 4 , 5 . Also , the model reference adaptive control method , the backbone of continuous-time adaptive control , is a \"direct\" version of such a pole-zero placement scheme. Often , such adaptive control algorithms are employed to control plants which are subject to time-variations , for which there is consequently an ever present need to adapt to the changing system characteristics . It is therefore important to develop a theory of robustness for such adaptive control algorithms for their use in the face of such system variations , as well as in the presence of uncertainties such as unmodeled dynamics and disturbances. In this paper we consider an indirect adaptive control law , as above , with a parameter estimation scheme employing \"projection\" to keep the parameter estimates confined to a compact convex set. We establish that this simple modification is powerful enough to provide robustness simultaneously with respect to system time-variations , small unmodeled dynamics , and bounded disturbances . In particular , no special signal normalization is used. Some background on the robustness problem for adaptive systems is in order . Much attention has been devoted over the past decade to the robustness problem caused by unmodeled dynamics and bounded disturbances , and an excellent unification of work up till 1988 is provided by Ioannou and Sun 6 . Recently , in an important paper , Ydstie 7 has shown that just the simple mechanism of \"projection,\" which confines the", "label": ["robust performance", "robustness", "adaptive systems", "indirect adaptivecontrol", "unmodeled dynamics", "time-varyingplants", "stability", "disturbances"], "stemmed_label": ["robust perform", "robust", "adapt system", "indirect adaptivecontrol", "unmodel dynam", "time-varyingpl", "stabil", "disturb"]}
{"doc": "The page migration problem is to manage a globally addressed shared memory in a multiprocessor system . Each physical page of memory is located at a given processor , and memory references to that page by other processors incur a cost proportional to the network distance . At times the page may migrate between processors at cost proportional to the distance times $D$ , a page size factor . The problem is to schedule movements on-line so that the total cost of memory references is within a constant factor $c$ of the best off-line schedule . An algorithm that does so is called c-competitive . Black and Sleator gave 3-competitive deterministic on-line algorithms for uniform networks (complete graphs with unit edge lengths) and for trees with arbitrary edge lengths . No good deterministic algorithm is known for general networks with arbitrary edge lengths . Randomized algorithms are presented for the migration problem that are both simple and better than 3-competitive against an oblivious adversary . An algorithm for uniform graphs is given . It is approximately 2.28-competitive as $D$ grows large . A second , more powerful algorithm that works on graphs with arbitrary edge distances is also given . This algorithm is approximately 2.62-competitive (or , 1 plus the golden ratio) for large $D$ . Both these algorithms use random bits only during an initialization phase , and from then on run deterministically . The competitiveness of a very simple coin-flipping algorithm is also examined . Introduction . A common design for a shared memory multiprocessor system is a network of processors , each of which has its own local memory 9 , 14 , 19 . In such a design , a programming abstraction of a single global memory address space is supported by a virtual memory system that distributes one or more copies of each physical page of memory among the processors' local memories . When processor wishes to read or write to memory address a , located in page b , it first looks to see if page b is contained in its own local memory . If so , then the memory access is done immediately . If not , determines some processor q that does hold page b, and transmits a memory request to q over the network . The communication cost is dependent on the interconnection distance between and q . Processor q services the request , and transmits back to the (updated) value at address a. Having a given virtual page stored at multiple processors reduces communication overhead during memory reads , but introduces the problem of maintaining consistency among the multiple copies during writes . Most multiprocessors do not provide mechanisms for maintaining consistency 5 . Therefore , various network designers have studied the page migration problem 4 , 5 , 17 , which arises when each writeable page is restricted to a single copy . Suppose the single copy of page b is initially located at processor q . If the page is going to be accessed frequently by processor p, then", "label": ["multiprocessors", "page migration", "competitive analysis", "memory management", "on-line algorithms"], "stemmed_label": ["multiprocessor", "page migrat", "competit analysi", "memori manag", "on-lin algorithm"]}
{"doc": "Many data-parallel algorithmsFast Fourier Transform , Batcher's sorting schemes , and the prefix-sumexhibit recursive structure . We propose a data structure called powerlist that permits succinct descriptions of such algorithms , highlighting the roles of both parallelism and recursion . Simple algebraic properties of this data structure can be explotied to derive properties of these algorithms and to establish equivalence of different algorithms that solve the same problem . Program under Grant No . 003658-219 and by the National Science Foundation Award CCR- 9111912. 1 A notable exception is the recursive description of a prefix sum algorithm in Karp and Ramachandran 12 . A data structure , powerlist , is proposed in this paper that highlights the role of both parallelism and recursion . Many of the known parallel algorithms- FFT , Batcher Merge , Prefix Sum , embedding arrays in hypercubes , etc.-have surprisingly concise descriptions using powerlists . Simple algebraic properties of powerlists permit us to deduce properties of these algorithms employing structural induction. Powerlist The basic data structure on which recursion is employed (in LISP 16 or ML 17 ) is a list . A list is either empty or it is constructed by concatenating an element to a list . (We restrict ourselves to finite lists throughout this paper.) We call such a list linear (because the list length grows by 1 as a result of applying the basic constructor) . Such a list structure seems unsuitable for expressing parallel algorithms succinctly; an algorithm that processes the list elements has to describe how successive elements of the list are processed. We propose powerlist as a data structure that is more suitable for describing parallel algorithms . The base-corresponding to the empty list for the linear case-is a list of one element . (Clearly , there are many bases , depending on the specific element in the list.) A larger powerlist is constructed from the elements of two powerlists of the same length , as described below . Thus , a powerlist is multiplicative in nature; its length doubles by applying the basic constructor. There are two different ways in which powerlists are joined to create a larger powerlist . If p; q are powerlists of the same length then is the powerlist formed by concatenating and q ./ q is the powerlist formed by successively taking alternate items from and q , starting with p. Further , we restrict p; q to contain similar elements (defined in Section 2.1). In the following examples the sequence of elements of a powerlist are enclosed within angular brackets. The operation j is called tie and ./ is zip. 2.1 Definitions A data item from the linear list theory will be called a scalar . (Typical scalars are the items of base types-integer , boolean , etc.-tuples of scalars , functions from scalars to scalars and linear lists of scalars.) Scalars are uninterpreted in our theory . We merely assume that scalars can be checked for type compatibility. We will use several standard operations on scalars for purposes of illustration. Notational Convention:", "label": ["hypercube", "algebra of parallel programs", "prefix sum", "batcher sort", "parallel programs", "recursion", "fast fourier transform"], "stemmed_label": ["hypercub", "algebra of parallel program", "prefix sum", "batcher sort", "parallel program", "recurs", "fast fourier transform"]}
{"doc": "Communication between processors has long been the bottleneck of distributed network computing . However , recent progress in switch-based high-speed Local Area Networks (LANs) may be changing this situation . Asynchronous Transfer Mode (ATM) is one of the most widely-accepted and emerging high-speed network standards which can potentially satisfy the communication needs of distributed network computing . In this paper , we investigate distributed network computing over local ATM networks . We first study the performance characteristics involving end-to-end communication in an environment that includes several types of workstations interconnected via a Fore Systems' ASX-100 ATM Switch . We then compare the communication performance of four different Application Programming Interfaces (APIs) . The four APIs were Fore Systems ATM API , BSD socket programming interface , Sun's Remote Procedure Call (RPC) , and the Parallel Virtual Machine (PVM) message passing library . Each API represents distributed programming at a different communication protocol layer . We evaluate parallel Matrix Multiplication over the local ATM network . The experimental results show that network computing is promising over local ATM networks . Introduction Distributed network computing offers great potential for increasing the amount of computing power and communication resources available to large-scale applications . The distributed environment in which we are interested is a cluster of workstations interconnected by a local area communication network . The combined computational power of a cluster of workstations, connected to a high speed LAN , can be applied to solve a variety of scientific and engineering problems . It is very likely that the combined power of an integrated heterogeneous network of workstations may exceed that of a stand-alone high-performance supercomputer. Since the early 1970s , computers have been interconnected by networks such as Ethernet , Token Ring , etc . The communication bandwidth of such networks is limited to the tens of megabits per second (Mbits/sec) and the bandwidth is shared by all of the computers . The communication resources required by a collection of cooperating distributed processors has often been the bottleneck for network computing , limiting its potential . Even the higher speed Fiber Distributed Data Interface (FDDI) , which provides a bandwidth of 100 Mbits/sec , can be saturated by data traffic between computers . Therefore , one of the design goals for distributed network computing has been to reduce the amount of communication between computers . However, based on the nature of an application , a certain degree of communication between computers may be necessary . Even when the communication channel is not saturated , the relatively long communication delay may degrade overall computing performance. The recent introduction of Asynchronous Transfer Mode (ATM) may change this situation. ATM is an emerging high-speed network technology which may satisfy the communication needs required in many distributed network computing applications . ATM , proposed by international standards organizations , uses small 53 bytes cells to transmit data in multiples of OC-1 rates (51.84 Mbits/sec) . Popular data transfer rates for ATM are OC-3 (155.52 Mbits/sec) and OC-12 (622.08 Mbits/sec) 7 , 10 . ATM was initially developed", "label": ["performance measurement", "asynchronous transfer mode", "application programming interface", "distributed network computing"], "stemmed_label": ["perform measur", "asynchron transfer mode", "applic program interfac", "distribut network comput"]}
{"doc": "AbstractThere are three projective invariants of a set of six points in general position in space . It is well known that these invariants cannot be recovered from one image , however an invariant relationship does exist between space invariants and image invariants . This invariant relationship is first derived for a single image . Then this invariant relationship is used to derive the space invariants , when multiple images are available.This paper establishes that the minimum number of images for computing these invariants is three , and the computation of invariants of six points from three images can have as many as three solutions . Algorithms are presented for computing these invariants in closed form.The accuracy and stability with respect to image noise , selection of the triplets of images and distance between viewing positions are studied both through real and simulated images.Applications of these invariants are also presented . Both the results of Faugeras 1 and Hartley et al . 2 for projective reconstruction and Sturms method 3 for epipolar geometry determination from two uncalibrated images with at least seven points are extended to the case of three uncalibrated images with only six points . Introduction Geometric invariants are playing a more and more important role in machine vision applications . A lot of work for recognition and shape description using invariants has already been reported , for instance cf . the collection book 4 and 5 , 6 , 1 , 7 , 8 , 9 , 10 , 2 , 11 , 12 . Most of the invariants 13 , 14 are derived for planar objects using geometric entities such as points , lines and conics , since in this case , there exists a plane projective transformation between object and image space . Plane projective geometry provides an ideal mathematical tool for describing this . As for general geometric configurations in space , it has been shown that it is not possible to estimate invariants from a single image 15 , except for some constraint geometric configurations 16 . Therefore , one (cf . 17 , 1 , 2 , 11 , 18 ) basically deals with space projective invariants from two images , provided that the epipolar geometry , or the fundamental matrix 19 , 20 of the two images is determined a priori. This paper is concerned with the computation of the invariants of sets of six points in space from three images taken with uncalibrated cameras , assuming that the correspondences between image points are known . The main new results obtained in this paper are that the minimum number of images for computing the invariants of six points is three; and the computation of invariants from three images can have as many as three solutions . All solutions Long Quan is with LIFIA-CNRS-INRIA , 46 , avenue Felix Viallet, 38031 Grenoble , France . E-mail: Long.Quan@imag.fr. are given in closed form . As a consequence of these re- sults , both Sturm's method for epipolar geometry determination and projective reconstruction of Faugeras 1", "label": ["self-calibration", "epipolar geometry", "uncalibrated images", "projective reconstruction", "projective geometry", "this invariant"], "stemmed_label": ["self-calibr", "epipolar geometri", "uncalibr imag", "project reconstruct", "project geometri", "thi invari"]}
{"doc": "AbstractWe develop efficient algorithms for low and intermediate level image processing on the scan line array processor , a SIMD machine consisting of a linear array of cells that processes images in a scan line fashion . For low level processing , we present algorithms for block DFT , block DCT , convolution , template matching , shrinking , and expanding which run in real-time . By real-time , we mean that , if the required processing is based on neighborhoods of size mm , then the output lines are generated at a rate of O(m) operations per line and a latency of O(m) scan lines , which is the best that can be achieved on this model . We also develop an algorithm for median filtering which runs in almost real-time at a cost of O(m$ \\rm log $m) time per scan line and a latency of $ \\bf \\lfloor^ \\underline m _ \\,\\ , 2 \\rfloor $ scan lines . For intermediate level processing , we present optimal algorithms for translation , histogram computation , scaling , and rotation . We also develop efficient algorithms for labelling the connected components and determining the convex hulls of multiple figures which run in O(n$ \\rm log $n) and O(n$ \\rm log $2n) time , respectively . The latter algorithms are significantly simpler and easier to implement than those already reported in the literature for linear arrays . Introduction 1.1 Motivation Real-time image processing and understanding has long been regarded as a particularly demanding problem for computer implementation , both because of the computational complexity and because of the large I/O bandwidth required by most of the tasks involved. Consider , as an example , the I/O bandwidth required to perform real-time HDTV simula- tion . Such a task typically involves the handling of 1K by 1K frames at the rate of 60 frames per second and results in a bandwidth requirement of approximately 500 Mbytes per second for a progressively scanned image . Not surprisingly , such problems generally lie well beyond the capacity of existing sequential processors . Consequently , a great deal of effort has been devoted to developing parallel architectures and algorithms for real-time image processing. The simplest category of the proposed architectures is the two-dimensional array , or mesh. Examples of this class include the MPP 1 , the CLIPP series 2 , the MasPar 3 , the DAP 4 , and the GAPP 5 . The general intent behind these SIMD (Single Instruction Stream, Single Data Stream) machines is that the dimensions of the mesh should match those of the input image , and that the pixels should be assigned to processors so as to maintain the spatial relationships of the image . As a consequence , these machines can perform the local window operations typical of low level image processing with extreme efficiency . Of course , there is a considerable cost usually associated with such a large number of processors. Furthermore , while nearest-neighbor links might make local inter-processor communication quite fast , communication between", "label": ["parallel algorithms", "image processing", "scan line array processors", "video procesor", "linear array", "simd algorithms"], "stemmed_label": ["parallel algorithm", "imag process", "scan line array processor", "video procesor", "linear array", "simd algorithm"]}
{"doc": "AbstractRegion-based image segmentation methods require some criterion for determining when to merge regions . This paper presents a novel approach by introducing a Bayesian probability of homogeneity in a general statistical context . Our approach does not require parameter estimation and is therefore particularly beneficial for cases in which estimation-based methods are most prone to error: when little information is contained in some of the regions and , therefore , parameter estimates are unreliable . We apply this formulation to three distinct parametric model families that have been used in past segmentation schemes: implicit polynomial surfaces , parametric polynomial surfaces , and Gaussian Markov random fields . We present results on a variety of real range and intensity images . Introduction The problem of image segmentation , partitioning an image into a set of homogeneous regions, is a fundamental problem in computer vision . Approaches to the segmentation problem can be grouped into region-based methods , in which image subsets are grouped together when they share some property (e.g. , 26 ); edge-based methods , in which dissimilarity between regions is used to partition the image (e.g. , 9 ); and combined region- and edge-based methods (e.g. , 22 ) . In this paper , we present a new , Bayesian region-based approach to segmentation. A standard approach to region-based segmentation is to characterize region homogeneity using parameterized models . With this approach , two regions are considered to be homogeneous if they can be explained by a single instance of the model , i.e. , if they have a common parameter value. For example , in range image applications , object surfaces are often modeled as being piecewise algebraic (e.g. , 30 ) . The parameters of such a surface are the coefficients of the corresponding polynomial . Two regions are homogeneous , and thus should be merged , if they belong to a single polynomial surface (i.e. , if the coefficients for their corresponding polynomials are the same). In practice , a region's parameters cannot be observed directly , but can only be inferred from the observed data and knowledge of the imaging process . In statistical approaches , this inference is made using Bayes' rule and the conditional density , p(y k ju k ) , which expresses the probability that certain data (or statistics derived from the data) , y k , will be observed , given that region k has the parameter value u k . In typical statistical region merging algorithms (e.g. , 27 ) point estimates in the parameter space are obtained for different regions , and merging decisions are based on the similarity of these estimates . Often the maximum a posteriori (MAP) estimate is used , which is obtained by maximizing p(y k ju k ). An inherent limitation of nearly all estimation-based segmentation methods reported to date is that they do not explicitly represent the uncertainty in the estimated parameter values , and therefore , are prone to error when parameter estimates are poor (one notable exception to this is the work", "label": ["bayes factor", "range images", "statistical image segmentation", "bayesian methods", "markov random field", "texture segmentation", "likelihoods"], "stemmed_label": ["bay factor", "rang imag", "statist imag segment", "bayesian method", "markov random field", "textur segment", "likelihood"]}
{"doc": "A program correctness checker is an algorithm for checking the output of a computation . That is , given a program and an instance on which the program is run , the checker certifies whether the output of the program on that instance is correct . This paper defines the concept of a program checker . It designs program checkers for a few specific and carefully chosen problems in the class FP of functions computable in polynomial time . Problems in FP for which checkers are presented in this paper include Sorting , Matrix Rank and GCD . It also applies methods of modern cryptography , especially the idea of a probabilistic interactive proof , to the design of program checkers for group theoretic computations.Two structural theorems are proven here . One is a characterization of problems that can be checked . The other theorem establishes equivalence classes of problems such that whenever one problem in a class is checkable , all problems in the class are checkable . Introduction In this paper we introduce the concept of a program checker . A program checker for a program P is itself a program C . For any instance I on which program P is run , C is run subsequently . C either certifies that the program P is correct on I or declares P to be buggy. There have been other methods proposed for gaining confidence in the output of programs . For example , program verification 9 seeks to achieve this by proving that a program is correct . Program verification suffers from the problem that it is very hard to prove programs correct . It has also been argued that proofs of correctness of programs do not improve our confidence in their correctness because of the nature of these proofs 13 . For a recent discussion of the role of verification in software development see 3 . In program testing 12 we run the program on test inputs for which the output is known and see if the program output matches the expected output . Testing is a fairly ad hoc technique . There are no general methods for generating test data and no theorems are proven about the behavior of a program that passes the tests. In addition there has been work in the the theoretical computer science community on the concept of helping 27 , 35 which may be regarded as a deterministic version of checking. Program checking is easier to do than verification; it yields mathematical proofs about program behavior unlike testing; it allows coin-tossing , greatly enhancing the power of the checker in comparison to the model of helping above. The ideas in this paper arise from cryptography , probabilistic algorithms , and program testing. Particularly important for this work are the interactive proofs of Goldwasser , Micali and Rackoff 19 and subsequent related work . As will be seen , several of the correctness checkers constructed in this paper use probabilistic interactive proofs as a first step in the design . Equally important for", "label": ["interactive proofs", "program verification", "testing", "program checking", "probabilistic algorithms"], "stemmed_label": ["interact proof", "program verif", "test", "program check", "probabilist algorithm"]}
{"doc": "Recent years have seen a shift in perception of the nature of HCI and interactive systems . As interface work has increasingly become a focus of attention for the social sciences , we have expanded our appreciation of the importance of issues such as work practice , adaptation , and evolution in interactive systems . The reorientation in our view of interactive systems has been accompanied by a call for a new model of design centered around user needs and participation . This article argues that a new process of design is not enough and that the new view necessitates a similar reorientation in the structure of the systems we build . It outlines some requirements for systems that support a deeper conception of interaction and argues that the traditional system design techniques are not suited to creating such systems . Finally , using examples from ongoing work in the design of an open toolkit for collaborative applications , it illustrates how the principles of computational reflection and metaobject protocols can lead us toward a new model based on open abstraction that holds great promise in addressing these issues . Introduction The last ten years or so have seen a remarkable shift in perspectives on the design , evaluation and use of interactive systems . The field of HCI has moved from being a relatively minor component of software engineering to being the focus of attention for researchers from a variety of disciplines , including psychology and social science . Studies and investigations from these perspectives have led to a gradual evolution in our conception of \"the interface\" and of computer-based work in general . As a result , HCI has increasingly come to concern itself not just with the mechanism of the interface , but with a range of related issues concerning the context in which interactive systems are used. 1.1 Studies of Work at the Interface To ground discussion of this new view of interactive systems development , I will discuss three areas of re-search which have informed it: the customisation of interactive systems; their embedding within a social organisation; and the co-adaptation of systems and work practices. 1.1.1 Customisation Customisation and adaptation of computer systems have been studied in a variety of contexts . Trigg et al 1987 studied adaptation in the Notecards hypertext system . They described four aspects of adaptability which could allow a tool to be used in different application areas by users with different working styles. These were: flexibility (providing generic , reusable objects and behaviours); parameterisability (offering a range of alternative behaviours that users could select); integrability (linking with other applications in the environment); and tailorability (allowing users to make changes to the system itself) . Their work showed how an adaptable system could be applied widely , essentially serving as an infrastructure within which a variety of information management applications could be generated. MacLean et al 1990 were also concerned with customisation in the Buttons systems . Buttons are graphical on-screen objects which encapsulate behaviour; they can be incorporated into on-line documents and", "label": ["computational reflection", "collaborative applications", "meta-object protocol", "system architecture", "open implementations"], "stemmed_label": ["comput reflect", "collabor applic", "meta-object protocol", "system architectur", "open implement"]}
{"doc": "An environment for general research into and prototyping of algorithms for reliable constrained and unconstrained global nonlinear optimization and reliable enclosure of all roots of nonlinear systems of equations , with or without inequality constraints , is being developed . This environment should be portable , easy to learn , use , and maintain , and sufficiently fast for some production work . The motivation , design principles , uses , and capabilities for this environment are outlined . The environment includes an interval data type , a symbolic form of automatic differentiation to obtain an internal representation for functions , a special technique to allow conditional branches with operator overloading and interval computations , and generic routines to give interval and noninterval function and derivative information . Some of these generic routines use a special version of the backward mode of automatic differentiation . The package also includes dynamic data structures for exhaustive search algorithms . Introduction , Background , and Motivation Numerous applications benefit from enclosure methods for numerical non-linear analysis . Such methods include rigorous global optimization , both constrained and unconstrained , and rigorous location of all roots to nonlinear systems of equations , with or without side inequality constraints. Global optimization is important in engineering , biological and economic modelling , and other applications; see 7 and 8 . Furthermore , enclosure (i.e . interval) methods , when applicable , not only can provide solutions with certainty , but can also be more efficient than other methods; see 14 or 37 . Enclosure methods for unconstrained and constrained solution of non-linear systems are useful in robotics in sensor data analysis and collision detection ( 12 and 13 ) , generally for reliability in computer graphics (as in 29 , 36 and elsewhere) , etc. Ad hoc algorithms for each of the above applications are sometimes the most efficient . However , all such enclosure methods contain common sub-tasks , such as computing interval residuals or interval function values. Furthermore , a substantial theory has been developed (see 32 ) , and there are many computational tools that can be incorporated in these methods in different ways; see , for example 14 , or , for recent tools of ours , 20 , 22 , or 23 . It is still unclear what the scope of applicability of these tools is . Furthermore , efficient prototyping of these tools requires a programming environment in which they are easily accessible in a uniform way. General research on such methods can proceed within a language such as Fortran 77 . For example , with elements of the Fortran 77 package INT- BIS ( 21 ) we have investigated acceleration at singular roots (in 19 ) and bound-constrained global optimization (in 24 ) . However , the speed of such investigations is constrained by lack of an interval data type Giving tasks to graduate students , we have personally observed much higher productivity with an interval data type (in ACRITH-XSC 39 ) than with accessing interval arithmetic through subroutine calls .", "label": ["global optimization", "symbolic computation", "automatic differentiation", "nonlinear algebraic systems", "fortran 90"], "stemmed_label": ["global optim", "symbol comput", "automat differenti", "nonlinear algebra system", "fortran 90"]}
{"doc": "Flow analyses of untyped higher-order functional programs have in the past decade been presented by Ayers , Bondorf , Consel , Jones , Heintze , Sestoft , Shivers , Steckler , Wand , and others . The analyses are usually defined as abstract interpretations and are used for rather different tasks such as type recovery , globalization , and binding-time analysis . The analyses all contain a global closure analysis that computes information about higher-order control-flow . Sestoft proved in 1989 and 1991 that closure analysis is correct with respect to call-by-name and call-by-value semantics , but it remained open if correctness holds for arbitrary beta-reduction.This article answers the question; both closure analysis and others are correct with respect to arbitrary beta-reduction . We also prove a subject-reduction result: closure information is still valid after beta-reduction . The core of our proof technique is to define closure analysis using a constraint system . The constraint system is equivalent to the closure analysis of Bondorf , which in turn is based on Sestoft's . INTRODUCTION 1.1 Background The optimization of higher-order functional languages requires powerful program analyses . The traditional framework for such analyses is abstract interpretation , and for typed languages , suitable abstract domains can often be defined by induction on the structure of types . For example , function spaces can be abstracted into function spaces . For untyped languages such as the -calculus , or dynamically typed languages such as Scheme , abstract domains cannot be defined by abstracting function spaces into function spaces . Other domains can be used , but it may then be difficult to relate the abstract interpretation to the denotational semantics . In this article we consider a style of program analysis where the result is an abstraction of the operational semantics. In the past decade , program analyses of untyped languages has been presented Author's address: Computer Science Department , Aarhus University , Ny Munkegade , DK-8000 Aarhus C , Denmark; email: palsberg@daimi.aau.dk. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copying is by permission of the Association for Computing Machinery . To copy otherwise , or to republish , requires a fee and/or specific permission. ACM Transactions on Programming Languages and Systems , 17(1):47-62 , January 1995 . Also in Proc . CAAP'94 , pages 276-290 . c Jens Palsberg by Ayers 1992 , Bondorf 1991 , Consel 1990 , Jones 1981 , Heintze 1992 , Sestoft 1989; 1991 , Shivers 1991a; 1991b , Wand and Steckler 1994 , and others. Although the analyses are used for rather different tasks such as type recovery, globalization , and binding-time analysis , they are all based on essentially the same Key idea . In the absence of types , define the abstract domains in terms of program points. For example , consider the following -term:", "label": ["constraints", "correctness proof", "flow analysis"], "stemmed_label": ["constraint", "correct proof", "flow analysi"]}
{"doc": "Compiler-directed cache prefetching has the potential to hide much of the high memory latency seen by current and future high-performance processors . However , prefetching is not without costs , particularly on a shared-memory multiprocessor . Prefetching can negatively affect bus utilization , overall cache miss rates , memory latencies and data sharing . We simulate the effects of a compiler-directed prefetching algorithm , running on a range of bus-based multiprocessors . We show that , despite a high memory latency , this architecture does not necessarily support prefetching well , in some cases actually causing performance degradations . We pinpoint several problems with prefetching on a shared-memory architecture (additional conflict misses , no reduction in the data-sharing traffic and associated latencies , a multiprocessor's greater sensitivity to memory utilization and the sensitivity of the cache hit rate to prefetch distance) and measure their effect on performance . We then solve those problems through architectural techniques and heuristics for prefetching that could be easily incorporated into a compiler: (1) victim caching , which eliminates most of the cache conflict misses caused by prefetching in a direct-mapped cache , (2) special prefetch algorithms for shared data , which significantly improve the ability of our basic prefetching algorithm to prefetch individual misses , and (3) compiler-based shared-data restructuring , which eliminates many of the invalidation misses the basic prefetching algorithm does not predict . The combined effect of these improvements is to make prefetching effective over a much wider range of memory architectures . Introduction Several factors contribute to the increasing need for processors to tolerate high memory latencies , particularly in multiprocessor systems . Certainly the widening gap in speed between CPUs and memory increases memory latencies in uniprocessors and multiprocessors alike 13 . Fast processors also increase contention in multiproces- sors , lengthening the actual latency seen by CPUs , because of CPU queuing for the interconnect . Second , parallel workloads exhibit more interconnect operations , caused by data sharing among the processors , resulting in more This research was supported by ONR Grant No . N00014-92-J-1395 and NSF PYI Award No . MIP-9058-439. Authors' address: Department of Computer Science and Engineering FR-35 , University of Washington , Seattle , WA 98195 delays and greater memory subsystem contention . Finally , as processors and memory become more physically distributed , memory latencies necessarily increase. Software-controlled cache prefetching is a technique that is designed to make processor speeds more tolerant of memory latency . In software-controlled cache prefetching , the CPU executes a special prefetch instruction for data that is to be loaded at some point in the near future . In the best case , the data arrives at the cache before it is needed by the CPU , and the CPU sees its load as a hit . Lockup-free caches 17 , 21 , 25 , 27 , which allow the CPU to continue execution during the prefetch , hide the prefetch latency from the CPU. In this paper we address the issue of prefetching in bus-based , shared memory", "label": ["bus-based multiprocessors", "cache prefetching", "false sharing", "memory latency hiding"], "stemmed_label": ["bus-bas multiprocessor", "cach prefetch", "fals share", "memori latenc hide"]}
{"doc": "Modern optimizing compilers use several passes over a program's intermediate representation to generate good code . Many of these optimizations exhibit a phase-ordering problem . Getting the best code may require iterating optimizations until a fixed point is reached . Combining these phases can lead to the discovery of more facts about the program , exposing more opportunities for optimization . This article presents a framework for describing optimizations . It shows how to combine two such frameworks and how to reason about the properties of the resulting framework . The structure of the frame work provides insight into when a combination yields better results . To make the ideas more concrete , this article presents a framework for combining constant propagation , value numbering , and unreachable-code elimination . It is an open question as to what other frameworks can be combined in this way . Introduction Modern optimizing compilers make several passes over a program's intermediate representation to generate good code . Many of these optimizations exhibit a phase ordering problem . Different facts are discovered (and different code generated) depending on the order in which the optimizations are executed . Getting the best code requires iterating several optimizations until a fixed point is reached . We will show that by combining optimization passes the compiler discovers more facts about the program , giving more opportunities for optimization. This has been shown in an ad hoc way in previous work - for example Wegman and Zadeck presented an algorithm to combine constant propagation and unreachable code elimination 10 . This paper provides a more formal basis for describing combinations and shows when and why these combinations yield better results . We present a proof that the simple iterative technique efficiently solves these combined optimiza- tions . Finally , we combine Conditional Constant Propagation (CCP) and Global Value Numbering (GVN) to get an optimization that is more than the sum of its parts 10 , 1 . Overview 2.1 Intermediate Representations Before we describe our algorithms , we need to describe our programs . A program is represented by a Control Flow Graph (CFG) , where the edges denote flow of control and the vertices are basic blocks . Basic blocks contain a set of assignment statements and a special final statement that may be a Return , an If or empty (fall through) . Program variables are always written in lower case letters (e.g. , x , y) . To simplify the presentation , we restrict the program to integer arithmetic . The set of all integers is represented by N . Assignment statements have a single function on the right-hand side and a variable on the left . The function op is of small constant arity (i.e. , x / aopb) . op may be a constant or the identity function, and is limited to being a k-ary function . This is a reasonable assumption for our application . We run This work has been supported by ARPA through ONR grant N00014-91-J-1989. the algorithm over a low-level compiler intermediate", "label": ["optimizing compilers", "value numbering", "data-flow analysis", "constant propagation"], "stemmed_label": ["optim compil", "valu number", "data-flow analysi", "constant propag"]}
{"doc": "We show how to specify components of concurrent systems . The specification of a system is the conjunction of its components' specifications . Properties of the system are proved by reasoning about its components . We consider both the decomposition of a given system into parts , and the composition of given parts to form a system . INTRODUCTION Large systems are built from smaller parts . We present a method for deducing properties of a system by reasoning about its components . We show how to represent an individual component \\Pi i by a formula S i so that the parallel composition usually denoted cobegin \\Pi coend is represented by the formula S 1 -Sn . Composition is conjunction. We reduce composition to conjunction not for the sake of elegance , but because it is the best way we know to prove properties of composite systems . Rigorous reasoning requires logic , and hence a language of logical formulas . It does not require a conventional programming language for describing systems . We find it most convenient to regard programs and circuit descriptions as low-level specifications , and to represent them in the same logic used for higher-level specifications . The logic we use is TLA , the Temporal Logic of Actions Lamport 1994 . We do not discuss here the important problem of translating from a low-level TLA specification to an implementation in a conventional language. The idea of representing concurrent programs and their specifications as formulas in a temporal logic was first proposed by Pnueli 1981 . It was later observed that , if specifications allow \"stuttering\" steps that leave the state unchanged , then S l asserts that S l implements S h Lamport 1983 . Hence , proving that a lower-level specification implements a higher-level one was reduced to proving a formula in Authors' address: Systems Research Center , Digital Equipment Corporation , 130 Lytton Avenue, Palo Alto , CA 94301. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copying is by permission of the Association for Computing Machinery . To copy otherwise , or to republish , requires a fee and/or specific permission. c ACM Transactions on Programming Languages and Systems , Vol . 17 , No . 3 , May 1995 , Pages 507-533. 508 \\Delta Mart'in Abadi and Leslie Lamport the logic . Still later , it was noticed that the formula 999 999x : S specifies the same system as S except with the variable x hidden Abadi and Lamport 1991; Lamport 1989 , and variable hiding became logical quantification . The idea of composition as conjunction has also been suggested Abadi and Plotkin 1993; Abramsky and Jagadeesan 1994; Zave and Jackson 1993 , but our method for reducing composition to conjunction is new. To deduce useful properties of a component , we must", "label": ["concurrent programming", "safety properties", "composition", "liveness properties", "modular specification", "decomposition", "temporal logic"], "stemmed_label": ["concurr program", "safeti properti", "composit", "live properti", "modular specif", "decomposit", "tempor logic"]}
{"doc": "The current algebraic models for nondeterminism focus on the notion of possibility rather than necessity and consequently equate (nondeterministic) terms that one would intuitively not consider equal . Furthermore , existing models for nondeterminism depart radically from the standard models for (equational) specifications of deterministic operators . One would prefer that a specification language for nondeterministic operators be based on an extension of the standard model concepts , preferably in such a way that the reasoning system for (possibly nondeterministic) operators becomes the standard equational one whenever restricted to the deterministic operatorsthe objective should be to minimize the departure from the standard frameworks . In this article we define a specification language for nondeterministic operators and multialgebraic semantics . The first complete reasoning system for such specifications is introduced . We also define a transformation of specifications of nondeterministic operators into derived specifications of deterministic ones , obtaining a computational semantics of nondeterministic specification by adopting the standard semantics of the derived specification as the semantics of the original one . This semantics turns out to be a refinement of multialgebra semantics . The calculus is shown to be sound and complete also with respect to the new semantics . Introduction The notion of nondeterminism arises naturally in describing concurrent systems . Various approaches to the theory and specification of such systems , for instance , CCS Milner 1980 , CSP Hoare 1985 , process algebras Bergstra 1986 , event structures Winskel 1988 , include the phenomenon of nondeterminism . But nondeterminism is also a natural concept in describing sequential programs , either as a means of indicating a \"don't care'' attitude as to which among a number of computational paths will actually be uti lized in a particular computation (e.g. , Dijkstra 1976 ) or as a means of increasing the level of abstraction Meldal 1989 , Walicki 1994a . The present work proceeds from the theory of algebraic specifications Ehrig 1985 , Wirsing 1990 and generalizes it so that it can be applied to describing nondeterministic operations . Our main concern is to make such an extension non-intrusive , i.e. , such that it does not change the existing framework , and in particular , reduces to the standard deterministic theory when only deterministic operations are present in the specification. In terms of satisfiability , allowing nondeterminism is quite distinct from underspecification. The latter , though admitting distinct models , still insists on a function always returning a specific value , given a particular list of arguments . In the case of nondeterministic operators this is no longer true . 1 Also , nondeterminism turns out to be a useful abstraction tool whenever there is a * We gratefully acknowledge the financial support received from the Norwegian Research Council. 1 In the interest of clarity we shall let the term function denote deterministic operator , and the term operation denote nondeterministic as well as deterministic operators. hidden state or other components of a system description which are , methodologically or technically , inaccessible at a particular level of abstraction .", "label": ["algebraic specifications", "reasoning with nondeterminism"], "stemmed_label": ["algebra specif", "reason with nondetermin"]}
{"doc": "If $A$ is a square matrix with spectral radius less than 1 then $A^k \\to 0$ as $k \\to \\infty$ , but the powers computed in finite precision arithmetic may or may not converge . We derive a sufficient condition for $fl(A^k) \\to 0$ as $k\\to\\infty$ and a bound on $\\norm fl(A^k) $ , both expressed in terms of the Jordan canonical form of $A$ . Examples show that the results can be sharp . We show that the sufficient condition can be rephrased in terms of a pseudospectrum of $A$ when $A$ is diagonalizable , under certain assumptions . Our analysis leads to the rule of thumb that convergence or divergence of the computed powers of $A$ can be expected according as the spectral radius computed by any backward stable algorithm is less than or greater than 1 . Introduction . Many numerical processes depend for their success upon the powers of a matrix tending to zero . A fundamental example is stationary iteration for solving a linear system b , in which a sequence of vectors is defined by and M is nonsingular . The errors e so the iteration converges for all x 0 if (M Many theorems are available about the convergence of stationary iteration, but virtually all of them are concerned with exact arithmetic (for exceptions see 12 , 13 and the references therein) . While the errors in stationary iteration are not precisely modelled by the errors in matrix powering , as matrix powers are not formed explicitly , the behaviour of the computed powers f l((M can be expected to give some insight into the behaviour of stationary iteration (indeed , the basic error recurrences in 12 and 13 involve powers of M \\Gamma1 N acting on vectors of rounding errors). In 18 , Chapter 20 , Ostrowski proves a theorem about a product of perturbed states \"assures the theoretical stability of the convergence of A - to 0 with respect to rounding off\" as - ! 1 for any matrix A with spectral radius ae(A) ! 1 . Although Ostrowski's theorem is correct , its interpretation with respect to computed powers is not as simple as this statement implies , because for any finite precision arithmetic , no matter how accurate , there are matrices that are sensitive enough to perturbations to cause the theoretically convergent sequence of powers to diverge . To illustrate this point , Figure 1.1 1 plots the 2-norms of the first 200 powers of a 14 \\Theta 14 nilpotent matrix C 14 discussed by Trefethen and Trummer 23 (see x3 for details) . The plot confirms the statement of these authors that the matrix is not power-bounded in floating point arithmetic , even though its 14th power should be zero . The powers for our plot were computed in Matlab , which has unit roundoff Reichel and Trefethen 19 also give an example Revised version dated March 7 , 1994 . To appear in SIAM J . Matrix Anal . Appl. , April 1995. y Department of Mathematics ,", "label": ["rounding errors", "pseudospectrum", "jordan canonical form", "nonnormal matrices", "matrix powers"], "stemmed_label": ["round error", "pseudospectrum", "jordan canon form", "nonnorm matric", "matrix power"]}
{"doc": "Algorithms based on Nested Generalized Exemplar (NGE) theory (Salzberg , 1991) classify new data points by computing their distance to the nearest generalized exemplar (i.e. , either a point or an axis-parallel rectangle) . They combine the distance-based character of nearest neighbor (NN) classifiers with the axis-parallel rectangle representation employed in many rule-learning systems . An implementation of NGE was compared to the k-nearest neighbor (kNN) algorithm in 11 domains and found to be significantly inferior to kNN in 9 of them . Several modifications of NGE were studied to understand the cause of its poor performance . These show that its performance can be substantially improved by preventing NGE from creating overlapping rectangles , while still allowing complete nesting of rectangles . Performance can be further improved by modifying the distance metric to allow weights on each of the features (Salzberg , 1991) . Best results were obtained in this study when the weights were computed using mutual information between the features and the output class . The best version of NGE developed is a batch algorithm (BNGE FWMI) that has no user-tunable parameters . BNGE FWMI's performance is comparable to the first-nearest neighbor algorithm (also incorporating feature weights) . However , the k-nearest neighbor algorithm is still significantly superior to BNGE FWMI in 7 of the 11 domains , and inferior to it in only 2 . We conclude that , even with our improvements , the NGE approach is very sensitive to the shape of the decision boundaries in classification problems . In domains where the decision boundaries are axis-parallel , the NGE approach can produce excellent generalization with interpretable hypotheses . In all domains tested , NGE algorithms require much less memory to store generalized exemplars than is required by NN algorithms . Introduction Salzberg (1991) describes a family of learning algorithms based on nested generalized exemplars (NGE) . In NGE , an exemplar is a single training example , and a generalized exemplar is an axis-parallel hyperrectangle that may cover several training examples . These hyperrectangles may overlap or nest . The NGE algorithm grows the hyperrectangles incrementally as training examples are processed. Once the generalized exemplars are learned , a test example can be classified by computing the Euclidean distance between the example and each of the generalized exemplars . If an example is contained inside a generalized exemplar , the distance D . WETTSCHERECK AND T.G . DIETTERICH to that generalized exemplar is zero . The class of the nearest generalized exemplar is output as the predicted class of the test example. The NGE approach can be viewed as a hybrid of nearest neighbor methods and propositional Horn clause rules . Like nearest neighbor methods , Euclidean distance is applied to match test examples to training examples . But like Horn clause rules, the training examples can be generalized to be axis-parallel hyperrectangles. Salzberg reported promising classification results in three domains . However , as we report below , when NGE is tested in 11 additional domains , it gives less accurate predictions in many", "label": ["nearest neighbors", "nested generalized exemplars", "feature weights", "exemplar-based learning", "instance-based learning"], "stemmed_label": ["nearest neighbor", "nest gener exemplar", "featur weight", "exemplar-bas learn", "instance-bas learn"]}
{"doc": "We analyze the performance of queues that serve readers and writers . Readers are served concurrently , while writers require exclusive service . We approximately analyze a first-come-first-serve (FCFS) reader/writer queue , and derive simple formulae for computing waiting times and capacity under the assumption of Poisson arrivals and exponential service . We extend the analysis to handle a one-writer queue , and a queue that includes write-intention locks . The simple analyses that we present can be used as rules-of-thumb for designing concurrent systems . Introduction Most analyses of database or operating system concurrency control algorithms handle only the case of exclusive access . In practice , however , many concurrency control algorithms use both shared and exclusive locks . Shared locks are important for increasing concurrency and reducing serialization delays. This paper describes queues that model reader and writer access to a shared resource . Readers place R (read) locks and writers place W (write) locks . Any number of R locks may be held simultaneously, but only one W lock may be placed at a given time . In addition , R and W locks are incompatible and cannot be held simultaneously . A queuing discipline that manages the lock access should be fair , so that readers should not starve writers , and vice versa . A common fairness criterion is FCFS . That is , if lock ff arrives before lock fi , grant ff before granting fi. The FCFS lock queuing mechanism obeys the following protocol: when the job in service finishes , if the first job in the queue is a reader , grant access to all readers up to the first writer . If the first job is a writer , grant the lock to the writer . In addition , if the queue is empty , or only readers are in service and a reader arrives , grant a lock to the reader (see figure 1) . We call this type of lock queue a FCFS reader/writer queue or a FCFS r/w queue , for short. We also analyze a variation on the FCFS R/W queue . In the variation , which we call the one-writer queue , there is at most one writer in the queue at a time , and the reader arrival rate is much larger than the writer arrival rate . The one-writer queue has many applications (for example , in the analysis of a communications driver 15 ) . We use the one-writer queue to model queues with write-intention locks, or R/U/W queues . In a R/U/W queue , the incoming stream consists of R and U locks . R locks are compatible both with each other and with U locks , but U locks are not compatible with each other . U locks occasionally upgrade to W locks , which are exclusive . The R/U/W queue can model write-intention locks , which are often used for concurrent data structures 3 and for multigranularity locking 4 . The model that we develop predicts the expected waiting time for", "label": ["performance analysis", "lock queue", "queuing system", "concurrent system", "reader/writer"], "stemmed_label": ["perform analysi", "lock queue", "queu system", "concurr system", "reader/writ"]}
{"doc": "AbstractThis paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast , variable background intensity and noise . Niblacks method with the addition of the postprocessing step of Yanowitz and Brucksteins method added performed the best and was also one of the fastest binarization methods . Introduction T HERE is currently a large and growing interest in the field of document image analysis . Numerous research groups are trying to design systems for extracting relevant information from such diverse documents as engineering drawings , maps , magazines and newspapers , forms , and mail envelopes 1 2 3 . In most of these systems , binarization of the scanned gray level image (labeling each pixel print or background) is done prior to further process- ing . This paper will focus on binarization of map images. Maps are central to a large number of public and private agencies . An example is utility maps , which are film copies of ordinary maps with specialized information added in the form of text , symbols , lines , and networks . The availability of high quality digital geographical information systems has created the possibility for a more flexible use and maintenance of the utility maps . However , these systems demand that the maps are available in digital format , preferably in a vector representation , with the associated text information in symbolic form. To digitize a map , it is first scanned at a high resolution, giving a gray scale image which is then binarized . Sub- sequently , symbol recognition and line vectorization programs are used to label symbols , text , lines and solid areas in the binary raster image . However , these algorithms require a high quality binary raster image to be able to correctly identify all the information present . Professionally drawn map originals for use in offset printing usually fulfill this requirement when global binarization methods are applied . In contrast , the print quality of utility maps is poor due to extensive manual handling and updating over time , giving areas with variable background intensity , low contrast and stochastic noise . Therefore , it is essential to - . D . Trier and T . Taxt are with the University of Oslo , Department of Informatics , P.O . Box 1080 Blindern , N-0316 Oslo , Norway . Email: trier@ifi.uio.no , torfinn@tor.pki.uib.no . find binarization methods which will correctly label all the information present , even in low contrast areas of the map, while being insensitive to variable background intensity and stochastic noise . These requirements exclude global binarization methods , and lead us to evaluate the best adaptive binarization methods available in the literature. In our evaluation , binarization methods requiring manual inspection of subimages and fine-tuning of parameters were excluded . This is because the binarization algorithms are intended to be part of an automatic digitizing system for maps , being able to process a large number of maps per time unit . Each gray scale map", "label": ["evaluation", "locally adaptive binarization", "thresholding", "document images", "utility maps"], "stemmed_label": ["evalu", "local adapt binar", "threshold", "document imag", "util map"]}
{"doc": "We consider the probabilistic relationship between the value of a random asymmetric traveling salesman problem $ATSP(M)$ and the value of its assignment relaxation $AP(M)$ . We assume here that the costs are given by an $n\\times n$ matrix $M$ whose entries are independently and identically distributed . We focus on the relationship between $Pr(ATSP(M)=AP(M))$ and the probability $p_n$ that any particular entry is zero . If $np_n\\rightarrow \\infty$ with $n$ then we prove that $ATSP(M)=AP(M)$ with probability 1-o(1) . This is shown to be best possible in the sense that if $np(n)\\rightarrow c$ , $c 0$ and constant , then $Pr(ATSP(M)=AP(M)) 1-\\phi(c)$ for some positive function $\\phi$ . Finally , if $np_n\\rightarrow 0$ then $Pr(ATSP(M)=AP(M))\\rightarrow 0$ . Introduction The Assignment Problem (AP) is the problem of finding a minimum-weight perfect matching in an edge-weighted bipartite graph.An instance of the AP can be specified by an n \\Theta n represents the weight of the edge between x i and y j , where is the set of \"left vertices\" in the bipartite graph , and is the set of \"right vertices.\"The AP can be stated in terms of the matrix M as follows: find a permutation oe of f1; ng that minimizes (M) be the optimal value of the instance of the AP specified by M . The Asymmetric Traveling-Salesman Problem (ATSP) is the problem of finding a Hamiltonian circuit of minimum weight in an edge-weighted directed graph . An instance of the ATSP can be specified by an n \\Theta n matrix denotes the weight of ? . The ATSP can be stated in terms of the matrix M as follows: find a cyclic permutation - of f1; ng that minimizes here a cyclic permutation is one whose cycle structure consists of a single cycle . Let ATSP (M) be the optimal value of the instance of the ATSP specified by M . It is evident from the parallelism between the above two definitions that AP (M) - ATSP (M ) . The ATSP is NP-hard , whereas the AP is solvable in time O(n 3 ) . Several authors (for a recent survey see BaTo ) have investigated whether the AP can be used effectively in a branch-and-bound method to solve the ATSP . The most striking evidence of the power of this approach is given by the recent work of Miller and Pekny . Among many other computational results , they obtained optimal solutions to random instances with up to 500,000 cities , in which the m ij were drawn independently from the integers in the range 0; n . Miller and Pekny noticed that AP (M) was often equal to ATSP (M ), and they exploited this observation by developing a special method to search for a cyclic permutation among the optimal solutions to the AP. Motivated by the computational experience of Miller and Pekny , we have investigated the following question: when the m ij are drawn independently from a common distribution (over , say , the nonnegative reals) , what is the probability that AP (M)? The", "label": ["probabilistic analysis", "traveling salesman"], "stemmed_label": ["probabilist analysi", "travel salesman"]}
{"doc": "The relative power of determinism , randomness , and nondeterminism for search problems in the Boolean decision tree model is studied . It is shown that the gaps between the nondeterministic , the randomized , and the deterministic complexities can be arbitrarily large for search problems . An interesting connection of this model to the complexity of resolution proofs is also mentioned . Introduction Ramsey's theorem asserts that every graph on n vertices has either a complete graph or an independent set of size 1log n . A natural search problem associated with this theorem is to find such a subgraph . Many other problems , like the ones below , have a similar flavor: Given an assignment of n pigeons into find two pigeons assigned to the same hole . Given a k-chromatic graph and a coloring of its nodes with fewer than k colors, find two neighbors which have the same color . Given an unsatisfiable 3-CNF formula and an assignment to its variables , find a clause which is not satisfied. How hard is it to solve such search problems? The answer depends of course on their representation and the computational model . We assume that the input is encoded in binary, and that we are only allowed to probe input bits . This gives the familiar Boolean decision tree Princeton University and Eotvos Lor'and University Budapest y Weizmann Institute . Part of this work was done while the author was at the IBM Almaden Research Center. z DIMACS center and Hebrew U . Jerusalem x Princeton University and Hebrew U . Jerusalem model , adapted to solving search problems rather than computing Boolean functions . We study the relationship between the standard nondeterministic , probabilistic and deterministic variants of this model , and discover that it is drastically different from the case of function computation , where all three measures are polynomially related (see 2 , 7 , 19 , 14 ) . In all the examples listed above it is easy to guess and verify the solution; hence the nondeterministic decision tree complexity is small (a constant or polylog) . If the decision tree was computing a function , this would imply that both the randomized and deterministic complexities are small , by the fact that the deterministic complexity (and thus the randomized too) is at most the square of the nondeterministic complexity 2 , 7 , 19 . It turns out that for search problems these gaps can be arbitrary large. Our investigation is partly motivated by a similar study of search problems in the communication complexity setting in the work of Karchmer and Wigderson 11 and Raz and 18 , where a similar phenomenon occurs but not to the same extent . Another study of search problems was carried out by Papadimitriou 15 where complexity classes defined by search problems were investigated . Some of our examples are inspired by this work and 8 , 10 . The examples above may remind the readers of resolution proofs . Indeed , resolution proofs viewed top down", "label": ["decision trees", "boolean functions"], "stemmed_label": ["decis tree", "boolean function"]}
{"doc": "A good software architecture facilitates application system development , promotes achievement of functional requirements , and supports system reconfiguration . We present a domain-specific software architecture (DSSA) that we have developed for a large application domain of adaptive intelligent systems (AIS's) . The DSSA provides: a) an AIS reference architecture designed to meet the functional requirements shared by applications in this domain , b) principles for decomposing expertise into highly reusable components , and c) an application configuration method for selecting relevant components from a library and automatically configuring instances of those components in an instance of the architecture . The AIS reference architecture incorporates features of layered , pipe and filter , and blackboard style architectures . We describe three studies demonstrating the utility of our architecture in the subdomain of mobile office robots and identify software engineering principles embodied in the architecture . Introduction The architecture of a complex software system is its \"style and method of design and construction\" 25 . When applied appropriately , a good software architecture facilitates application system development , promotes achievement of the system's functional requirements, and supports reconfiguration . A \"bad\" architecture-or the absence of a clearly defined architecture-can thwart all three objectives. Designing and implementing a good software architecture (with associated development and debugging environments) is challenging and expensive . Replicating this activity across many projects for systems that have similar requirements unnecessarily inflates their expense. Conversely , competition for limited project resources may limit the quality of the architectural support that can be realized for a given system. How can we achieve the benefits of good software architecture while containing the cost? We have been studying a software engineering methodology based on domain-specific software architectures (DSSAs) 18 , 36 , 34 , 35 , 37 , 24 , where the term \"domain\" refers to a class of applications . A DSSA comprises: (a) a reference architecture , which describes a general computational framework for a significant domain of applications , (b) a component library, which contains reusable chunks of domain expertise , and (c) an application configuration method for selecting and configuring components within the architecture to meet particular application requirements. We have been developing and experimenting with a particular DSSA for the domain of adaptive intelligent systems (AISs) that perceive , reason , and act to achieve multiple goals in dynamic , uncertain , complex environments . AIS applications share functional requirements such as: concurrent perception , reasoning , and action; sensitivity to externally determined priorities and deadlines; and dynamic global control of the system's own behavior . As illustrated by the taxonomy in Figure 1 , the AIS domain may be partitioned into sub-domains defined by more specific shared task requirements . For example , all autonomous robots require capabilities for path planning and navigation , while all monitoring systems require capabilities for pattern classification and fault detection . Sub-classes may introduce additional task requirements or place constraints on inherited requirements. Instantiating the general definition given above , our AIS DSSA comprises: (a) an implemented AIS reference architecture that", "label": ["intelligent agents", "software reuse", "domain-specific software architectures", "mobile robots", "software architecture"], "stemmed_label": ["intellig agent", "softwar reus", "domain-specif softwar architectur", "mobil robot", "softwar architectur"]}
{"doc": "Recent developments in mobile communication and personal computer technology have laid a new foundation for mobile computing . Performance of the data communication system as seen by an application program is a fundamental factor when communication infrastructure at the application layer is designed . This paper provides results of performance measurements of data transmission over two different cellular telephone networks , a digital GSM-network and an analogue NMT-network . Since our emphasis is on performance as seen by application programs , we use the standard TCP/IP protocols in the measurements . The performance is measured using three basic operations: establishment of a wireless dial-up connection , exchange of request-reply messages , and bulk data transfer . The external conditions under which the measurements were carried out present a normal office environment when the field strength of the cellular link is good or fairly good . Introduction In the computer industry mobile computing will be the revolution of 90's in the same way as personal computers were in the 80's . In mobile computing wireless networking is a key factor . Recent developments in cellular network technology and telephones as well as in portable computers are opening new possibilities for wireless data communication . Portable computers and mobile telephones have become smaller , lighter , and more powerful while cellular networks offer more advanced services . Integration of wireline and wireless networking creates new possibilities to use the services available in computer networks . However , the technical challenges in the integration are hardly trivial. Global System for Mobile communications (GSM) , which is a European digital cellular telephone network Rah93 , MP92 , offers a platform for wireless data communication by specifying a variety of data services; both teleservices and bearer services . In addition to digital cellular networks , analogue cellular telephone networks can nowadays , due to recent developments in modem technology , be used as a platform for wireless data communica- tion . The most widely used analogue cellular systems are Advanced Mobile Phone System (AMPS) , Total Access Communications Systems (TACS) , and Nordic Mobile Telephone The end users of today are accustomed to wireline LANs , in which the transfer rate is megabits per second and the bit error rate is below 10 \\Gamma9 . Many client-server applications are primarily designed to work in such environments . Compared to traditional wireline links, wireless links offered by cellular telephone networks have low throughput , low reliability , and often low quality . The maximum line speed in cellular telephone networks varies from 1,200 bps up to 19,200 bps . Radio signal is affected by noise and interference , caused , for example, by automobile ignition sparks or by adjacent channels . This implies that a wireless link has a high error rate and that disconnections are not uncommon . The integration of LAN and a cellular telephone network implies that two networking environments , having very different characteristics , are to be combined. Since the performance of cellular wireless links is low , it is important to understand", "label": ["performance measurements", "wireless dial-up connections", "nmt", "gsm", "cellular telephones"], "stemmed_label": ["perform measur", "wireless dial-up connect", "nmt", "gsm", "cellular telephon"]}
{"doc": "Earlier work concerning control of discrete event systems usually assumed that a correct model of the system to be controlled was available . A goal of this work is to provide an algorithm for determining the correct model from a set of models . The result of the algorithm is a finite language that can be used to test for the correct model or notification that the remaining models cannot be controllably distinguished . We use the finite state machine model with controllable and uncontrollable events presented by Ramadge and Wonham . Introduction A discrete event system (DES) is one which responds to distinct events occurring at asynchronous times 7 . Examples of such systems include computer networks , manufacturing systems , and other dynamic systems which require high level coordinated control . There has been some success recently in developing a theory for the control of such systems (see 13 and the references therein) . Most of this work has assumed that an accurate model for the system of interest is available. The motivation for this work is the desire to control systems in the presence of uncertainty in the model of the system and environment in which the system operates . Part of this work is an extension of learning and inference theory 6 , 2 , 16 to the domain of discrete event systems. This work is also related to recent results concerning the determination of a system model when certain assumptions are made about the model and type of experiments 14 , 15 . In both the learning theory and system determination work , an assumption is that all events are controllable . The uncontrollability of certain events figures prominently in this work . The approach taken in this paper is similar to the approach used for system identification in 17 in that any model which is falsified is dropped from consideration as a correct model. There are many different types of uncertainty which might occur in a system model . To discuss such uncertainties , a model representation must be chosen . In this work , we investigate uncertainty in a deterministic finite state machine . An example of such uncertainty is an uncertainty in the transitions of a system which can be described as a state which has a single event specified as providing transitions to at least two different resulting states; however , only one of the transitions is actually present in the sys- tem . Other examples are discussed in Section 3 . Such uncertainty results in multiple models of the system which might potentially be correct . The goal is to specify conditions and algorithms which enable the identification of the correct model in a finite number of transitions despite the presence of uncontrollable actions . In particular , an algorithm provides either notification that no more models may be controllably distinguished or a finite distinguishing language which can be used to remove an incorrect model. Section 2 describes the method used to model the plant and the relevant controllability results . Section", "label": ["system identification", "discrete event systems"], "stemmed_label": ["system identif", "discret event system"]}
{"doc": "A widely used approach to parameter identification is the output least-squares formulation . Numerical methods for solving the resulting minimization problem almost invariably require the computation of the gradient of the output least-squares functional . When the identification problem involves time-dependent distributed parameter systems (or approximations thereof) , numerical evaluation of the gradient can be extremely time consuming . The costate method can greatly reduce the cost of computing these gradients . However , questions have been raised concerning the accuracy and convergence of costate approximations , even when the numerical methods being used are known to converge rapidly on the forward problem . In this paper it is shown that the use of time-marching schemes that yield high-order accuracy on the forward problem does not necessarily lead to high-order accurate costate approximations . In fact , in some cases these approximations do not converge at all . However , under certain circumstances , rapidly converging gradient approximations do result because of rapid weak-star-type convergence of the costate approximations . These issues are treated both theoretically and numerically . Introduction . In this paper we analyze temporal discretizations of the costate method for computing gradients in the output least-squares approach to parameter esti- mation . This analysis applies to initial value problems of the form Here A(q) is a bounded linear operator on a Hilbert space H , and the inner product on H is denoted h\\Delta; \\Deltai H . The dot over u indicates differentiation with respect to t . We will refer to u as the state variable and to (1.1) as the state equation . We assume q lies in set QAD of admissible parameters contained in a normed linear \"parameter\" space Q . Throughout the paper we assume that the map q 7! A(q) is Gateaux differentiable in the operator norm. In applications of interest , (1.1) is a finite dimensional (i.e. , dim(H) ! 1) approximation of a time-dependent PDE . An important example is the diffusion equation @t Department of Mathematical Sciences , Montana State University , Bozeman MT 59717 . Research was supported in part by the NSF under Grant DMS-9106609 and by the Center for Interfacial Microbial Process Engineering at Montana State University , an NSF-sponsored Engineering Research Center , and the Center's Industrial Associates. y Center for Applied Mathematical Sciences , University of Southern California , Los Angeles , CA 90089- 1113 . Address as of July 1 , 1992: Department of Mathematics , Texas A & M University , College Station, 77843-3368 . Research was supported in part by the Air Force Office of Scientific Research under grants AFOSR-90-0091 and AFOSR-86-0126 , and by the NSF under grants DMS-8818530 and DMS-8704169. In these situations , dim(H) can be arbitrarily large. In general we assume that the solution u lies in the \"state space\" which is a Hilbert space with inner product As in Banks and Kunish 3 , we assume the existence of an \"observation space\" Z , which is a Hilbert space with inner product hh \\Delta; \\Delta ii Z ,", "label": ["costate method", "evolution equations", "parameter estimation"], "stemmed_label": ["costat method", "evolut equat", "paramet estim"]}
{"doc": "This paper presents a globally convergent successive approximation method for solving $F(x)=0$ where $F$ is a continuous function . At each step of the method , $F$ is approximated by a smooth function $f_ k ,$ with $\\pa f_ k -F\\pa \\rightarrow 0$ as $k \\rightarrow \\infty$ . The direction $-f'_ k (x_ k )^ -1 F(x_ k )$ is then used in a line search on a sum of squares objective . The approximate function $f_k$ can be constructed for nonsmooth equations arising from variational inequalities , maximal monotone operator problems , nonlinear complementarity problems , and nonsmooth partial differential equations . Numerical examples are given to illustrate the method . Introduction be a continuous , but not necessarily differentiable, function . We consider the system of nonlinear equations The recent literature of such nonsmooth equations includes 1-3 , 6-8 , 10- 13 , 15 , 17 , 19-21 . This work is supported by the Australian Research Council. If F is smooth , a popular method for solving (1) is the damped Newton method 4 9 Solve F to get d k (2) where the step size ff k in (0; 1 is chosen by a line search. Han , Pang and Rangaraj 6 generalized the damped Newton method to solve the nonsmooth equation (1) using the idea of an \"iteration function\". defined by Damped Newton Method with Iteration Function (IF) Let ae; oe 2 (0; 1) be given . Let G : R n\\Thetan ! R n be a given iteration function. Solve F to get d k is the smallest nonnegative integer m such that Global convergence was established in 6 under four assumptions on G and F T G . In general , G(x; \\Delta) is nonlinear . This implies that a system of nonlinear equations (generally easier than (1)) is solved at each step in the above method. Recently , Gabriel and Pang 7 proposed a trust region algorithm using iteration functions . They also required certain assumptions on the iteration functions to establish convergence of their algorithm . Poliquin and Qi 14 proved that , in the case of nonsmooth optimization , the assumptions on the iteration functions actually implied restrictions on the original function. There are other globally convergent methods for nonsmooth equations 10-13, 20 . These methods either assume conditions much stronger than continuity, or only work for some special problems. In this paper , we introduce a successive approximation method . Let jj \\Delta jj denote the Euclidean norm . At the k-th step , we approximate F by a smooth function f k such that and ff 2 (0; 1) is a fixed constant . The algorithm uses f 0 derivative of F at x k is needed. There are two outstanding advantages of the new algorithm over existing methods . The first advantage is that a linear approximation is made at each step , so the subproblem is a system of linear equations . Known globally convergent methods for solving nonsmooth equations do not have this feature . The second", "label": ["successive approximation", "global convergence", "integration convolution"], "stemmed_label": ["success approxim", "global converg", "integr convolut"]}
{"doc": "This paper considers the exact number of character comparisons needed to find all occurrences of a pattern of length $m$ in a text of length $n$ using on-line and general algorithms . For on-line algorithms , a lower bound of about $(1+\\frac 9 4(m+1) )\\cdot n$ character comparisons is obtained . For general algorithms , a lower bound of about $(1+\\frac 2 m+3 )\\cdot n$ character comparisons is obtained . These lower bounds complement an on-line upper bound of about $(1+\\frac 8 3(m+1) )\\cdot n$ comparisons obtained recently by Cole and Hariharan . The lower bounds are obtained by finding patterns with interesting combinatorial properties . It is also shown that for some patterns off-line algorithms can be more efficient than on-line algorithms . Introduction . The classical string matching problem is the problem of finding all occurrences of a pattern in a text String matching is among the most extensively studied problems in computer science . A survey of the various algorithms devised for it can be found in Ah90 . Among the most efficient algorithms devised for string matching are algorithms that gain information about the pattern and text only by performing comparisons between pattern and text characters . Such algorithms need not have any prior knowledge of the (possibly infinite) alphabet from which the pattern and text are drawn. We investigate the exact comparison complexity of string matching in this model and obtain lower bounds on the number of comparisons required (in the worst case) . These lower bounds allow the algorithms to preprocess the pattern (but not the text) . The lower bounds remain valid even if the algorithms do know the alphabet in advance provided that the alphabet contains a character not appearing in the pattern. Two kinds of comparison based algorithms have been studied . An on-line algorithm is an algorithm that examines text characters only in a window of size m sliding monotonically to the right; furthermore , the window can slide to the right only when all matching pattern instances to the left of the window or aligned with the window have been discovered . A general (or off-line) algorithm is an algorithm that can access both the pattern and the text in an unrestricted manner. Perhaps the most widely known linear time algorithms for string matching are the Knuth-Morris-Pratt KMP77 and Boyer-Moore BM77 algorithms . We refer to them as the KMP and BM algorithms , respectively . The KMP algorithm makes at most comparisons and this bound is tight . The exact complexity of the BM algorithm was an open question until recently . It was shown in KMP77 that the BM algorithm makes at most 6n comparisons if the pattern does not occur in the text. y Courant Institute , New York University , New York 10012 . The first two authors were supported in part by NSF grants CCR-8902221 , CCR-8906949 , CCR-9202900 and CCR-8901484. z Department of Computer Science , University of Warwick , Coventry CV4 7AL , England . This author was supported in part by the ESPRIT", "label": ["string matching", "complexity", "lower bounds", "comparisons", "pattern matching"], "stemmed_label": ["string match", "complex", "lower bound", "comparison", "pattern match"]}
{"doc": "This paper proves that for a strongly connected planar directed graph of size $n$ , a depth-first search tree rooted at a specified vertex can be computed in $O(\\log^ 5 n)$ time with $n/\\log n $ processors . Previously , for planar directed graphs that may not be strongly connected , the best depth-first search algorithm runs in $O(\\log^ 10 n)$ time with $n$ processors . Both algorithms run on a parallel random access machine that allows concurrent reads and concurrent writes in its shared memory , and in case of a write conflict , permits an arbitrary processor to succeed . Introduction . Depth-first search is one of the most useful tools in graph theory 32 , 4 . The depth-first search problem is the following: given a graph and a distinguished vertex , construct a tree that corresponds to performing depth-first search in the graph starting from the given vertex. The parallelization of depth-first search has been studied by numerous authors. Reif showed that lexicographic depth-first search is P-complete even for general undirected graphs 28 . For unordered depth-first search , Smith gave the first NC algorithm for planar undirected graphs 30 . The processor complexity of his algorithm was reduced to linear by He and Yesha 15 . Independently , Ja'Ja and Kosaraju 16 and Shannon 29 also achieved the same result . Aggarwal and Anderson gave a randomized NC algorithm for general undirected graphs 2 . Kao studied the problem for directed graphs , and found an NC algorithm using n 4 processors for a planar directed graph of size n 17 . This was followed by the randomized NC algorithm of Aggarwal, Anderson and Kao for general directed graphs 3 . Recently , Kao and Klein gave an algorithm that computes depth-first search trees in O(log 10 n) time using n processors for planar directed graphs that may not be strongly connected 19 . This paper shows that for a strongly connected planar directed graph of size n, a depth-first search tree rooted a specified vertex can be computed in O(log 5 n) time using n= log n processors . This algorithm runs on a parallel random access machine that allows concurrent reads and concurrent writes in its shared memory , and in case of a write conflict , permits an arbitrary processor to succeed. Both the algorithm of this paper and that of Kao and Klein use directed graph separators defined by Kao 17 , and follow the framework of the randomized NC algorithm for general directed graphs 3 . The algorithm in this paper achieves a superior complexity by exploiting topological properties of strongly connected planar directed graphs . The strongly connected components of key subgraphs created in the course of the algorithm have very regular structures . A major task of the algorithm is to recursively maintain and utilize these structures. This paper is organized as follows . Section 2 reviews basic definitions and relevant facts about planar directed graphs. Department of Computer Science , Duke University , Durham , NC 27706 . Supported", "label": ["strong connectivity", "depth-first search", "s-t graphs", "linear-processor nc algorithms", "graph separators", "planar directed graphs", "bubblegraphs"], "stemmed_label": ["strong connect", "depth-first search", "s-t graph", "linear-processor nc algorithm", "graph separ", "planar direct graph", "bubblegraph"]}
{"doc": "The following file distribution problem is considered: Given a network of processors represented by an undirected graph $G=(V,E)$ and a file size $k$ , an arbitrary file w of $k$ bits is to be distributed among all nodes of $G$ . To this end , each node is assigned a memory device such that by accessing the memory of its own and of its adjacent nodes , the node can reconstruct the contents of w . The objective is to minimize the total size of memory in the network . This paper presents a file distribution scheme which realizes this objective for $k \\gg \\log \\Delta_G$ , where $\\Delta_G$ stands for the maximum degree in $G$: For this range of $k$ , the total memory size required by the suggested scheme approaches an integer programming lower bound on that size . The scheme is also constructive in the sense that given $G$ and $k$ , the memory size at each node in $G$ , as well as the mapping of any file w into the node memory devices , can be computed in time complexity which is polynomial in $k$ and $|V|$ . Furthermore , each node can reconstruct the contents of such a file w in $O(k^2)$ bit operations . Finally , it is shown that the requirement of $k$ being much larger than $\\log \\Delta_G$ is necessary in order to have total memory size close to the integer programming lower bound . Introduction Consider the following file distribution problem: A network of processors is represented by an undirected graph G . An arbitrary file w of a prescribed size k (measured , say , in bits) is to be distributed among all nodes of G . We are to assign memory devices to the nodes of G such that , by accessing the memory of its own and of its adjacent nodes , each node can reconstruct the contents of w . Given G and k , the objective is to find a static memory allocation to the nodes of G , independent of w , as to minimize the total size of memory in the network . Although we do not restrict the file distribution or reconstruction algorithms to be of any particular form , we aim at simple and efficient ones. The problem of file allocation in a network , i.e. , of storing a file in a network so that every processor has \"easy\" access to the file , has been considered in many variants (see 4 for a survey) . The specific version of reconstruction from adjacent nodes only has received attention in the form of file segmentation , where the task is to partition the file so that , for each node u in the network , the union of the file segments stored at nodes adjacent to u is the complete file 4 8 13 . As we shall see , allowing more general reconstruction procedures than simply taking the union of file segments at adjacent nodes can result in a considerable savings of", "label": ["resource sharing", "distributed networks", "integer programming", "linear programming", "derandomization", "set cover", "linear codes", "file assignment", "probabilistic algorithms"], "stemmed_label": ["resourc share", "distribut network", "integ program", "linear program", "derandom", "set cover", "linear code", "file assign", "probabilist algorithm"]}
{"doc": "Measure-theoretic aspects of the $\\leq^ \\rm P _ \\rm m $-reducibility structure of the exponential time complexity classes E=DTIME($2^ \\rm linear $) and $E_ 2 = \\rm DTIME (2^ \\rm polynomial )$ are investigated . Particular attention is given to the complexity (measured by the size of complexity cores) and distribution (abundance in the sense of measure) of languages that are $\\leq^ \\rm P _ \\rm m $-hard for E and other complexity classes . Tight upper and lower bounds on the size of complexity cores of hard languages are derived . The upper bound says that the $\\leq^ \\rm P _ \\rm m $-hard languages for E are unusually simple , in the sense that they have smaller complexity cores than most languages in E . It follows that the $\\leq^ \\rm P _ \\rm m $-complete languages for E form a measure 0 subset of E (and similarly in $E_2$) . This latter fact is seen to be a special case of a more general theorem , namely , that \\it every \\pmr-degree (e.g. , the degree of all \\pmr-complete languages for NP) has measure 0 in E and in \\Ep . Introduction A decision problem (i.e. , language) A ' f0; 1g is said to be hard for a complexity class C if every language in C is efficiently reducible to A . If A is also an element of C , then A is complete for C . The most common interpretation of \"efficiently reducible\" here is \"polynomial time many-one reducible,\" abbreviated \"- P -reducible.\" (See section 2 for notation and terminology used in this introduction.) For example , in most usages , \"NP-complete\" means m -complete for NP,\" the completeness notion introduced by Karp 15 and Levin 16 . This research was supported in part by National Science Foundation Grants CCR-8809238 and CCR- 9157382 , with matching funds from Rockwell International and Microware Systems Corporation , and in part by the Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) , where the second author was a visitor while part of this work was carried out. In this paper , we investigate the complexity (measured by size of complexity cores) and distribution (i.e. , abundance in the sense of measure) of languages that are - P (equivalently , classes , including NP . (By \"measure\" here , we mean resource-bounded measure as developed by Lutz 17 and described in section 3 of the present paper.) We give a tight lower bound and , perhaps surprisingly , a tight upper bound on the sizes of complexity cores of hard languages . More generally , we analyze measure-theoretic aspects of the - P -reducibility structure of exponential time complexity classes . We prove that - P -hard problems are rare , in the sense that they form a p-measure 0 set . We also prove that every - P m -degree has measure 0 in exponential time. Complexity cores , first introduced by Lynch 24 have been studied extensively 8 , 9 , 10, 11 , 12 , 14", "label": ["resource-bounded measure", "polynomial reducibilities", "complexity classes", "complexitycores", "computational complexity", "complete problems"], "stemmed_label": ["resource-bound measur", "polynomi reduc", "complex class", "complexitycor", "comput complex", "complet problem"]}
{"doc": "The subject of this work is the possibility of private distributed computations of $n$-argument functions defined over the integers . A function $f$ is $t$-private if there exists a protocol for computing $f$ , so that no coalition of at most $t$ participants can infer any additional information from the execution of the protocol . It is known that over finite domains , every function can be computed $\\left\\lfloor (n-1)/2 \\right\\rfloor$-privately . Some functions , like addition , are even $n$-private . We prove that this result cannot be extended to infinite domains . The possibility of privately computing $f$ is shown to be closely related to the communication complexity of $f$ . Using this relation , we show , for example , that $n$-argument addition is $\\left\\lfloor (n-1)/2 \\right\\rfloor$-private over the nonnegative integers , but not even $1$-private over all the integers . Finally , a complete characterization of $t$-private Boolean functions over countable domains is given . A Boolean function is $1$-private if and only if its communication complexity is bounded . This characterization enables us to prove that every Boolean function falls into one of the following three categories: It is either $n$-private , $\\left\\lfloor (n-1)/2 \\right\\rfloor$-private but not $\\left\\lceil n/2 \\right\\rceil $-private , or not $1$-private . Introduction A set of n - 3 computationally unbounded parties , each holding an input x i taken from a domain D , wishes to cooperate in distributively computing the value predetermined function f . These parties are honest , namely they all follow their prescribed protocol . They communicate over a complete point-to-point communication network , where eavesdropping is not possible . A function f is called t-private if there is a communication protocol for computing f , so that no coalition of at most t participants gets any additional information from the execution of the protocol . Ben-Or , Goldwasser , and Wigderson 5 , and An early version of this paper appeared in Proc . of 31th FOCS , 1990 , pp . 335-344 . Research supported by US-Israel Binational Science Foundation grant 88-00282. y Department of Computer Science , Technion , Haifa 32000 , Israel . e-mail: benny@cs.technion.ac.il . Part of this research was done while visiting the Computer Science Department in the University of Toronto. z Department of Computer Science , Tufts University , Medford , MA 02155 . e-mail: gereb@cs.tufts.edu . x Department of Computer Science , Technion , Haifa 32000 , Israel . e-mail: eyalk@cs.technion.ac.il . Chaum , Crepeau , and Damgard 8 , have shown that if the domain D of f is finite , then f is like addition , are even n-private over finite domains 6 , while certain functions , like Boolean OR , are not dn=2e-private 1 5 . However , functions of interest are typically defined not over finite domains , but rather over all strings , over the integers , or more generally over some countable domain . To apply the protocol of 5 , 8 , one has to (implicitly or explicitly) assume an upper bound", "label": ["private distributed computations", "communication complexity"], "stemmed_label": ["privat distribut comput", "commun complex"]}
{"doc": "We present a new approach to formal language theory using Kolmogorov complexity . The main results presented here are an alternative for pumping lemma(s) , a new characterization for regular languages , and a new method to separate deterministic context-free languages and nondeterministic context-free languages . The use of the new \"incompressibility arguments\" is illustrated by many examples . The approach is also successful at the high end of the Chomsky hierarchy since one can quantify nonrecursiveness in terms of Kolmogorov complexity . Introduction It is feasible to reconstruct parts of formal language theory using algorithmic information theory (Kolmogorov complexity) . We provide theorems on how to use Kolmogorov complexity as a concrete and powerful tool . We do not just want A preliminary version of part of this work was presented at the 16th International Colloquium on Automata , Languages , and Programming , Stresa , Italy , July 1989. y Supported in part by National Science Foundation Grant DCR-8606366 , Office of Naval Research Grant N00014-85-k-0445 , Army Research Office Grant DAAL03-86-K-0171 , and by operating grants OGP-0036747 and OGP-046506 . Part of the work was performed while he was with the Department of Computer Science , York University , North York , Ontario, Canada . Address: Computer Science Department , University of Waterloo , Waterloo , Ontario, Canada N2L 3G1 . Email: mli@math.waterloo.edu z Partially supported by NSERC International Scientific Exchange Award ISE0046203 , and by NWO through NFI Project ALADDIN under Contract number NF 62-376 . Address: CWI, Kruislaan 413 , 1098 SJ Amsterdam , The Netherlands . Email: paulv@cwi.nl to introduce fancy mathematics; our goal is to help our readers do a large part of formal language theory in the most essential , usually easiest , sometimes even obvious ways . In this paper it is only important to us to demonstrate that the application of Kolmogorov complexity in the targeted area is not restricted to trivialities . The proofs of the theorems in this paper may not be easy . However, the theorems are of the type that are used as a tool . Once derived , our theorems are easy to apply. 1.1 Prelude The first application of Kolmogorov complexity in the theory of computation was in 19 , 20 . By re-doing proofs of known results , it was shown that static, descriptional (program size) complexity of a single random string can be used to obtain lower bounds on dynamic , computational (running time) complexity. None of the inventors of Kolmogorov complexity originally had these applications in mind . Recently , Kolmogorov complexity has been applied extensively to solve classic open problems of sometimes two decades standing , 16 , 12 , 9 , 10 . For more examples see the textbook 13 . The secret of Kolmogorov complexity's success in dynamic , computational lower bound proofs rests on a simple fact: the overwhelming majority of strings has hardly any computable regularities . We call such a string 'Kolmogorov ran- dom' or `incompressible' . A Kolmogorov random string cannot be (effectively) compressed . Incompressibility", "label": ["kolmogorov complexity", "pumping lemmas", "deterministic context-free languages", "formal language theory", "regular languages", "finite automata"], "stemmed_label": ["kolmogorov complex", "pump lemma", "determinist context-fre languag", "formal languag theori", "regular languag", "finit automata"]}
{"doc": "The spectral method is the best currently known technique to prove lower bounds on expansion . Ramanujan graphs , which have asymptotically optimal second eigenvalue , are the best-known explicit expanders . The spectral method yielded a lower bound of k/4 on the expansion of linear-sized subsets of k-regular Ramanujan graphs . We improve the lower bound on the expansion of Ramanujan graphs to approximately k/2 . Moreover , we construct a family of k-regular graphs with asymptotically optimal second eigenvalue and linear expansion equal to k/2 . This shows that k/2 is the best bound one can obtain using the second eigenvalue method . We also show an upper bound of roughly 1+k-1 on the average degree of linear-sized induced subgraphs of Ramanujan graphs . This compares positively with the classical bound 2k-1 . As a byproduct , we obtain improved results on random walks on expanders and construct selection networks (respectively , extrovert graphs) of smaller size (respectively , degree) than was previously known . Introduction Expander graphs are widely used in Theoretical Computer Science , in areas ranging from parallel computation 1 , 7 , 21 , 28 , 34 to complexity theory and cryptography 2 , 8 , 16 , 35 . Given an XEROX Palo Alto Research Center , 3333 Coyote Hill Road , CA 94304 . This work was done mostly when the author was at the Massachusetts Institute of Technology , and partly at DIMACS . This work was partially supported by the Defense Advanced Research Projects Agency under Contracts N00014-92-J- 1799 and N00014-91-J-1698 , the Air Force under Contract F49620-92-J-0125 , and the Army under Contract DAAL-03-86-K-0171 . This paper was based on \"Better Expansion for Ramanujan graphs\" , by Nabil Kahale, which appeared in the 32nd Annual Symposium on Foundations of Computer Science , San Juan , Puerto Rico , October 1-4 , 1991; pp . 398-404 . c flIEEE , and on \"On the Second Eigenvalue and Linear Expansion of Regular Graphs\" , by Nabil Kahale , which appeared in the 33rd Annual Symposium on Foundations of Computer Science , Pittsburgh , Pennsylvania , October 24-27 , 1992; pp . 296-303 . c flIEEE . An updated version of the second paper appeared in DIMACS Series in Discrete Mathematics and Theoretical Computer Science , Volume 10 , 1993; pp . 49-62 . c flAmerican Mathematical Society. undirected k-regular graph E) and a subset X of V , the expansion of X is defined to be the ratio jN (X)j=jXj , where is the set of neighbors of X . An n)-expander is a k-regular graph on n nodes such that every subset of size at most ffn has expansion at least fi. It is known that random regular graphs are good expanders . In particular , for any fi there exists a constant ff such that , with high probability , all the subsets of a random k-regular graph of size at most ffn have expansion at least fi . The explicit construction of expander graphs is much more difficult , however", "label": ["expander graphs", "load balancing", "selection networks", "random walks", "induced subgraphs", "ramanujan graphs", "eigenvalues"], "stemmed_label": ["expand graph", "load balanc", "select network", "random walk", "induc subgraph", "ramanujan graph", "eigenvalu"]}
{"doc": "Constraint networks have been shown to be useful in formulating such diverse problems as scene labeling , natural language parsing , and temporal reasoning . Given a constraint network , we often wish to (i) find a solution that satisfies the constraints and (ii) find the corresponding minimal network where the constraints are as explicit as possible . Both tasks are known to be NP-complete in the general case . Task (1) is usually solved using a backtracking algorithm , and task (ii) is often solved only approximately by enforcing various levels of local consistency . In this paper , we identify a property of binary constraint called row convexity and show its usefulness in deciding when a form of local consistency called path consistency is sufficient to guarantee that a network is both minimal and globally consistent . Globally consistent networks have the property that a solution can be found without backtracking . We show that one can test for the row convexity property efficiently and we show , by examining applications of constraint networks discussed in the literature , that our results are useful in practice . Thus , we identify a class of binary constraint networks for which we can solve both tasks (i) and (ii) efficiently . Finally , we generalize the results for binary constraint networks to networks with nonbinary constraints . Introduction Constraint networks have been shown to be useful in formulating such diverse problems as graph coloring 24 , scene labeling 16 , 28 , natural language parsing 22 , and temporal reasoning 1 . A constraint network is defined by a set of variables , a domain of values for each variable , and a set of constraints between the variables . Given a constraint network , we often wish to (i) find a solution-an instantiation of the variables that satisfies the constraints and (ii) find the corresponding minimal network where the constraints are as explicit as possible . Finding the minimal network has applications in removing redundant information from a knowledge base 23 and temporal reasoning 25 . However, both tasks are known to be NP-complete in the general case . Task (i) is usually solved using a backtracking algorithm , which is exponential in the worst case but often useful in practice , and task (ii) is often solved only approximately by enforcing various levels of local consistency. In this paper , we begin by examining constraint networks with only binary constraints . We identify a property of binary constraints called row convexity and show its usefulness in deciding when a form of local consistency called path consistency is sufficient to guarantee that a network is both minimaland globally consistent . Globally consistent networks have the property that a solution can be found without backtracking . In particular , we show that if a binary constraint network is path consistent and all of the binary relations are row convex or can be made row convex , then the network is minimal and globally consistent . We also show that if there exists", "label": ["consecutive ones property", "row convexity", "relations", "constraint networks", "constraint-based reasoning", "constraint satisfaction problems", "path consistency"], "stemmed_label": ["consecut one properti", "row convex", "relat", "constraint network", "constraint-bas reason", "constraint satisfact problem", "path consist"]}
{"doc": "Consider a switching component in a packet-switching network , where messages from several incoming channels arrive and are routed to appropriate outgoing ports according to a service policy . One requirement in the design of such a system is to determine the buffer storage necessary at the input of each channel and the policy for serving these buffers that will prevent buffer overflow and the corresponding loss of messages . In this paper , a class of buffer service policies , called Least Time to Reach Bound (LTRB) , is introduced that guarantees no overflow , and for which the buffer size required at each input channel is independent of the number of channels and their relative speeds . Further , the storage requirement is only twice the maximal length of a message in all cases , and as a consequence the class is shown to be optimal in the sense that any nonoverflowing policy requires at least as much storage as LTRB . Introduction We consider a system consisting of several input channels and a single output channel. Variable length messages , with a maximumlength of L bits , arrive over each input channel and are stored in the buffer associated with that channel . The buffers are emptied into the output channel by a single server whose speed is at least as great as the aggregate speed of the input channels . The system is to be work-conserving subject to the constraint that service can only be provided to complete messages . Accordingly , the server: (a) may not begin serving a buffer until it contains at least one complete message; (b) cannot be idle if at least one buffer contains a complete message; (c) serves complete messages without interruption. Service is provided by the server according to a rule which , given the contents of each buffer at the beginning of a service period , determines the buffer to be served next . Simple examples of such a service policy include Exhaustive Round Robin and First Come First Served. The system described above can be found in various devices , e.g. , packet switches in communication networks . Here the server is the switch itself , and the service policy provides the rule that determines which buffer the switch will serve . In such systems it is important , for economic reasons , to minimize the amount of storage required in each buffer 11 . Yet the buffers must be large enough to limit overflow (the loss of messages which arrive to a full buffer) . Ideally , the buffers would be designed to eliminate overflow. Our interest is in a nonoverflowing policy that minimizes the size of the largest buffer required under any message arrival pattern . In many applications , it is also desirable that the buffer storage required for each channel be independent of the number of channels and their relative speeds . This will enable the reuse of the input channels when the system is reconfigured to allow higher speed channels or a larger number", "label": ["multiplexor", "parallel queues", "service discipline", "gradual input", "switch", "buffer overflow"], "stemmed_label": ["multiplexor", "parallel queue", "servic disciplin", "gradual input", "switch", "buffer overflow"]}
{"doc": "The MEG (minimum equivalent graph) problem is the following: \"Given a directed graph , find a smallest subset of the edges that maintains all reachability relations between nodes.\" This problem is NP-hard; this paper gives an approximation algorithm achieving a performance guarantee of about 1.64 in polynomial time . The algorithm achieves a performance guarantee of 1.75 in the time required for transitive closure . The heart of the MEG problem is the minimum SCSS (strongly connected spanning subgraph) problem --- the MEG problem restricted to strongly connected digraphs . For the minimum SCSS problem , the paper gives a practical , nearly linear-time implementation achieving a performance guarantee of 1.75 . The algorithm and its analysis are based on the simple idea of contracting long cycles . The analysis applies directly to $2$-\\Exchange , a general \"local improvement\" algorithm , showing that its performance guarantee is 1.75 . Introduction . Connectivity is fundamental to the study of graphs and graph algorithms . Recently , many approximation algorithms for finding minimumsubgraphs that meet given connectivity requirements have been developed 1 , 9 , 11 , 15 , 16 , 24 . These results provide practical approximation algorithms for NP-hard network-design problems via an increased understanding of connectivity properties. Until now , the techniques developed have been applicable only to undirected graphs . We consider a basic network-design problem in directed graphs 2 , 12 , 13 , 18 which is as follows: given a digraph , find a smallest subset of the edges (forming a minimum equivalent graph (MEG)) that maintains all reachability relations of the original graph. When the MEG problem is restricted to strongly-connected graphs we call it the minimum SCSS (strongly connected spanning subgraph) problem . When the MEG problem is restricted to acyclic graphs we call it the acyclic MEG problem . The problem reduces in linear time 5 to a single acyclic problem given by the so-called \"strong component graph\" , together with one minimumSCSS problem for each strong component (given by the subgraph induced by that component) . Furthermore, approximating the MEG problem is linear-time equivalent to approximating both restricted versions. Moyles and Thompson 18 observe this decomposition and give exponential-time algorithms for the restricted problems . Hsu 13 gives a polynomial-time algorithm for the acyclic MEG problem. The related problem of finding a transitive reduction of a digraph - a smallest set of edges yielding the same reachability relations is studied by Aho , Garey and Ullman 2 . Transitive reduction differs from the MEG problem in that the edges Computer Science Department and Institute for Advanced Computer Studies , University of Maryland , College Park , MD 20742 . Research supported by NSF Research Initiation Award CCR- y Computer Science Department , The University of Texas at Dallas , Richardson, z School of Operations Research and Industrial Engineering , Cornell University , Ithaca , NY 14853-3801 . Part of this work was done while at UMIACS and supported in part by NSF grants CCR-8906949 and CCR-9111348 . E-mail : ney@orie.cornell.edu. in the transitive reduction", "label": ["local improvement", "strong connectivity", "directed graph", "approximation algorithm"], "stemmed_label": ["local improv", "strong connect", "direct graph", "approxim algorithm"]}
{"doc": "Primal-dual interior-point methods for linear complementarity and linear programming problems solve a linear system of equations to obtain a modified Newton step at each iteration . These linear systems become increasingly ill-conditioned in the later stages of the algorithm , but the computed steps are often sufficiently accurate to be useful . We use error analysis techniques tailored to the special structure of these linear systems to explain this observation and examine how theoretically superlinear convergence of a path-following algorithm is affected by the roundoff errors . Introduction . The monotone linear complementarity problem (LCP) is the problem of finding a vector pair (x; y) 2 R l n \\Theta R l n such that (1) where M (a real , n \\Theta n positive semidefinite matrix) and q (a real vector with n are given . Note that M need not be symmetric . It is well known that (1) includes the linear programming problem as a special case . Specifically , for the linear programming formulation min z c T z subject to Az - b; z - 0; (2) where A 2 R l m\\Thetap , we can introduce the dual variable - l m for the constraint and obtain the following necessary and sufficient conditions for optimality of the primal-dual pair (z; -): z c \\Gammab z (3a) z 0: For appropriate definitions of M and q , (3) has the form (1) . Little is lost from either the practical or theoretical point of view by applying interior-point algorithms for (1) to the special cases of linear and convex quadratic programming , provided that the special structure of each problem is exploited in the solution of the linear systems at each iteration. Interior-point methods for (1) generate a sequence of iterates are strictly positive . Many such methods require a linear system of the form - u where This work was based on research supported by the Office of Scientific Computing , U.S . Department of Energy , under Contract W-31-109-Eng-38. y Mathematics and Computer Science Division , Argonne National Laboratory , 9700 South Cass Avenue , Argonne , IL 60439. to be solved for a search direction (u; v) at each iteration . Affine-scaling methods solve (4) with to find a search direction , then step a fraction of the distance along this direction to the boundary of the nonnegative orthant defined by (x; y) - 0 . Affine- scaling steps (u; v) are simply Newton steps for the system of nonlinear equations Path-following methods (see , for example , Monteiro and Adler 10 , Zhang 19 , Wright 14 ) generate steps by using generally positive values of oe in (4) . (As we see later , the algorithm of 14 allows some iterates in an attempt to attain the rapid local convergence associated with Newton's method.) Potential-reduction methods (see, for example , Kojima , Mizuno , and Yoshise 6 , Kojima , Kurita , and Mizuno 5 ) also determine search directions by solving systems like (4) , but they refer to a logarithmic", "label": ["primal-dual interior-point methods", "error analysis", "stability"], "stemmed_label": ["primal-du interior-point method", "error analysi", "stabil"]}
{"doc": "This paper studies a notion called polynomial-time membership comparable sets . For a function $g$ , a set $A$ is polynomial-time $g$-membership comparable if there is a polynomial-time computable function $f$ such that for any $x_1 , \\cdots , x_m$ with $m \\geq g(\\max\\ |x_1| , \\cdots , |x_m| \\ )$ , outputs $b \\in \\ 0,1\\ ^m$ such that $(A(x_1) , \\cdots , A(x_m)) \\neq b$ . The following is a list of major results proven in the paper . 1 . Polynomial-time membership comparable sets construct a proper hierarchy according to the bound on the number of arguments . 2 . Polynomial-time membership comparable sets have polynomial-size circuits . 3 . For any function $f$ and for any constant $c 0$ , if a set is $\\leq^p_ f(n)-tt $-reducible to a P-selective set , then the set is polynomial-time $(1+c)\\log f(n)$-membership comparable . 4 . For any $\\cal C$ chosen from $\\ \\rm PSPACE , UP , FewP , NP , C_ = P , PP , MOD_ 2 P , MOD_ 3 , \\cdots \\ $ , if $\\cal C \\subseteq \\rm P-mc (c\\log n)$ for some $c 1$ , then $\\cal As a corollary of the last two results , it is shown that if there is some constant $c 1$ such that all of $\\cal C$ are polynomial-time $n^c$-truth-table reducible to some P-selective sets , then $\\cal which resolves a question that has been left open for a long time . Introduction Given two strings x and y , can we tell which is more likely to be in a set A? Jockusch Joc68 defined a set A to be semirecursive if there is a recursive function f such that for all x and y, A . We call the function f a selector for A . Selman Sel79 considered a polynomial-time analogue of semirecursive sets and defined a set A to be P-selective if A has a polynomial-time computable selector . P-selective sets have been widely studied Sel82b , Sel79 , Sel82a , AH92 , Ko83 , Tod91 , LS93 , BvHT93, Recently , there have been some remarkable results about P-selective sets . Buhrman , van Helden , and Torenvliet BvHT93 have shown that a set is in P if and only if it is - T -self-reducible and P-selective , while previously known characterization is A 2 P if and only if A is - ptt -self-reducible and P-selective Sel82b . Naik et al NOS93 , HNOS93 have proven , by constructing P-selective sets with certain properties , that NP search problems are not reducible to corresponding decision problems unless some implausible collapses of exponential-time complexity classes occur . Hemachan- dra et al HHO studied internal structure of the class of sets - T -reducible to P-selective sets and introduced the notion of FC-selectivity for various function classes FC . Hemas- paandra , Naik , Ogiwara , and Selman HNOS94 have studied sets with nondeterministically polynomial-time computable selectors , and proven that if there is an NP-function that computes satisfying assignments uniquely , then", "label": ["polynomial-size circuits", "polynomial-time reducibilities", "p-selective sets"], "stemmed_label": ["polynomial-s circuit", "polynomial-tim reduc", "p-select set"]}
{"doc": "There has been rapid growth in the demand for mobile communications over the past few years . This has led to intensive research and development efforts for complex PCS (personal communication service) networks . Capacity planning and performance modeling is necessary to maintain a high quality of service to the mobile subscriber while minimizing cost to the PCS provider . The need for flexible analysis tools and the high computational requirements of large PCS network simulations make it an excellent candidate for parallel simulation.Here , we describe our experiences in developing two PCS simulation models on a general purpose distributed simulation platform based on the Time Warp mechanism . These models utilize two widely used approaches to simulating PCS networks: (i) the call-initiated and (ii) the portable-initiated models . We discuss design decisions that were made in mapping these models to the Time Warp executive , and characterize the workloads resulting from these models in terms of factors such as communication locality and computation granularity . We then present performance measurements for their execution on a network of workstations . These measurements indicate that the call-initiated model generally outperforms the portable initiated model , but is not able to capture phenomenon such as the busy line effect . Moreover , these studies indicate that the high locality in large-scale PCS network simulations make them well-suited for execution on general purpose parallel and distributed simulation platforms . Introduction A personal communication service (PCS) network 3 provides wireless communication services for nomadic users . The service area of a PCS network is populated with a set of geographically distributed transmitters/receivers called radio ports. A set of radio channels are assigned to each radio port , and the users in the coverage area (or cell for the radio port) can send and receive phone calls by using these radio channels . When a user moves from one cell to another during a phone call a hand-off is said to occur . In this case the PCS network attempts to allocate a radio channel in the new cell to allow the phone call connection to continue . If all channels in the new cell are busy, then the phone call is forced to terminate . It is important to engineer the system so that the likelihood of force termination is very low (e.g. , less than 1%). Traditionally , analytic models have been used to understand the performance characteristics of these types of networks. However , analytic models are often not sufficiently general or flexible because they must make simplifying assumptions about the system parameters to make the analysis tractable . For ex- ample , the blocking probability of a fixed channel assignment PCS network can be modeled analytically using the Erlang-B system 11 , 20 . However , the Erlang-B system is only appropriate for predicting the blocking probability b when the Figure 1: Estimating the problem size3.63.84.0 e r 500 1000 1500 2000 (a) The impact of network size e r c e (b) The impact of network size r c simulated sec (c)", "label": ["performance measurements", "mobile communications", "pcs networks", "time warp", "personal communication service", "discrete event simulation", "telecommunication computing", "time warp simulation", "distributed", "parallel", "flexible analysis tools", "simulation platforms", "mobile communication"], "stemmed_label": ["perform measur", "mobil commun", "pc network", "time warp", "person commun servic", "discret event simul", "telecommun comput", "time warp simul", "distribut", "parallel", "flexibl analysi tool", "simul platform", "mobil commun"]}
{"doc": "In a distributed memory environment the communication overhead of Time Warp as induced by the rollback procedure due to overoptimistic progression of the simulation is the dominating performance factor . To limit optimism to an extent that can be justified from the inherent model parallelism , an optimism control mechanism is proposed , which by maintaining a history record of virtual time differences from the time stamps carried by arriving messages , and forecasting the timestamps of forthcoming messages , probabilistically delays the execution of scheduled events to avoid potential rollback and associated communication overhead (antimessages) . After investigating statistical forecast methods which express only the central tendency of the arrival process , we demonstrate that arrival processes in the context of Time Warp simulations of timed Petri nets have certain predictable and consistent ARIMA characteristics , which encourage the use of sophisticated and recursive forecast procedures based on those models . Adaptiveness is achieved in two respects: the synchronization behavior of logical processes automatically progressing and conservatively blocking , that is the most adequate for (i) the specific simulation model and (ii) the communication/computation speed characteristics of the underlying execution platform . Introduction The distributed simulation of event occurrences by a set of logical processes (LPs) executing asynchronously in parallel generates the same sequence of event occurrences that a sequential simulator would have produced , provided that every LP simulates events in nondecreasing timestamp order only . Although sufficient , it is not always necessary to obey this \"local causality constraint\" (lcc) 13 because events may be independent of each other with respect to their impact on the simulation future (concurrent events) . Generally , therefore , a distributed discrete event simulation (DDES) insures correctness if the partial event ordering produced by the LPs executing concurrently is consistent with the total event ordering generated by a (hypothetical) sequential , discrete event simulation 17 . The Time Warp (TW) 16 DDES protocol , as opposed to the conservative Chandy-Misra-Bryant (CMB) protocols optimistically ignores lcc by letting causality errors occur , but employs a rollback mechanism to recover from causality violations immediately upon or after their detection . The rollback procedure relies on the recon- structability of past states , which can be guaranteed by a systematic state saving policy and corresponding state re-construction procedures . Performance inefficiencies caused by potentially excessive amounts of memory consumption for storing state histories , or by the waste of CPU cycles due to overoptimistically progressing simulations that eventually have to be \"rolled back\" are not present in CMB protocols . On the other hand , while CMB protocols need to verify whether it is safe to process an event (with respect to lcc) , TW is not reliant on any information coming from the simulation model (e.g . lookahead) . Furthermore, the severe performance degrade imposed on CMB by the mandatory deadlock management strategy is relieved from TW in a natural way , since deadlocks due to cyclic waiting conditions for messages able to make \"unsafe\" events safe to process by exploiting information from their timestamps", "label": ["rs6000 cluster", "time warp", "forecast models", "optimism control", "pvm", "petri nets"], "stemmed_label": ["rs6000 cluster", "time warp", "forecast model", "optim control", "pvm", "petri net"]}
{"doc": "Critical path analysis has been suggested as a technique for establishing a lower bound on the completion times of parallel discrete event simulations . A protocol is super-critical if there is at least one simulation that can complete in less than the critical path time using that protocol . Previous studies have shown that several practical protocols are super-critical while others are not . We present a sufficient condition to demonstrate that a protocol is super-criticality . It has been claimed that super-criticality requires independence of one or more messages (states) on events in the logical past of those messages (states) . We present an example which contradicts this claim and examine the implications of this contradiction on lower bounds . Introduction One of the techniques that has been suggested to derive a theoretical lower bound on the completion time of all parallel discrete-event simulations (PDES) is critical path analysis . This application of critical path analysis is particularly interesting because of the somewhat counter-intuitive result that it is possible for certain simulations to complete in less than the critical path time , a phenomenon we call super-critical speed . We say a protocol is super-critical if it is possible for at least one simulation using that protocol to complete in super-critical time . There are several practical protocols that are super-critical and several that are not JeRe91(6) . In this paper , we re-examine two issues concerned with super-critical speed: (i) a sufficient condition to demonstrate a protocol is super-critical , and (ii) the requirement for super- criticality , of independence of messages or states on events earlier in logical time. Berry and Jefferson BeJe85(2) applied critical path analysis to PDES and argued that the critical path time is a lower bound on the completion time . In Berr86(1) , JeRe91(6) it was shown that certain variants of the Time Warp protocol Jeff85(5) are super-critical . In particular , JeRe91(6) presented a criterion for super-criticality and used it to show that four protocols were super-critical . These results showed that the critical path time is not a lower bound for all PDES's . Lin and Lazowska LiLa91(8) proposed a lower bound that applies to all PDES's but is a very loose one since it requires that each LP guess all of its computation correctly . These early analyses defined inter-event dependence based on the timestamps of events and messages . This scheme has the disadvantage of incorrectly assuming some pairs of events to be dependent when in fact there is no semantic dependence between them . Recently , Gunter Gunt94a(3) has proposed an enhanced definition of dependence which attempts to overcome this limitation . Based on this definition , he contends that independence is necessary for super-criticality and derives a new lower bound which is tighter than that of LiLa91(8) . This paper makes two contributions: We present a sufficient condition for a protocol to be super-critical (recall that a super-critical protocol allows the possibility of super-critical speed; it does not guarantee it). We show that the condition used in JeRe91(6)", "label": ["protocol", "critical path analysis", "discrete event simulation", "parallel discrete event simulations", "lower bound", "protocols"], "stemmed_label": ["protocol", "critic path analysi", "discret event simul", "parallel discret event simul", "lower bound", "protocol"]}
{"doc": "Mechanisms for managing message buffers in Time Warp parallel simulations executing on cache-coherent shared-memory multiprocessors are studied . Two simple buffer management strategies called the sender pool and receiver pool mechanisms are examined with respect to their efficiency , and in particular , their interaction with multiprocessor cache-coherence protocols . Measurements of implementations on a Kendall Square Research KSR-2 machine using both synthetic workloads and benchmark applications demonstrate that sender pools offer significant performance advantages over receiver pools . However , it is also observed that both schemes , especially the sender pool mechanism , are prone to severe performance degradations due to poor locality of reference in large simulations using substantial amounts of message buffer memory . A third strategy called the partitioned buffer pool approach is proposed that exploits the advantages of sender pools , but exhibits much better locality . Measurements of this approach indicate that the partitioned pool mechanism yields substantially better performance than both the sender and receiver pool schemes for large-scale , small-granularity parallel simulation applications.The central conclusions from this study are: (1) buffer management strategies play an important role in determining the overall efficiency of multiprocessor-based parallel simulators , and (2) the partitioned buffer pool organization offers significantly better performance than the sender and receiver pool schemes . These studies demonstrate that poor performance may result if proper attention is not paid to realizing an efficient buffer management mechanism . Introduction Large-scale shared-memory multiprocessors such as the Kendall Square Research KSR-2 and (more recently) the Convex SPP are an important class of parallel computers for high performance computing applications . Recently , shared-memory machines have become popular compute servers , with multi-processor \"workstations\" such as the SGI Challenge and Sun SparcServer becoming common in engineering and scientific computing laboratories . As technological advances enable multiple CPUs to be placed within a single chip or substrate of a multi-chip module , the simpler programming model offered by shared-memory machines will enable them to remain an important class of parallel computers in the foreseeable future. It is well known that many large-scale discrete event simulation computations are excessively time consuming , and are a natural candidate for parallel computation . Time Warp is a well known synchronization protocol that detects out-of-order executions of events as they occur , and recovers using a rollback mechanism 8 . Time Warp has demonstrated some success in speeding up simulations of combat models 14 , communication networks 12 , queuing networks 4 , and digital logic circuits 1 , among others . We assume that the reader is familiar with the Time Warp mechanism described in 8 . Here , we are concerned with the efficient implementation of Time Warp on shared-memory multiprocessor computers . While prior work in this area has focused on data structures 4 , synchronization 9 , or implementation of shared state 6 , 11 , we are concerned here with efficient buffer management strategies for message passing in shared-memory machines. We assume that the hardware platform is a cache-coherent, shared-memory multiprocessor . The commercial machines mentioned", "label": ["message passing", "message buffers", "mall-granularity parallel simulation applications", "severe performance degradations", "storage management", "shared memory systems", "buffer management", "shared-memory time warp systems", "kendall square research ksr-2 machine", "receiver pool", "discrete event simulation", "time warp simulation", "message buffer memory", "multiprocessor cache-coherence protocols", "sender pool", "partitioned pool mechanism", "cache-coherent shared-memory multiprocessors", "partitioned buffer pool approach", "multiprocessing programs", "multiprocessor-based parallel simulators", "buffer storage"], "stemmed_label": ["messag pass", "messag buffer", "mall-granular parallel simul applic", "sever perform degrad", "storag manag", "share memori system", "buffer manag", "shared-memori time warp system", "kendal squar research ksr-2 machin", "receiv pool", "discret event simul", "time warp simul", "messag buffer memori", "multiprocessor cache-coher protocol", "sender pool", "partit pool mechan", "cache-coher shared-memori multiprocessor", "partit buffer pool approach", "multiprocess program", "multiprocessor-bas parallel simul", "buffer storag"]}
{"doc": "In practice , time critical portions of hard real-time systems are still implemented in low-level programming languages and manually tuned to meet all the timing requirements . Without a real-time language that supports an appropriate way of specifying timing constraints for a generic hard real-time systems , and high precision timing analysis that is transparent to users , the users will ever suffer from the complex coding and analysis , particularly for systems requiring fast turnaround responses.In this paper , we propose novel language constructs that can be added to any imperative programming language so that the extended language provides users a way to specify relative timing constraints between arbitrary operations at instruction-level . The compilation techniques unique to transformation of the proposed language are also presented as a part of CHaRTS , the Compiler for Hard Real-Time Systems , which generates a valid instruction sequence for a target execution model . Introduction In our view of real-time systems , a real-time system consists of a controlling subsystem and controlled entities. A controlling subsystem is a set of computer systems, while the controlled entities can be any of a broad range of systems with mechanical behavior , any device from a simple blender to a complex robot 19 . Typically , a controlling subsystem executes control programs to receive input from the environment and/or to send commands to the controlled entities appropriately. For a real-time system to function correctly , the control program must be logically correct and the controlling subsystem must execute the program without timing faults . Either a failure to perform an action at the appropriate time or a flaw in the control program's logic can yield catastrophic consequences in hard real-time systems . Thus , meeting the timing constraints is extremely important in such systems. Based on when the control program is scheduled, real-time systems can be divided into two categories: dynamic and static . Execution order of control tasks in a dynamic system is determined on-the-fly at run-time by a scheduler that examines the current status of the system; often , this scheduler is a part of the operating system . Even though the dynamic systems are flexible, they suffer from scheduling overhead and unpredictable risks. In contrast , a static system is scheduled at compile time based on analysis of the program , timing con- straints , and resource use predictions 16 . A static system schedules the execution order at compile time based on the predicted behavior of the controlled entities and the timing properties of the controlling subsys- tems . Thus , the static system guarantees that properly scheduled code will function without a timing failure. However , despite the fact that guaranteed timely execution makes the static systems very attractive in a hard real-time environment , the high-precision static systems have received little attention due to: 1 . Unpredictable machine behavior: general-purpose processors often implement instructions with execution time dependent on operand values , pipeline conflicts , or memory hierarchy use (e.g. , cache misses , dynamic RAM refresh , virtual memory page", "label": ["hard real-time", "timing constraint", "charts", "real-time language"], "stemmed_label": ["hard real-tim", "time constraint", "chart", "real-tim languag"]}
{"doc": "A new method is presented for visualizing data as they are generated from real-time applications . These techniques allow viewers to perform simple data analysis tasks such as detection of data groups and boundaries , target detection , and estimation . The goal is to do this rapidly and accurately on a dynamic sequence of data frames . Our techniques take advantage of an ability of the human visual system called preattentive processing . Preattentive processing refers to an initial organization of the visual system based on operations believed to be rapid , automatic , and spatially parallel . Examples of visual features that can be detected in this way include hue , orientation , intensity , size , curvature , and line length . We believe that studies from preattentive processing should be used to assist in the design of visualization tools , especially those for which high speed target , boundary , and region detection are important . Previous work has shown that results from research in preattentive processing can be used to build visualization tools that allow rapid and accurate analysis of individual , static data frames . We extend these techniques to a dynamic real-time environment . This allows users to perform similar tasks on dynamic sequences of frames , exactly like those generated by real-time systems such as visual interactive simulation . We studied two known preattentive features , hue and curvature . The primary question investigated was whether rapid and accurate target and boundary detection in dynamic sequences is possible using these features . Behavioral experiments were run that simulated displays from our preattentive visualization tools . Analysis of the results of the experiments showed that rapid and accurate target and boundary detection is possible with both hue and curvature . A second question , whether interactions occur between the two features in a real-time environment , was answered positively . INTRODUCTION The field of scientific visualization draws on research from a wide spectrum of traditional disciplines . These include computer science , psychology , and the visual arts . The \"domain of visualization\" , as defined by a National Science Foundation panel on scientific computing , includes the development of specific applications , the development of general purpose tools , and the study of research problems that arise in the process McCormick et al. , 1987; Rosenblum, 1994 . To date , most research efforts have focused on ad hoc visualization applications . Relatively few efforts have formulated general guidelines for the design of visualization tools. In this paper , we report on new work that derives from an area of cognitive psychology known as preattentive processing . This work is part of an on-going investigation whose goal is a set of guidelines for visualization design. Authors' addresses: C.G . Healey and K.S . Booth , Imager Computer Graphics Laboratory , Department of Computer Science , 2366 Main Mall , University of British Columbia , Vancouver , British Columbia , V6T 1Z4 , Canada; healey@cs.ubc.ca , ksbooth@cs.ubc.ca . James T. Enns , Department of Psychology", "label": ["target detection", "curvature", "visual interactive simulation", "preattentive", "scientific visualization", "multivariate data", "human vision", "boundary detection", "cognitive psychology"], "stemmed_label": ["target detect", "curvatur", "visual interact simul", "preattent", "scientif visual", "multivari data", "human vision", "boundari detect", "cognit psycholog"]}
{"doc": "We describe a system for off-line production and real-time playback of motion for articulated human figures in 3D virtual environments . The key notion are (1) the logical storage of full-body motion in posture graphs , which provides a simple motion access method for playback , and (2) mapping the motions of high DOF figures to lower DOF figures using slaving to provide human models at several levels of detail , both in geometry and articulation , for later playback . We present our system in the context of a simple problem: animating human figures in a distributed simulation , using DIS protocols for communicating the human state information . We also discuss several related techniques for real-time animation of articulated figures in visual simulation . Introduction The ability to render realistic motion is an essential part of many virtual environment and visual simulation applications . Nowhere is this more true than in virtual worlds containing simulated humans . Whether these human figures represent the users' virtual personae (avatars) or computer-controlled characters, people's innate sensitivity as to what looks ``natural'' with respect to human motion demands , at the very least , that moving characters be updated with each new frame that the image generator produces. We first discuss a topical problem in visual simulation which requires the real-time rendering of realistic human motion , and then describe our system for authoring the motion off-line , and playing back that motion in real time . We also address some of the issues in real-time image generation of highly-articulated figures , as well as look at several other methods used for real-time animation. Human motion in DIS The problem we are interested in is generating and displaying motion for human figures , in particular soldiers , in a distributed virtual environment . Parts of the general problem and the need for representing simulated soldiers (referred to as Dismounted Infantry , or DIs) , are covered in 21 , 5 . Although primarily driven by military requirements today , the general technologies for projecting real humans into , and representing simulated humans within , virtual environ- ments , should be widely applicable in industry , entertainment and commerce in the near future. The Distributed Interactive Simulation (DIS) 9 protocol is used for defining and communicating human state information in the distributed virtual environment A typical distributed simulation contains many simulation hosts , each concerned with simulating a portion , or sub-set , of all the objects (or entities) involved in a simulation (here , entity can refer to a human figure , a vehicle , or other part of the environment) and processes involved in the simulation. DIS defines a protocol for heterogeneous simulation applications to inter- operate , typically for the real-time simulation of battlefield operations . It defines the packets of information (which are referred to as protocol data units - PDUs) and the set of rules for exchanging the packets between simulation applications , with the goal of achieving a shared and correlated synthetic environment between the applications . For a", "label": ["multiresolution motion", "posture graphs", "animation", "visual simulation", "real-time animation"], "stemmed_label": ["multiresolut motion", "postur graph", "anim", "visual simul", "real-tim anim"]}
{"doc": "AbstractThis correspondence presents a new technique for calibrating a camera mounted on a controllable head/eye platform . It uses the trajectories of an arbitrary number of tracked corner features to improve the calibration parameter estimates over time , utilizing a novel variable state dimension form of recursive filter . No special visual stimuli are required and no assumptions are made about the structure of the scene , other than that it is stationary relative to the head . The algorithm runs at 4 frames per second on a single Inmos T805 transputer , and is fully integrated into a real-time active vision system . Updated calibration parameters are regularly passed to the vision modules that require them . Although the algorithm requires an initial estimate of camera focal length , results are presented from real experiments demonstrating that convergence is achieved for initial errors up to 50% . Introduction Scene reconstruction and object recognition are areas of computer vision which have been plagued by the need for accurate camera calibration 19 . Calibration typically requires objects made to high precision to be placed in front of the cameras 13 , 8 and requires considerable experimental care , making the methods impractical for an autonomous robot acting in an unstructured world. For these reasons much emphasis has been placed recently in the fields of structure from motion 12 , stereo 7 , object recognition 21 and active vision 5 on algorithms that obviate camera calibration . However , when vision is to control robotic systems , there seems a limit to how far these ideas can be pushed . In order to make controlled motions , an active system must convert image quantities into angles and distances, requiring calibration of some form . For example , consider 1D fixation on a target point P which corresponds under perspective projection to a point x in the image . If the focal length is f , and igonoring any image distortions , the angle that the camera must turn through to fixate P is first sight, one of the merits of an active system exploiting visual feedback is that it can redirect gaze without knowing f . However , if one underestimates f , the value for ' is overestimated , and vice versa , so that the choice of f affects the damping of the fixation control system. In this correspondence we describe a calibration method which exploits our head/eye platform's ability to make precisely known head movements while robustly tracking stationary points in an unstructured world . The approach is novel in several ways . First it utilises all measurements of image features tracked through multiple images in a computationally efficient and statistically principled manner . Secondly , the process is fully integrated into our real-time reactive vision system for gaze control 18 , 17 and provides continual updates of calibration parameters to the other vision modules . Thirdly , the algorithm uses a novel form of recursive filter , which allows observations from an arbitrary number of tracked features to be incorpo-", "label": ["recursive filter", "active vision", "real-time vision", "camera calibration"], "stemmed_label": ["recurs filter", "activ vision", "real-tim vision", "camera calibr"]}
{"doc": "AbstractA multiscale morphological dilation-erosion smoothing operation and its associated scale-space expansion for multidimensional signals are proposed . Properties of this smoothing operation are developed and , in particular a scale-space monotonic property for signal extrema is demonstrated . Scale-space fingerprints from this approach have advantages over Gaussian scale-space fingerprints in that they are defined for negative values of the scale parameter; have monotonic properties in two and higher dimensions , do not cause features to be shifted by the smoothing , and allow efficient computation . The application of reduced multiscale dilation-erosion fingerprints to the surface matching of terrain is demonstrated . Introduction There has been an increasing trend to use multiple scales in parallel in image analysis and computer vision since the pioneering work of Marr and colleagues who appreciated that the multiscale analysis of images offers many benefits 1 , 2 , 3 , 4 . A major difficulty with any multiscale approach is: how do we relate information obtained at one scale to that obtained at another? Do we not just have a stack of different signal descriptions? One solution to this problem lies in embedding this stack of descriptions in a mathematical space known as \"scale-space\" 5 . Then the signal features form continuous paths in this scale-space and can be tracked from scale-to-scale . Suppose we have a signal, R and a smoothing kernel g(x; oe) : R n \\Theta R! R . The signal smoothed at scale oe is then given by F : R n \\Theta R! R: where denotes convolution . F is a function on the (n 1)-dimensional space called \"scale-space\"and is known as the \"scale-space image\" of the signal 5 . The ideas behind scale-space first appeared in a report on expert systems by Stansfield 6 who was looking at ways to extract features from graphs of commodity prices . The May 11 , 1995 scale-space concept was named , formalised , and brought to image analysis by Witkin 5 , 7 . Both these authors used Gaussian functions as the smoothing kernel: (2) The idea is elegant: if scale is considered as a continuous variable rather than a parameter, then a signal feature at one scale is identified with that at another scale if they lie on the same feature path in the resulting \"scale-space\" . This technique provides a means for \" . managing the ambiguity of scale in an organized and natural way\" 5 . A central idea in Witkin's work is that important signal features would persist through to relatively coarse scales even though their location may be distorted by the filtering process . However by \"coarse-to-fine tracking\" they could be tracked back down a path in scale-space to zero scale to be located exactly on the original signal . In this way the benefit of large smoothing to detect the major features could be combined with precise localisation . In a way these linkages across scale are used to overcome the \"uncertainty principle\" which states that spatial localisation and frequency domain localisation are conflicting requirements 8 .", "label": ["scale-space fingerprints", "scale-space filtering", "monotonic property", "multiscale morphology", "signal analysis"], "stemmed_label": ["scale-spac fingerprint", "scale-spac filter", "monoton properti", "multiscal morpholog", "signal analysi"]}
{"doc": "We study different genetic algorithm operators for one permutation problem associated with the Human Genome Projectthe assembly of DNA sequence fragments from a parent clone whose sequence is unknown into a consensus sequence corresponding to the parent sequence . The sorted-order representation , which does not require specialized operators , is compared with a more traditional permutation representation , which does require specialized operators . The two representations and their associated operators are compared on problems ranging from 2K to 34K base pairs (KB) . Edge-recombination crossover used in conjunction with several specialized operators is found to perform best in these experiments&semi; these operators solved a 10KB sequence , consisting of 177 fragments , with no manual intervention . Natural building blocks in the problem are exploited at progressively higher levels through macro-operators . This significantly improves performance . Introduction The computational problems posed by the Human Genome Project are challenging both because they are complex and because they involve large quantities of data. The Human Genome Project plans to identify the exact sequence of base pairs, called a map , for the entire human genome which consists of approximately 3 billion base pairs . There are many different components to this project; our problem involves combining partial information about the sequences of DNA fragments into a consistent map that accounts for the known pieces. We explore the application of a genetic algorithm to the problem of DNA fragment assembly . We draw parallels to a more familiar permutation problem , the Traveling Salesman Problem (Lawler , Rinnooy Kan , & Shmoys 1985) , both to explicate interesting features of our problem and as a source for possibly useful heuristics . Specifically , we find that the use of specialized operators provides good performance on data sets up to about 10KB in size . Two of these specialized op- erators , transposition and inversion , are macro-operators in that they transform the individual based on groups of fragments as opposed to single fragments . These groups of fragments , called contigs , are the natural building blocks for the fragment assembly problem . We found adding these macro-operators , which operate directly on the building blocks , significantly increased the performance of the genetic algo- rithm . Throughout the course of a run , the genetic algorithm assembles larger and larger building blocks (contigs) , and the macro-operators thus operate at a higher and higher level . This progression is an explicit example of the implicit behavior described by the building-blocks hypothesis. The accuracy of the various sequencing processes constrain laboratory approaches to DNA sequencing (Howe & Ward 1989); (Hunkapiller , Kaiser , & Hood 1991); (Hunkapiller et al . 1991); (Churchill et al . 1993) . Currently , strands of DNA longer than approximately 500 base pairs cannot routinely be sequenced accurately . Con- sequently , large strands of DNA are broken into smaller pieces for sequencing . In the shotgun sequencing method , to which this work applies , DNA is first replicated many times , and then individual strands", "label": ["edge-recombination crossover", "dna fragment assembly", "ordering problems", "genetic algorithms", "building blocks", "human genome project"], "stemmed_label": ["edge-recombin crossov", "dna fragment assembl", "order problem", "genet algorithm", "build block", "human genom project"]}
{"doc": "The MEME algorithm extends the expectation maximization (EM) algorithm for identifying motifs in unaligned biopolymer sequences . The aim of MEME is to discover new motifs in a set of biopolymer sequences where little or nothing is known in advance about any motifs that may be present . MEME innovations expand the range of problems which can be solved using EM and increase the chance of finding good solutions . First , subsequences which actually occur in the biopolymer sequences are used as starting points for the EM algorithm to increase the probability of finding globally optimal motifs . Second , the assumption that each sequence contains exactly one occurrence of the shared motif is removed . This allows multiple appearances of a motif to occur in any sequence and permits the algorithm to ignore sequences with no appearance of the shared motif , increasing its resistance to noisy data . Third , a method for probabilistically erasing shared motifs after they are found is incorporated so that several distinct motifs can be found in the same set of sequences , both when different motifs appear in different sequences and when a single sequence may contain multiple motifs . Experiments show that MEME can discover both the CRP and LexA binding sites from a set of sequences which contain one or both sites , and that MEME can discover both the 10 and 35 promoter regions in a set of E . coli sequences . Introduction The problem addressed by this work is that of identifying and characterizing shared motifs in a set of unaligned genetic or protein sequences . A motif is defined here as a pattern common to a set of nucleic or amino acid subsequences which share some biological property of interest such as being DNA binding sites for a regulatory protein . In computer science terminology , the problem is , given a set of strings , to find a set of non-overlapping , approximately matching substrings . In this report we are concerned only with contiguous motifs . In biological terms , this means that appearances of a motif may differ in point mutations , but insertions or deletions are not allowed . In computer science terms , this means that the approximately matching substrings must all have the same length . A simpler version of the problem is , given a dataset of biopolymer sequences believed to contain a single shared motif, to locate the starting position in each sequence of the appearance of the shared motif and to describe the shared motif . This report addresses the more general problem of finding and describing multiple , distinct shared motifs in a set of biopolymer 52 TIMOTHY L . BAILEY AND CHARLES ELKAN sequences . It is not assumed that anything is known in advance about the width, position or letter frequencies of the motifs , or even how many common motifs may exist in a set of sequences. Several methods have been presented in the literature which work on problems related to discovering multiple ,", "label": ["binding site", "motif", "expectation maximization", "dna", "unsupervised learning", "promoter", "biopolymer", "consensus sequence", "protein", "sequence analysis"], "stemmed_label": ["bind site", "motif", "expect maxim", "dna", "unsupervis learn", "promot", "biopolym", "consensu sequenc", "protein", "sequenc analysi"]}
{"doc": "In this introduction , we define the term bias as it is used in machine learning systems . We motivate the importance of automated methods for evaluating and selecting biases using a framework of bias selection as search in bias and meta-bias spaces . Recent research in the field of machine learning bias is summarized . Introduction This special issue of Machine Learning focuses on the evaluation and selection of biases . The papers in this issue describe methods by which intelligent systems automatically evaluate and select their own biases , and tools for analyzing and testing various approaches to bias selection . In this paper , we motivate the importance of this topic . Since most readers will be familiar with supervised concept learning , we phrase our discussion within that framework . However , bias as we present it here is a part of every type of learning. We outline a framework for treating bias selection as a process of designing appropriate search methods over the bias and meta-bias spaces . This framework has two essential features: it divides bias into representational and procedural compo- nents , and it characterizes learning as search within multiple tiers . The sources of bias within a system can thus be identified and analyzed with respect to their influence on this multi-tiered search process , and bias shift becomes search at the bias level . The framework provides an analytic tool with which to compare different systems (including those not developed within the framework) , as well as an abstract formalism and architecture to guide the development of new systems. We begin by defining what we mean by the term bias . Next , we explain why the selection and evaluation of biases is a critical task for intelligent systems . We then describe our search-based framework for bias selection . Finally , we survey recent research in this field , using the concepts developed in our framework to guide the discussion. M . desJARDINS AND D . GORDON 2 . What is a bias? Mitchell 23 defines bias as \"any basis for choosing one generalization over an- other , other than strict consistency with the instances.\" We broaden this definition to include any factor (including consistency with the instances) that influences the definition or selection of inductive hypotheses . 1 There are two major types of bias: representational and procedural . Background (e.g. , task) knowledge has sometimes been considered to be a bias as well 17 . However , since knowledge has the supportive role of providing information to select a representational or procedural bias, here we do not consider it to be a bias per se. A representational bias defines the states in a search space . Typically , this search space is the space of hypotheses . A representational bias specifies a language (such as first-order predicate calculus or a restriction to disjunctive normal form (DNF) expressions) , an implementation for this language (e.g. , DNF can be implemented using rules or decision trees) , and a set of primitive", "label": ["concept learning"], "stemmed_label": ["concept learn"]}
{"doc": "AbstractRun-time data redistribution can enhance algorithm performance in distributed-memory machines . Explicit redistribution of data can be performed between algorithm phases when a different data decomposition is expected to deliver increased performance for a subsequent phase of computation . Redistribution , however , represents increased program overhead as algorithm computation is discontinued while data are exchanged among processor memories . In this paper , we present a technique that minimizes the amount of data exchange for BLOCK to CYCLIC(c) (or vice-versa) redistributions of arbitrary number of dimensions . Preserving the semantics of the target (destination) distribution pattern , the technique manipulates the data to logical processor mapping of the target pattern . When implemented on an IBM SP , the mapping technique demonstrates redistribution performance improvements of approximately 40% over traditional data to processor mapping . Relative to the traditional mapping technique , the proposed method affords greater flexibility in specifying precisely which data elements are redistributed and which elements remain on-processor . Introduction In an effort to standardize data-parallel Fortran programming for distributed-memory machines, the High Performance Fortran Forum , composed of over forty academic , industrial , and governmental agencies , has proposed HPF (High Performance Fortran) 1 . Many of the concepts originally proposed in Fortran D 2 , Vienna Fortran 3 , and other data-parallel Fortran languages have been incorporated in HPF . A fundamental component of HPF is the specification of the distribution and alignment of data arrays through compiler directives . Due to the non-uniform memory access times characteristic of distributed-memory machines , determining an appropriate data decomposition is critical to the performance of data-parallel programs on these machines . Data distribution deals with how data arrays should be distributed among processor memories , while data alignment specifies the collocation of data arrays . The goal of data decomposition is to maximize system performance by balancing the computational load among the processors and by minimizing remote memory accesses (or communication messages). A data distribution that is well-suited for one phase of an algorithm may not be good , in terms of performance , for a subsequent phase; therefore , HPF supports explicit run-time data redistribution. Redistribution may also occur (implicitly) at subprogram boundaries or as the result of other run-time operations , e.g. , data realignment . The use of data redistribution represents a performance tradeoff between the expected higher efficiency of a new distribution for subsequent computation and the communication cost of redistributing the data among processor memories . Consequently, minimizing the execution time of data redistribution has obvious merit . Reducing the amount of data exchanged among processor memories is one possible optimization toward reducing overall redistribution execution time; this is the subject of this paper. We present a technique that minimizes the amount of data exchanged among processor memories for BLOCK to CYCLIC(c) (or vice-versa) redistributions of arbitrary number of dimensions. Preserving the semantics of the target (destination) distribution pattern , the technique manipulates the data to logical processor mapping of the target pattern . For clearer presentation of the mapping technique ,", "label": ["data redistribution", "data-parallel programming", "data decomposition", "processor mapping", "distributed-memory architectures", "high performance fortran"], "stemmed_label": ["data redistribut", "data-parallel program", "data decomposit", "processor map", "distributed-memori architectur", "high perform fortran"]}
{"doc": "The performance of the error backpropagation (BP) and ID3 learning algorithms was compared on the task of mapping English text to phonemes and stresses . Under the distributed output code developed by Sejnowski and Rosenberg , it is shown that BP consistently out-performs ID3 on this task by several percentage points . Three hypotheses explaining this difference were explored: (a) ID3 is overfitting the training data , (b) BP is able to share hidden units across several output units and hence can learn the output units better , and (c) BP captures statistical information that ID3 does not . We conclude that only hypothesis (c) is correct . By augmenting ID3 with a simple statistical learning procedure , the performance of BP can be closely matched . More complex statistical procedures can improve the performance of both BP and ID3 substantially in this domain . Introduction There is no universal learning algorithm that can take a sample of training examples for an arbitrary unknown function f and produce a good approximation to f (see Dietterich , 1989) . Instead , every learning algorithm embodies some assumptions (or \"bias\") about the nature of the learning problems to which it will be applied . Some algorithms , for example , assume that only a small number of the features describing the data are relevant . Other algorithms assume that every feature makes a small , but independent , contribution to determining the classifi- cation . Many algorithms order the hypotheses according to syntactic simplicity in some representation and attempt to find the simplest hypothesis consistent with the training examples. Unfortunately , for many popular learning algorithms , the assumptions they embody are not entirely known-or , if they are known , they are stated in terms that are difficult to check in any given application domain . For example , Quinlan's decision-tree algorithm ID3 assumes that the unknown function f can be represented as a small decision tree . However , given a new learning problem , it is difficult to know whether this assumption holds without first running the ID3 algorithm . The result is that we do not have a good understanding of the range of problems for which ID3 is appropriate . Similarly , the backpropagation algorithm (Rumelhart , Hinton , & Williams , 1986) assumes , at a minimum , that the unknown function f can be represented as a multilayer feed-forward network of sigmoid units . Although there have been many successful applications of backpropagation (Touretzky , 1989 , 1990) , we still lack an understanding of the situations for which it is appropriate. Furthermore , because clear statements of the assumptions made by ID3 and back-propagation are unavailable , we do not understand the relationship between these two algorithms . Some investigators have even suggested that these algorithms are making very similar assumptions (Lorien Pratt , personal communication). Hence , we confront two related questions . First , what are the assumptions embodied in ID3 and backpropagation (or equivalently , in what situations should these algorithms be applied)?", "label": ["experimental comparisons", "text-to-speech", "backpropagation"], "stemmed_label": ["experiment comparison", "text-to-speech", "backpropag"]}
{"doc": "A weak completeness phenomenon is investigated in the complexity class $ \\rm E = \\rm DTIME (2^ \\rm linear )$ . According to standard terminology , a language $H$ is $\\leq^ \\rm P _ m $-hard for E if the set $ \\rm P _ m (H)$ , consisting of all languages $A \\leq^ \\rm P _ m H$ , contains the entire class E . A language $C$ is $\\leq^ \\rm P _ m $-complete for E if it is $\\leq^ \\rm P _ m $-hard for E and is also an element of E . Generalizing this , a language $H$ is weakly $\\leq^ \\rm P _ m $-hard for E if the set $ \\rm P _ m (H)$ does not have measure 0 in E . A language $C$ is weakly $\\leq^ \\rm P _ m $-complete for E if it is weakly $\\leq^ \\rm P _ m $-hard for E and is also an element of E . The main result of this paper is the construction of a language that is weakly $\\leq^ \\rm P _ m $-complete , but not $\\leq^ \\rm P _ m $-complete , for E . The existence of such languages implies that previously known strong lower bounds on the complexity of weakly $\\leq^ \\rm P _ m $-hard problems for E (given by work of Lutz , Mayordomo , and Juedes) are indeed more general than the corresponding bounds for $\\leq^ \\rm P _ m $-hard problems for E . The proof of this result introduces a new diagonalization method , called martingale diagonalization . Using this method , one simultaneously develops an infinite family of polynomial time computable martingales (betting strategies) and a corresponding family of languages that defeat these martingales (prevent them from winning too much money) while also pursuing another agenda . Martingale diagonalization may be useful for a variety of applications . Introduction In practice to date , proving that a decision problem (i.e. , language) H ' f0; 1g is computationally intractable usually amounts to proving that every member of the complexity class linear )-or some larger class- is efficiently reducible to H . (See 25 for a survey of such arguments.) For example , some problems involving the existence of winning strategies for certain two-person combinatorial games are known to be intractable because they are polynomial time many-one hard (in fact , logarithmic space many-one Briefly , a language H is polynomial time many-one hard (abbreviated - P hard) for E if every language A 2 E is polynomial time many-one reducible to H (abbreviated A - P H) . A language C is - P and C is - P m -hard for E. A language H that is - P m -hard for E is clearly intractable in the sense that H is not decidable in polynomial time . This is because a well-known diagonalization argument 3 shows that there is a language must be the case that B - P follows that P. In fact , languages that are - P", "label": ["resource-bounded measure", "weak completeness", "complexity classes", "computational complexity", "complete problems"], "stemmed_label": ["resource-bound measur", "weak complet", "complex class", "comput complex", "complet problem"]}
{"doc": "Pattern matching is an important operation used in many applications such as functional programming , rewriting , and rule-based expert systems . By preprocessing the patterns into a DFA-like automaton , we can rapidly select the matching pattern(s) in a single scan of the relevant portions of the input term . This automaton is typically based on left-to-right traversal of the patterns . By adapting the traversal order to suit the set of input patterns , it is possible to considerably reduce the space and matching time requirements of the automaton . The design of such adaptive automata is the focus of this paper . We first formalize the notion of an adaptive traversal . We then present several strategies for synthesizing adaptive traversal orders aimed at reducing space and matching time complexity . In the worst case , however , the space requirements can be exponential in the size of the patterns . We show this by establishing an exponential lower bounds on space that is independent of the traversal order used . We then discuss an orthogonal approach to space minimization based on direct construction of optimal dag automata . Finally , our work brings forth the impact of typing in pattern matching . In particular , we show that several important problems (e.g. , lazy pattern matching in ML) are computationally hard in the presence of type disciplines , whereas they can be solved efficiently in the untyped setting . Introduction Pattern matching is a fundamental operation in a number of important applications such as functional and equational programming , term rewriting and theorem proving . In most of these applica- tions , patterns are partially ordered by assigning priorities . For instance , in languages such as ML 5 and Haskell 6 , a pattern occurring earlier in the text has a higher priority over those following it . Applications that do not impose priorities can also be handled as a special case of matching with priorities. The typical approach to pattern matching is to preprocess the patterns into a DFA-like automaton that can rapidly select the patterns that match the input term 1 . The main advantage of such a matching automaton is that all pattern matches can be identified in a single scan (i.e. , no backtracking) of portions of input term relevant for matching purposes and is done in time that is independent of the number of patterns . Fig . 1 shows such a matching automaton constructed on the basis of a left-to-right traversal of patterns . This automaton can be represented by tables or compiled into case statements . Each state of the automaton corresponds to the prefix of the input term seen in reaching that state and is annotated with the set of patterns that can possibly match . For instance , state s 4 corresponds to having inspected the prefix f(b; a; x) , where x denotes the subterm that has not yet been examined . This state is annotated with the pattern set f1; 2; 3g since we cannot rule", "label": ["indexing", "discrimination nets", "functional programming", "algorithms and complexity", "pattern matching"], "stemmed_label": ["index", "discrimin net", "function program", "algorithm and complex", "pattern match"]}
{"doc": "We consider the following problem: given a labelled directed graph $G$ and a regular expression $R$ , find all pairs of nodes connected by a simple path such that the concatenation of the labels along the path satisfies $R$ . The problem is motivated by the observation that many recursive queries in relational databases can be expressed in this form , and by the implementation of a query language , $ \\bf G ^+$ , based on this observation . We show that the problem is in general intractable , but present an algorithm than runs in polynomial time in the size of the graph when the regular expression and the graph are free of conflicts . We also present a class of languages whose expressions can always be evaluated in time polynomial in the size of both the graph and the expression , and characterize syntactically the expressions for such languages . Introduction . Much of the success of the relational model of data can be attributed to its simplicity , which makes it both amenable to mathematical analysis and easy for users to comprehend . In this latter respect , the availability of non-procedural query languages has been a great asset . However , the fact that queries which are especially useful in new application domains are not expressible in traditional query languages has led to proposals for more powerful query languages , such as the logic-based language Datalog 23 and our query language G The original proposal for the relational model included two query languages of equivalent expressive power: the relational calculus and the relational algebra 7 . These languages have been used as the yardstick bywhich other query languages are classified; a query language is said to be relationally complete if it has (at least) the expressive power of the relational calculus . However , this notion of completeness has been questioned since it was shown that certain reasonable queries , such as finding the transitive closure of a binary relation , cannot be expressed in the calculus 3 , 4 . This particular limitation is overcome in the languages and Datalog through their ability to express recursive queries. The design of G + is based on the observation that many of the recursive queries that arise in practice-and in the literature-amount to graph traversals (for example , 1 , 12 , 19 ). In G + , we view the database as a directed , labelled graph , and pose queries which are graph patterns; the answer to a query is the set of subgraphs of the database that match the given pattern . Useful applications for such a language can be found in systems representing transportation networks , communication networks , hypertext documents , and so on . In our prototype implementation , queries are drawn on a workstation screen and the database and query results are also displayed pictorially. Example 1 . Let G be a graph describing a hypertext document: nodes are chunks of text and edges are links (cross-references) . Readers read the", "label": ["regular expressions", "np-completeness", "labelled directed graphs", "simple paths", "polynomial-time algorithms"], "stemmed_label": ["regular express", "np-complet", "label direct graph", "simpl path", "polynomial-tim algorithm"]}
{"doc": "Remotely sensed imagery has been used for developing and validating various studies regarding land cover dynamics . However , the large amounts of imagery collected by the satellites are largely contaminated by the effects of atmospheric particles . The objective of atmospheric correction is to retrieve the surface reflectance from remotely sensed imagery by removing the atmospheric effects . We introduce a number of computational techniques that lead to a substantial speedup of an atmospheric correction algorithm based on using look-up tables . Excluding I/O time , the previous known implementation processes one pixel at a time and requires about 2.63 seconds per pixel on a SPARC-10 machine , while our implementation is based on processing the whole image and takes about 4-20 microseconds per pixel on the same machine . We also develop a parallel version of our algorithm that is scalable in terms of both computation and I/O . Experimental results obtained show that a Thematic Mapper (TM) image (36 MB per band , 5 bands need to be corrected) can be handled in less than 4.3 minutes on a 32-node CM-5 machine , including I/O time . Introduction Data from the Landsat series of satellites have been available since 1972 . The primary source of data from the first three satellites was the Multispectral Scanner System (MSS ) . The Thematic Mapper (TM) of Landsats 4 and 5 represents a major improvement compared with the MSS in terms of spectral resolution (4 wave-bands for MSS , 7 narrower wave-bands for TM) , and spatial resolution (79 meters for MSS, and meters for TM) . The TM data have been widely used for resource inventory, environmental monitoring , and a variety of other applications 1 . Since 1979 , the Advanced Very High Resolution Radiometers (AVHRR) on board of the National Oceanic and Atmospheric Administration (NOAA) series of satellites have been in continuous polar orbit . AVHRR data have become extremely important for global studies because they carry multiple bands in the visible , the infrared and the thermal spectrum , and a complete coverage of the Earth is available twice daily with 1.1 km resolution at nadir and from two platforms . AVHRR has allowed us for the first time to improve our studies of the earth surface from the regional scale to the global scale using remote sensing techniques 1 , 2 . The radiation from the earth surface , which highly characterizes surface inherent properties , are largely contaminated by the atmosphere . The atmospheric particles (aerosols and molecules) scatter and absorb the solar photons reflected by the surface in such a way that only part of the surface radiation can be detected by the sensor . On the other hand , atmospheric particles scatter the sunlight into the sensor's field of view directly , resulting in a radiation that does not contain any surface information at all. The combined atmospheric effects due to scattering and absorption are wavelength dependent , vary in time and space , and depend on the surface reflectance and its spatial variation", "label": ["high performance computing", "remote sensing", "avhrr", "atmospheric correction", "scalable parallel processing", "parallel i/o"], "stemmed_label": ["high perform comput", "remot sens", "avhrr", "atmospher correct", "scalabl parallel process", "parallel i/o"]}
{"doc": "We present and analyze a portable , high-performance algorithm for finding connected components on modern distributed memory multiprocessors . The algorithm is a hybrid of the classic DFS on the subgraph local to each processor and a variant of the Shiloach-Vishkin PRAM algorithm on the global collection of subgraphs . We implement the algorithm in Split-C and measure performance on the the Cray T3D , the Meiko CS-2 , and the Thinking Machines CM-5 using a class of graphs derived from cluster dynamics methods in computational physics . On a 256 processor Cray T3D , the implementation outperforms all previous solutions by an order of magnitude . A characterization of graph parameters allows us to select graphs that highlight key performance features . We study the effects of these parameters and machine characteristics on the balance of time between the local and global phases of the algorithm and find that edge density , surface-to-volume ratio , and relative communication cost dominate performance . By understanding the effect of machine characteristics on performance , the study sheds light on the impact of improvements in computational and/or communication performance on this challenging problem . Introduction The problem of finding the connected components of a graph has broad importance in both computer science and computational science . Computer vision , for example , makes extensive use of connected components algorithms for problems such as edge detection and object recognition . Use of connected components algorithms has also advanced the study of various physical properties of magnetic materials near critical temperatures , among other physical phenomena. Connected components also appears to offer a unique challenge for parallel computing . Sequential solutions are well understood and commonly used in introductory computer science theory courses as an application of depth-first and breadth-first search . Parallel solutions have received a great deal of attention from both theorists and practical computer scientists , and have proven difficult . Theoretical work shows good results on the CRCW PRAM model 3 , 10 , 11 , 24 , which assumes uniform memory access time and arbitrary bandwidth to any memory location. This material is based upon work supported under a National Science Foundation Presidential Faculty Fellowship Award , a Graduate Research Fellowship , and Infrastructure Grant number CDA-8722788 , as well as Lawrence Livermore National Laboratories Inst . for Scientific Research Grants #UCB-ERL-92/69 and #UCB-ERL-92/172. Any opinions , findings , conclusions , or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of either organization. The inherent contention in the algorithm has made even EREW solutions much more challenging 5 , 14 , 15 , 17 . Practical application of the theoretical work to parallel machines has been largely restricted to small shared-memory machines and SIMD machines with very slow processors 11 . Many practical solutions have been developed for modern MIMD massively parallel platforms , or MPP's 6 , 9 , 13 , 22 , 18 , and vector machines 8 , 22 . The practical solutions typically emphasize performance over issues of", "label": ["distributed memory", "hybrid algorithm", "connected components", "parallel machines", "performance modeling modelling"], "stemmed_label": ["distribut memori", "hybrid algorithm", "connect compon", "parallel machin", "perform model model"]}
{"doc": "The message passing programs are executed with the Parallel Virtual Machine (PVM) library and the shared memory programs are executed using TreadMarks . The programs are Water and Barnes-Hut from the SPLASH benchmark suite; 3-D FFT , Integer Sort (IS) and Embarrassingly Parallel (EP) from the NAS benchmarks; ILINK , a widely used genetic linkage analysis program; and Successive Over-Relaxation (SOR) , Traveling Salesman (TSP) , and Quicksort (QSORT) . Two different input data sets were used for Water (Water-288 and Water-1728) , IS (IS-Small and IS-Large) , and SOR (SOR-Zero and SOR-NonZero) . Our execution environment is a set of eight HP735 workstations connected by a 100Mbits per second FDDI network . For Water-1728 , EP , ILINK , SOR-Zero , and SOR-NonZero , the performance of TreadMarks is within 10%of PVM . For IS-Small , Water-288 , Barnes-Hut , 3-D FFT , TSP , and QSORT , differences are on the order of 10%to 30% . Finally , for IS-Large , PVM performs two times better than TreadMarks . More messages and more data are sent in TreadMarks , explaining the performance differences . This extra communication is caused by 1) the separation of synchronization and data transfer , 2) extra messages to request updates for data by the invalidate protocol used in TreadMarks , accumulation for migratory data in TreadMarks . Introduction Parallel computing on networks of workstations has been gaining more attention in recent years . Because workstation clusters use \"off the shelf\" products , they are cheaper than supercomputers . Furthermore , high- This research was supported in part by NSF NYI Award CCR-9457770 , NSF CISE postdoctoral fellowship Award CDA-9310073, NSF Grants CCR-9116343 and BIR-9408503 , and by the Texas Advanced Technology Program under Grant 003604012. speed general-purpose networks and very powerful workstation processors are narrowing the performance gap between workstation clusters and supercomputers. Processors in workstation clusters do not share physical memory , so all interprocessor communication between processors must be performed by sending messages over the network . Currently , the prevailing programming model for parallel computing on networks of workstations is message passing , using libraries such as PVM 9 , TCGMSG 11 and Express 18 . A message passing standard MPI 17 has also been developed . With the message passing paradigm , the distributed nature of the memory system is fully exposed to the application programmer . The programmer needs to keep in mind where the data is , decide when to communicate with other processors , whom to communicate with , and what to communicate , making it hard to program in message passing , especially for applications with complex data structures. Software distributed shared memory (DSM) systems (e.g. , 3 , 5 , 14 , 16 ) provide a shared memory abstraction on top of the native message passing facilities . An application can be written as if it were executing on a shared memory multiprocessor , accessing shared data with ordinary read and write operations . The chore of message passing is left to the underlying DSM system", "label": ["message passing", "lazy release consistency", "pvm", "distributed shared memory", "treadmarks"], "stemmed_label": ["messag pass", "lazi releas consist", "pvm", "distribut share memori", "treadmark"]}
{"doc": "We evaluate the impact of a gigabit network on the implementation of a distributed chemical process optimization application . The optimization problem is formulated as a stochastic Linear Assignment Problem and was solved using the Thinking Machines CM-2 (SIMD) and the Cray C-90 (vector) computers at PSC , and the Intel iWarp (MIMD) system at CMU , connected by the Gigabit Nectar testbed . We report our experience distributing the application across this heterogeneous set of systems and present measurements that show how the communication requirements of the application depend on the structure of the application . We use detailed traces to build an application performance model that can be used to estimate the elapsed time of the application for different computer system and network combinations . Our results show that the application benefits from the high-speed network , and that the need for high network throughput is increasing as computer systems get faster . We also observed that supporting high burst rates is critical , although structuring the application so that communication is overlapped with computation relaxes the bandwidth requirements . Introduction High-performance networks have made it attractive to distribute compute-intensive applications across computer systems connected by local-area and wide-area networks . The obvious benefit is that the applications can combine the resources of several systems to reduce execution time. Heterogeneous computing is a special case of distributed computing . It has the added benefit that each application component can be mapped onto the most appropriate architecture , thus optimizing the efficiency of the computation . As a result , heterogeneous computing can result in super-linear speed up , i.e. , using N systems , the application runs more than N times faster than on any of the individual systems (e.g . 22 ). An important question is how critical network performance is to the success of distributed computing . While many coarse-grain applications have been distributed successfully across relatively slow networks , high-speed networks are needed if we want to apply distributed computing to a wide class of applications , including grand challenge and national challenge applications . A first indication is that many applications are not only computationally intensive , but also data intensive , so large data sets have to be exchanged between the distributed tasks . A second observation is that as computer systems get faster , the networks will have to keep up. In this paper we evaluate the impact of network bandwidth on the performance of a chemical process optimization application . This application is economically important for the chemical process industry, and it is representative of large class of optimization problems in other fields . We use a two-step evaluation strategy . We first distributed the application across three systems connected by the Gigabit Nectar testbed: the Intel iWarp system (MIMD) at CMU , and the Thinking Machines and the Cray C-90 (vector) computers at PSC . This implementation shows the feasibility of distributed computing for this class of problems , and allows us to identify the problems in distributing large applications across heterogeneous", "label": ["distributed computing", "gigabit networks", "heterogeneous computing", "optimal resource allocation", "chemical process optimization", "stochastic linear assignment problem"], "stemmed_label": ["distribut comput", "gigabit network", "heterogen comput", "optim resourc alloc", "chemic process optim", "stochast linear assign problem"]}
{"doc": "This paper presents an extensive empirical evaluation of an interprocedural parallelizing compiler , developed as part of the Stanford SUIF compiler system . The system incorporates a comprehensive and integrated collection of analyses , including privatization and reduction recognition for both array and scalar variables , and symbolic analysis of array subscripts . The interprocedural analysis framework is designed to provide analysis results nearly as precise as full inlining but without its associated costs . Experimentation with this system shows that it is capable of detecting coarser granularity of parallelism than previously possible . Specifically , it can parallelize loops that span numerous procedures and hundreds of lines of codes , frequently requiring modifications to array data structures such as privatization and reduction transformations . Measurements from several standard benchmark suites demonstrate that an integrated combination of interprocedural analyses can substantially advance the capability of automatic parallelization technology . Introduction Symmetric shared-memory multiprocessors , built out of the latest mi- croprocessors , are now a widely available class of computationally pow- This research was supported in part by the Air Force Material Command and ARPA contract F30602-95-C-0098 , ARPA contract DABT63-94-C-0054 , an NSF CISE postdoctoral fellowship , Jet Propulsion Laboratory , fellowships from Intel Corporation and AT&T Bell Laboratories , and an NSF Young Investigator Award. erful machines . As hardware technology advances make pervasive parallel computing a possibility , it is ever more important that tools be developed to simplify parallel programming . A parallelizing compiler that automatically locates parallel computations in sequential programs is a particularly attractive programming tool , as it frees programmers from the difficult task of explicitly managing parallelism in their programs. Unfortunately , today's commercially available parallelizing compilers are not effective at getting good performance on multiprocessors 3, 23 . As these parallelizers were developed from vectorizing compiler technology , they tend to be successful in parallelizing only innermost loops . Parallelizing just inner loops is not adequate for multiprocessors for two reasons . First , inner loops may not make up a significant portion of the sequential computation , thus limiting the parallel speedup by limiting the amount of parallelism . Second , synchronizing processors at the end of the inner loops leaves little computation occurring in parallel between synchronization points . The cost of frequent synchronization and load imbalance can potentially overwhelm the benefits of parallelization. Multiprocessors are more powerful than vector machines in that they can execute different threads of control simultaneously , and can thus exploit a coarser granularity of parallelism . Thus , for a parallelizing compiler to target a multiprocessor effectively , it must identify outer parallelizable loops to extract coarse-grain parallelism . This requires two major improvements over standard parallelization techniques: Advanced Array Analyses . A loop is often not parallelizable unless the compiler modifies the data structures it accesses . For example, it is very common for each iteration of a loop to define and use the same variable . The compiler must give each processor a private copy of the variable for the loop to be", "label": ["shared memory multiprocessors", "compiler optimizations", "parallelizing compilers", "interprocedural data-flow analysis"], "stemmed_label": ["share memori multiprocessor", "compil optim", "parallel compil", "interprocedur data-flow analysi"]}
{"doc": "Because large scientific codes are rarely static objects , developers are often faced with the tedious task of accounting for discrepancies between new and old versions . In this paper , we describe a new technique called relative debugging that addresses this problem by automating the process of comparing a modified code against a correct reference code . We examine the utility of the relative debugging technique by applying a relative debugger called Guard to a range of debugging problems in a large atmospheric circulation model . Our experience confirms the effectiveness of the approach . Using Guard , we are able to validate a new sequential version of the atmospheric model , and to identify the source of a significant discrepancy in a parallel version in a short period of time . Introduction Large scientific codes are constantly evolving . Refinements in understanding of physical phenomena result in changes to physics , improved numerical methods result in changes to solution techniques , and developments in computer architecture result in new algorithms . Unfortunately, this evolutionary process often introduces subtle errors that can be extremely difficult to find. As a consequence , scientific programmers can spend many hours , days , or weeks laboriously comparing the executions of two almost identical codes , seeking to identify the source of a small discrepancy. Debuggers assist in locating program errors . They are tools which allow a user to investigate the execution state of an application program , by for example examining the state of program variables 11 , 12 , 13 , 17 . Significant recent extensions include graphical user interfaces to improve the ease of use , data visualization facilities to aid the interpretation of large and complex data structures , the concept of process groups to aid the management of many independent threads in parallel machines , and support for parallel and distributed debugging 2 , 8 , 9 , 11 , 14 . Traditional debuggers have proved invaluable when developing new programs . However , they do not directly address the problems of maintaining and extending existing computer programs, or converting software from one machine or language to another . Programmers do not want to examine new versions of existing programs in isolation . Instead , they want to compare their execution with the execution of an old , reference program which is assumed to be correct . By acting as a reference , the working version can assist in locating the section of code in the modified program which introduces incorrect values. Existing techniques for comparing executions of two program versions are tedious , error prone and limited in scope . For example , a programmer may invoke the two programs under separate debuggers , manually set breakpoints , run the programs , and visually compare the resulting program states . A more advanced approach is to insert output statements into both programs and then compare the output using a file comparison program 6 . This approach also has its limitations: it can requires huge amounts of disk storage", "label": ["parallelism", "guard", "relative debugging", "tools", "debugging", "scientific computing", "meteorology"], "stemmed_label": ["parallel", "guard", "rel debug", "tool", "debug", "scientif comput", "meteorolog"]}
{"doc": "Release consistency is a widely accepted memory model for distributed shared memory systems . Eager release consistency represents the state of the art in release consistent protocols for hardware-coherent multiprocessors , while lazy release consistency has been shown to provide better performance for software distributed shared memory (DSM) . Several of the optimizations performed by lazy protocols have the potential to improve the performance of hardware-coherent multiprocessors as well , but their complexity has precluded a hardware implementation . With the advent of programmable protocol processors it may become possible to use them after all . We present and evaluate a lazy release-consistent protocol suitable for machines with dedicated protocol processors . This protocol admits multiple concurrent writers , sends write notices concurrently with computation , and delays invalidations until acquire operations . We also consider a lazier protocol that delays sending write notices until release operations . Our results indicate that the first protocol outperforms eager release consistency by as much as 20% across a variety of applications . The lazier protocol , on the other hand , is unable to recoup its high synchronization overhead . This represents a qualitative shift from the DSM world , where lazier protocols always yield performance improvements . Based on our results , we conclude that machines with flexible hardware support for coherence should use protocols based on lazy release consistency , but in a less ''aggressively lazy'' form than is appropriate for DSM . Introduction Remote memory accesses experience long latencies in large shared-memory multiprocessors , and are one of the most serious impediments to good parallel program performance . Relaxed consistency models 6 , 18 can help reduce the cost of memory accesses by masking the latency of write operations . Relaxed consistency requires that memory be consistent only at certain synchronization events , and thus allows a protocol to buffer , merge, and pipeline write requests as long as it respects the consistency constraints specified in the model. This work was supported in part by NSF Institutional Infrastructure grant no . CDA-8822724 , ONR research grant no . N00014- 92-J-1801 (in conjunction with the DARPA Research in Information Science and Technology-High Performance Computing, Software Science and Technology program , ARPA Order no . 8930) , and Brazilian CAPES and NUTES/UFRJ fellowships. Release consistency 10 is the most widely accepted relaxed consistency model . Under release consistency each memory access is classified as an ordinary access , an acquire , or a release . A release indicates that the processor is completing an operation on which other processors may depend; all of the releasing processor's previous writes must be made visible to any processor that performs a subsequent acquire . An acquire indicates that the processor is beginning an operation that may depend on some other processor; all other processors' writes must now be made locally visible. This definition of release consistency provides considerable flexibility to a coherence protocol designer as to when to make writes by a processor visible to to other processors . Hardware implementations of release consistency , as", "label": ["lazy release consistency", "cache coherence", "shared memory", "protocol processors"], "stemmed_label": ["lazi releas consist", "cach coher", "share memori", "protocol processor"]}
{"doc": "We describe pHPF , an research prototype HPF compiler for the IBM SP series parallel machines . The compiler accepts as input Fortran 90 and Fortran 77 programs , augmented with HPF directives; sequential loops are automatically parallelized . The compiler supports symbolic analysis of expressions . This allows parameters such as the number of processors to be unknown at compile-time without significantly affecting performance . Communication schedules and computation guards are generated in a parameterized form at compile-time . Several novel optimizations and improved versions of well-known optimizations have been implemented in pHPF to exploit parallelism and reduce communication costs . These optimizations include elimination of redundant communication using data-availability analysis; using collective communication; new techniques for mapping scalar variables; coarse-grain wavefronting; and communication reduction in multi-dimensional shift communications . We present experimental results for some well-known benchmark routines . The results show the effectiveness of the compiler in generating efficient code for HPF programs . Introduction Fortran has always been synonymous with fast execution . High Performance Fortran (HPF) 13 , 8 defines a set of directive extensions to Fortran to facilitate performance portability of Fortran programs when compiling for large-scale , multiprocessor architectures , while preserving a shared-address space programming model . Unfortunately , HPF compilers have not appeared as rapidly as originally had been hoped , and it is now accepted that high quality compilers for HPF will have to evolve over time and with experience . Some of the complexities of compiling HPF result from the ffl The ability to perform communication optimizations is essential for high performance . A single inner-loop communication can result in a significant loss of performance . For HPF performance to approach hand-coded performance , more and more sophisticated optimizations will have to be implemented. ffl The implementation of every feature of Fortran is affected by the distribution of data across different address spaces . Fortran data is primarily static , but HPF data must be dynamically allocated , since arrays can be redistributed . Even without redistribution , the number of processors is , in general , not known at compile-time , so that the sizes of local array partitions are not known statically . Thus , in addition to loop parallelization , HPF requires an IBM T.J . Watson . Research , P.O . Box 704 , Yorktown Heights , NY , 10598 . The authors can be reached by e-mail at fmgupta,midkiff,schnbrg,shields,kyw,ching,tangog@watson.ibm.com . The corresponding author can be reached at schnbrg@watson.ibm.com. y IBM Software Solutions Division , 1150 Eglinton Ave . East , North York , Ontario , CANADA M3C 1V7 . The author can be reached by e-mail at seshadri@vnet.ibm.com enhanced run-time model , and new implementations of such features as common blocks , data statements , block data , and array addressing. ffl HPF is an extremely high-level language , in that the amount of generated/executed code per source line is generally larger than for other common programming languages . This poses a challenge for code generation , run-time library design , and tool development. ffl In", "label": ["compiler", "automatic parallelization", "fortran", "ibm sp2", "hpf", "distributed memory compilation", "optimizing compiler", "communication optimization"], "stemmed_label": ["compil", "automat parallel", "fortran", "ibm sp2", "hpf", "distribut memori compil", "optim compil", "commun optim"]}
{"doc": "This paper discusses the comprehensive performance profiling , improvement and benchmarking of a Computational Fluid Dynamics code , one of the Grand Challenge applications , on three popular multiprocessors . In the process of analyzing performance we considered language , compiler , architecture , and algorithmic changes and quantified each of them and their incremental contribution to bottom-line performance . We demonstrate that parallelization alone cannot result in significant gains if the granularity of parallel threads and the effect of parallelization on data locality are not taken into account . Unlike benchmarking studies that often focus on the performance or effectiveness of parallelizing compilers on specific loop kernels , we used the entire CFD code to measure the global effectiveness of compilers and parallel architectures . We probed the performance bottlenecks in each case and derived solutions which eliminate or neutralize the performance inhibiting factors . The major conclusion of our work is that overall performance is extremely sensitive to the synergetic effects of compiler optimizations , algorithmic and code tuning , and architectural idiosyncrasies . Introduction Despite the continuing quest to achieve high performance , complete scientific applications obtain only a fraction of the expected speedup on modern multiprocessors . On the other hand , the proliferation of parallel architectures throughout the spectrum of computer systems is indisputable . Few would argue against the significance of parallelism , but even fewer would suggest that parallel machines deliver the performance that users have come to expect. In this paper , by means of a \"Grand Challenge\" application , we show that compiler , architectural limi- tations , and algorithmic characteristics can restrict performance more severely than Amdahl's law suggests, even in cases where parallelism may be abundant . As some of our results indicate , a synergetic approach in simultaneously addressing all these limitations can result in significant performance payback. Our work focused on the comprehensive and multi-level analysis of a complete commercial scientific application , a Computational Fluid Dynamics (CFD) code based on SIMPLE (Semi-Implicit Method for Pressure-Linked Equation) 8 . This paper reports on the performance bottlenecks of hardware , architectures, compilers and operating systems , and on the importance of manual optimizations and code tuning . The hand optimizations , used in this work to improve performance , as well as , the isolation of hardware bottlenecks, point to possible architectural and software improvements that can alleviate the performance limitations of multiprocessor machines. For our experiments , we used three commercial multiprocessors: the SGI Challenge , the Alliant FX/2800, and the Alliant FX/80 . We used two commercial and two experimental parallelizing compilers . Our results suggest that a user of a CFD application who is not an expert on code optimization and/or computer architecture , should expect to see little , if any , performance improvement by running such a code on a multiprocessor . This is true even in the presence of powerful automatic parallelizing compilers . Such tools can be effective only under expert intervention. Even though our results from a single commercial application cannot be", "label": ["parallel architectures", "performance evaluation", "parallelizing compilers", "program optimization", "parallel processing", "parallel algorithms and programs", "profiling and program tuning", "cfd computational fluid dynamics", "cache optimization"], "stemmed_label": ["parallel architectur", "perform evalu", "parallel compil", "program optim", "parallel process", "parallel algorithm and program", "profil and program tune", "cfd comput fluid dynam", "cach optim"]}
{"doc": "Abstract: Designers of embedded systems are facing ever tighter constraints on design time , but computer-aided design tools for embedded systems have not kept pace with these trends . The Chinook co-synthesis system addresses the automation of the most time-consuming and error-prone tasks in embedded controller design , namely the synthesis of interface hardware and software needed to integrate system components , the migration of functions between processors or custom logic , and the co-simulation of the design before , during and after synthesis . This paper describes the principal elements of Chinook and discuss its application to a variety of embedded designs . Introduction Embedded system designers , in varied industry segments that include consumer electronics , automotive control , and medical equipment , are facing increased pressure to create products quickly and inexpensively . This trend is coupled to the increasing levels of integration , performance, and programmability achievable in off-the-shelf integrated circuits including microprocessors , programmable logic , and devices such as LCDs , network interface controllers , and speech generators. Designers find using these devices to be advantageous because of their low cost and the way in which they facilitate rapid realization of designs not only for prototyping but for production as well . In fact , with embedded controllers now found in everything from consumer electronics and automobiles to smart credit cards and medical equipment , many products have declining lifetimes that make custom integrated circuits a less economically viable option. The job of the embedded system designer has also changed . In addition to time to market constraints , the designer must worry about correctness and cost effectiveness of the implementation. Thus , designers have a need to explore a large design space of potential solutions , yet no integrated CAD tools are available to help them with this task . The design must be quickly defined and simulated and then mapped onto the cheapest combination of components . Unlike general-purpose computers embedded systems are designed and optimized to provide specific functionality . Thus, the most time consuming and error-prone task in embedded system design is precisely the detailed mapping of the abstract functional specification onto the target components . In fact , the process is so time-consuming that many designers fix the target architecture and system components well before a complete evaluation of the final system and perform only one mapping . This often leads designers to over-design their systems with faster processors or larger capacity logic devices then really needed , thereby increasing the cost . If the target architecture were to prove inadequate due to performance or capacity constraints , designers would face a costly re-mapping process. It is clear that design exploration tools to automate the mapping process and thus provide faster feedback on design decisions are sorely needed . Many design automation tools and frameworks have been proposed to address a few of these problems . These tools either look at high-level specifications but do not assist with the actual implementation , or they help with individual parts of the implementation", "label": ["custom logic", "software tools", "microprocessors", "logic cad", "error-prone tasks", "real-time systems", "computer-aided design tools", "interface software", "system components integration", "chinook hardware/software co-synthesis system", "interface hardware", "microcontrollers", "function migration", "embedded controller design", "logic design", "design co-simulation", "design time constraints"], "stemmed_label": ["custom logic", "softwar tool", "microprocessor", "logic cad", "error-pron task", "real-tim system", "computer-aid design tool", "interfac softwar", "system compon integr", "chinook hardware/softwar co-synthesi system", "interfac hardwar", "microcontrol", "function migrat", "embed control design", "logic design", "design co-simul", "design time constraint"]}
{"doc": "Abstract: One of the challenging tasks in code generation for embedded systems is register assignment . When more live variables than registers exist , some variables are necessarily accessed from data memory . Because loops are typically executed many times and are often time-critical , good register assignment in loops is exceedingly important , since accessing data memory can degrade performance . The issue of finding an optimal register assignment to loops , one which minimizes the number of spills between registers and memory , has been open for some time . In this paper , we address this issue and present an optimal , but exponential , algorithm which assigns registers to loop bodies such that the resulting spill code is minimal . We also show that a heuristic modification performs as well as the exponential approach on typical loops from scientific code . INTRODUCTION Typically , an embedded system consists of an embedded , programmable processor interconnected with some memory and specialized \"accelerators\" This work was supported in part by ONR grant K000042879921 . A preliminary version of this paper appears in the Proceedings of the 8th International Symposium on System Synthesis (ISSS-95). Authors' addresses: D.J . Kolson , A . Nicolau , and N . Dutt , Department of Information and Computer Science , University of California , Irvine , Irvine , CA 92717-3425; K . Kennedy, Department of Computer Science , Rice University , Houston, Permission to make digital / hard copy of part or all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage , the copyright notice , the title of the publication , and its date appear, and notice is given that copying is by permission of the ACM , Inc . To copy otherwise , to republish , to post on servers , or to redistribute to lists , requires prior specific permission and / or a fee. ACM Transactions on Design Automation of Electronic Systems , Vol . 1 , No . 2 , April 1996 , Pages 251-279. (application-specific components) . This embedded processor can be realized by either a processor core or an application-specific instruction-set processor (ASIP) . The architecture of an embedded processor may resemble a general-purpose processor in its datapath \"regularity\" or may have some degree of irregularity in the datapath for efficient implementation of the application-specific instructions and/or features . In either case , the proces- sor's memory may be consolidated into one memory module or may be distributed into various modules (which can have size one , corresponding to a single register) . Examples of embedded processors with a consolidated memory are the MIPS RC4000 and the microSPARC-II , whereas Texas Instruments' TMS series and Motorola's 56000 are examples with distributed memories. Currently , much research has focused on code generation for these embedded systems . 1 One of the challenging tasks in generating code for an embedded processor is that of register assignment . In this assignment process ,", "label": ["heuristic modification", "loops", "storage allocation", "minimal spill code", "real-time systems", "scientific code", "data memory access", "optimal register assignment", "embedded code generation", "program control structures", "optimisation", "exponential algorithm", "live variables"], "stemmed_label": ["heurist modif", "loop", "storag alloc", "minim spill code", "real-tim system", "scientif code", "data memori access", "optim regist assign", "embed code gener", "program control structur", "optimis", "exponenti algorithm", "live variabl"]}
{"doc": "Abstract: Software synthesis is a new approach which focuses on the support of embedded systems without the use of operating systems . Compared to traditional design practices , a better utilization of the available time and hardware resources can be achieved , because the static information provided by the system specification is fully exploited and an application-specific solution is automatically generated . On-going research on a software synthesis approach for real-time information processing systems is presented which starts from a concurrent process system specification and tries to automate the mapping of this description to a single processor . An internal representation model which is well-suited for the support of concurrency and timing constraints is proposed , together with flexible execution models for multi-tasking with real-time constraints . The method is illustrated on a personal terminal receiver demodulator for mobile satellite communication . Introduction The target application domain of our approach is advanced real-time information processing systems , such as consumer electronics and personal communication systems. The distinctive characteristic of these systems is the coexistence of two different types of functionalities , namely digital signal processing and control functions , which require different timing constraint support . Specifically , signal processing functions operate on sampled data streams , and are subject to the real-time constraint derived from the required sample frequency or throughput . Control procedures vary in nature from having to be executed as soon as possible (like e.g . a man-machine interface) , but an eventual execution delay does not usually compromise the integrity of the entire system (soft deadline) , to having very stringent constraints, like e.g . a critical feedback control loop (hard deadline). Traditionally , real-time kernels , i.e . specialized operating systems , are used for software support in the design of embedded systems 5 . These small kernels , often stripped-down versions of traditional time-sharing operating-system, are in the first place designed to be fast (e.g . fast context switch) . Above all , real-time kernels provide the run-time support for real-time multi-tasking to perform software scheduling , and primitives for inter-process communication and synchronization , and for accessing the hardware resources . Since processes are considered as black boxes, This workwas supportedby the EuropeanCommission , undercontract most kernels apply a coarse grain model for process schedul- ing . Most kernels tend to use a fixed priority preemptive scheduling mechanism , where process priorities have to be used to mimic the timing constraints . Alternatively , traditional process scheduling approaches use timing constraints, specified as process period , release time and deadline 11 . From the designer viewpoint however , these constraints are more naturally specified with respect to the occurrence of observable events . Moreover , the scheduler has no knowledge about the time stamps when the events are generated by the processes , and consequently can not exploit this . Assignment of the process priorities , as in the case of the fixed priority scheduling scheme , is a manual task to be performed without any tool support . Typically , an iterative ,", "label": ["hardware resource utilization", "internal representation model", "real-time multi-tasking", "concurrency control", "real-time systems", "multiprocessing programs", "concurrent process system specification", "information processing systems", "automatically generated application-specific solution", "embedded systems", "static information", "automatic processor mapping", "software synthesis", "computer aided software engineering", "flexible execution models", "mobile satellite communication", "personal terminal receiver demodulator", "time utilization", "timing constraints", "processor scheduling"], "stemmed_label": ["hardwar resourc util", "intern represent model", "real-tim multi-task", "concurr control", "real-tim system", "multiprocess program", "concurr process system specif", "inform process system", "automat gener application-specif solut", "embed system", "static inform", "automat processor map", "softwar synthesi", "comput aid softwar engin", "flexibl execut model", "mobil satellit commun", "person termin receiv demodul", "time util", "time constraint", "processor schedul"]}
{"doc": "An important challenge in the area of distributed computing is to automate the selection of the parameters that control the distributed computation . A performance-critical parameter is the grain size of the computation , i.e. , the interval between successive synchronization points in the application . This parameter is hard to select since it depends both on compile time (loop structure and data dependences , computational complexity) and run time components (speed of compute nodes and network) . On networks of workstations that are shared with other users , the run-time parameters can change over time . As a result , it is also necessary to consider the interactions with dynamic load balancing , which is needed to achieve good performance in this environment . In this paper we present a method for automatically selecting the grain size of the computation consisting of nested DO loops . The method is based on close cooperation between the compiler and the runtime system . We evaluate the method using both simulation and measurements for an implementation on the Nectar multicomputer . Introduction Because of their high availability and relatively low cost , networks of workstations are now often considered as platforms for applications that used to be relegated to dedicated multiprocessors . Parallel languages and parallelizing compilers have simplified the programming of shared and distributed memory multiprocessors . However, modifications to these tools are needed if they are to be targeted for networks of workstations because of the independent nature of the machines and the higher , more variable costs of communication over a network . Our research investigates these issues in the context of parallelizing compilers. Generally , parallelizing compilers assume a specific , homogeneous target system that is dedicated to the application , and allocate the same amount of work to each processor . On networks of worksta- tions , processors may be heterogeneous and may have performance that varies at run time due to competing users , and different types of networks with different loads may be encountered . As a result, static , equal distribution of work does not result in good utilization of the available resources . To address this problem , we have designed a system that supports dynamic load balancing of parallelized code by periodically adjusting the amount of work allocated to each processor at run time 11 , 12 . At each load balancing point , the system attempts to allocate work units in numbers proportional to the relative processing capabilities of the processors. The grain size of an application-the amount of computation between successive synchronization points-is a very important performance parameter for parallelized applications because it affects both communication costs and load balancing effectiveness . Because communication costs and load balancing depend on the configuration and dynamic aspects of the system , an appropriate grain size can not be selected using just compile-time information . Cooperation between the compiler and runtime system is necessary for selection and control of the grain size of an application distributed over a network . This paper investigates the impact", "label": ["automatic parallelization", "dynamic load balancing", "network of workstations", "grain size"], "stemmed_label": ["automat parallel", "dynam load balanc", "network of workstat", "grain size"]}
{"doc": "Abstract: DSP algorithms are , in most cases , subject to hard real-time constraints . In the case of programmable DSPs , meeting those constraints must be ensured by appropriate code generation techniques . For processors offering instruction-level parallelism , the task of code generation includes code compaction . The exact timing behavior of a DSP program is only known after compaction . Therefore , real-time constraints should be taken into account during the compaction phase . While most known DSP code generators rely on rigid heuristics for that phase , this paper proposes a novel approach to local code compaction based on an integer programming model , which obeys exact timing constraints . Due to a general problem formulation , the model also obeys encoding restrictions and possible side-effects . Introduction R ESEARCH on electronic CAD is currently taking the step towards system-level design automation . For economical reasons , contemporary embedded VLSI systems are of heterogeneous nature , comprising both hardware and software components in the form of ASICs and embedded programmable processors . Consequently , system-level CAD tools need to provide support for integrated hardware and software synthesis . Software synthesis is the task of extracting those pieces of functionality from a system specifi- cation , which should be assigned to programmable proces- sors , and mapping these pieces into executable , processor- specific machine code. The general optimization goal in hardware/software co-synthesis of embedded VLSI systems is to minimize the amount of custom hardware needed to implement a system under given performance constraints . This is due to the fact , that implementation by software provides more flexibility , lower implementation effort , and better opportunities for reuse . On the other hand , software synthesis turns out to be a bottleneck in design of systems comprising programmable digital signal processors (DSPs): Most DSP software is still coded at the assembly-language level 1 , in spite of the well-known drawbacks of low-level pro- gramming . Although high-level language compilers for off- the-shelf DSPs are available , the execution speed overhead of compiler-generated code (up to several hundred percent compared to hand-crafted code 2 ) is mostly unacceptable. The reason for this overhead is , that compilers are hardly capable of exploiting the highly dedicated and irregular architectures of DSPs . Furthermore , there is still no desig- Authors' affiliation: University of Dortmund , Department of Computer Science 12 , 44221 Dortmund , Germany , E-mail: leupersjmarwedel@ls12.informatik.uni-dortmund.de nated standard programming language for DSPs . The situation is even worse for application-specific DSPs (ASIPs). Since these are typically low-volume and product-specific designs , high-level language compilers for ASIPs hardly ex- ist . Nevertheless , ASIPs are expected to gain increasing market shares in relation to standard DSPs 1 . Current research efforts to overcome the productivity bottleneck in DSP code generation concentrate on two central issues 3 : Code quality: In order to enable utilization of high-level language compilers , the code overhead must be reduced by an order of magnitude . This can only be achieved by means of", "label": ["exact timing behavior", "integer programming", "instruction-level parallelism", "encoding restrictions", "side-effects", "timing", "programmable dsp", "real-time systems", "time-constrained code compaction", "local code compaction", "digital signal processing algorithms", "rigid heuristics", "integer programming model", "hard real-time constraints", "code generation techniques", "source coding", "automatic programming", "digital signal processing chips"], "stemmed_label": ["exact time behavior", "integ program", "instruction-level parallel", "encod restrict", "side-effect", "time", "programm dsp", "real-tim system", "time-constrain code compact", "local code compact", "digit signal process algorithm", "rigid heurist", "integ program model", "hard real-tim constraint", "code gener techniqu", "sourc code", "automat program", "digit signal process chip"]}
{"doc": "Abstract: To construct complete systems on silicon , application specific DSP accelerators are needed to speed up the execution of high throughput DSP algorithms . In this paper , a methodology is presented to synthesize high throughput DSP functions into accelerator processors containing a datapath of highly pipelined , bit-parallel hardware units . Emphasis is put on the definition of a controller architecture that allows efficient run-time schedules of these DSP algorithms on such highly pipelined data paths . The methodology is illustrated by means of an FFT butterfly accelerator block . Introduction C OMPLEX digital systems such as the videophone terminal of figure 1 typically consist out of a heterogeneous mix of hardware blocks 1 : processor cores , general purpose macro blocks , and dedicated accelerator proces- sors . These accelerator blocks are required to execute high performant DSP functions such as motion estimation and DCT/IDCT functions. In this paper we will concentrate on the generation of such application specific accelerator processors . We will highlight both the design issues and the architecture char- acteristics . The requirements of such accelerator processors are: ffl High throughput requirements impose the usage of pipelined data paths. ffl Area can be saved through the hardware sharing of different micro-instructions. ffl The accelerator processor has to be embedded in an overall system architecture. P . Schaumont , B . Vanthournout and I . Bolsens are with the In- teruniversitary Micro-Electronics Center (IMEC) , Kapeldreef 75 , B- 3001 Leuven , Belgium . H . De Man is with the Interuniversitary Micro-Electronics Center and Professor at the Katholieke Universiteit Leuven , Belgium control data Variable Length Coder Variable Length Decoder Motion Estimator Reconstructor Compressor accelerator components micro controller video RAM I/O Fig . 1 . Architecture of a Video Phone ffl The accelerator functions can execute both at a manifest rate and a nonmanifest rate or Data Introduction Interval (DII 2 , 3 ) . An example of the former is the processing of a data stream out of an A/D converter. An example of the latter is the processing of data out of a processor core inside the system. The support of a nonmanifest DII allows to split the development of the system control component schedule and the accelerator processor schedule . The software executed by the system control component thus can be revised even after the accelerator processor was developed . This is an essential feature in the presence of today's complex algorithms As seen from the system control software , the accelerator component is a function call . Execution of this call spawns off the system control thread into the accelerator , executes the accelerator operations , and resynchronizes with the system control thread . Such a scheme is used by some commercial numerical coprocessor components 4 . The presented synthesis system allows to generate such components , but with a much higher complexity and processing power. II . Overview of the work Automated synthesis systems for pipelined datapaths have been reported previously: pisyn 2 , sodas 3 , and sehwa 5", "label": ["highly pipelined data paths", "parallel architectures", "pipelined dsp accelerator synthesis", "application specific dsp accelerators", "datapath", "dynamic scheduling", "pipeline processing", "controller architecture", "circuit cad", "application specific integrated circuits", "pipelined bit-parallel hardware", "scheduling", "fft butterfly accelerator block", "network synthesis", "run-time schedules", "silicon", "digital signal processing chips", "dsp algorithms"], "stemmed_label": ["highli pipelin data path", "parallel architectur", "pipelin dsp acceler synthesi", "applic specif dsp acceler", "datapath", "dynam schedul", "pipelin process", "control architectur", "circuit cad", "applic specif integr circuit", "pipelin bit-parallel hardwar", "schedul", "fft butterfli acceler block", "network synthesi", "run-tim schedul", "silicon", "digit signal process chip", "dsp algorithm"]}
{"doc": "Abstract: This paper describes an exact solution methodology , implemented in Rensselaer's Voyager design space exploration system , for solving the scheduling problem in a 3-dimensional (3D) design space: the usual 2D design space (which trades off area and schedule length) , plus a third dimension representing clock length . Unlike design space exploration methodologies which rely on bounds or estimates , this methodology is guaranteed to find the globally optimal solution to the 3D scheduling problem . Furthermore , this methodology efficiently prunes the search space , eliminating provably inferior design points through: a careful selection of candidate clock lengths; and tight bounds on the number of functional units of each type or on the schedule length . Introduction In high-level synthesis , the process of solving the scheduling problem can be viewed as the process of exploring a 2-dimensional (2D) design space , with axes representing time (schedule length) and area (ideally total area , but often simplified to functional unit area) . In reality , however, this 2D design space is only a small part of a much larger design space . One such larger design space is presented by De Micheli in 15 , and is illustrated in Figure 1 . Here the design space for high-level synthesis is viewed as a 3- dimensional (3D) space , with axes not only representing schedule length and area , but clock (cycle) length as well. A typical scheduling algorithm explores only one 2D slice of this larger 3D design space - the 2D slice corresponding to a fixed clock length chosen a priori by the designer. This clock length depends on many factors , including the delays of the functional units , storage elements , glue logic, and wiring , as well as clock skew . Some of those values are unknown before scheduling , and can therefore only be estimated at this stage in the design process. Given this lack of detailed information , the designer is forced to make an ad hoc and frequently arbitrary guess at the clock length , unfortunately eliminating an entire dimension of the search space . Thus even an optimal scheduler will explore only that one 2D slice of the design space , and will produce a schedule that is optimal only for that one clock length . A better schedule may exist for a different clock length , but that better schedule will not be found. To motivate the need to explore this larger design space, consider the problem of scheduling the well-known Elliptic Wave Filter 23 , p.206 (EWF) benchmark , under a variety This material is based upon work supported by the National Science Foundation under Grant No . MIP-9211323. y Dept . of Electrical , Computer , and Systems Engineering z Department of Computer Science. Schedule Length Area Length Figure 1: The Larger 3-Dimensional (3D) Design Space Clock Csteps ns Csteps ns Csteps ns 48 25 1200 26 1248 37 1776 Table 1: Resource-Constrained Scheduling Results for the EWF of resource constraints , to find the fastest possible schedule.", "label": ["high level synthesis", "clocks", "three dimensional scheduling", "voyager design space exploration system", "candidate clock lengths", "3d scheduling problem", "2d design space", "clock length", "globally optimal solution", "three-dimensional design space", "schedule length", "3d design space", "two dimensional design space", "search problems", "tight bounds", "optimisation", "scheduling", "network synthesis", "search space pruning"], "stemmed_label": ["high level synthesi", "clock", "three dimension schedul", "voyag design space explor system", "candid clock length", "3d schedul problem", "2d design space", "clock length", "global optim solut", "three-dimension design space", "schedul length", "3d design space", "two dimension design space", "search problem", "tight bound", "optimis", "schedul", "network synthesi", "search space prune"]}
{"doc": "Abstract: This paper describes the application of a measurement based power analysis technique for an embedded DSP processor . An instruction-level power model for the processor has been developed using this technique . Significant points of difference have been observed between this model and the ones developed earlier for some general-purpose commercial microprocessors . In particular , the effect of circuit state on the power cost of an instruction stream is more marked in the case of this DSP processor . In addition , the DSP processor has a special architectural feature that allows instructions to be packed into pairs . The energy reduction possible through the use of this feature is studied . The on-chip Booth multiplier on the processor is a major source of energy consumption for DSP programs . A micro-architectural power model for the multiplier is developed and analyzed for further energy minimization . A scheduling algorithm incorporating these new techniques is proposed to reduce the energy consumed by DSP software . Energy reductions varying from 11% to 56% have been observed for several example programs . These energy savings are real and have been verified through physical measurement . Introduction Embedded computing systems are characterized by the presence of application specific software running on specialized processors . These processors may be off the shelf digital signal processors (DSPs) or application specific instruction-set processors (ASIPs) . A large fraction of these applications are power critical. However , there is very little available in the form of design tools to help embedded system designers evaluate their designs in terms of the power metric. Recently an instruction-level power model was developed for two general-purpose commercial microprocessors 1 , 2 , which is based on the base cost and the overhead cost of an instruction , obtained by physical current measurements . The base cost of a given instruction is defined as the average current drawn by the processor during the repeated execution of the in- struction . The \"overhead cost\" was needed to account for the effect of circuit state change for an instruction sequence consisting of different instructions . How- ever , the impact of this effect on the overall power cost of programs was found to be limited for these large general-purpose microprocessors . The aim of this study is to analyze this and other issues related to software power consumption , in the context of a smaller , more specialized processor. A Fujitsu embedded DSP processor , referred to as the target processor from here on , is used for our study . This processor is used in several Fujitsu embedded applications and is representative of a large class of DSP processors . The analysis results are used in this paper to develop an instruction-level power model that makes it possible to evaluate the power cost of programs that run on the target DSP processor . It is observed that the effect of circuit state is more marked for this processor . This suggests that changing the instruction order by an appropriate scheduling of instructions can lead", "label": ["energy minimization", "embedded dsp software", "circuit state", "instruction sets", "general-purpose commercial microprocessors", "instruction-level power model", "real-time systems", "energy consumption", "micro-architectural power model", "low-power scheduling", "energy reduction", "on-chip booth multiplier", "circuit cad", "application specific integrated circuits", "dsp processor", "scheduling", "measurement based power analysis", "scheduling algorithm", "digital signal processing chips", "power analysis"], "stemmed_label": ["energi minim", "embed dsp softwar", "circuit state", "instruct set", "general-purpos commerci microprocessor", "instruction-level power model", "real-tim system", "energi consumpt", "micro-architectur power model", "low-pow schedul", "energi reduct", "on-chip booth multipli", "circuit cad", "applic specif integr circuit", "dsp processor", "schedul", "measur base power analysi", "schedul algorithm", "digit signal process chip", "power analysi"]}
{"doc": "We study the minimum-cost bounded-skew routing tree problem under the Elmore delay model . We present two approaches to construct bounded-skew routing trees: (i) the Boundary Merging and Embedding (BME) method which utilizes merging points that are restricted to the boundaries of merging regions , and (ii) the Interior Merging and Embedding (IME) algorithm which employs a sampling strategy and dynamic programming to consider merging points that are interior to , rather than on the boundary of , the merging regions . Our new algorithms allow accurate control of Elmore delay skew , and show the utility of merging points inside merging regions . Introduction In layout synthesis of high-performance systems , it has become increasingly important to control signal delays , e.g. , for clock skew minimization or the timing-driven routing of large global nets . At the same time , routing solutions should have low wiring area to reduce die size and capacitive effects on both performance and power dissipation . Thus , the \"zero-skew\" clock tree and performance-driven routing literatures have seen rapid growth over the past several years; see 22 for a detailed review . Recent works have accomplished exact zero skew under the Elmore delay model 30 , 6 , 15 , and have given new methods for single-layer (planar) clock routing 32 , 23 , 24 . Over the past two years , a number of authors have applied wiresizing optimizations and/or buffer optimizations to minimize phase delay 18 , 28 , 16 , 26 , 27 , 33 , 34 , skew sensitivity to process variation 28 , 8 , 25 , and/or power dissipation 28 . The work of 29 developed a clock router that accomplishes specified pin-to-pin delays. \"Exact zero skew\" is typically obtained at the expense of increased wiring area and higher power dissipation . In practice, circuits still operate correctly within a given skew tolerance , and indeed exact zero skew is never an actual design requirement 22 . The works of Zhu and Dai 33 , 34 and Pullela et al . 27 are notable in that they use initial non-zero skew routing solutions which are then wiresized to satisfy a given skew bound . Construction of a minimum-cost bounded-skew routing tree (BST) is a key underlying optimization . 1 Given these antecedents , two recent works 10 , 19 have addressed the BST problem , and proposed clock and Steiner global routing algorithms that construct BSTs under the linear , i.e. , pathlength , delay model . The enabling concept in 10 , 19 is that of a merging region , which generalizes the merging segment concept of 2 , 5 , 13 for zero- skew clock trees. Unfortunately , in practice we find that bounding the pathlength skew does not afford any reliable control of the actual delay skew. Figure 1(a) shows HSPICE delay skew against pathlength delay skew for routing trees generated by the ExG-DME algorithm 19 on the r1-5 benchmark clock sink placements . Not only is the correlation poor , In general , not only", "label": ["bounded-skew", "zero-skew", "elmore delay", "routing trees", "global routing", "pathlength delay", "clock routing", "vlsi"], "stemmed_label": ["bounded-skew", "zero-skew", "elmor delay", "rout tree", "global rout", "pathlength delay", "clock rout", "vlsi"]}
{"doc": "We present efficient , optimal algorithms for timing optimization by discrete wire sizing and buffer insertion . Our algorithms are able to minimize dynamic power dissipation subject to given timing constraints . In addition , we compute the complete power-delay tradeoff curve for added flexibility . We extend our algorithm to take into account the effect of signal slew on buffer delay which can contribute substantially to overall delay . The effectiveness of these methods is demonstrated experimentally . Introduction Timing optimization techniques for VLSI circuits have received much attention in recent years due to increasingly aggressive designs and the impact of technological trends such as shrinking geometries . Among these techniques are performance driven placement and routing , gate sizing , buffer insertion (often referred to as fanout optimization in pre-layout works) , and wire sizing . In this work , we focus on wire sizing and buffer insertion Wire Sizing: Automatic sizing of wire widths is an attractive technique for timing optimization in signal nets , particularly with the advent of sub-micron technology . The benefit of wire sizing lies in the fact that , with shrinking geometries , wire resistance is now a significant contributor to overall delay . As a result , it makes sense to tune the widths of wires to balance the tradeoff between added capacitance and decreased resistance . Wire sizing can be of significant benefit for both on-chip and for inter-chip (e.g . MCM) interconnects. Cong , Leung , Zhou and Koh provided several studies of wire sizing in 4 , 2 , 3 and demonstrated the potential of wire sizing in improving delay . In these works the problem was formulated as the task of minimizing the weighted sum of the source-to-sink Elmore delays for a set of identified critical sinks in a given routing tree . The weighting coefficients are presumably provided by the user . Under this formulation they prove several properties which lead to an O(n r ) algorithm for a net with n segments each having r possible widths . The authors also propose a greedy heuristic procedure with run time of O(n 3 r) . Cong et . al . also attack the problem of incorporating a cost function such as area or power . Their formulation is , again , a weighted sum of their stated timing objective function and the cost function. Later , in 12 , Sapatnekar studied the more common metric of maximum source-to-sink delay - or , more generally , the task of minimizing cost subject to given timing constraints . He noted that the key property of separability used by Cong and Leung in designing their algorithm did not hold for this case . In addition , the property of monotonicity utilized by Cong et . al. does not apply when the length of all wire segments is not identical . In the same paper Sapatnekar proposed a geometric programming formulation of the maximum delay , continuous wire-sizing problem followed by a mapping heuristic to discretize the solution. Later , in 8", "label": ["timing optization", "elmore delay", "dynamic power dissipation", "dynamic programming", "signal slew"], "stemmed_label": ["time optiz", "elmor delay", "dynam power dissip", "dynam program", "signal slew"]}
{"doc": "Abstract: Functions that map boolean vectors into the integers are important for the design and verification of arithmetic circuits . MTBDDs and BMDs have been proposed for representing this class of functions . We discuss the relationship between these methods and describe a generalization called hybrid decision diagrams which is often much more concise . We show how to implement arithmetic operations efficiently for hybrid decision diagrams . In practice , this is one of the main limitations of BMDs since performing arithmetic operations on functions expressed in this notation can be very expensive . In order to extend symbolic model checking algorithms to handle arithmetic properties , it is essential to be able to compute the BDD for the set of variable assignments that satisfy an arithmetic relation . In our paper , we give an efficient algorithm for this purpose . Moreover , we prove that for the class of linear expressions , the time complexity of our algorithm is linear in the number of variables . Introduction Functions that map boolean vectors into the integers are important for the design and verification of arithmetic circuits . In this paper , we investigate how to represent and manipulate such functions efficiently . In a previous paper 6 , we have proposed two ways (MTBDDs and BDD arrays) for representing this class of functions using Binary Decision Diagrams. Recently , Bryant and Chen 4 have proposed Binary Moment Diagrams (BMDs) for representing this class of functions . In this paper , we show that the BMD of a function is the MTBDD that results from applying the inverse Reed-Muller transformation 9 to the func- tion . Furthermore , it can be computed using the techniques that we have developed . The transformation matrix in this case is the Kronecker product 2 of a number of identical 2 \\Theta 2 matrices . We show that the Kronecker products of other 2 \\Theta 2 matrices behave in a similar way . In fact , the transformations obtained from Kronecker products of other matrices will in many cases more concise than the BMD . We have further generalized this idea so that the transformation matrix can be the Kronecker product of different matrices . In this way , we obtain a representation , called the Hybrid Decision Diagram (HDD) , that is more concise than either the MTBDD or the BMD. A similar strategy has been used by Becker 7 . However , his technique only works for the boolean domain and is not suitable for functions mapping boolean vectors into integers. When using his technique , all of the transformation matrices , the original function and the resulting function must have boolean values . Our technique , on the other hand , works over the integers . By allowing integer values , we can handle a wider range of functions . Moreover, we can obtain larger reduction factors since we have more choices for the transformation ma- trices . When our technique is applied to boolean functions , it can often achieve comparable", "label": ["circuit analysis computing", "hybrid decision diagrams", "multi-terminal binary decision diagrams", "digital arithmetic", "mtbdds", "arithmetic circuits verification", "integers", "binary decision diagrams", "symbolic model checking algorithms", "computational complexity", "time complexity", "boolean vectors", "linear expressions"], "stemmed_label": ["circuit analysi comput", "hybrid decis diagram", "multi-termin binari decis diagram", "digit arithmet", "mtbdd", "arithmet circuit verif", "integ", "binari decis diagram", "symbol model check algorithm", "comput complex", "time complex", "boolean vector", "linear express"]}
{"doc": "This paper presents a method to synthesize labeled Petri nets from state-based models . Although state-based models (such as Finite State Machines) are a powerful formalism to describe the behavior of sequential systems , they cannot explicitly express the notions of concurrency , causality and conflict . Petri nets can naturally capture these notions . The proposed method in based on deriving an Elementary Transition System (ETS) from a specification model . Previous work has shown that for any ETS there exists a Petri net with minimum transition count (one transition for each label) with a reachability graph isomorphic to the original ETS . This paper presents the first known approach to obtain an ETS from a non-elementary TS and derive a place-irredundant Petri net . Furthermore , by imposing constraints on the synthesis method , different classes of Petri nets can be derived from the same reachability graph (pure , free choice , unique choice) . This method has been implemented and efficiently applied in different frameworks: Petri net composition , synthesis of Petri nets from asynchronous circuits , and resynthesis of Petri nets . Introduction In this paper we present a method which given a finite state model, called Transition System (TS) , synthesizes a safe Petri Net with a reachability graph that is either isomorphic to the original TS or isomorphic to a minimized version of the original TS . The synthesized PN is always place-irredundant , i.e. , it is not possible to remove any place from the net without violating its behavior. The synthesis method provides us with a technique for transforming specifications . Given a model which can be mapped into a TS , we can derive a PN which is equivalent to the initial model of the process . In such a way we can create a tool which automatically translates CSP , CCS , FSM , Burst Mode machines and other models into labeled Petri Nets . Also , we can use this tool for transformation of Petri Nets aimed at optimality under some criterion (place count , transition count , number of places , PN graph complexity , etc.) or for deriving a net belonging to a given class (safe , Free-Choice , Unique-Choice , etc.) This opensup an avenue for building interactive tools where a designer has the possibility to play with a PN-like specification , performing equivalent transformations of PNs , and/or transformations of other specifications This work has been partly supported by the Ministry of Education of Spain (CICYT TIC 95-0419). y This work has been partly supported by the U.K . SERC GR/J78334. z This work has been partly supported by the U.K . SERC GR/J72486 and by MURST research project \"VLSI architectures\". x This work has been partly supported by the U.K . SERC GR/J52327. into PNs under different design constraints and optimization criteria A basic intermediate object between a TS and a PN is a region 11 , 1 , 3 , 10 . \"State\" in safe Petri nets is distributed among places: each state is a", "label": ["asynchronous circuits", "finite state machines", "transition systems", "synthesis", "petri nets"], "stemmed_label": ["asynchron circuit", "finit state machin", "transit system", "synthesi", "petri net"]}
{"doc": "We present a simulation-based method for combinational design verification that aims at complete coverage of specified design errors using conventional ATPG tools . The error models used in prior research are examined and reduced to four types: gate substitution errors (GSEs) , gate count errors (GCEs) , input count errors (ICEs) , and wrong input errors (WIEs) . Conditions are derived for a gate to be completely testable for GSEs; These conditions lead to small test sets for GSEs . Near-minimal test sets are also derived for GCEs . We analyze redundancy in design errors and relate this to single stuck-line (SSL) redundancy . We show how to map all the foregoing error types into SSL faults , and describe an extensive set of experiments to evaluate the proposed method . Our experiments demonstrate that high coverage of the modeled design errors can be achieved with small test sets . Introduction Design verification is the process of ensuring that a new design exhibits specified behavior . Many approaches to design error detection have been proposed based on formal verification 1 . However , formal verification is impractical for large logic circuits . In practice , such circuits are verified by simulation using representative input patterns (tests) 2 . A basic question that we address here is: Which tests should be applied and what is their efficiency? Abadir et al . 3 have defined a set of likely design errors for combinational logic and have shown that complete test sets for single stuck-line (SSL) faults detect many , but not all , such errors . Recent research has considered the use of implementation-independent \"universal\" test sets 4,5 , as well as random tests 6 for design error detection . In each case , the number of tests needed for good coverage of design errors can be excessive , and 100 percent coverage is not guaranteed . For example , universal tests exploit any unateness properties of the functions being implemented, but the tests become exhaustive when , as is often the case, there are no unate variables. In Section 2 , we reduce the design errors considered in the literature to four classes . Then , we study the detection properties of these error classes . Section 3 describes the mapping of design errors into SSL faults , as well as the process of generating test sets for them using standard ATPG tools for SSL faults . Section 4 presents the results of applying our method to representative benchmark circuits. Tests for Design Errors Many types of design errors have been classified in the literature 3,5-7 . These error types are not necessarily com- plete , but they are believed to be common in the design pro- cess . We condense the errors identified by Abadir et al . 3 into four categories . similar classification is given independently in 5 ). . Gate substitution error (GSE): This refers to mistakenly replacing a gate by another gate with the same number of inputs . The extra and missing inverter errors of 3,5- 7", "label": ["logic simulation", "error models", "test generation", "design verification"], "stemmed_label": ["logic simul", "error model", "test gener", "design verif"]}
{"doc": "Abstract: Precise failure analysis requires accurate fault diagnosis . A previously proposed method for diagnosing bridging faults using single stuck-at dictionaries was applied only to small circuits , produced large and imprecise diagnoses , and did not take into account the Byzantine Generals Problem for bridging faults . We analyze the original technique and improve it by introducing the concepts of match restriction , match requirement , and failure recovery . Our new technique , which requires no information other than that used by standard stuck-at methods , produces diagnoses that are an order of magnitude smaller than those produced by the original technique and produces many fewer misleading diagnoses than that of traditional stuck-at diagnosis . Introduction Accurate fault diagnosis of realistic defects is an integral part of failure analysis . The majority of spot defects in modern CMOS technologies cause changes in the circuit description that result in electrical shorts 9 , which implies that many failures are bridging faults 16 . However , most fault diagnosis techniques use the single stuck-at fault model to diagnose faulty ICs. Diagnosing bridging faults with single stuck-at fault information is an appealing idea , but this approach can lead to unusably large diagnoses or an unacceptable percentage of misleading diagnoses . To address these deficiencies , Aitken and Maxwell built dictionaries comprised of realistic faults 3 . While there are obvious advantages to this approach , the number of realistic faults in a circuit is significantly larger than the number of single stuck-at faults for a circuit , and the cost of simulating each individual realistic fault is frequently much greater . In summary , while diagnosis using a realistic fault model is an ideal , achieving similar results using single stuck-at information is a very desirable goal. In this paper we investigate and improve a bridging fault diagnosis technique using the single stuck-at fault model that was proposed by Millman , Mc- Cluskey , and Acken (henceforth called the MMA tech- nique) 17 . The MMA technique has many advan- tages , the most notable of which are the ubiquitous single stuck-at fault model , the obviation of the need for additional circuit information for bridging fault di- agnosis , and the absence of misleading diagnoses . How- ever , the MMA technique , like other techniques , has the disadvantages of intractable diagnosis size and assumption of identical down-stream logic thresholds 5 . In addition , the MMA technique was originally demonstrated only on circuits smaller than any of those in the ISCAS-85 benchmark circuits 4 . By removing vectors that cannot detect a bridging fault from its composite signature (match restriction), and requiring vectors that should detect it (match re- quirement) , we have reduced the average diagnosis size by more than an order of magnitude . Together with failure recovery , our improvements allow us to provide a diagnosis no larger than ten faults for more than 80% of the thousands of diagnostic trials we have performed on the ISCAS-85 circuits . This improvement has transformed a theoretical technique", "label": ["fault diagnosis", "single stuck-at information", "stuck-at methods", "stuck-at diagnosis", "failure recovery", "match restriction", "match requirement", "realistic bridging faults diagnosis", "single stuck-at dictionaries", "failure analysis", "fault location", "logic testing"], "stemmed_label": ["fault diagnosi", "singl stuck-at inform", "stuck-at method", "stuck-at diagnosi", "failur recoveri", "match restrict", "match requir", "realist bridg fault diagnosi", "singl stuck-at dictionari", "failur analysi", "fault locat", "logic test"]}
{"doc": "We address the problem of instruction selection in code generation for embedded DSP microprocessors . Such processors have highly irregular data-paths , and conventional code generation methods typically result in inefficient code . Instruction selection can be formulated as directed acyclic graph (DAG) covering . Conventional methods for instruction selection use heuristics that break up the DAG into a forest of trees and then cover them independently . This breakup can result in suboptimal solutions for the original DAG . Alternatively , the DAG covering problem can be formulated as a binate covering problem , and solved exactly or heuristically using branch-and-bound methods . We show that optimal instruction selection on a DAG in the case of accumulator-based architectures requires a partial scheduling of nodes in the DAG , and we augment the binate covering formulation to minimize spills and reloads . We show how the irregular data transfer costs of typical DSP data-paths can be modeled in the binate covering formulation . INTRODUCTION An increasingly common micro-architecture for embedded systems is to integrate a microprocessor or microcontroller , a ROM and an ASIC all on a single IC . Such a micro-architecture can currently be found in many diverse embedded systems , e.g. , FAX modems, laser printers , and cellular telephones. The programmable component in embedded systems can be an application-specific instruction processor (ASIP) , a general-purpose microprocessor such as the SPARC , a microcontroller such as Intel 8051 , or a digital signal processor such as TMS320C25 . This paper focuses on the DSP application domain , where embedded systems are increasingly used . Many of these systems use processors from the TMS320C2x , DSP5600x or ADSP families , all fixed-point DSP microprocessors with irregular data-paths. Code size matters a great deal in embedded systems since program code resides in on-chip ROM , the size of which directly translates into silicon area and cost . Designers often devote a significant amount of time to reduce code size so that the code will fit into available ROM; exceeding on-chip ROM size could require expensive redesign of the entire IC 7 . As a result , a compiler that automatically generates small , dense code will result in a significant productivity gain as well. We believe that generating the best code for embedded processors will require not only traditional optimization techniques , but also new techniques that take advantage of special architectural features that decrease code size . This paper presents one of our efforts at developing such techniques . We address the problem of instruction selection in code generation for embedded DSP microprocessors. We emphasize decreasing code size , although our techniques can also increase execution speed. Instruction selection can be formulated as directed acyclic graph (DAG) covering . Conventional methods for instruction selection use heuristics that break up the DAG into a forest of trees , which are then covered optimally but independently 1 3 . Independent covering of the trees may result in a suboptimal solution for the original DAG . Trees , as a heuristic formulation ,", "label": ["instruction selection", "digital signal processors", "code generation"], "stemmed_label": ["instruct select", "digit signal processor", "code gener"]}
{"doc": "The optimal wiresizing problem for nets with multiple sources is studied under the distributed Elmore delay model . We decompose such a net into a source subtree (SST) and a set of loading subtrees (LSTs) , and show the optimal wiresizing solution satisfies a number of interesting properties , including: the LST separability , the LST monotone property , the SST local monotone property and the general dominance property . Furthermore , we study the optimal wiresizing problem using a variable grid and reveal the bundled refinement property . These properties lead to efficient algorithms to compute the lower and upper bounds of the optimal solutions . Experiment results on nets from an Intel processor layout show an interconnect delay reduction of up to 35.9\\% when compared to the minimum-width solution . In addition , the algorithm based on a variable grid yields a speedup of two orders of magnitude without loss of accuracy , when compared with the fixed grid based methods . INTRODUCTION Interconnect delay has become the dominating factor in determining system performance in deep submicron VLSI designs . Recently developed techniques for interconnect delay minimization in the physical design level This work is partially supported by ARPA/CSTO under contract J-FBI-93-112 , the NSF Young Investigator Award MIP-9357582 , and a grant from Intel Corporation under the NYI matching award program . An extended abstract of this paper was presented in ICCAD'95. Authors' addresses: Department of Computer Science , University of California , Los Angeles, Permission to make digital / hard copy of part or all of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage , the copyright notice , the title of the publication , and its date appear, and notice is given that copying is by permission of the ACM , Inc . To copy otherwise , to republish , to post on servers , or to redistribute to lists , requires prior specific permission and / or a fee. ACM Transactions on Design Automation of Electronic Systems , Vol . 1 , No . 4 , October 1996 , Pages 478 -511. fall into two categories . One is topology optimization , such as the constructions of bounded-radius bounded-cost trees Cong et al . 1992 , AHHK trees Alpert et al . 1993 , A-trees Cong et al . 1993 , low-delay trees Boese et al. 1993 , and IDW/CFD trees Hong et al . 1993 . In essence , these methods construct an interconnect tree to minimize both the total tree length and the paths between the input pin (also called the source) and a set of timing-critical output pins (also called critical sinks) , whereas the conventional Steiner tree algorithms minimize only the total tree length . In addition , the nontree routing for delay minimization was explored in McCoy and Robins 1994 and Xue and Kuh 1995 . The other type of interconnect optimization methods is wiresizing optimi- zation , which computes optimal wire width for", "label": ["performance driven layout", "optimal wiresizing", "vlsi routing", "interconnect optimization"], "stemmed_label": ["perform driven layout", "optim wires", "vlsi rout", "interconnect optim"]}
{"doc": "We address the problem of minimizing power consumption in behavioral synthesis of data-dominated circuits . The complex nature of power as a cost function implies that the effects of several behavioral synthesis tasks like module selection , clock selection , scheduling , and resource sharing on supply voltage and switched capacitance need to be considered simultaneously to fully derive the benefits of design space exploration at the behavior level . Recent work has established the importance of behavioral synthesis in low power VLSI design . However , most of the algorithms that have been proposed separate these tasks and perform them sequentially , and are hence not able to explore the tradeoffs possible due to their interaction . We present an efficient algorithm for performing scheduling , clock selection , module selection , and resource allocation and assignment simultaneously with an aim of reducing the power consumption in the synthesized data path . The algorithm , which is based on an iterative improvement strategy , is capable of escaping local minima in its search for a low power solution . The algorithm considers diverse module libraries and complex scheduling constructs such as multicycling , chaining , and structural pipelining . We describe supply voltage and clock pruning strategies that significantly improve the efficiency of our algorithm by cutting down on the computational effort involved in exploring candidate supply voltages and clock periods that are unlikely to lead to the best solution . Experimental results are reported to demonstrate the effectiveness of the algorithm . Our techniques can be combined with other known methods of behavioral power optimization like data path replication and transformations , to result in a complete data path synthesis system for low power applications . INTRODUCTION Low power consumption has been established as an important metric for VLSI design . Recent work 1 , 2 , 3 has shown that the most savings in power consumption are often obtained at the higher levels of the design hierarchy . In this paper , we concentrate on the behavioral synthesis process,that takes as its input the behavioral description of a design , and produces a register-transfer level (RTL) circuit that implements the specified behavior . Behavioral synthesis can be sub-divided into several tasks including module selection , clock selection , scheduling , allocation and assignment. It is important to note that these tasks interact , and solving each one separately is likely to compromise the quality of the design. Pioneering work in architectural power optimization was presented in 1 , which used data path replication and pipelining to enable supply voltage scaling for power reduction . A methodology that used a variety of architectural transformations to reduce power consumption was presented in 2 . Module selection 4 , allocation and assignment 5 , 6 methods have also been proposed to reduce power consumption . While all the above methods perform some subset of the behavioral synthesis tasks to reduce power consumption by reducing the supply voltage or reducing the switched capacitance , few explore the tradeoffs involved in considering the interaction", "label": ["low power vlsi design", "behavioral synthesis", "power consumption"], "stemmed_label": ["low power vlsi design", "behavior synthesi", "power consumpt"]}
{"doc": "Sather extends the notion of an iterator in a powerful new way . We argue that iteration abstractions belong in class interfaces on an equal footing with routines . Sather iterators were derived from CLU iterators but are much more flexible and better suited for object-oriented programming . We retain the property that iterators are structured , i.e. , strictly bound to a controlling structured statement . We motivate and describe the construct along with several simple examples . We compare it with iteration based on CLU iterators , cursors , riders , streams , series , generators , coroutines , blocks , closures , and lambda expressions . Finally , we describe experiences with iterators in the Sather compiler and libraries . INTRODUCTION AND MOTIVATION Sather is an object-oriented language developed at the International Computer Science Institute Stoutamire and Omohundro 1995 . It has clean and simple syntax, parameterized classes , object-oriented dispatch (late binding) , multiple inheritance, strong typing , and garbage collection . It was originally derived from Eiffel but aims to achieve the performance of C without sacrificing elegance or safety . The first version of the language (\"Sather 0\") was released in May , 1991 . Feedback from users and our own use led to the design of \"Sather 1\" which incorporated a number of new language constructs . This article describes Sather iterators , a form of iteration abstraction. The original Sather had a fairly conventional until . loop . end state- ment . While this suffices for the most basic iterative tasks , we felt the need for a more general construct . As with C++ , Sather 0 libraries made heavy use of cursor Authors' addresses: S . Murer , Credit Suisse Os1 , 8070 Zurich , Switzerland; email: stephan.murer @ska.com; S . Omohundro , NEC Research Institute , Inc. , 4 Independence Way , Princeton , NJ 08540; email: om@research.nj.nec.com; D . Stoutamire , The International Computer Science In- stitute , 1947 Center Street , Suite 600 , Berkeley , CA 94704; email: davids@icsi.berkeley.edu; C. Szyperski , School of Computing Science , Queensland University of Technology , GPO Box 2434, Brisbane , QLD 4001 , Australia; email: c.szyperski@qut.edu.au. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage , the ACM copyright notice and the title of the publication and its date appear , and notice is given that copying is by permission of ACM. To copy otherwise , or to republish , requires a fee and/or specific permission. c objects to iterate through the contents of container objects Omohundro and Lim 1992 . While these work quite well in certain circumstances , they have a number of problems , described in detail in Section 4 . That section also describes approaches based on riders , closures , streams , series , generators , coroutines , and blocks. Like the language designers of CLU Liskov and Guttag 1986 , we felt a need to encapsulate the common", "label": ["iteration abstraction", "general control structures", "sather"], "stemmed_label": ["iter abstract", "gener control structur", "sather"]}
{"doc": "One popular family of low dicrepancy sets is the (t , m , s)-nets . Recently a randomization of these nets that preserves their net property has been introduced . In this article a formula for the mean square L2-discrepancy of (0 , m , s)-nets in base b is derived . This formula has a computational complexity of only O(s log(N) + s2) for large N or s , where bm is the number of points . Moreover , the root mean square L2-discrepancy of (0 , m , s)-nets is show to be O(N-1 log(N) (s-1)/2) as N tends to infinity , the same asymptotic order as the known lower bound for the L2-discrepancy of an arbitrary set . INTRODUCTION Multidimensional integrals over the s-dimensional unit cube C may be approximated by the sample mean of the integrand evaluated on a point set , P , with N points . (Here , in contrast to ordinary sets , P may have multiple copies of the same point Niederreiter 1992 , . 14 .) The quadrature error depends on how uniformly the points in P are distributed on the unit cube and on how much the integrand varies from a constant . For example , if D(P ) is the L 1 -star discrepancy Niederreiter 1992 , Definition 2.1 , and V (f) is the variation of f on the sense of Hardy and Krause , then the Koksma-Hlawka inequality Niederreiter 1992 , Theorem 2.11 is Z This research was partially supported by a Hong Kong RGC grant 94-95/38 and HKBU FRG grant 96-96/II-01. Address: Department of Mathematics , Hong Kong Baptist University , Kowloon Tong , Hong Kong , E-mail: fred@hkbu.edu.hk , URL: http://www.math.hkbu.edu.hk/~fred Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , to republish , to post on servers , to redistribute to lists , or to use any component of this work in other works , requires prior specific permission and/or a fee . Permissions may be requested from Publications Dept , ACM Inc. , 1515 Broadway , New York , NY 10036 USA , fax +1 (212) 869-0481 , or permissions@acm.org. ACM Transactions on Modeling and Computer Simululation , 1997 bounds of this form with other definitions of D(P ) and V (f) appear in the literature as well . A good set P for quadrature is one that has a small discrepancy, sets have been found that have smaller discrepancies than simple random points . These sets are often called quasi-random points. Calculating the L 1 -star discrepancy of a particular set is impractical unless both N and s are small", "label": ["quasi-random sets", "multidimensional integration", "quasi-monte carlo methods", "quadrature", "number-theoretic nets and sequences"], "stemmed_label": ["quasi-random set", "multidimension integr", "quasi-mont carlo method", "quadratur", "number-theoret net and sequenc"]}
{"doc": "This article studies an analytic model of parallel discrete-event simulation , comparing the YAWNS conservative synchronization protocol with Bounded Time Warp . The assumed simulation problem is a heavily loaded queuing network where the probability of an idle server is closed to zero . We model workload and job routing in standard ways , then develop and validate methods for computing approximated performance measures as a function of the degree of optimism allowed , overhead costs of state-saving , rollback , and barrier synchronization , and workload aggregation . We find that Bounded Time Warp is superior when the number of servers per physical processor is low (i.e. , sparse load) , but that aggregating workload improves YAWNS relative performance . INTRODUCTION Discrete-event simulations model physical systems . The literature on parallel discrete-event simulation (PDES) usually views a physical system as a set of communicating physical processes , each of which is represented in the simulation by a logical process (LP) . LPs communicate through time-stamped messages reflecting changes to the system state . A time-stamp reflects an instant where a state change occurs in the physical process model. Parallel discrete event simulation poses difficult synchronization problems , due to the underlying sense of logical time . Each LP maintains its own logical clock representing the time up to which the corresponding physical process has been simulated . The fundamental problem is to determine when an LP may execute a known future event , and in so doing advance its logical clock . If an LP advances its logical clock too far ahead of any other LP in the system it may receive a message with a time-stamp in its logical past , called a straggler . The threat of stragglers is dealt with by saving the simulation state periodically , and rolling back as appropriate when a straggler arrives . Messages sent at times ahead of the straggler's time-stamp must be undone . Fundamental problems of PDES are reviewed in Misra 1986 , Fujimoto 1990 , and Righter and Walrand 1989 . Nicol and Fujimoto Nicol and Fujimoto 1994 give a more current state-of-the-art review. Most PDES synchronization protocols fall into two basic categories (although a more detailed taxonomy is given in Reynolds 1988 ) . Conservative protocols (e.g. Chandy and Misra 1979 , Bryant 1977 , Peacock et al . 1979 , Lubachevsky 1988 , Chandy and Sherman 1989 , and Nicol 1993a ) do not allow an LP to process an event with time-stamp t if one is unable to assert that it will not receive another event with time-stamp less than t at some point in the future . Optimistic protocols (e.g . Time Warp , Jefferson 1985 ) allow an LP to process an event before it is known for certain that the LP will not later need to process an event with earlier time-stamp . Causality errors are corrected through a rollback mechanism. The earliest synchronization protocols are asynchronous-an LP synchronizes solely on the basis of interactions with LPs with which it directly communicates . Recently", "label": ["synchronization protocol", "parallel simulation"], "stemmed_label": ["synchron protocol", "parallel simul"]}
{"doc": "AbstractWe introduce a computation model for developing and analyzing parallel algorithms on distributed memory machines . The model allows the design of algorithms using a single address space and does not assume any particular interconnection topology . We capture performance by incorporating a cost measure for interprocessor communication induced by remote memory accesses . The cost measure includes parameters reflecting memory latency , communication bandwidth , and spatial locality . Our model allows the initial placement of the input data and pipelined prefetching.We use our model to develop parallel algorithms for various data rearrangement problems , load balancing , sorting , FFT , and matrix multiplication . We show that most of these algorithms achieve optimal or near optimal communication complexity while simultaneously guaranteeing an optimal speed-up in computational complexity . Ongoing experimental work in testing and evaluating these algorithms has thus far shown very promising results . Introduction Parallel processing promises to offer a quantum leap in computational power that is likely to have a substantial impact on various aspects of the computing field , and that in particular can be exploited to investigate a wide range of what has been called \"grand challenge\" problems in science and engineering . It is widely recognized 23 that an important ingredient for the success of this technology is the emergence of computational models that can be used for algorithms development and for accurately predicting the performance of these algorithms on real machines . We take a similar view as in 24 in that the computation model should be a \"bridging model\" that links the two layers of hardware and software . Existing computation models tend to be biased towards one or the other layer , except for very few exceptions . The Bulk Synchronous Parallel (BSP) model advocated by Valiant 24 is one of the few exceptions. In this paper , we introduce a computation model that specifically attempts to be a bridging model between the shared memory (single address) programming model and the distributed-memory message passing architectures . Distributed memory systems configured as a single address space are usually referred to as (scalable) shared memory multiprocessors . These machines achieve the scalability of distributed memory architectures and the simple programming style provided by the single address space. Our model can also be used for predicting performance of data parallel algorithms running on distributed memory architectures. Since a computation model should predict performance on real machines , we start with a discussion on the basis of our measure of communication costs incurred by accessing remote data . As indicated in 8 , the hardware organizations of massively parallel processors (MPPs) seem to be converging towards a collection of powerful processors connected by a communication network that can be modeled as a complete graph on which communication is subject to the restrictions imposed by the latency and the bandwidth properties of the network . According to this common or- ganization , the communication between the different processors is handled by point- to-point messages whose routing times are controlled by parameters related to the network", "label": ["parallel algorithms", "parallel model", "personalized communication", "matrix multiplication", "load balancing", "broadcasting", "sorting", "fast fourier transform"], "stemmed_label": ["parallel algorithm", "parallel model", "person commun", "matrix multipl", "load balanc", "broadcast", "sort", "fast fourier transform"]}
{"doc": "AbstractThis paper develops the theoretical background for the design of deadlock-free adaptive routing algorithms for virtual cut-through and store-and-forward switching . This theory is valid for networks using either central buffers or edge buffers . Some basic definitions and three theorems are proposed , developing conditions to verify that an adaptive algorithm is deadlock-free , even when there are cyclic dependencies between routing resources . Moreover , we propose a necessary and sufficient condition for deadlock-free routing . Also , a design methodology is proposed . It supplies fully adaptive , minimal and non-minimal routing algorithms , guaranteeing that they are deadlock-free.The theory proposed in this paper extends the necessary and sufficient condition for wormhole switching previously proposed by us . The resulting routing algorithms are more flexible than the ones for wormhole switching . Also , the design methodology is much easier to apply because it automatically supplies deadlock-free routing algorithms . Introduction Deadlocks may appear if the routing algorithms are not carefully designed . A deadlock occurs when no message or packet can advance toward its destination because the queues of the message system are full . Obviously , deadlocks arise because the number of resources is finite. Many deadlock-free routing algorithms have been developed for store-and- forward computer networks . Most of them require the use of central queues , restricting buffer allocation 7 , 16 , 19 , 21 , 28 , 33 . These algorithms are also applicable to virtual cut-through networks with central queues . Although algorithms that use central queues require less storage than those using edge buffers , central queues can become a bottleneck . So , algorithms that use edge buffers usually achieve a higher performance . Several researchers have proposed the use of edge buffers for multicomputer networks 22 , 25 . The restriction of buffer allocation , although it avoids deadlock , can increase traffic jams , especially in heavily loaded networks . In order to avoid congested regions of the network , an adaptive routing algorithm can be used . Adaptive strategies have been shown to outperform deterministic strategies in store-and- forward switching 5 , in packet-switched communications 24 , 35 and in wormhole switching 11 , 12 . When adaptive routing is used , deadlocks can be avoided in virtual cut-through and store-and-forward switching by misrouting packets in the presence of conges- tion . This technique , known as deflection or hot-potato routing 20 , requires the use of non-minimal paths . Examples of deflection routers for virtual cut-through networks can be found in 29 , 17 , 26 , 27 . This mechanism relies on the existence of as many input channels as output channels in each node . Incoming packets will always find a free output channel from the switch , sending packets away from the destination if necessary . If the only free output channel is the one connecting to local memory , the packet is buffered in the node . As mentioned above , this mechanism requires the use of misrouting , thus wasting channel", "label": ["design methodologies", "virtual cut-through", "interconnection networks", "deadlock avoidance", "adaptive routing", "store-and-forward"], "stemmed_label": ["design methodolog", "virtual cut-through", "interconnect network", "deadlock avoid", "adapt rout", "store-and-forward"]}
{"doc": "AbstractThe fault-tolerance of distributed algorithms is investigated in asynchronous message passing systems with undetectable process failures . Two specific synchronization problems are considered , the dining philosophers problem and the binary committee coordination problem . The abstraction of a bounded doorway is introduced as a general mechanism for achieving individual progress and good failure locality . Using it as a building block , optimal fault-tolerant algorithms are constructed for the two problems . Introduction The ability to tolerate failures is an important design requirement of computer systems in general , and of distributed systems in particular as the detection of failures becomes difficult in such systems . We investigate the effects of failures on distributed synchronization problems that require the co-operation of a set of independent processes . The specific problems we study assume an underlying undirected graph that defines the neighborhood of the processes . Inter-process communication is through message-passing and is only possible between neighboring processes . The goal is to design solutions for which the effect of the failure of a process can be confined to its immediate neighborhood . In other words, we are interested in solutions where processes are shielded from the effects of non-local failures . We assume the fail-stop model in which failures are undetectable and failed processes are indistinguishable from processes that are very slow. We choose the problems of dining philosophers and committee coordination as representatives of the class of distributed synchronization problems . The dining philosophers problem is a generalization of the mutual exclusion problem and can be used to solve many other synchronization problems . The committee coordination problem occurs in languages such as CSP 4 and Ada 1 that are based on synchronous message communication . We use failure locality 6 to measure the degree of fault- tolerance . The failure locality of an algorithm denotes the size of the neighborhood that gets affected by a failure . Thus , if an algorithm has a failure locality of m then any process for which there are no failures within a distance of m in the underlying graph executes as if no failures occurred . In other words , any such process continues to meet the specified safety and progress properties. The main contribution of this paper is the presentation of tight lower bounds on the failure locality of solutions to the dining philosophers and the committee coordination problem . This is achieved through the presentation of lower bounds and the design of solutions that achieve them . As a part of the optimal algorithms , we also introduce the idea of a bounded doorway . This doorway has the interesting property that when coupled with an algorithm ensuring the absence of global starvation , the doorway ensures the absence of local starvation without adding to the failure locality of the algorithm. This is in contrast to other kind of doorways 6 , 13 that add to the failure locality of the underlying algorithm. The rest of the paper is organized as follows . In Section 2 we present some of", "label": ["concurrency", "fault-tolerance", "lower bounds", "distributed algorithms", "synchronization"], "stemmed_label": ["concurr", "fault-toler", "lower bound", "distribut algorithm", "synchron"]}
{"doc": "AbstractWe consider the problem of statically assigning many tasks to a (smaller) system of homogeneous processors , where a task's structure is modeled as a branching process , all tasks are assumed to have identical behavior , and the tasks may synchronize frequently . We show how the theory of majorization can be used to obtain a partial order among possible task assignments . We show that if the vector of numbers of tasks assigned to each processor under one mapping is majorized by that of another mapping , then the former mapping is better than the latter with respect to a large number of objective functions . In particular , we show how the metrics of finishing time , the space-time product , and reliability are all captured . We also apply majorization to the problem of partitioning a pool of processors for distribution among parallelizable tasks . Limitations of the approach , which include the static nature of the assignment , are also discussed . Introduction We consider the problem of statically assigning tasks to processors when the tasks have unknown random processing times , a certain type of stochastic structure , and which synchronize with each other periodically . The stochastic structure we examine embodies the notion of one task spawning a set of others; we examine static assignments , under the assumption that all offspring of a task are executed on the same processor as the task . Static assignment of the type we consider is likely to be used when a task's state is large , thereby making dynamic assignment very costly in terms of communication . Semi-static assignments frequently also make sense 13 , 14 , where one periodically adjusts the load globally (executing a static assignment algorithm) once the performance degradation due to imbalance is severe enough to justify suffering task migration overheads . We consider different variations on synchronization , from the situation where a task's generation i offspring synchronize globally with all other tasks' generation i offspring , to the situation where the tasks execute independently and synchronize only to establish termination. This paper examines theoretical issues associated with comparing different static mappings of a set of complex stochastic tasks . In particular , we show how the theory of majorization can be used to derive strong results concerning the comparison of different mappings . The strength of our contribution lies in our providing a formal underpinning to the analysis of mapping complex stochastic tasks of a form common to parallel processing , and to the optimization of a rich class of objective functions . The theory we apply for Schur-convex objective functions is drawn from 10 ; the main result for symmetric convex objective functions we develop ourselves . Overall , our main contribution is in demonstrating how majorization can be applied to parallel processing's mapping problem . We also comment on the limitations of this application. Previous work on load balancing or task assignment 3 , 4 , 7 , 8 , 9 , 12 , 21 in parallel systems may", "label": ["majorization", "performance of parallel systems", "processor allocation", "load balancing", "task allocation", "task assignment", "resource allocation"], "stemmed_label": ["major", "perform of parallel system", "processor alloc", "load balanc", "task alloc", "task assign", "resourc alloc"]}
{"doc": "AbstractManagement of replicated data has received considerable attention in the last few years . Several replica control schemes have been proposed which work in the presence of both node and communication link failures . However , this resiliency to failure inflicts a performance penalty in terms of the communication overhead incurred . Though the issue of performance of these schemes from the standpoint of availability of the system has been well addressed , the issue of message overhead has been limited to the analysis of worst case and best case message bounds . In this paper we derive expressions for computing the average message overhead of several well known replica control protocols and provide a comparative study of the different protocols with respect to both average message overhead and system availabilities . Introduction In a distributed system , replication of data improves system availability . Replication however burdens the system with added responsibility of maintaining consistency among different copies of the same data . A replica control protocol is essentially a protocol for \"synchronizing\" concurrent read and write operations on a replicated data object by different concurrent transactions . To ensure one-copy serializability 4 , a read and a write operation to two different copies of the data (residing in two different \"nodes\" in the system) should not be allowed to execute concurrently . Also , two write requests to two different copies of the data should not be allowed to simultaneously update the copies. The simplest replica control protocol is the Majority Voting protocol suggested by Thomas 11 . In this protocol a node can proceed with an operation only if it gets permission from a majority of other nodes in the system . This has been generalized by Gifford 6 to what is called the Weighted Voting protocol where different votes may be assigned to each node . A node needs a majority of the votes before it can proceed with an operation . Availability of a system running a replica control protocol is the probability that an operation initiated in the system will proceed in spite of node failures . For example , availability of a system using the majority voting protocol is given by the probability that at least a majority of the nodes in the system are functional (are not faulty) . The communication overhead of these protocols is measured in terms of the number of messages that have to be exchanged before either permission is obtained for an operation to proceed or could be deemed unobtainable . For example , in the majority voting protocol , even if all the nodes are functional , the node initiating an operation has to send messages to b N+ 1c nodes in the system requesting permission to proceed with an operation . Though the majority voting (and weighted voting) protocol has high availability, the communication overhead increases linearly with the number of nodes in the system , making this protocol unsuitable for large systems. In replica control protocols based on Quorum Consensus , an operation initiated at a node", "label": ["quorum consensus", "replica control", "availability", "message overhead", "replicated databases", "update synchronization"], "stemmed_label": ["quorum consensu", "replica control", "avail", "messag overhead", "replic databas", "updat synchron"]}
{"doc": "AbstractWe address the problem of mapping divide-and-conquer programs to mesh connected multicomputers with wormhole or store-and-forward routing . We propose the binomial tree as an efficient model of parallel divide-and-conquer and present two mappings of the binomial tree to the 2D mesh . Our mappings exploit regularity in the communication structure of the divide-and-conquer computation and are also sensitive to the underlying flow control scheme of the target architecture . We evaluate these mappings using new metrics which are extensions of the classical notions of dilation and contention . We introduce the notion of communication slowdown as a measure of the total communication overhead incurred by a parallel computation . We conclude that significant performance gains can be realized when the mapping is sensitive to the flow control scheme of the target architecture . Introduction A well-known problem-solving paradigm that occurs in many computations is divide-and- conquer . If the subproblems are independent of each other , they may be executed in parallel , and this makes it a useful paradigm for designing large scale parallel programs. Divide-and-conquer has been studied by many researchers 7 , 2 , 3 , 13 , 14 and is applicable to a wide range of applications . In this paper , we address the problem of mapping degree- two divide and conquer computations on two-dimensional meshes . We represent these computations as a binomial tree and show that it runs in a phase by phase manner and that there is a regular pattern in the times at which messages are sent . In addition , the message volumes also exhibit regularity . One of our goals is to exploit all aspects of the regularity (topological , temporal , and message volume) , and still develop parameterized mappings for a family of graphs rather than a single graph. We present two mappings , called the reflecting mapping and the growing mapping , for embedding the divide-and-conquer binomial tree to a mesh . In addition to exploiting the regularity of the binomial tree , our mappings are sensitive to the flow-control technology of the target machine . Furthermore , we evaluate the mappings using new cost functions that are extensions of the standard contention and dilation metrics used in the embedding literature . We consider four pragmatic cases-whether the communication volumes are significantly larger or smaller than the startup overhead , and whether the routing mechanism is wormhole or store-and-forward. The remainder of the paper is organized as follows: Section 2 discusses related work. Section 3 describes the regular structure of divide-and-conquer computations . We present our mappings in Section 4 and describe the new performance metrics in Section 5 . Section 6 presents our analysis and we conclude with a discussion and indication of future work. Related Work The divide and conquer model has been widely recognized as an effective parallel programming paradigm 14 , 7 . Recently , an algebraic theory has been developed to provide a general framework to describe this class of computations and the mapping of such class of algorithms to hypercube-like architectures", "label": ["routing", "wormhole routing", "mesh connected machines", "mapping", "dilation", "binomial tree", "divide-and-conquer algorithms", "embedding", "store-and-forward routing", "contention"], "stemmed_label": ["rout", "wormhol rout", "mesh connect machin", "map", "dilat", "binomi tree", "divide-and-conqu algorithm", "embed", "store-and-forward rout", "content"]}
{"doc": "AbstractPhenomenal improvements in the computational performance of multiprocessors have not been matched by comparable gains in I/O system performance . This imbalance has resulted in I/O becoming a significant bottleneck for many scientific applications . One key to overcoming this bottleneck is improving the performance of multiprocessor file systems . The design of a high-performance multiprocessor file system requires a comprehensive understanding of the expected workload . Unfortunately , until recently , no general workload studies of multiprocessor file systems have been conducted . The goal of the CHARISMA project was to remedy this problem by characterizing the behavior of several production workloads , on different machines , at the level of individual reads and writes . The first set of results from the CHARISMA project describe the workloads observed on an Intel iPSC/860 and a Thinking Machines CM-5 . This paper is intended to compare and contrast these two workloads for an understanding of their essential similarities and differences , isolating common trends and platform-dependent variances . Using this comparison , we are able to gain more insight into the general principles that should guide multiprocessor file-system design . Introduction There is a growing imbalance between the computational performance and the I/O subsystem performance in multiprocessors . This imbalance has resulted in I/O becoming a significant bottleneck for many scientific applications . Thus , there is a clear need for improvements in the design of high-performance parallel file systems to enable them to meet the I/O needs of these applications. To be successful , a system designer must possess a thorough understanding of how the system is likely to be used . Only with such an understanding can a system's policies and mechanisms be optimized for the cases expected to be most common in that system's work- load . Designers have so far been forced to rely on speculation about how parallel file systems would be used , extrapolating from file-system characterizations of general-purpose workloads on uniprocessor and distributed systems or of scientific workloads on vector supercomputers. To address this limitation , we initiated the CHARISMA project in June 1993 to CHARacterize I/O in Scientific Multiprocessor Applications from a variety of production parallel computing platforms and sites . 1 While some work has been done in studying the I/O needs of parallel scientific applications (typically by examining a small number of selected appli- cations) , the CHARISMA project is unique in recording individual read and write requests in live , multiprogramming , parallel workloads . We have so far completed characterization studies on an Intel iPSC/860 at NASA's Ames Research Center 1 and on a Thinking Machines CM-5 at the National Center for Supercomputing Applications 2 . On both systems we addressed a similar set of questions: ffl What did the job mix look like: How many jobs were run concurrently? How many processors did each job use? ffl How many files were read and written? What were their 1 More about CHARISMA may be found at http://www.cs.dartmouth.edu/research/charisma.html. ffl What were typical read and write request sizes , and how were", "label": ["workload characterization", "parallel file system", "parallel i/o", "multiprocessor", "scientific computing"], "stemmed_label": ["workload character", "parallel file system", "parallel i/o", "multiprocessor", "scientif comput"]}
{"doc": "AbstractAs massively parallel computers proliferate , there is growing interest in finding ways by which performance of massively parallel codes can be efficiently predicted . This problem arises in diverse contexts such as parallelizing compilers , parallel performance monitoring , and parallel algorithm development . In this paper , we describe one solution where one directly executes the application code , but uses a discrete-event simulator to model details of the presumed parallel machine , such as operating system and communication network behavior . Because this approach is computationally expensive , we are interested in its own parallelization , specifically the parallelization of the discrete-event simulator . We describe methods suitable for parallelized direct execution simulation of message-passing parallel programs , and report on the performance of such a system , LAPSE (Large Application Parallel Simulation Environment) , we have built on the Intel Paragon . On all codes measured to date , LAPSE predicts performance well , typically within 10% relative error . Depending on the nature of the application code , we have observed low slowdowns (relative to natively executing code) and high relative speedups using up to 64 processors . Introduction Performance prediction and/or analysis of parallel programs is currently an important area of research , especially as parallel computers are coming to dominate the high performance computing arena . Writers of parallel compilers would like to be able to predict performance as an aid towards generating efficient highly parallel code . Users of performance instrumentation and tuning tools are interested in predicting and observing parallel performance , but must deal with the fact that instrumentation code may perturb their measurements . Developers of new parallel algorithms are interested in predicting how well the performance of a new algorithm scales up with increasing problem size and machine architecture . General users may be interested in performance tuning their codes for large numbers of processors (which are only infrequently available) using fewer , more readily available resources . Designers of new communication networks are interested in evaluating their designs under realistic workloads. The method of direct execution simulation 4 , 5 , 9 , 11 , 16 of application codes offers a solution to each of these problems . Under a direct execution simulation all application code is directly executed to obtain information about the application's execution behavior , but all references by the application code to the simulated virtual machine are trapped by the simulator . From the point of view of the application code , it is running on the virtual machine . Thus , when the application executes temporal calls such as \"what is the wallclock time now\" , or , \"is there a message of type T available now\" , the response depends on the state of the virtual machine simulator at the simulated time of the call's placement . From the point of view of the simulator , the application code is a driver , describing the activity to be simulated . A detailed direct execution simulator for parallel programs offers the potential for accurate", "label": ["message-passing programs", "parallel simulation", "direct execution simulation", "architectural simulation", "synchronization", "mimd", "contention"], "stemmed_label": ["message-pass program", "parallel simul", "direct execut simul", "architectur simul", "synchron", "mimd", "content"]}
{"doc": "We describe a divide-and-conquer tridiagonalization approach for matrices with repeated eigenvalues . Our algorithm hinges on the fact that , under easily constructively verifiable conditions , a symmetric matrix with band width $b$ and $k$ distinct eigenvalues must be block diagonal with diagonal blocks of size at most $b k$ . A slight modification of the usual orthogonal band-reduction algorithm allows us to reveal this structure , which then leads to potential parallelism in the form of independent diagonal blocks . Compared to the usual Householder reduction algorithm , the new approach exhibits improved data locality , significantly more scope for parallelism , and the potential to reduce arithmetic complexity by close to 50% for matrices that have only two numerically distinct eigenvalues . The actual improvement depends to a large extent on the number of distinct eigenvalues and a good estimate thereof . However , at worst the algorithms behave like a successive band-reduction approach to tridiagonalization . Moreover , we provide a numerically reliable and effective algorithm for computing the eigenvalue decomposition of a symmetric matrix with two numerically distinct eigenvalues . Such matrices arise , for example , in invariant subspace decomposition approaches to the symmetric eigenvalue problem . Introduction Let A be an n \\Theta n symmetric matrix . Our goal is to compute an orthogonal-tridiagonal decomposition of A , AQ=QT , where Q is orthogonal and T is tridiagonal . Reduction to tridiagonal form is a standard preprocessing step in dense eigensolvers based on QR iteration , bisection , or Cuppen's method 16 . The conventional tridiagonalization procedure 16 , . 419 reduces A one column at a time through a Householder transformation at a cost of O(4n 3 =3) flops for the reduction of A , and an This work was supported by the Advanced Research Projects Agency , under contract DM28E04120 and P-95006, and the Mathematical , Information , and Computational Sciences Division subprogram of the Office of Computational and Technology Research , U.S . Department of Energy , under Contract W-31-109-Eng-38. y The work of this author was partially performed while she was a postdoctoral associate at Argonne National Laboratory. z All PRISM Working Notes can be retrieved via anonymous ftp from the pub/prism directory at ftp.super.org. additional O(4n 3 =3) flops if the orthogonal matrix is accumulated at the same time . This algorithm employs mainly matrix-vector multiplications and symmetric rank-one updates , which require more memory references than the matrix-matrix operations 9,8,14 . The block tridiagonalization algorithm in 5 , 15 combines sets of successive symmetric rank- updates into one symmetric rank-p update , at the cost of O(2pn 2 ) extra flops . As a result, this algorithm exhibits improved data locality and hence is likely to be preferable on cache-based architectures . This block algorithm has been incorporated into the LAPACK library of portable linear algebra codes for high-performance architectures 1 , 2 . Parallel versions for distributed-memory machines of the standard algorithm and of the block algorithm are described in 12 and in 13 , respectively . A different", "label": ["repeated eigenvalues", "eigenvalue decomposition", "tridiagonalization"], "stemmed_label": ["repeat eigenvalu", "eigenvalu decomposit", "tridiagon"]}
{"doc": "An approximate minimum degree (AMD) ordering algorithm for preordering a symmetric sparse matrix prior to numerical factorization is presented . We use techniques based on the quotient graph for matrix factorization that allow us to obtain computationally cheap bounds for the minimum degree . We show that these bounds are often equal to the actual degree . The resulting algorithm is typically much faster than previous minimum degree ordering algorithms and produces results that are comparable in quality with the best orderings from other minimum degree algorithms . Introduction . When solving large sparse symmetric linear systems of the is common to precede the numerical factorization by a symmetric reordering . This reordering is chosen so that pivoting down the diagonal in order on the resulting permuted matrix PAP produces much less fill-in and work than computing the factors of A by pivoting down the diagonal in the original order . This reordering is computed using only information on the matrix structure without taking account of numerical values and so may not be stable for general matrices . However, if the matrix A is positive-definite 21 , a Cholesky factorization can safely be used. This technique of preceding the numerical factorization with a symbolic analysis can also be extended to unsymmetric systems although the numerical factorization phase must allow for subsequent numerical pivoting 1 , 2 , 16 . The goal of the preordering is to find a permutation matrix P so that the subsequent factorization has the least fill-in . Unfortunately , this problem is NP-complete 31 , so heuristics are used. The minimum degree ordering algorithm is one of the most widely used heuristics, since it produces factors with relatively low fill-in on a wide range of matrices . Because of this , the algorithm has received much attention over the past three decades . The algorithm is a symmetric analogue of Markowitz' method 26 and was first proposed by Tinney and Walker 30 as algorithm S2 . Rose 27 , 28 developed a graph theoretical model of Tinney and Walker's algorithm and renamed it the minimum degree algorithm , since it performs its pivot selection by selecting from a graph a node of minimum degree . Later implementations have dramatically improved the time and memory requirements of Tinney and Walker's method , while maintaining the basic idea of selecting a node or set of nodes of minimum degree . These improvements have reduced the memory complexity so that the algorithm can operate within the storage of the original matrix , and have reduced the amount of work needed to keep track of the degrees of nodes in the graph (which is the most computationally intensive part Computer and Information Sciences Department University of Florida , Gainesville , Florida, USA . phone: (904) 392-1481 , email: davis@cis.ufl.edu . Support for this project was provided by the National Science Foundation (ASC-9111263 and DMS-9223088) . Portions of this work were supported by a post-doctoral grant from CERFACS. y ENSEEIHT-IRIT , Toulouse , France . email: amestoy@enseeiht.fr. z Rutherford Appleton Laboratory , Chilton", "label": ["ordering algorithms", "quotient graph", "graph algorithms", "approximate minimum degree ordering algorithm", "sparse matrices"], "stemmed_label": ["order algorithm", "quotient graph", "graph algorithm", "approxim minimum degre order algorithm", "spars matric"]}
{"doc": "Certain interesting classes of functions on a real inner product space are invariant under an associated group of orthogonal linear transformations . This invariance can be made explicit via a simple decomposition . For example , rotationally invariant functions on \\bf R $^2$ are just even functions of the Euclidean norm , and functions on the Hermitian matrices (with trace inner product) which are invariant under unitary similarity transformations are just symmetric functions of the eigenvalues . We develop a framework for answering geometric and analytic (both classical and nonsmooth) questions about such a function by answering the corresponding question for the (much simpler) function appearing in the decomposition . The aim is to understand and extend the foundations of eigenvalue optimization , matrix approximation , and semidefinite programming . Introduction Why is there such a strong parallel between , on the one hand , semidefinite programming and other eigenvalue optimization problems , and on the other hand , ordinary linear programming and related problems? Why are there close analogies between many important matrix norms on the one hand , and associated vector norms on the other? This paper aims to explain the simple algebraic symmetries which drive these parallels. A simple example may be illustrative . Suppose that we wish to understand convex functions f which are 'orthogonally invariant' . By this we mean that point x in R n and any orthogonal matrix U . What can we say about such functions? We might observe first that , since f is determined by its behaviour on the where the function h : R+ ! R is defined by What conditions on h are equivalent to the convexity of f? Clearly h must be convex (being the restriction of f to a half-line) , but this is not sufficient. After some more thought we might arrive at the answer: h must be convex , and nondecreasing at the origin . But this obscures the essential symmetry of f . A simple trick allows us to preserve this in our answer. Instead of examining the restriction of f to the half-line R+ e 1 we consider the restriction to the whole subspace Re 1 . We then arrive at the much more only if the function h even and convex. This easy example illustrates the fundamental technique of this paper: analyzing the consequences of the symmetries of a function by analyzing its symmetries on a 'transversal' (or defining) subspace . Von Neumann's famous 1937 characterization of unitarily invariant matrix norms 33 is precisely in this mold . One statement of this result is that a unitarily invariant matrix function f (one satisfying unitary u and v) is a norm exactly when its restriction to the subspace of real diagonal matrices is a symmetric gauge function. What algebraic structure underlies von Neumann's result? There are three essential ingredients: first , a real inner product space X (in this case secondly , a (closed) group G of orthogonal linear transformations (in this case those of the form x 7! uxv for unitary u and", "label": ["convexity", "semidefinite program", "fenchel conjugate", "von neumann's lemma", "spectral function", "extreme point", "group invariance", "nonsmooth analysis", "unitarily invariant norm", "schur convex", "eigenvalue optimization", "subdifferential"], "stemmed_label": ["convex", "semidefinit program", "fenchel conjug", "von neumann' lemma", "spectral function", "extrem point", "group invari", "nonsmooth analysi", "unitarili invari norm", "schur convex", "eigenvalu optim", "subdifferenti"]}
{"doc": "AbstractMemory hierarchies have long been studied by many means: system building , trace-driven simulation , and mathematical analysis . Yet little help is available for the system designer wishing to quickly size the different levels in a memory hierarchy to a first-order approximation . In this paper , we present a simple analysis for providing this practical help and some unexpected results and intuition that come out of the analysis . By applying a specific , parameterized model of workload locality , we are able to derive a closed-form solution for the optimal size of each hierarchy level . We verify the accuracy of this solution against exhaustive simulation with two case studies: a three-level I/O storage hierarchy and a three-level processor-cache hierarchy . In all but one case , the configuration recommended by the model performs within 5% of optimal . One result of our analysis is that the first place to spend money is the cheapest (rather than the fastest) cache level , particularly with small system budgets . Another is that money spent on an n-level hierarchy is spent in a fixed proportion until another level is added . Introduction F AST memory and storage systems are vital to achieving good system performance , as CPU speeds increase faster than memory and disk speeds . Almost all systems use caching throughout the disk , memory , and processor subsystems to improve the average time to access data, but the widening gap between storage technologies makes it easy to lose significant performance through poor cache sizing . Unfortunately , little practical help exists for system designers and administrators seeking to optimize their cache hierarchies . Exhaustive simulation takes far too long, particularly as hierarchies become more complex 16 ; trial and error on running systems is usually impossible; and prior mathematical analyses have stopped short of providing much-needed , intuitive insight into cache sizing 10 or have assumed the availability of memory technologies with B . Jacob , P . Chen , and T . Mudge are with the Advanced Computer Architecture Laboratory , Department of Electrical Engineering and Computer Science , University of Michigan , Ann Arbor , MI 48109-2122 . e-mail: blj@eecs.umich.edu; pmchen@eecs.umich.edu; tnm@eecs.umich.edu. S . Silverman is with Chelmsford Systems Software Lab , Hewlett- Packard , Chelmsford , MA 01824 . e-mail: seth@apollo.hp.com Personal use of this material is permitted . However , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or distribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the IEEE . This material is presented to ensure timely dissemination of scholarly and technical work . Copyright and all rights therein are retained by authors or by other copyright holders . All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright . In most cases , these works may not be reposted without the explicit permission of the copyright holder. arbitrary speeds and", "label": ["cache", "optimization of cache configurations", "memory", "and storage hierarchies", "trace-driven simulations"], "stemmed_label": ["cach", "optim of cach configur", "memori", "and storag hierarchi", "trace-driven simul"]}
{"doc": "Object-code compatibility between processor generations is an open issue for VLIW architectures . A potential solution is a technique termed dynamic rescheduling , which performs run-time software rescheduling at the first-time page faults . The time required for rescheduling the pages constitutes a large portion of the overhead of this method . A disk caching scheme that uses a persistent rescheduled-page cache (PRC) is presented . The scheme reduces the overhead associated with dynamic rescheduling by saving rescheduled pages on disk , across program executions . Operating system support is required for dynamic rescheduling and management of the PRC . The implementation details for the PRC are discussed . Results of simulations used to gauge the effectiveness of PRC indicate that: the PRC is effective in reducing the overhead of dynamic rescheduling; and due to different overhead requirements of programs , a split PRC organization performs better than a unified PRC . The unified PRC was studied for two different page replacement policies: LRU and overhead-based replacement . It was found that with LRU replacement , all the programs consistently perform better with increasing PRC sizes , but the high-overhead programs take a consistent performance hit compared to the low-overhead programs . With overhead-based replacement , the performance of high-overhead programs improves substantially , while the low-overhead programs perform only slightly worse than in the case of the LRU replacement . Introduction Unlike contemporary superscalar processors 1 2 3 which employ dynamic scheduling , VLIW processors de- Published in: Proc . 29th Annual Int'l Symp . on Microarchitecture, Paris , 1996 pend on a schedule of code generated by the compiler . The compiler has full knowledge of the machine model , described in terms of the hardware resources available , and the latencies related to execution on each resource . Correct execution of a program scheduled under one machine model assumptions is guaranteed only on processors that have exactly the same machine model or , its supersets where the assumptions are strictly held . Thus , a program scheduled for a particular generation in a VLIW family cannot be guaranteed to be binary compatible with other generations. This is known as the object-code compatibility problem in VLIW architectures 4 . Lack of object-code compatibility is a commonly cited reason why VLIWs may not become a general-purpose computing paradigm 5 . Solutions to the problem have been suggested and can be classified as hardware or software approaches . Hardware techniques typically employ scheduling hardware 6 , 7 , 4 , 8 , 9 , which could substantially increase the hardware complexity of the machine . A common software approach is that of off-line recompilation of source programs , which yields excellent performance because the compiler has access to all the necessary information to expose the ILP in the program. The drawback of this technique is that it is cumbersome to use , because access to source code may not always be pos- sible . A variant of this is off-line object-code translation, which is more practical when the source code is unavailable", "label": ["low overhead object code compatibility", "run-time software rescheduling", "program executions", "persistent rescheduled-page cache", "high-overhead programs", "page replacement policies", "first-time page faults", "simulations", "lru replacement", "cache storage", "vliw architectures", "program performance", "operating system support", "disk caching scheme", "overhead-based replacement", "dynamic rescheduling"], "stemmed_label": ["low overhead object code compat", "run-tim softwar reschedul", "program execut", "persist rescheduled-pag cach", "high-overhead program", "page replac polici", "first-tim page fault", "simul", "lru replac", "cach storag", "vliw architectur", "program perform", "oper system support", "disk cach scheme", "overhead-bas replac", "dynam reschedul"]}
{"doc": "Code scheduling to exploit instruction level parallelism (ILP) is a critical problem in compiler optimization research in light of the increased use of long-instruction-word machines . Unfortunately optimum scheduling is computationally intractable , and one must resort to carefully crafted heuristics in practice . If the scope of application of a scheduling heuristic is limited to basic blocks , considerable performance loss may be incurred at block boundaries . To overcome this obstacle , basic blocks can be coalesced across branches to form larger regions such as super blocks . In the literature , these regions are typically scheduled using algorithms that are either oblivious to profile information (under the assumption that the process of forming the region has fully utilized the profile information) , or use the profile information as an addendum to classical scheduling techniques . We believe that even for the simple case of linear code regions such as super blocks , additional performance improvement can be gained by utilizing the profile information in scheduling as well . We propose a general paradigm for converting any profile-insensitive list scheduler to a profile-sensitive scheduler . Our technique is developed via a theoretical analysis of a simplified abstract model of the general problem of profile-driven scheduling over any acyclic code region , yielding a scoring measure for ranking branch instructions . Introduction The performance of a VLIW machine depends strongly on the ability of the compiler to exploit instruction level parallelism (ILP) in programs . Unfortunately , the task of the compiler is made difficult by the presence of a number of intractable optimization problems such as instruction scheduling and register allocation . In this paper , we study one such problem - scheduling with profile information. We believe that our results will serve as a good starting point for developing practical heuristics that are to be included in compilers for VLIW machines . As evidence , we present experimental results validating heuristics suggested by our analysis. A basic block is a program fragment that may only be entered at the top and exited at the bottom . The precedence graph of a single basic block will be a directed acyclic graph (DAG) 2 , and in practice , typically consists of fewer than vertices . Scheduling small basic blocks consecutively and separately leads to underutilization of the functional units due to sequentialization effects at the block bound- aries . To overcome this limitation two broad approaches have been proposed . One called if-conversion , eliminates the branches via hardware support for predicated execution, allowing instructions to be moved outside of their basic blocks , see 4 for instance . The other approach does not require hardware support , and involves the formation of larger code regions such as traces , 7 , and super blocks , 14 . A super block consists of a sequence of basic blocks strung together , with conditional exits at the branch points that separate the basic blocks . Super blocks are typically formed as follows . Given is a code region with branch probabilities", "label": ["long-instruction-word machines", "scheduling heuristic", "compiler optimization", "optimum scheduling", "abstract model", "ranking branch instructions", "optimising compilers", "profile-driven instruction level parallel scheduling", "profile-sensitive scheduler", "linear code regions", "code scheduling"], "stemmed_label": ["long-instruction-word machin", "schedul heurist", "compil optim", "optimum schedul", "abstract model", "rank branch instruct", "optimis compil", "profile-driven instruct level parallel schedul", "profile-sensit schedul", "linear code region", "code schedul"]}
{"doc": "Much of the previous work on modulo scheduling has targeted numeric programs , in which , often , the majority of the loops are well-behaved loop-counter-based loops without early exits . In control-intensive non-numeric programs , the loops frequently have characteristics that make it more difficult to effectively apply modulo scheduling . These characteristics include multiple control flow paths , loops that are not based on a loop counter , and multiple exits . In these loops , the presence of unimportant paths with high resource usage or long dependence chains can penalize the important paths . A path that contains a hazard such as another nested loop can prohibit modulo scheduling of the loop . Control dependences can severely restrict the overlap of the blocks within and across iterations . This paper describes a set of methods that allow effective modulo scheduling of loops with multiple exits . The techniques include removal of control dependences to enable speculation , extensions to modulo variable expansion , and a new epilogue generation scheme . These methods can be used with superblock and hyperblock techniques to allow modulo scheduling of the selected paths of loops with arbitrary control flow . A case study is presented to show how these methods , combined with superblock techniques , enable modulo scheduling to be effectively applied to control-intensive non-numeric programs . Performance results for several SPEC CINT92 benchmarks and Unix utility programs are reported and demonstrate the applicability of modulo scheduling to this class of programs . Introduction The scheduling of instructions in loops is of great interest because many programs spend the majority of their execution time in loops . It is often necessary for the scheduler to overlap successive iterations of a loop in order to find Copyright 1996 IEEE . Published in the Proceedings of the 29th Annual International Symposium on Microarchitecture , December 2-4 , 1996 , Paris , France . Personal use of this material is permitted . However , permission to reprint/republish this material for resale or redistribution purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE . Contact: Manager , Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O. 908-562-3966 sufficient instruction-level parallelism (ILP) to effectively utilize the resources of high-performance processors. Software pipelining 18 , 6 , 1 , 15 , is a loop scheduling scheme that allows motion of instructions from one iteration to another and maintains the overlap of loop iterations throughout the execution of the loop . A description of the various approaches to software pipelining is given in 17 . This paper focuses on a class of software pipelining methods called scheduling 16 . Modulo scheduling simplifies the generation of overlapped schedules by initiating iterations at a constant rate and by requiring all iterations of the loop to have a common schedule . The constant interval between the start of successive iterations is called the initiation", "label": ["speculation", "software pipelining", "control-intensive", "instruction-level parallelism", "modulo scheduling", "modulo variable expansion"], "stemmed_label": ["specul", "softwar pipelin", "control-intens", "instruction-level parallel", "modulo schedul", "modulo variabl expans"]}
{"doc": "Many high performance processors predict conditional branches and consume processor resources based on the prediction . In some situations , resource allocation can be better optimized if a confidence level is assigned to a branch prediction; i.e . if the quantity of resources allocated is a function of the confidence level . To support such optimizations , we consider hardware mechanisms that partition conditional branch predictions into two sets: those which are accurate a relatively high percentage of the time , and those which are accurate a relatively low percentage of the time . The objective is to concentrate as many of the mispredictions as practical into a relatively small set of low confidence dynamic branches . We first study an ideal method that profiles branch predictions and sorts static branches into high and low confidence sets , depending on the accuracy with which they are dynamically predicted . We find that about 63 percent of the mispredictions can be localized to a set of static branches that account for 20 percent of the dynamic branches . We then study idealized dynamic confidence methods using both one and two levels of branch correctness history . We find that the single level method performs at least as well as the more complex two level method and is able to isolate 89 percent of the mispredictions into a set containing 20 percent of the dynamic branches . Finally , we study practical , less expensive implementations and find that they achieve most of the performance of the idealized methods . Introduction It is becoming common practice in high performance processors to predict conditional branches 4 , 7 , 9 , 13 and speculatively execute instructions based on the prediction 2 , 8 . Typically , when speculation is used , all branch predictions are acted upon because there is low penalty for speculating incorrectly . I.e . most resources available to speculative instructions would be unused anyway . And , on average , a branch prediction will be correct a high percentage of the time. However , as processors become more advanced, we can envision implementations where the penalty for an incorrect speculation may be high enough that it may be better not to speculate in those instances where the likelihood of a branch misprediction is relatively high . That is, it may be desirable to vary behavior depending on the likelihood of a misprediction . Consequently , we would like to develop hardware methods for assessing the likelihood that a conditional branch prediction is correct; we refer to these as branch prediction confidence mechan- isms . Consider the following potential applications. Selective Dual Path Execution: Resources may be made available for simultaneously executing instructions down both paths following a conditional branch . How- ever , it will likely be too expensive to follow both paths after all branches , especially when several conditional branches may be unresolved at any given time . Conse- quently , it may be desirable to set a limit of two threads at any given time and to fork", "label": ["dynamic branches", "processor resources", "branch correctness", "static branches", "conditional branch predictions", "resource allocation"], "stemmed_label": ["dynam branch", "processor resourc", "branch correct", "static branch", "condit branch predict", "resourc alloc"]}
{"doc": "VLIW architectures use very wide instruction words in conjunction with high bandwidth to the instruction cache to achieve multiple instruction issue . This report uses the TINKER experimental testbed to examine instruction fetch and instruction cache mechanisms for VLIWs . A compressed instruction encoding for VLIWs is defined and a classification scheme for i-fetch hardware for such an encoding is introduced . Several interesting cache and i-fetch organizations are described and evaluated through trace-driven simulations . A new i-fetch mechanism using a silo cache is found to have the best performance . Introduction VLIW architectures use very wide instruction words to achieve multiple instruction issue . These architectures require high bandwidth instruction fetch (i-fetch) mechanisms to transport instruction words from the cache to the execution pipeline . The complexity of the hardware support required for i-fetch is related to the type of instruction encoding used . In general , VLIW instructions are horizontally encoded wide words that issue an operation on every clock cycle to functional units (FUs) in the machine . The sequence of instruction words that compose a program is the schedule c fl1996 IEEE . This paper will appear in the Proceedings of the 29th Annual Symposium on Microarchitecture , Dec.2-4 , 1996 , Paris , France. Personal use of this material is permitted . However , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. for the program . The instruction words can be encoded in several ways , and the choice of encoding can greatly influence the hardware required for i-fetch . A VLIW with an uncompressed encoding is one that explicitly stores NOP operations in the instruction word . The VLIW instruction stores a NOP in the operation slot for a particular FU if this FU is not scheduled to execute an operation at that point in the schedule . Use of an uncompressed encoding yields a fixed length instruction word , which can simplify the i-fetch hardware but at the expense of the potentially poor memory utilization. Another class of encodings are compressed encodings, which do not store NOPs . VLIW instructions encoded using a compressed encoding are variably sized . The size of an instruction is dependent on the number of FUs that will receive an operation at that point in the schedule . This type of encoding has a higher memory utilization and allows greater effective memory bandwidth than an uncompressed encoding . A compressed encoding also aids in object-code compatibility for VLIWs , such as in the dynamic rescheduling algorithm that has been proposed in the TINKER VLIW testbed 9 . A drawback is that such an encoding requires more complicated i-fetch to handle the variable length instructions This paper focuses on the requirements of i-fetch imposed by a compressed encoding . Several mechanisms for i-fetch are presented , and the effect of each mechanism on instruction cache", "label": ["parallel architectures", "i-fetch hardware", "instruction words", "tinker experimental testbed", "compressed encodings", "compressed instruction encoding", "silo cache", "instruction cache", "instruction fetch mechanisms", "vliw architectures", "multiple instruction issue", "trace-driven simulations"], "stemmed_label": ["parallel architectur", "i-fetch hardwar", "instruct word", "tinker experiment testb", "compress encod", "compress instruct encod", "silo cach", "instruct cach", "instruct fetch mechan", "vliw architectur", "multipl instruct issu", "trace-driven simul"]}
{"doc": "AbstractThis paper presents a new model for estimating optical flow based on the motion of planar regions plus local deformations . The approach exploits brightness information to organize and constrain the interpretation of the motion by using segmented regions of piecewise smooth brightness to hypothesize planar regions in the scene . Parametric flow models are estimated in these regions in a two step process which first computes a coarse fit and estimates the appropriate parameterization of the motion of the region (two , six , or eight parameters) . The initial fit is refined using a generalization of the standard area-based regression approaches . Since the assumption of planarity is likely to be violated , we allow local deformations from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus local deformations . This parametric+deformation model exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches . Experimental results on a variety of images indicate that the parametric+deformation model produces accurate flow estimates while the incorporation of brightness segmentation provides precise localization of motion boundaries . Introduction Estimating the optical flow in scenes containing significant depth variation , independent motion , or articulate objects necessitates the segmentation of the scene into regions of coherent motion . If the scene were segmented into roughly planar surface patches then the motion of each surface patch could be estimated using a parametric flow model . Given large numbers of constraints computed within the patch and a small number of parameters to be estimated , these parametric models provide strong constraints on the motion within a region resulting in accurate flow estimates . In contrast to recent parametric approaches which assume that an arbitrary image region can be modeled by a single motion , we independently model the motion of segmented planar surface regions . But segmentation is a hard problem in its own right and , in particular , the recovery of segmented , or piecewise smooth , flow fields is notoriously difficult . Instead , this paper makes the simple hypothesis that image regions of piecewise smooth brightness are likely to correspond to surfaces in the world . These brightness regions are assumed to be planar surfaces in the scene and their motion is estimated using a variable-order parametric flow model containing two , six , or eight parameters. In this way , information about image brightness is used to organize and constrain the interpretation of the optical flow . Since the assumption of planarity may be violated , we allow local deformation from the planar assumption in the same spirit as physically-based approaches which model shape using coarse parametric models plus deformations . The resulting model , in which optical flow is represented by the motion of planar image patches with local deformations , exploits the strong constraints of parametric approaches while retaining the adaptive nature of regularization approaches. Experiments with natural and synthetic image sequences indicate that the parametric+deformation model produces accurate flow estimates while the incorporation of brightness", "label": ["segmentation", "parameterized flow models", "robust regression", "local deformation", "optical flow"], "stemmed_label": ["segment", "parameter flow model", "robust regress", "local deform", "optic flow"]}
{"doc": "AbstractFeature detectors using a quadratic nonlinearity in the filtering stage are known to have some advantages over linear detectors; here , we consider their scale-space properties . In particular , we investigate whether , like linear detectors , quadratic feature detectors permit a scale selection scheme with the \"causality property,\" which guarantees that features are never created as scale is coarsened . We concentrate on the design most common in practice , i.e. , one dimensional detectors with two constituent filters , with scale selection implemented as convolution with a scaling function . We consider two special cases of interest: constituent filter pairs related by the Hilbert transform , and by the first spatial derivative . We show that , under reasonable assumptions , Hilbert-pair quadratic detectors cannot have the causality property . In the case of derivative-pair detectors , we describe a family of scaling functions related to fractional derivatives of the Gaussian that are necessary and sufficient for causality . In addition , we report experiments that show the effects of these properties in practice . Thus we show that at least one class of quadratic feature detectors has the same desirable scaling property as the more familiar detectors based on linear filtering . Introduction The process of detecting image features across a range of scales is important in many machine vision applications , and dates at least from Rosenfeld 18 and Marr 10 . In practical systems using multiscale techniques , features detected at a coarse scale can determine the flow of processing at finer scales . It is thought to be important in this context that features detected at a given resolution were not created gratuitously at that scale , but rather are \"grounded\" in image detail at a finer resolution . When a multiscale feature detection method never introduces features as the scale is coarsened , it has the desirable property of causality . 1 A multiscale feature detection method comprises a way of detecting features, and a way of selecting the scale of features detected . It is known that edge detectors which operate by marking edges at zeros or extrema in the output of a linear differential filter acting on the image have the causality property if scale is selected by convolution of the image with a Gaussian 2,19 , and these results have been extended to scale selection by anisotropic diffusion 15 . More recently , quadratic nonlinear filters for feature detection have been proposed as having advantages over linear filters , particularly in their ability to detect and localize features with complex structure 6,9,12-14 . However , the question whether these quadratic or \"energy\" detectors permit a causal scale selection technique has remained open. In this paper , we address this question for one-dimensional quadratic feature detectors when scale is selected by convolution of the image with a scaling function. We concentrate on detectors with two constituent filters , one even-symmetric and one odd-symetric , this being the design most widely used in practice . We consider two special cases of practical interest:", "label": ["feature detection", "quadratic filters", "edge detection", "causality", "nonlinear filtering", "energy filters", "scale space"], "stemmed_label": ["featur detect", "quadrat filter", "edg detect", "causal", "nonlinear filter", "energi filter", "scale space"]}
{"doc": "AbstractThe rapid advances in high-performance computer architecture and compilation techniques provide both challenges and opportunities to exploit the rich solution space of software pipelined loop schedules . In this paper , we develop a framework to construct a software pipelined loop schedule which runs on the given architecture (with a fixed number of processor resources) at the maximum possible iteration rate ( la rate-optimal) while minimizing the number of buffersa close approximation to minimizing the number of registers.The main contributions of this paper are: First , we demonstrate that such problem can be described by a simple mathematical formulation with precise optimization objectives under a periodic linear scheduling framework . The mathematical formulation provides a clear picture which permits one to visualize the overall solution space (for rate-optimal schedules) under different sets of constraints . Secondly , we show that a precise mathematical formulation and its solution does make a significant performance difference . We evaluated the performance of our method against three leading contemporary heuristic methods . Experimental results show that the method described in this paper performed significantly better than these methods.The techniques proposed in this paper are useful in two different ways: 1) As a compiler option which can be used in generating faster schedules for performance-critical loops (if the interested users are willing to trade the cost of longer compile time with faster runtime) . 2) As a framework for compiler writers to evaluate and improve other heuristics-based approaches by providing quantitative information as to where and how much their heuristic methods could be further improved . Introduction OFTWARE PIPELINING has been proposed as an efficient method for loop scheduling . It derives a static parallel schedule - a periodic pattern - that overlaps instructions from different iterations of a loop body . Software pipelining has been successfully applied to high-performance architectures 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 . Today , rapid advances in computer architecture - hardware and software technology - R . Govindarajan is with the Supercomputer Education and Re-search Center , and Department of Computer Science and Automa- tion , Indian Institute of Science , Bangalore , 560 012 , India . E- mail:govind@serc.iisc.ernet.in . Erik Altman is with the IBM T . J. Watson Research Center , Yorktown Heights , NY 10598 , U.S.A . E- mail:erik@watson.ibm.com . Guang Gao is with the School of Computer Science , McGill University , 3480 University Street , Montreal, H3A 2A7 , Canada . E-mail:gao@cs.mcgill.ca . This work was done when the first two authors were at McGill University . This research was partly funded by research grants from MICRONET - Network Centres of Excellence , Canada and NSERC , Canada. provide a rich solution space involving a large number of schedules for software pipelining . In exploiting the space of good compile-time schedules , it is important to find a fast, software-pipelined schedule which makes the best use of the machine resources - both function", "label": ["software pipelining", "instruction-level parallelism", "superscalar and vliw architectures", "instruction scheduling", "integer linear programming"], "stemmed_label": ["softwar pipelin", "instruction-level parallel", "superscalar and vliw architectur", "instruct schedul", "integ linear program"]}
{"doc": "Let W be a Coxeter group . We define an element w W to be fully commutative if any reduced expression for w can be obtained from any other by means of braid relations that only involve commuting generators . We give several combinatorial characterizations of this property , classify the Coxeter groups with finitely many fully commutative elements , and classify the parabolic quotients whose members are all fully commutative . As applications of the latter , we classify all parabolic quotients with the property that (1) the Bruhat ordering is a lattice , (2) the Bruhat ordering is a distributive lattice , (3) the weak ordering is a distributive lattice , and (4) the weak ordering and Bruhat ordering coincide . Introduction Let W be an arbitrary Coxeter group . This paper is concerned with the elements with the property that any reduced word for w can be obtained from any other by using only the Coxeter relations that involve commuting generators . We say that such elements are fully commutative. Our motivation for studying full commutativity arose from some applications we discovered that involve the symmetric functions associated with the Weyl groups of type B and D studied by Billey and Haiman BH , Fomin and Kirillov FK , and T . K . Lam L . (These applications are discussed in Ste .) A second (related) motivation arose from the interesting combinatorial properties of full commutativity in the symmetric group case. For example (quoting BJS ) , the fully commutative members of Sn are the permutations w that avoid the pattern 321 (in one-line notation) . The number of these is the Catalan number Cn , and there is a skew Young diagram ' naturally associated to each fully commutative w with the property that the standard Young tableaux of shape ' are in one-to-one correspondence with the reduced words for w. A third motivation , valid in any Coxeter group , is the fact that full commutativity is equivalent to several other natural combinatorial properties . For example (Theorem 2.2 below) , w 2 W is fully commutative if any only if the set of reduced words for w is order-theoretic , by which we mean that there is a labeled partially ordered set whose linear extensions are the reduced words for w . Also , one can show (again Theorem 2.2) that knowledge of the fully commutative elements of W is equivalent to knowledge of the subintervals of the weak ordering of W that are distributive lattices . (By a theorem of Bj-orner Bj , one knows that every subinterval of the weak order is at least a lattice.) In his recent Ph . D . thesis F (see also F2 ) , C . K . Fan has independently studied the fully commutative elements of simply-laced 1 Coxeter groups with an entirely different set of motivations in mind . Fan proves that the fully commutative elements index a basis for a quotient of the associated Iwahori-Hecke algebra . In the symmetric group case , this", "label": ["coxeter group", "weak order", "reduced word", "bruhat order"], "stemmed_label": ["coxet group", "weak order", "reduc word", "bruhat order"]}
{"doc": "Elmore delay has been widely used as an analytical estimate of interconnect delays in the performance-driven synthesis and layout of VLSI routing topologies . However , for typical RLC interconnections with ramp input , Elmore delay can deviate by up to 100% or more from SPICE-computed delay since it is independent of rise time of the input ramp signal . We develop new analytical delay models based on the first and second moments of the interconnect transfer function when the input is a ramp signal with finite rise time . Delay estimates using our first moment based analytical models are within 4% of SPICE-computed delay , and models based on both first and second moments are within 2.3% of SPICE , across a wide range of interconnect parameter values . Evaluation of our analytical models is several orders of magnitude faster than simulation using SPICE . We also describe extensions of our approach for estimation of source-sink delays in arbitrary interconnect trees . Introduction Accurate calculation of propagation delay in VLSI interconnects is critical to the design of high speed systems , and transmission line effects now play an important role in determining interconnect delays and system performance . Existing techniques are basedon either simulation or analytical formulas . Simulation methods such as SPICE give the most accurate insight into arbitrary interconnect structures , but are computationally expensive . Faster methodsbasedonmoment matching techniques are proposed in 12 , 13 , 14 , 17 , but are still too expensive to be used during layout optimization . Thus , Elmore delay 2 , a first order approximation of delay under step input , is still the most widely used delay model in the performance-driven synthesis of clock distribution and Steiner global routing topologies . However , Elmore delay cannot be applied to estimate the delay for interconnect lines with ramp input source; this inaccuracy is harmful to current performance-driven routing methods which try to determine optimal interconnect segment lengths and widths (as well as driver sizes) . Previous moment-based approaches 12 , 14 , 17 can compute a response for interconnects under ramp input within a simulation-based methodology , but no previous work has given analytical delay estimation modelsbasedon the first few moments. Recently , 3 presented lower and upper bounds for the ramp input their delay model is the same as the Elmore model for ramp input (we refer to this model as analytical ramp input model (T AD ) in this paper) . Delay estimates for the analytical ramp input model are off by as much as 50% from SPICE-computed delays for 50% threshold voltage , and the analytical ramp input model cannot be used to obtain threshold delay for various threshold voltages . The authors of 5 used Elmore delay as an upper bound on the 50% threshold delay for RC interconnection lines under arbitrary input waveforms . However , we find that Elmore delay is not at all close to SPICE-computed 50% threshold delay and , depending on the input slew time and driver resistance, can be either greater", "label": ["interconnect transfer function", "ramp input", "analytical delay models", "vlsi routing topologies layout", "rlc interconnections", "performance-driven synthesis", "source-sink delays", "elmore delay", "spice-computed delay", "interconnect delays", "vlsi", "vlsi interconnects", "arbitrary interconnect trees"], "stemmed_label": ["interconnect transfer function", "ramp input", "analyt delay model", "vlsi rout topolog layout", "rlc interconnect", "performance-driven synthesi", "source-sink delay", "elmor delay", "spice-comput delay", "interconnect delay", "vlsi", "vlsi interconnect", "arbitrari interconnect tree"]}
{"doc": "We present techniques for estimating switching activity and power consumption in register-transfer level (RTL) circuits . Previous work on this topic has ignored the presence of glitching activity at various data path and control signals , which can lead to significant underestimation of switching activity . For data path blocks that operate on word-level data , we construct piecewise linear models that capture the variation of output glitching activity and power consumption with various word-level parameters like mean , standard deviation , spatial and temporal correlations , and glitching activity at the block's inputs . For RTL blocks that operate on data that need not have an associated word-level value , we present accurate bit-level modeling techniques for glitching activity as well as power consumption . This allows us to perform accurate power estimation for control-flow intensive circuits , where most of the power consumed is dissipated in non-arithmetic components like multiplexers , registers , vector logic operators , etc . Since the final implementation of the controller is not available during high-level design iterations , we develop techniques that estimate glitching activity at control signals using control expressions and partial delay information . Experiments on example RTL designs resulted in power estimates that were within 7% of those produced by an inhouse power analysis tool on the final gate-level implementation . Introduction Techniquesfor evaluatinga design for various metrics like area, delay , and power consumption at all levels of the design hierarchy are an important part of the design process . While it is typically the case that lower-level estimation tools offer higher estimation accuracy , their use to explore architectural tradeoffs during higher-level design tends to be prohibitively time-consuming . Several efficient techniques for estimating area and delay during high-level design have been proposed 1 , 2 , 3 , 4 . In this paper , we focus on the problem of estimating power consumption from RTL descriptions. Designs at the architecture or RT level are characterized by the instantiation of pre-designed macro blocks including arithmetic operators , multiplexers , registers , vector logic operators , etc . In order to avoid the increase in computational complexity introduced by expanding these blocks to lower-level descriptions , it is necessary to develop power models for these library blocks . The development of such \"black-box\" models is an important part of high-level power estimation , and is typically a one-time cost incurred during library development . Another important task to be performed in RTL power estimation is the estimation of switching activity and signal statistics at various signals in the RTL circuit, Supported by NEC C&C Research Labs y Supported by NSF under Grant No . MIP-9319269. that are then fed into the power models for each block to estimate power consumption. One of the early architecture level power estimation techniques, called the power factor approximation (PFA) method 5 , characterized the power consumption in architectural blocks by simulating their implementations using random input sequences . The inability of the PFA technique to account for the dependency of power consumption in embedded", "label": ["switching activity", "power consumption", "gate-level implementation", "rtl designs", "glitching", "register-transfer level estimation", "logic design"], "stemmed_label": ["switch activ", "power consumpt", "gate-level implement", "rtl design", "glitch", "register-transf level estim", "logic design"]}
{"doc": "In this paper , we study the simultaneous transistor and interconnect sizing (STIS) problem . We define a class of optimization problems as CH-posynomial programs and reveal a general dominance property for all CH-posynomial programs . We show that the STIS problems under a number of transistor delay models are CH-posynomial programs and propose an efficient and near-optimal STIS algorithm based on the dominance property . When used to solve the simultaneous driver/buffer and wire sizing problem for real designs , it reduces the maximum delay by up to 16.1% , and more significantly , reduces the power consumption by a factor of 1.63X , when compared with the original designs . When used to solve the transistor sizing problem , it achieves a smooth area-delay trade-off . Moreover , the algorithm optimizes a clock net of 367 drivers/buffers and 59304 /spl mu/m-long wire in 120 seconds , and a 32-bit adder with 1026 transistors in 66 seconds on a SPARC-5 workstation . INTRODUCTION The interconnect delay has become the dominating factor in determining the circuit performance in deep submicron designs . We believe that the most effective approach to performance optimization in deep submicron designs is to consider both logic and interconnect designs throughout the entire design process (from RTL level to layout design) . As part of our effort to develop a unified methodology and platform for simultaneous logic and interconnect design and optimization , we study the simultaneous transistor and interconnect sizing (STIS) problem in this paper. Most previous works on layout optimization size transistor and interconnect separately , which may lead to suboptimal designs . The transistor sizing problem is to find the optimal width for each transistor under certain objective functions as studied in 14 , 18 , while the gate sizing problem is to find the optimal width for each gate by assuming all transistor sizes within a gate increase or decrease by a uniform factor 1 , 5 , 2 . The interconnect sizing problem, also called the wiresizing problem , was first introduced in 10 , 11 to determine the optimal width for each wire segment in interconnects and the first polynomial-time optimal algorithm was developed . Later on , alternative wiresizing algorithms were proposed in 17 , 23 , 25 , 6 , 3 . Recently , several studies considered simultaneous transistor and interconnect sizing for some special cases . The This work is partially supportedby ARPA/CSTO under contract J-FBI-93-112 , the NSF Young Investigator Award MIP- 9357582 and a grant from Intel Corporation. authors of 8 proposed an efficient algorithm for the simultaneous driver and wire sizing problem . The authors of 16 solved the simultaneous buffer insertion and wire sizing problem by a dynamic programming approach . The authors of 19 studied the simultaneous gate and wire sizing problem and solved it by the sequential quadratic programming technique . Most recently , the authors of 20 solved the simultaneous buffer insertion , wiresizing and tree construction problem . Their gate sizing formulation , however , may lead to suboptimal designs ,", "label": ["stis", "driver/buffer", "ch-posynomial programs", "transistor sizing", "circuit cad", "transistor and interconnect sizing", "wire sizing problem"], "stemmed_label": ["sti", "driver/buff", "ch-posynomi program", "transistor size", "circuit cad", "transistor and interconnect size", "wire size problem"]}
{"doc": "Move-based iterative improvement partitioning methods such as the Fiduccia-Mattheyses (FM) algorithm and Krishnamurthy's Look-Ahead (LA) algorithm are widely used in VLSI CAD applications largely due to their time efficiency and ease of implementation . This class of algorithms is of the \"local improvement\" type . They generate relatively high quality results for small and medium size circuits . However , as VLSI circuits become larger , these algorithms are not so effective on them as direct partitioning tools . We propose new iterative-improvement methods that select cells to move with a view to moving clusters that straddle the two subsets of a partition into one of the subsets . The new algorithms significantly improve partition quality while preserving the advantage of time efficiency . Experimental results on 25 medium to large size ACM/SIGDA benchmark circuits show up to 70% improvement over FM in cutsize , with an average of per-circuit percent improvements of about 25% , and a total cut improvement of about 35% . They also outperform the recent placement-based partitioning tool Paraboli and the spectral partitioner MELO by about 17% and 23% , respectively , with less CPU time . This demonstrates the potential of iterative improvement algorithms in dealing with the increasing complexity of modern VLSI circuitry . INTRODUCTION The essence of VLSI circuit partitioning is to divide a circuit into a number of subcircuits with minimum interconnections between them . This can be accomplished by recursively partitioning a circuit into two parts until we reach the desired level of complexity . Thus two-way partitioning is a basic problem in circuit partitioning and placement. Kernighan and Lin 1 proposed the well-known KL heuristic for graph partitioning . The KL algorithm starts with a random initial two-way partition and proceeds by swapping pair of cells iteratively . Schweikert and Kernighan extended KL to hypergraphs so that it can partition actual circuits . Fiduccia and Mattheyses 3 reduced the complexity of the algorithm to linear-time with respect to the number of pins in the circuit . This is done by moving one cell at a time and using an efficient bucket data structure . Krishnamurthy 4 enhanced FM by adding higher level lookahead gains and improved the results for small circuits . Recently , a number of clustering algorithms 9 , 10 , 11 , 12 , 15 have been proposed and excellent results have been obtained. FM and LA are the most commonly used two-way partitioning algorithms largely due to their excellent run times, simple implementations and flexibility . However , this class of iterative improvement algorithms have a common weak- ness , viz. , they only find solutions corresponding to local minima . Because of their iterative improvement nature, they can only evolve from an initial partition through very shortsighted moves . Thus the results strongly depend on the initial partition . In order to get a local minimum that is close to the optimum partition , multiple runs on randomly generated initial partitions are needed . As the circuit size becomes large , the probability of finding a", "label": ["fiduccia-mattheyses algorithm", "cluster-removal", "iterative improvement techniques", "vlsi", "acm/sigda benchmark circuits", "look-ahead algorithm", "spectral partitioner melo", "partition quality", "cad", "vlsi circuit partitioning"], "stemmed_label": ["fiduccia-mattheys algorithm", "cluster-remov", "iter improv techniqu", "vlsi", "acm/sigda benchmark circuit", "look-ahead algorithm", "spectral partition melo", "partit qualiti", "cad", "vlsi circuit partit"]}
{"doc": "AbstractA fail-silent node is a self-checking node that either functions correctly or stops functioning after an internal failure is detected . Such a node can be constructed from a number of conventional processors . In a software-implemented fail-silent node , the nonfaulty processors of the node need to execute message order and comparison protocols to \"keep in step\" and check each other , respectively . In this paper , the design and implementation of efficient protocols for a two processor fail-silent node are described in detail . The performance figures obtained indicate that in a wide class of applications requiring a high degree of fault-tolerance , software-implemented fail-silent nodes constructed simply by utilizing standard \"off-the-shelf\" components are an attractive alternative to their hardware-implemented counterparts that do require special-purpose hardware components , such as fault-tolerant clocks , comparator , and bus interface circuits . INTRODUCTION Replicated processing on distinct processors whereby outputs from faulty processors can be prevented from appearing at the application level (by employing means such as comparing or voting the outputs produced by the processors) , provides a practical means of constructing systems capable of tolerating Byzantine (also referred to as fail-uncontrolled) processor failures . Such an approach can be used for constructing a fail-controlled node composed of a number of conventional processors on which application level processes are replicated . A particular case of a fail-controlled node is a p+1 processor fail-silent node that either works correctly , or stops functioning (becomes silent) soon after an internal failure is detected . This behaviour of a node is guaranteed so long as no more than processors in the node fail . A two processor fail-silent node (p=1) offers a practical and economical solution to the problem of constructing fail-controlled nodes , as such , in this paper we will concentrate on the design , implementation and performance evaluation of two-processor nodes . In particular , we will describe practical designs of software implemented two-processor fail-silent nodes suitable for use in distributed systems that meet the abstraction of fail-silence in the following sense: a node produces either correct messages which can be verified as such by destination nodes , or it ceases to produce new correct messages , in which case destination nodes can detect any messages it may produce as unwanted. The paper is structured as follows . We begin by reviewing related work in the area of reliable node design , contrasting it with our approach and summarising the main contributions of the paper . We then describe the basic principles that underpin our fail-silent nodes , and then present what we term a reference implementation of a fail-silent node; this implementation makes use of a standard , synchronised clock based message order protocol . After describing how the performance of this protocol itself can be improved , we present two new , much faster order protocols , based on logical clock and leader-follower (master-slave) approaches . Following this , we describe the design of a comparison protocol that makes use of the master-slave approach for message comparison. We", "label": ["replicated processing", "distributed processing", "fault-tolerance", "fail-silence", "reliability"], "stemmed_label": ["replic process", "distribut process", "fault-toler", "fail-sil", "reliabl"]}
{"doc": "AbstractPrefix computation is a basic operation at the core of many important applications , e.g. , some of the Grand Challenge problems , circuit design , digital signal processing , graph optimizations , and computational geometry.1 In this paper , we present new and strict time-optimal parallel schedules for prefix computation with resource constraints under the concurrent-read-exclusive-write (CREW) parallel random access machine (PRAM) model . For prefix of N elements on processors (p independent of N) when N p(p + 1)/2 , we derive Harmonic Schedules that achieve the strict optimal time (steps) , $\\left\\lceil 2\\left( N-1 \\right) \\mathord \\left/ \\vphantom 2\\left( N-1 \\right) \\left( p+1 \\right) \\right . \\kern-\\nulldelimiterspace \\left( p+1 \\right) \\right\\rceil $ . We also derive Pipelined Schedules that have better program-space efficiency than the Harmonic Schedule , yet only require a small constant number of steps more than the optimal time achieved by the Harmonic Schedule . Both the Harmonic Schedules and the Pipelined Schedules are simple and easy to implement . For prefix of N elements on processors (p independent of N) where Np(p + 1)/2 , the Harmonic Schedules are not time-optimal . For these cases , we establish an optimization method for determining key parameters of time-optimal schedules , based on connections between the structure of parallel prefix and Pascal's triangle . Using the derived parameters , we devise an algorithm to construct such schedules . For a restricted class of values of N and , we prove that the constructed schedules are strictly time-optimal . We also give strong empirical evidence that our algorithm constructs strict time-optimal schedules for all cases where Np(p Introduction Given a computation evaluates a 0 ffi a associative operation ffi. Prefix sum (or first-order linear recurrence with coefficients 1) is a special case of prefix computation that can be stated as a simple loop: We refer to our problem interchangeably as recurrence , prefix sums , or prefix computation , since the results on prefix sum can be readily applied to prefix computation with other associative operations. Prefix computation is a fundamental operation at the core of many key applications such as the Grand Challenge problems , circuit design , digital signal processing , graph optimizations , and computational geometry 1 , 8 , 15 . In addition , it is also an important tool in loop parallelization . Traditional automatic loop parallelization techniques 4 respect loop-carried dependences , and are thus unable to generate scalable parallel code from loops containing loop-carried dependences . To understand how to parallelize loops with loop-carried dependences beyond these techniques , it is essential to understand the simplest case of loops with loop-carried dependence , namely prefix sums . The optimal schedules and the technique used to derive them in this paper could be applied-with some extensions- to parallelizing many sequential algorithms containing loop carried dependences. Since in practical applications the amount of resources (i.e. , functional units , processors) is fixed a priori and independent of the problem size , it is desirable to devise a scheme which performs prefix computation in", "label": ["pascal's triangle", "loop-carried dependences", "loop parallelization", "combinatorial optimization", "parallel prefix computation", "scan operator resource-constrained parallel algorithms", "tree-height reduction", "strict time-optimal schedules", "associative operations"], "stemmed_label": ["pascal' triangl", "loop-carri depend", "loop parallel", "combinatori optim", "parallel prefix comput", "scan oper resource-constrain parallel algorithm", "tree-height reduct", "strict time-optim schedul", "associ oper"]}
{"doc": "In a gate-level description of a finite state machine (\\fsm) , there is a tradeoff between the number of latches and the size of the logic implementing the next-state and output functions . Typically , an initial implementation is generated via explicit state assignment or translation from a high-level language , and the tradeoff is subsequently only lightly explored . We efficiently explore good latch/logic tradeoffs for large designs generated from high-level specifications . We reduce the number of latches while controlling the logic size . We demonstrate the efficacy of our techniques on some large industrial examples . Introduction In a gate-level description of a -nite state machine (fsm) , there is a tradeooe between the number of latches and the size of the logic implementing the next-state logic . This tradeooe can be exploited at two levels: during generation of the initial implementation , and during subsequent logic optimization steps. 1.1 Background State assignment is the generation of a state encoding and an initial latch/logic implementation from a higher level in the design process . To date , primarily two approaches have been used: Explicit state assignment begins from an explicit state transition graph and chooses a minimum- latch encoding while minimizing the size of the combinational logic DBSV85 , VSV90 , Har61 . State assignment from high-level languages chooses an encoding according to the delay statements in the speci-cation , relying on logic synthesis to later optimize the gate-level implementation BT93 . Explicit state assignment is impractical for large designs , and despite sophisticated techniques for determining an optimal assignment , it can produce results far worse than hand-coded implementations. Furthermore , explicit state assignment programs have not targeted greater-than-minimum-latch imple- mentations . With current technology (e.g . FPGAs) , it is no longer necessary to minimize the number of latches and doing so often produces prohibitively large combinational logic . One-hot encoding can also be applied to an explicit state graph , where one latch is used for each state . The resulting logic will be small and fast since the states do not need to be encoded and decoded . However , the number of latches is huge , and a one-hot implementation can be a diOEcult starting place for logic synthesis. Automatic techniques for reducing the number of latches in a one-hot implementation to produce a good tradeooe have not been resoundingly successful. State assignment from high-level languages is typically done by a statement-by-statement transla- tion , which results in a natural insertion of registers at the delay statements in the description . This is a good starting point for logic synthesis , but results in far more latches than are required to implement the design BT93 . Even if the number of latches is not important for the -nal implementation, too many can drastically reduce the eOEciency of many synthesis and optimization algorithms (e.g., symbolic state traversal). After state assignment , the latch/logic tradeooe can be explored via logic optimization . Standard techniques , e.g. , extracting common factors , function simpli-cation , and retiming", "label": ["state assignment", "high-level synthesis", "sequential optimisation"], "stemmed_label": ["state assign", "high-level synthesi", "sequenti optimis"]}
{"doc": "AbstractAn algorithm is described which rapidly verifies the potential rigidity of three-dimensional point correspondences from a pair of two-dimensional views under perspective projection . The output of the algorithm is a simple yes or no answer to the question \"Could these corresponding points from two views be the projection of a rigid configuration?\" Potential applications include 3D object recognition from a single previous view and correspondence matching for stereo or motion over widely separated views . The rigidity checking problem is different from the structure-from-motion problem because it is often the case that two views cannot provide an accurate structure-from-motion estimate due to ambiguity and ill conditioning , whereas it is still possible to give an accurate yes/no answer to the rigidity question . Rigidity checking verifies point correspondences using 3D recovery equations as a matching condition . The proposed algorithm improves upon other methods that fall under this approach because it works with as few as six corresponding points under full perspective projection , handles correspondences from widely separated views , makes full use of the disparity of the correspondences , and is integrated with a linear algorithm for 3D recovery due to Kontsevich . Results are given for experiments with synthetic and real image data . A complete implementation of this algorithm is being made publicly available . Introduction An algorithm is given for accurately and rapidly verifying the potential rigidity of three dimensional point correspondences from a pair of two dimensional views under perspective projection . Our motivation comes from the problem of finding corresponding point features between two or more disparate views of an object . The output of the method is a simple yes or no answer based on the residual error of a minimum variance estimator for a parameter space of rigid transformations and structure . The rigidity verification approach proposed here is shared by other methods for verifying point correspondences using 3D recovery equations as a matching condition . The algorithm , however , substantially improves upon other methods because it works with as few as six corresponding points under full perspective projection, handles correspondences from widely separated views , makes full use of the disparity of the correspondences which necessarily involves the scene structure , and is integrated with a linear estimator based on a weak perspective model. The matching condition for verifying rigidity is based on a set of 3D scene recovery constraints whose satisfaction minimizes the residual error of an iterative nonlinear optimization algorithm . Although iterative nonlinear methods can be computationally intensive , an accurate answer to the rigidity question is computed quickly for two main reasons . First , a reasonably good initial parameter estimate is computed from a linear algorithm , and sec- ondly , the nonlinear model for 3D recovery makes full use of the image disparity . The 3D recovery equations proposed here are derived from the collinearity condition of the scene and image points under perspective projection which provides a natural and integrated approach to the simultaneous estimation of relative motion and scene structure. Matching point-feature", "label": ["perspective projection", "nonlinear parameter estimation", "rigidity checking", "image matching", "structure-from-motion", "point correspondences"], "stemmed_label": ["perspect project", "nonlinear paramet estim", "rigid check", "imag match", "structure-from-mot", "point correspond"]}
{"doc": "AbstractStructures of dynamic scenes can only be recovered using a real-time range sensor . Depth from defocus offers an effective solution to fast and dense range estimation . However , accurate depth estimation requires theoretical and practical solutions to a variety of problems including recovery of textureless surfaces , precise blur estimation , and magnification variations caused by defocusing . Both textured and textureless surfaces are recovered using an illumination pattern that is projected via the same optical path used to acquire images . The illumination pattern is optimized to maximize accuracy and spatial resolution in computed depth . The relative blurring in two images is computed using a narrow-band linear operator that is designed by considering all the optical , sensing , and computational elements of the depth from defocus system . Defocus invariant magnification is achieved by the use of an additional aperture in the imaging optics . A prototype focus range sensor has been developed that has a workspace of 1 cubic foot and produces up to 512 480 depth estimates at Hz with an average RMS error of 0.2% . Several experimental results are included to demonstrate the performance of the sensor . Introduction A pertinent problem in computational vision is the recovery of three-dimensional scene structure from two-dimensional images . Of all problems studied in vision , the above has by far attracted the most attention . This has resulted in a panoply of sensors and algorithms Jarvis-1983 Besl- 1988 that can be broadly classified into two categories; passive and active . Passive techniques such as shape from shading and shape from texture attempt to extract structure from a single image . These algorithms are still under investigation and , given the assumptions they are forced to invoke , it is expected they will prove complementary to other techniques but not serve as stand-alone strategies . Other passive methods such as stereo and structure from motion use multiple views to resolve shape ambiguities inherent in a single image . The primary bottleneck for these methods has proved to be correspondence and feature tracking . In addition , passive algorithms have yet to demonstrate the accuracy and robustness required for high-level perception tasks such as object recognition and pose estimation. Hitherto , high quality depth maps have resulted only from the use of active sensors based on time of flight or light striping Jarvis-1983 . From a practical perspective , light stripe range finding has emerged as a clear winner . In structured environments , where active radiation of a scene is feasible , it offers a robust yet inexpensive solution to a variety of problems . However , it has suffered from one inherent drawback , namely , speed . To achieve depth maps with sufficient spatial resolution , a large number (say , N) of closely spaced stripes are used . If all stripes are projected simultaneously it is impossible to associate a unique stripe with any given image point , a process that is necessary to compute depth by triangulation . The classical approach is", "label": ["active illumination pattern", "tuned focus operator", "optical transfer function", "constant magnification defocusing", "image sensing", "depth from defocus", "real-time range sensor", "depth estimation"], "stemmed_label": ["activ illumin pattern", "tune focu oper", "optic transfer function", "constant magnif defocus", "imag sens", "depth from defocu", "real-tim rang sensor", "depth estim"]}
{"doc": "AbstractThis paper presents a motion estimation algorithm based on a new multiresolution representation , the quadtree spline . This representation describes the motion field as a collection of smoothly connected patches of varying size , where the patch size is automatically adapted to the complexity of the underlying motion . The topology of the patches is determined by a quadtree data structure , and both split and merge techniques are developed for estimating this spatial subdivision . The quadtree spline is implemented using another novel representation , the adaptive hierarchical basis spline , and combines the advantages of adaptively-sized correlation windows with the speedups obtained with hierarchical basis preconditioners . Results are presented on some standard motion sequences . Introduction One of the fundamental tradeoffs in designing motion estimation and stereo matching algorithms is selecting the size of the windows or filters to be used in comparing portions of corresponding im- ages . Using larger windows leads to better noise immunity through averaging and can also disambiguate potential matches in areas of weak texture or potential aperture problems . However , larger windows fail where they straddle motion or depth discontinuities , or in general where the motion or disparity varies significantly within the window. Many techniques have been devised to deal with this problem , e.g. , using adaptively-sized windows in stereo matching . In this paper , we present a technique for recursively subdividing an image into square patches of varying size and then matching these patches to subsequent frames in a way which preserves inter-patch motion continuity . Our technique is an extension of the spline-based image registration technique presented in Szeliski and Coughlan , 1994 , and thus has the same advantages when compared to correlation-based approaches , i.e. , lower computational cost and the ability to handle large image deformations. As a first step , we show how using hierarchical basis splines instead of regular splines can lead to faster convergence and qualitatively perform a smoothing function similar to regulariza- tion . Then , we show how selectively setting certain nodes in the hierarchical basis to zero leads to an adaptive hierarchical basis . We can use this idea to build a spline defined over a quadtree domain , i.e. , a quadtree spline . To determine the size of the patches in our adaptive basis , i.e. , the shape of the quadtree , we develop both split and merge techniques based on the residual errors in the current optical flow estimates. While this paper deals primarily with motion estimation (also known as image registration or optical flow computation) , the techniques developed here can equally well be applied to stereo match- ing . In our framework , we view stereo as a special case of motion estimation where the epipolar geometry (corresponding lines) are known , thus reducing a two-dimensional search space at each pixel to a one-dimensional space . Our techniques can also be used as part of a direct method which simultaneously solves for projective depth and camera motion Szeliski and Coughlan ,", "label": ["quadtrees", "image pyramids", "hierarchical basis functions", "motion analysis", "splines", "multiresolution analysis", "image registration", "local parametric motion models", "motion segmentation", "optical flow"], "stemmed_label": ["quadtre", "imag pyramid", "hierarch basi function", "motion analysi", "spline", "multiresolut analysi", "imag registr", "local parametr motion model", "motion segment", "optic flow"]}
{"doc": "AbstractAs part of our continuing research on using Petri nets to support automated analysis of Ada tasking behavior , we have investigated the application of Petri net reduction for deadlock analysis . Although reachability analysis is an important method to detect deadlocks , it is in general inefficient or even intractable . Net reduction can aid the analysis by reducing the size of the net while preserving relevant properties . We introduce a number of reduction rules and show how they can be applied to Ada nets , which are automatically generated Petri net models of Ada tasking . We define a reduction process and a method by which a useful description of a detected deadlock state can be obtained from the reduced net's information . A reduction tool and experimental results from applying the reduction process are discussed . INTRODUCTION One major difficulty that faces developers of concurrent and distributed software is analysis for concurrency- based faults like deadlocks . Techniques for such analysis are generally limited in their applicability due to the high complexity of most interesting analysis problems . For example , Reif and Smolka 1 prove some undecidable and NP-completeness results for reachability problems of various models of communicating processes . Rauchle and Toueg 2 provide a PSPACE-hardness result for deadlock detection in a bounded communication channel model for communicating finite state machines . With regards to concurrency analysis for models based on Ada tasking , Taylor 3 proved NP-Completeness results related to the classical (static) deadlock detection problem. This work was supported in part by the Office of Naval Research (ONR) under grant number N00014-90-J-1446 and the National Science Foundation (NSF) under grant numbers CCR-8913580 and CCR-9321743. An earlier version of this paper has been published in the Proceedings of the 10th International Conference on Distributed Computing Systems. Despite the difficulty of the concurrency analysis problem , a number of techniques have been proposed, especially for static analysis of Ada tasking 4-16 . We previously defined a Petri net framework for this type of analysis 6 and developed a toolkit that supports this approach 10 . The architecture of the toolkit , called TOTAL, is shown in Fig . 1.1 . The FETS (Front-End Translator Subsystem) translates Ada source or Ada Tasking Language (ATL) design descriptions 10 into Petri net format , i.e. , a set of appropriately labeled place nodes , transition nodes and arcs . We refer to the resulting Petri net as an (original) Ada net . These nets are suitable only for analysis of programs composed of a static set of tasks . The BIDS (Back-end Information Display Subsystem) is defined to receive users' queries and present tasking analysis results based on analysis of the Ada net 11 . BIDS uses different support tools to carry out the desired analysis . For example , deadlock detection using the method described in 9 would invoke the tool to calculate net invariants . For the approach that is the subject of this paper , BIDS first invokes the net reduction tool and then uses a", "label": ["reachability analysis", "net reduction", "concurrent software", "ada tasking", "petri nets", "deadlock analysis"], "stemmed_label": ["reachabl analysi", "net reduct", "concurr softwar", "ada task", "petri net", "deadlock analysi"]}
{"doc": "AbstractThis paper discusses detection of global predicates in a distributed program . A run of a distributed program results in a set of sequential traces , one for each process . These traces may be combined to form many global sequences consistent with the single run of the program . A strong global predicate is true in a run if it is true for all global sequences consistent with the run . We present algorithms which detect if the given strong global predicate became true in a run of a distributed program . Our algorithms can be executed on line as well as off line . Moreover , our algorithms do not assume that underlying channels satisfy FIFO ordering . Introduction Detection of global predicates is a fundamental problem in distributed computing . It arises in the designing , debugging and testing of distributed programs . Global predicates can be classified into two types - stable and unstable . A stable predicate is one which never turns false once it becomes true . An unstable predicate is one without such a property. Its value may alternate between true and false . Detection of stable predicates has been addressed in the literature by means of global snapshots of a distributed computation ChaLam85 , SpeKea86 , Bouge87 . Any stable property can be detected by taking global snapshots periodically . This approach does not work for an unstable predicate which may turn true only between two snapshots and not at the time when the snapshot is taken . An entirely different approach is required for such predicates WalGar91 , CooMar91 , GarWal92, SchMat92 , GarWal94 , BabMar93 , TomGar93 , HPR93 . We have earlier presented an approach to detect a class of unstable predicates called predicates GarWal94 . In this paper , we continue our investigation of detection for a different class of unstable predicates . The reader is referred to GarWal94 for a discussion of related work and the background . Two types of predicates are discussed in this paper . The first type , called strong linked predicates , refers to a causal sequence of local predicates . The second type , called strong conjunctive predicates , correspond to existence of a global state in which all local predicates are true simultaneously . We introduce the notion of overlapping intervals which is used to detect predicates of this type . Cooper and Marzullo CooMar91 also describe strong predicate detection (they call such predicates definitely) . However, they deal with general predicates , i.e. , they propose detection of definitely : where is any predicate defined on a global state . In this paper , we have restricted to conjunction of local predicates . Detection of general predicates is intractable since it involves a combinatorial This work was supported in part by the NSF Grant CCR 9110605 , the Navy Grant N00039-91-C-0082, a TRW faculty assistantship award , and IBM Agreement 153. explosion of the state space . For example , the algorithm proposed by Cooper and Marzullo CooMar91 has complexity O(k", "label": ["predicate detection", "unstable predicates", "distributed debugging", "distributed algorithms"], "stemmed_label": ["predic detect", "unstabl predic", "distribut debug", "distribut algorithm"]}
{"doc": "AbstractIn many designs a large portion of path delay faults is not robustly testable . In this paper , we investigate testing strategies for robustly untestable faults . We show that the quality of nonrobust tests may be very poor in detecting small defects caused by manufacturing process variation . We demonstrate that better quality nonrobust tests can be obtained by including timing information into the process of test generation . A good nonrobust test can tolerate larger timing variations on the off-inputs . We also show that not all nonrobustly untestable path delay faults may be ignored in high quality delay testing . Functional sensitizable paths are nonrobustly untestable but , under some faulty conditions , may degrade the performance of the circuit . However , up till now , there was no strategy for generating tests for such faults.In this paper , we present algorithms for generating high quality nonrobust and functional sensitizable tests . We also devise an algorithm for generating tests for validatable nonrobust faults which have a high quality in detecting defects but are hard to be generated automatically . Our experimental results show that the quality of delay testing increases if validatable and high quality nonrobust tests , as well as tests for functional sensitizable path delay faults are included . Introduction The objective of delay testing is to detect timing defects which could degrade the circuit's performance . Two fault models are commonly used for timing defects: the gate delay fault model 24 , 25 and the path delay fault model 16 , 22 , 17 . The path delay fault model assumes that the propagation delay of a target path exceeds the clock period while the gate delay fault model assumes that the propagation delay of a gate/node exceeds its specified limit . There are pros and cons for both models and they have been discussed in many articles (e.g. , 11 ) and will not be repeated here . In this paper , we use the path delay fault model. In order to test a path for timing defects an input vector pair needs to be applied . The first vector initializes the circuit , while the second causes the desired transitions. After a clock period from the time when the second input vector was applied , the values on the primary outputs are observed and compared to the prestored response of a circuit to determine if there is a defect. Path Delay Fault Classification . There are two conditions that can be imposed on tests for path delay faults: the robust (R) condition and the non-robust (NR) condition . A robust test 22 , 17 guarantees the detection of a fault on the target path regardless of the delays on all other signals in the circuit . Results reported in 17 and 6 show that for many benchmark and industrial circuits a large number of faults does not have any robust test. These faults are called robustly untestable faults . In Table 1 we cite the results reported in 6 for ISCAS", "label": ["automatic test generation", "timing defects", "robust", "nonrobust", "path delay faults", "delay testing", "vlsi testing"], "stemmed_label": ["automat test gener", "time defect", "robust", "nonrobust", "path delay fault", "delay test", "vlsi test"]}
{"doc": "We consider linear plants controlled by dynamic output feedback which are subjected to blockdiagonal stochastic parameter perturbations . The stability radii of these systems are characterized , and it is shown that , for real data , the real and the complex stability radii coincide . A corresponding result does not hold in the deterministic case , even for perturbations of single-output feedback type . In a second part of the paper we study the problem of optimizing the stability radius by dynamic linear output feedback . Necessary and sufficient conditions are derived for the existence of a compensator which achieves a suboptimal stability radius . These conditions consist of a parametrized Riccati equation , a parametrized Liapunov inequality , a coupling inequality , and a number of linear matrix inequalities (one for each disturbance term) . The corresponding problem in the deterministic case , the optimal $\\mu$-synthesis problem , is still unsolved . Introduction One of the main purposes of feedback control is to ensure satisfactory behaviour of a dynamical system in the presence of unforeseen disturbances . This classical problem which was central to the work of Bode and Nyquist has seen a vigorous renaissance over the past decade and recent developments in control theory have been strongly influenced by it . The focus has been on deterministic disturbances: either unstructured (additive or multiplicative) perturbations of the plant's transfer function or structured perturbations of the parameters of a given nominal state space model . As examples we mention two approaches , H 1 and stability radii . H 1 theory (see 6 ) deals with the problem of minimizing (by feedback compensation) the effect of deterministic disturbances on the to be controlled variables . The results can be applied to maximize robustness of stability with respect to unstructured perturbations of the transfer matrix . On the other hand the theory of stability radii determines precise robustness measures for stable linear state space systems subject to different classes of structured parameter perturbations 14 . Surprisingly there is a close relationship between the two theories for the special case where stability radii with respect to complex perturbations of single output feedback type are considered . In fact , in this case the problem of optimizing the stability radius by feedback control is equivalent to a singular H 1 control problem 13 . In this paper we use the framework of stability radii to study robust stability and robust stabilization problems for systems with stochastic uncertainty . Because of the close relationship between the theories of stability radii and H 1 control our results can be regarded as an extension of H 1 control theory to systems with stochastic uncertainty. We consider the system: where the matrices A; B; C; are given and the processes w i are independent scalar We view the above equations as describing a linear deterministic differentiable system (A; B; C) perturbed by stochastic multi-perturbations (t) . The family (D of matrix pairs describe the structure of these perturbations while are unkown Lipschitzian nonlinearities . We assume that all", "label": ["dynamic output feedback", "linear matrix inequalities", "multiperturbations", "stability radius", "state-dependent noise", "riccati inequalities", "stochastic systems", "scaling"], "stemmed_label": ["dynam output feedback", "linear matrix inequ", "multiperturb", "stabil radiu", "state-depend nois", "riccati inequ", "stochast system", "scale"]}
{"doc": "A technique to construct a low-order finite difference preconditioner for solving orthogonal collocation equations for boundary value problems is presented . It is shown numerically and theoretically that the spectral condition numbers of the preconditioned collocation matrices are bounded by constants independent of the number of mesh nodes when certain exact low-order finite difference preconditionings are used . Preconditioners based on incomplete LU factorization are also discussed . Numerical experiments show the efficiency and robustness of the preconditioning . Introduction . In this paper , we shall consider orthogonal collocation methods for solving elliptic differential equations . These methods have been extensively investigated in the last twenty years due to their ease of implementationand high-order accuracy (see RS72 , DS73 and PR76 ) . An apparent disadvantage of orthogonal collocation lies in the fact that a collocation matrix is generally nonsymmetric , even for a Poisson equation with a uniform mesh . Gauss elimination often has been used for solving the collocation equations , and its cost has restricted the applicability of the methods. In recent years , some efforts in solving the collocation equations by alternative methods have been made . A so-called alternating direction collocation (ADC) or generalized ADI method was introduced by Hayes Hay80 and Hayes , Pinder and Celia HPC81 for solving a parabolic problem . A full theory for convergence of ADC on a uniform mesh is given for the model problem in a rectangular domain by Dyksen Dyk87 . Significantly , a closed form for the eigenvalues and their associated eigenfunctions is also given . Cooper and Prenter CP91 give a complete theory for convergence of ADC applied to a large class of linear separable elliptic partial differential equations on a rectangular domain . Bialecki Bia91 considers the problem of determining optimal acceleration parameters for ADC by using the Jordan acceleration technique . Besides ADC , a fast direct methods (FFT) has been developed for solving on a uniform mesh in SZ89 and BFB92 . In Sun(a) , a class of block stationary (standard) methods are applied to second-order separable elliptic partial differential equations and their convergence is proven . However , all of above methods are only applicable for linear separable and self-adjoint elliptic partial differential equations. It has been well demonstrated that when solving partial differential equations (PDEs) a significant improvement in convergence of conventional iterative methods y This work is supported in part by the Natural Science and Engineering Research Council of Canada (NSERC) Grant A8781. z Department of Mathematics & Statistics , Simon Fraser University Burnaby , B . C . V5A 1S6, Canada (wsun@cs.sfu.ca). x Department of Mathematics & Statistics , Simon Fraser University Burnaby , B . C . V5A 1S6, Canada . Current address: Department of Mathematics , University of Kansas , Lawrence , KS 66045, U.S.A . (whuang@math.ukans.edu). - Department of Mathematics & Statistics , Simon Fraser University Burnaby , B . C . V5A 1S6, Canada (rdr@cs.sfu.ca). W . SUN , W . HUANG AND R.D . RUSSELL can be gained by using preconditioning techniques . They", "label": ["collocation", "boundary value problem", "preconditioning"], "stemmed_label": ["colloc", "boundari valu problem", "precondit"]}
{"doc": "Repositories for software reuse are faced with two interrelated problems: (1) acquiring the knowledge to initially construct the repository and (2) modifying the repository to meet the evolving and dynamic needs of software development organizations . Current software repository methods rely heavily on classification , which exacerbates acquistition and evolution problems by requiring costly classification and domain analysis efforts before a repository can be used effectively , This article outlines an approach that avoids these problems by choosing a retrieval method that utilizes minimal repository structure to effectively support the process of finding software conponents . The approach is demonstrated through a pair of proof-of-concept prototypes: PEEL , a tool to semiautomatically identify reusable components , and CodeFinder , a retrieval system that compensates for the lack of explicit knowledge structures through a spreading activation retrieval process . CodeFinder also allows component representations to be modified while users are searching for information . This mechanism adapts to the changing nature of the information in the repository and incrementally improves the repository while people use it . The combination of these techniques holds potential for designing software repositories that minimize up-front costs , effectively support the search process , and evolve with an organization's changing needs . Introduction As libraries of reusable software components continue to grow , the issue of retrieving components from software libraries has captured the attention of the software reuse community Burton et al . 1987; Devanbu et al . 1991; Frakes , Gandel 1990; Frakes , Nejmeh 1987; Frakes , Pole 1994; Maarek et al . 1991; Prieto-D-az , Freeman 1987; Sommerville , Wood 1986 . Especially in component-based reuse approaches , where developers compose software parts into an application , libraries of components are necessary to achieve software reuse . Component-based software reuse faces an inherent dilemma: in order for the approach to be useful , the repository must contain enough components to support developers , but when many examples are available , finding and choosing appropriate ones becomes troublesome . Retrieval techniques as diverse as enumerated classification Booch 1987 , facets Prieto- D-az 1985; Prieto-D-az , Freeman 1987 , frame-based classification Ostertag et al . 1992 , free-text indexing Frakes , Nejmeh 1987 , relational databases Burton et al . 1987 , and formal specifications Chen et al . 1993 , have been employed to address the problem of finding relevant components . But issues involving how effective repositories are built , populated , and evolved to meet the changing needs of development organizations have received considerably less attention. Most retrieval algorithms require that a pre-defined structure is in place before designers can effectively search the repository . At a minimum , components must be categorized before they are placed in the repository . This value-added approach to building software repositories creates a barrier of real and intellectual capital investments that many organizations cannot overcome Biggerstaff , Richter 1987 . Most development organizations are pressed to deliver specific products , and cannot afford the extra work required to generalize and categorize work products created in individual", "label": ["software reuse", "component repositories", "information retrieval"], "stemmed_label": ["softwar reus", "compon repositori", "inform retriev"]}
{"doc": "AbstractA graduated assignment algorithm for graph matching is presented which is fast and accurate even in the presence of high noise . By combining graduated nonconvexity , two-way (assignment) constraints , and sparsity , large improvements in accuracy and speed are achieved . Its low order computational complexity O(lm) , where l and m are the number of links in the two graphs and robustness in the presence of noise offer advantages over traditional combinatorial approaches . The algorithm , not restricted to any special class of graph , is applied to subgraph isomorphism , weighted graph matching , and attributed relational graph matching . To illustrate the performance of the algorithm , attributed relational graphs derived from objects are matched . Then , results from twenty-five thousand experiments conducted on 100 node random graphs of varying types (graphs with only zero-one links , weighted graphs , and graphs with node attributes and multiple link types) are reported . No comparable results have been reported by any other graph matching algorithm before in the research literature . Twenty-five hundred control experiments are conducted using a relaxation labeling algorithm and large improvements in accuracy are demonstrated . Introduction The process of approximately matching two abstract representations lies at the heart of the development of artificial systems with human-like abilities such as vision . Con- sequently , within the field of Computer Vision it has been the focus of much research. Many algorithms for matching sets of features , such as points or line segments derived from two images have been explored . One approach has been to represent the images or objects in the form of graphs . A weighted graph may be used to formulate a structural description of an object 1 . Such descriptions can be further enhanced with parametric information and represented by attributed relational graphs (ARGs) 2 . Because of the representational power of graphs , much effort has gone into the development of efficient algorithms which can effectively match graphs . Two main approaches have been tried . One approach involves the construction of a state-space which is then searched with techniques similar to the branch and bound methods employed in operations research 3 . These algorithms are of exponential time worst-case complexity . However the assumption is made , that with the help of heuristics, the size of each level of the resulting state-space search tree will be reduced to a low order polynomial (as a function of the number of nodes of the graphs) 4 . However even under these assumptions , the algorithm typically has a high-order polynomial complexity . For example the method in 5 , is approximately O(l 3 (where l and m are the number of links in the two graphs) , though special instances are faster. The second approach employs nonlinear optimization methods (or heuristic approximations thereof) . The most successful of these methods use some form of relaxation labeling 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 . Relaxation labeling algorithms do not", "label": ["model matching", "graduated assignment", "continuation method", "attributed relational graphs", "softassign", "weighted graphs", "relaxation labeling", "graph matching"], "stemmed_label": ["model match", "graduat assign", "continu method", "attribut relat graph", "softassign", "weight graph", "relax label", "graph match"]}
{"doc": "We show that for most complexity classes of interest , all sets complete under first-order projections (fops) are isomorphic under first-order isomorphisms . That is , a very restricted version of the Berman--Hartmanis conjecture holds . Since \"natural\" complete problems seem to stay complete via fops , this indicates that up to first-order isomorphism there is only one \"natural\" complete problem for each \"nice\" complexity class . Introduction In 1977 Berman and Hartmanis noticed that all NP complete sets that they knew of were polynomial-time isomorphic , BH77 . They made their now-famous isomorphism conjecture: namely that all NP complete sets are polynomial-time isomorphic . This conjecture has engendered a large amount of work (cf . KMR90 , You for surveys). The isomorphism conjecture was made using the notion of NP completeness via polynomial- time , many-one reductions because that was the standard definition at the time . In Coo , A preliminary version of this work appeared in Proc . 10th Symposium on Theoretical Aspects of Computer Science , 1993 , Lecture Notes in Computer Science 665 , pp . 163-174. y Some of this work was done while on leave at Princeton University; supported in part by National Science Foundation grant CCR-9204874. z Supported in part by ESPRIT-II BRA EC project 3075 (ALCOM) and by Acci'on Integrada Hispano- Alemana 131 B x Supported by NSF grant CCR-9207797. Cook proved that the Boolean satisfiability problem (SAT) is NP complete via polynomial-time Turing reductions . Over the years SAT has been shown complete via weaker and weaker reductions , e.g . polynomial-time many-one Kar , logspace many-one Jon , one-way logspace many-one HIM , and first-order projections (fops) Dah . These last reductions, defined in Section 3 , are provably weaker than logspace reductions . It has been observed that natural complete problems for various complexity classes including NC 1 , L , NL , P , NP, and PSPACE remain complete via fops , cf . I87 , IL , SV , Ste , MI . On the other hand , Joseph and Young , JY have pointed out that polynomial-time , many-one reductions may be so powerful as to allow unnatural NP-complete sets . Most researchers now believe that the isomorphism conjecture as originally stated by Berman and Hartmanis is false . 1 We feel that the choice of polynomial-time , many-one reductions in the statement of the Isomorphism Conjecture was made in part for historical rather than purely scientific reasons. To elaborate on this claim , note that the class NP arises naturally in the study of logic and can be defined entirely in terms of logic , without any mention of computation Fa . Thus it is natural to have a notion of NP-completeness that is formulated entirely in terms of logic . On another front , Valiant Val noticed that reducibility can be formulated in algebra using the natural notion of a projection , again with no mention of computation . The sets that are complete under fops are complete in all of these different ways of", "label": ["complexity classes", "reduction", "first-order projection", "descriptive complexity"], "stemmed_label": ["complex class", "reduct", "first-ord project", "descript complex"]}
{"doc": "In this paper , we consider the stochastic profile scheduling problem of a partially ordered set of tasks on uniform processors . The set of available processors varies in time . The running times of the tasks are independent random variables with exponential distributions . We obtain a sufficient condition under which a list policy stochastically minimizes the makespan within the class of preemptive policies . This result allows us to obtain a simple optimal policy when the partial order is an interval order , an in-forest , or an out-forest . Introduction Consider the following scheduling problem . We are given a set of tasks to be run in a system consisting of uniform processors (i.e. , processors having different speeds) . The executions of these tasks must satisfy some precedence constraints which are described by a directed acyclic graph , referred to as the task graph . The processing requirements of the tasks are independent random variables with a common exponential distribution . The set of processors available to these tasks varies in time . The availability of the processors is referred to as the profile , and it can be arbitrary . The goal is to find preemptive schedules that stochastically minimize the makespan. Our study of scheduling under variable profile is motivated by situations where processors are subject to failures and repairs . The failure and repair times are arbitrary . Another motivation is scheduling of multiprogrammed systems . In such a system , execution of tasks of a program may be preempted by tasks of higher-priority programs. When the task graph is an in-forest , and the profile is a constant set of two processors, Chandy and Reynolds 2 proved that the Highest Level First (HLF) policy minimizes the expected makespan . Here , the level of a task is simply the distance from it to the root of the tree in which it appears . Bruno 1 subsequently showed that HLF stochastically minimizes the makespan when the system has two identical parallel processors . Pinedo and Weiss 14 extended this last result to the case where tasks at different levels may have different expected task running times . Frostig 7 further generalized the result of Pinedo and Weiss to include increasing likelihood ratio distributions for the task running times . Recently , Kulkari and Chimento 9 extended the result of 1 to the case of variable profile (with two identical parallel processors). When the number of identical parallel processors in the system is arbitrarily fixed , and the task running times have a common exponential distribution , Papadimitriou and Tsitsiklis 12 proved that HLF is asymptotically optimal as the number of tasks tends to infinity. Coffman and Liu 3 investigated the stochastic scheduling of out-forest on identical parallel processors with constant profile . For a uniform out-forest where all subtrees are ordered by an embedding relation (see definition in Section 4.3) , they showed that an intuitive priority scheduling policy induced by the embedding relation , referred to as the Most Successors (MS) policy in this", "label": ["stochastic scheduling", "profile scheduling", "stochastic ordering", "makespan", "precedence constraint", "interval order", "uniform processors", "out-forest", "in-forest"], "stemmed_label": ["stochast schedul", "profil schedul", "stochast order", "makespan", "preced constraint", "interv order", "uniform processor", "out-forest", "in-forest"]}
{"doc": "This paper investigates the computational complexity of approximating several \\NP-optimization problems using the number of queries to an \\NP\\ oracle as a complexity measure . The results show a tradeoff between the closeness of the approximation and the number of queries required . For an approximation factor $k(n)$ , $\\log \\log_ k(n) n$ queries to an \\NP\\ oracle can be used to approximate the maximum clique size of a graph within a factor of $k(n)$ . However , this approximation cannot be achieved using fewer than $\\log \\log_ k(n) n - c$ queries to any oracle unless is a constant that does not depend on $k$ . These results hold for approximation factors $k(n) \\geq 2$ that belong to a class of functions which includes any integer constant function , $\\log n$ , $\\log^ a n$ , and $n^ 1/a $ . Similar results are obtained for Graph Coloring , Set Cover , and other \\NP-optimization problems . Introduction The approximability of NP-optimization problems is a central theme both in the study of algorithms and in computational complexity theory . Most NP-optimization problems have decision versions that are NP-complete and are hence equivalent to each other as decision problems . However , the approximability of the optimization problems may vary greatly. For some NP-optimization problems , there are efficient algorithms that find good approximate solutions . For others , no such algorithm can exist unless some standard intractability assumption is violated (e.g. , or the Polynomial Hierarchy collapses) . Recently, Arora , Lund , Motwani , Sudan and Szegedy ALM showed that the problem of finding the largest clique in a graph is in the latter category . Following a series of breakthrough results AS92 , BFL91 , FGL showed that there exists a constant ffl such that no deterministic polynomial time algorithm can approximate the maximum clique size !(G) of a graph G with n vertices within a factor of n ffl , unless . While this result strongly suggests that no efficient algorithm can find good approximations to the maximum clique problem , it does not resolve all of the questions about the computational complexity of approximating the maximum clique size of a graph . In particular , it is not clear what computational resources are sufficient and/or necessary to compute an approximation of the maximum clique size using any of the traditional resource bounded measures (e.g. , time, space , random bits and alternation). In this paper we use the number of queries to an NP-complete oracle as a complexity measure . Krentel Kre88 used this measure to show that the maximum clique size is complete for polynomial time functions which use only O(log n) queries , denoted PF NP O(log n) . Since Krentel's original work , many connections between bounded query classes and standard complexity classes have been discovered ABG90 , AG88 , Bei87 , Bei91 , CK90 , GKR , Wag86, WW85 . In many circumstances , these results show that one cannot decrease the number of queries needed to solve a problem by even a", "label": ["bounded queries", "set cover", "np-completeness", "maximum clique", "chromatic number", "approximation algorithm"], "stemmed_label": ["bound queri", "set cover", "np-complet", "maximum cliqu", "chromat number", "approxim algorithm"]}
{"doc": "Self-stabilizing message-driven protocols are defined and discussed . The class weak exclusion that contains many natural tasks such as $\\ell$-exclusion and token passing is defined , and it is shown that in any execution of any self-stabilizing protocol for a task in this class , the configuration size must grow at least in a logarithmic rate . This last lower bound is valid even if the system is supported by a time-out mechanism that prevents communication deadlocks . Then we present three self-stabilizing message-driven protocols for token passing . The rate of growth of configuration size for all three protocols matches the aforementioned lower bound . Our protocols are presented for two-processor systems but can be easily adapted to rings of arbitrary size . Our results have an interesting interpretation in terms of automata theory . Introduction A distributed system is a set of state machines , called processors , which communicate either by shared variables or by message-passing . In the first case , the system is a shared memory system , in the second case the system is a message-passing system . A distributed system is self-stabilizing if it can be started in any possible global state . Once started , the system regains its consistency by itself , without any kind of an outside intervention . The self-stabilization property is very useful for systems in which processors may crash and then recover spontaneously in an arbitrary state . When the intermediate period in between one recovery and the next crash is long enough , the system-stabilizes . Self-stabilizing systems were defined and discussed first in the fundamental paper of Dijkstra , Dij-74 . The work of Dij-74 as well as most of the following work on self-stabilizing systems assume the communication model of shared variables . Among these papers are Kr-79 , Tc-81 , Dij-82 , La-86 , BGW-87 , Bu-87 , BP-88 , IJ-90 , IJ-90a , DIM-90 and DIM-91 . In the study of fault tolerant message-passing systems , it is customarily assumed that messages might be corrupted over links , hence , processors may enter arbitrary states and link contents may be arbitrary . Self-stabilizing protocols treat these problems naturally , since they are designed to recover from inconsistent global-states . Surprisingly , there are very few papers which address self-stabilizing , message-passing systems . The earliest research in this model was done by Gouda and Multari in Mu-89 , GM-91 . In that work , they have developed a self-stabilizing sliding window protocol and two-way handshake that use unbounded counters . They proved that any self-stabilizing message passing protocol must use time-outs and have infinite number of safe states . Following GM-91 , two additional works dealt with self-stabilizing protocols in this model: The work of Katz and Perry , KP-90 , presents a general tool for extending an arbitrary message-passing protocol to a self-stabilizing protocol . The work of Afek and Brown, AB-89 , presents a self-stabilizing version of the well-known alternating-bit protocol , (see e.g. BSW-69 ). In this work we research complexity", "label": ["message passing", "self-stabilization", "token passing", "shared memory"], "stemmed_label": ["messag pass", "self-stabil", "token pass", "share memori"]}
{"doc": "AbstractIn this paper , we examine the wormhole routing problem in terms of the \"congestion\" c and \"dilation\" d for a set of packet paths . We show , with mild restrictions , that there is a simple randomized algorithm for routing any set of P packets in $O\\left( cd\\eta +cL\\eta \\,\\, \\rm log \\,\\,P \\right)$ time with high probability , where L is the number of flits in a packet , and only a constant number of flits are stored in each queue at any time . Using this result , we show that a fat-tree network of area (A) can simulate wormhole routing on any network of comparable area with O(log3A) slowdown , when all worms have the same length . Variable-length worms are also considered . We run some simulations on the fat-tree which show that not only does wormhole routing tend to perform better than the more heavily studied store-and-forward routing in this context , but that performance superior to our provable bound is attainable in practice . Introduction An efficient routing algorithm is critical to the design of most large-scale general-purpose parallel computers . One must move data between different locations in an appropriate routing network as quickly as possible and with as little queuing hardware as possible . Store-and-forward routing is the most extensively studied model and many asymptotically efficient algorithms have been proposed for this model (e.g. , 15 and the references therein) . Recently , increasing attention has been devoted to the wormhole routing model 3 , since it can lead to a reduction in routing time and the storage requirements of intermediate nodes. In this model , packets (or worms) are composed of flits or flow control digits , and packets snake through the network one flit after another. Few works have performed any theoretical analysis of This work was supported in part by the National Science Foundation under grants CCR-9109550and CCR-9321388and by a Summer Research Award from the University of Maryland Office of Graduate Studies and Research. R . I . Greenberg is with the Department of Mathematical and Computer Sciences Loyola University , 6525 N . Sheridan Rd. , Chicago , IL 60626, rig@math.luc.edu. H-C . Oh is with the Department of Information Engineering , Korea University , Chochiwon , Korea , hyeong@tiger.korea.ac.kr. wormhole routing or similar schemes . Leighton 17 performs average-case analysis of greedy cut-through routing on meshes . But cut-through routing 13 differs from wormhole routing in that it uses buffers that can store at least one full packet rather than a few flits . Makedon and Simvonis 20 give worst case bounds for cut-through routing of permutations on the mesh and the torus . Aiello, Leighton , Maggs , and Newman 1 give an efficient algorithm for wormhole routing of permutations on a dilated butterfly . Their algorithm is nonoblivious (may use information about other packets when routing a given packet). More recently , Felperin , Raghavan , and Upfal 6 have obtained a simple , oblivious algorithm for wormhole routing of permutations on the butterfly and", "label": ["wormhole routing", "packet routing", "greedy routing", "fat-tree interconnection network", "area-universal networks", "randomized routing"], "stemmed_label": ["wormhol rout", "packet rout", "greedi rout", "fat-tre interconnect network", "area-univers network", "random rout"]}
{"doc": "AbstractReducing communication latency , which is a performance bottleneck in optically interconnected multiprocessor systems , is of prominent importance . A conventional approach for establishing connections in multiplexed networks uses a set of independent time slots (or virtual channels) along a path for each connection . This approach requires the use of switching devices capable of interchanging time slots , and thus introduces latency in addition to hardware and control complexity . In this paper , we propose an approach to all-optical Time Division Multiplexed (TDM) communications in multiprocessor systems . The idea is to establish a connection along a path using a set of time slots (or virtual channels) that are dependent on each other , so that no time-slot interchanging is required . We compare the proposed approach with the conventional one in terms of the overall communication latency . We found that , despite the possibility that establishing a connection may take a longer time , the proposed approach will result in lower overall communication latency as it eliminates the delays introduced by the time-slot interchanging switching devices . Having virtual channels increases bandwidth utilization and facilitates adaptive routing algorithms as well as the static mapping of the communication requirements of various applications 6-8 . TDM techniques are also useful for tolerating the propagation latency in optically interconnected multiprocessor systems 9-12 , and for reducing the control complexity of channel allocation in TDM systems 13 , 14 and in Wavelength Division Multiplexed (WDM) systems 15 , 16 . A key issue to be addressed in optically interconnected multiprocessor systems is the reduction of the communication latency which is a performance bottleneck in such systems . In this paper , we describe a new multiplexing approach for establishing all-optical connections in multiprocessor systems , and compare it with a conventional multiplexing approach. The paper is organized as follows . In Section 2 , we provide motivations for considering circuit-switching, and describe possible ways to achieve global synchronization which is required for TDM communication. In Section 3 , we describe how connections , especially virtual connections , are established in multiplexed networks . Specifically , a conventional approach which we call Link Multiplexing (or LM) is described in Section 3.1 . Using LM , a connection may be established by selecting a time slot on each link independently of the time slots selected on the other links along a path . Thus , in order to transfer messages between two possibly different time slots , the switches in the network are required to have the capability of interchanging time slots 17-19 . The proposed approach called Path Multiplexing (or PM) is described in Section 3.2. Using that approach , the time slots selected on the links along a path are dependent on each other , such that no time-slot interchanging is needed to transfer messages along the path . For example , a connection may be established along a path by selecting the same time slot on every link . Network control , or signaling, involved in selecting the time slots", "label": ["time division multiplexing", "fiber-optical interconnects", "communication latency", "switching networks", "time slot interchangers"], "stemmed_label": ["time divis multiplex", "fiber-opt interconnect", "commun latenc", "switch network", "time slot interchang"]}
{"doc": "AbstractThe bound on component failures and their spatial distribution govern the fault tolerance of any candidate error-detecting algorithm . For distributed memory multiprocessors , the specific algorithm and the topology of the processor interconnection network define these bounds . This paper introduces the maximal fault index , derived from the system topology and local communication patterns , to demonstrate how a maximal number of simultaneous component failures can be tolerated for a particular interconnection network and error-detecting algorithm . The index is used to design a mapping of processes to processor groups such that the error-detecting ability of the algorithm is preserved for certain multiple simultaneous processor failures . Introduction In a fixed multi-processor topology , the number of permitted faults and their distribution in the topology is restricted if we want to be able to detect all resulting errors . This paper introduces the maximal fault index , derived from the system topology and local communication patterns of an algorithm , to obtain a maximal number of simultaneous (Byzantine) component failures and their distribution such that all errors can still be detected . We will introduce a mapping for the individual processes to processor groups such that the error-detecting abilities of algorithms are maximized . This fault-tolerant process-to-processor mapping can be used for safety critical systems since it ensures that the failure of certain combinations of multiple components does not go undetected , which increases the dependability of the system. We call the set of processors obtained from the local interprocess communications of the algorithm a communication environment (Figure 1(a) shows the star pattern). Given , as design parameters , the maximum number of faults that can be permitted in each communication environment such that all errors can still be detected , the local tolerance t l , and the topology of the entire system , we want to compute the global tolerance t g which maximizes the number of permitted faults in the system while maintaining the local fault tolerance condition. Figure 1(b) shows a scenario where two simultaneously faulty components in the system will not violate the local fault tolerance . By contrast , Figure 1c shows a syndrome of faults which violates the local fault tolerance for at least one communication environment. An optimal fault distribution yields a partitioning of processes into groups such that all processes within a particular group can be simultaneously faulty and still all errors can be detected . The processor groups are then mapped , disjointly , into the actual topology. Thus , the failure of elements in any single processor group still allows for the detection of all errors. 3,0 . 3,3 0,0 . 0,3 mapped to the same group simultaneously faulty are c) processes that may be a) communication environment for the algorithm 0,0 . 0,3 3,0 . 3,3 conventional process-to- processor mapping Figure 2: Logical adjacency in the algorithm and physical mapping. An example for a fault-tolerant mapping is given in Figure 2 . The communication environment used (the square) is described in Figure 2(a) . The conventional process-to- processor", "label": ["error detection", "architecture", "fault tolerance", "mapping", "fault-tolerant algorithms", "multicomputers"], "stemmed_label": ["error detect", "architectur", "fault toler", "map", "fault-toler algorithm", "multicomput"]}
{"doc": "AbstractParallel scheduling is a new approach for load balancing . In parallel scheduling , all processors cooperate to schedule work . Parallel scheduling is able to accurately balance the load by using global load information at compile-time or runtime . It provides high-quality load balancing . This paper presents an overview of the parallel scheduling technique . Scheduling algorithms for tree , hypercube , and mesh networks are presented . These algorithms can fully balance the load and maximize locality at runtime . Communication costs are significantly reduced compared to other existing algorithms . Introduction Static scheduling balances the workload before runtime and can be applied to problems with a predictable structure , which are called static problems . Dynamic scheduling performs scheduling activities concurrently at runtime , which applies to problems with an unpredictable structure, which are called dynamic problems . Static scheduling utilizes the knowledge of problem characteristics to reach a well-balanced load 1 , 2 , 3 , 4 . However , it is not able to balance the load for dynamic problems . In addition , the requirement of large memory space to store the task graph restricts the scalability of static scheduling . Dynamic scheduling is a general approach suitable for a wide range of applications 5 , 6 , 7 . It can adjust load distribution based on runtime system load information . However , most runtime scheduling algorithms utilize neither the characteristics information of application problems , nor the global load information for load balancing decisions. System stability usually sacrifices both quality and quickness of load balancing. Parallel scheduling is a promising technique for processor load balancing . In parallel schedul- ing , all processors cooperate to schedule work . Parallel scheduling utilizes global load information and is able to accurately balance the load . It provides high-quality , scalable load balancing . Some parallel scheduling algorithms have been introduced in 8 , 9 , 10 , 11 . Parallel scheduling can be applied to static problems . Most existing scheduling algorithms for static problems running on a single processor are not scalable to massively parallel computers because storing the task graph requires large memory space . To speed up scheduling and to relax the demand of memory space , static scheduling can be parallelized . Kwok and Ahmad have developed a parallel algorithm 12 . Wu has parallelized the MCP algorithm 13 . Parallel scheduling can also be applied to dynamic problems . When parallel scheduling is applied at runtime , it becomes an incremental collective scheduling . It is applied whenever the load becomes unbalanced . All processors collectively schedule the workload . Such a system has been described in 11 . It starts with a system phase which schedules initial tasks; it is followed by a user computation phase to execute the scheduled tasks and possibly to generate new tasks. In the next system phase , the old tasks that have not been executed will be scheduled together with the newly generated tasks . In each system phase , a parallel scheduling", "label": ["distributed memory computers", "trees", "runtime parallel scheduling", "load balancing", "meshes", "scheduling algorithms", "hypercubes"], "stemmed_label": ["distribut memori comput", "tree", "runtim parallel schedul", "load balanc", "mesh", "schedul algorithm", "hypercub"]}
{"doc": "AbstractThe performance of the Time Warp mechanism is experimentally evaluated when only a limited amount of memory is available to the parallel computation . An implementation of the cancelback protocol is used for memory management on a shared memory architecture , viz. , KSR to evaluate the performance vs . memory tradeoff . The implementation of the cancelback protocol supports canceling back more than one memory object when memory has been exhausted (the precise number is referred to as the salvage parameter) and incorporates a non-work-conserving processor scheduling technique to prevent starvation.Several synthetic and benchmark programs are used that provide interesting stress cases for evaluating the limited memory behavior . The experiments are extensively monitored to determine the extent to which various factors may affect performance . Several observations are made by analyzing the behavior of Time Warp under limited memory: 1) Depending on the available memory and asymmetry in the workload , canceling back several memory objects at one time (i.e. , a salvage parameter value of more than one) improves performance significantly , by reducing certain overheads . However , performance is relatively insensitive to the salvage parameter except at extreme values . 2) The speedup vs . memory curve for Time Warp programs has a well-defined knee before which speedup increases very rapidly with memory and beyond which there is little performance gain with increased memory . performance nearly equivalent to that with large amounts of memory can be achieved with only a modest amount of additional memory beyond that required for sequential execution , if memory management overheads are small compared to the event granularity . These results indicate that contrary to the common belief , memory usage by Time Warp can be controlled within reasonable limits without any significant loss of performance . common belief , memory usage by Time Warp can be controlled within reasonable limits without a significant loss of performance . This work also suggests that limiting memory can act as an effective throttling mechanism for Time Warp executions. tion protocols is that Time Warp offers the potential for greater exploitation of parallelism and, perhaps more importantly , greater transparency of the synchronization mechanism to the simulation programmer . Time Warp has demonstrated a fair amount of success in speeding up simulations of combat models 31 , communication networks 3 , 26 , queueing networks 8 , and digital logic circuits 2 , among many others. One major critique of Time Warp is its apparent large and inefficient use of memory . Time Warp uses a checkpointing technique to implement the rollback mechanism . Past states of the processes need to be saved to enable rollback . In addition , the Time Warp system may hold a large amount of incorrect computations that will be rolled back or canceled in the future . Thus Time Warp may be inefficient in its memory usage . Large simulations may cause severe performance degradations due to overheads in the virtual memory system of the underlying architecture . Memory utilization in Time Warp can be unbounded in principle", "label": ["checkpointing", "time warp", "performance evaluation", "virtual time", "discrete event simulation", "memory management", "parallel and distributed simulation", "rollback"], "stemmed_label": ["checkpoint", "time warp", "perform evalu", "virtual time", "discret event simul", "memori manag", "parallel and distribut simul", "rollback"]}
{"doc": "AbstractAn end-to-end data delivery protocol for dynamic communication networks is presented . The protocol uses bounded sequence numbers and can tolerate both link failures and (intermediate) processor crashes . Previous bounded end-to-end protocols could not tolerate crashes.We present a self-stabilizing version of the algorithm that can recover from crashes of the sender and the receiver as well as of intermediate processors . Starting with the network in an arbitrary state , the self-stabilizing version guarantees proper transmission of messages following a finite convergence period . Introduction A basic communication task in any network is end-to-end communication , that is, delivery in finite time of data items generated at a designated sender processor, to a designated receiver processor , without duplication , omission or reordering of data items . End-to-end communication is easy to achieve in a reliable net- work , where links never fail and processors do not crash . However , in existing communication networks both link failures and processor crashes are possible. A network that is subject to such failures is called a dynamic network. One approach to constructing end-to-end protocols for dynamic networks is to use unbounded sequence numbers to uniquely identify the data items sent by the sender . Such an approach is used in the protocol of AE86 . The use of unbounded sequence numbers implies that both message size and the amount of memory needed will grow with the number of data items transmitted . Therefore, much effort has been spent in designing end-to-end protocols that use bounded sequence numbers. An important aspect of an end-to-end communication protocol is the type of faults that it can tolerate . Clearly the end-to-end task is unsolvable when there is a permanent sender-receiver link cut of the network such that all of its This work was supported by NSF Presidential Young Investigator Award CCR-91- 58478 and funds from the Texas A&M University College of Engineering . Contact author: Jennifer L . Welch , e-mail: welch@cs.tamu.edu , Phone: 409-845-5076 , Fax: links are down forever . Thus , some assumption on the behavior of faulty links is necessary . Three common assumptions in the literature are: infinitely frequent stability: Infinitely often the network topology stabilizes for a period of time and there is no sender-receiver link cut in this stabilized topology (e.g . AAG87 , AS88 ). infinitely frequent path stability: Infinitely often there is a period of time during which links forming at least one path between the sender and the receiver are operating (e.g . AGH90 , H92 ). eventual connectivity: The only assumption is that there is no permanent sender-receiver link cut (e.g . AG88 , AMS89 , AG91 , AGR92 ). Almost all existing end-to-end protocols depend on having physical links that are , or can be made to be , \"well-behaved\" in that the sequence of messages delivered is always a prefix of the sequence sent , i.e. , no messages are lost in the middle . If processors do not crash , then this behavior can be ensured by running the alternating bit protocol", "label": ["dynamic networks", "communication networks", "self-stabilization", "crash failures", "end-to-end protocols"], "stemmed_label": ["dynam network", "commun network", "self-stabil", "crash failur", "end-to-end protocol"]}
{"doc": "AbstractThis paper describes a generalized sequential diagnosis algorithm whose analysis leads to strong diagnosability results for a variety of multiprocessor interconnection topologies . The overall complexity of this algorithm in terms of total testing and syndrome decoding time is linear in the number of edges in the interconnection graph and the total number of iterations of diagnosis and repair needed by the algorithm is bounded by the diameter of the interconnection graph . The degree of diagnosability of this algorithm for a given interconnection graph is shown to be directly related to a graph parameter which we refer to as the partition number . We approximate this graph parameter for several interconnection topologies and thereby obtain lower bounds on degree of diagnosability achieved by our algorithm on these topologies . If we let N denote total number of vertices in the interconnection graph and denote the maximum degree of any vertex in it , then our results may be summarized as follows . We show that a symmetric d-dimensional grid graph is sequentially $\\Omega \\left( N^ d \\over d+1 \\right)$-diagnosable for any fixed d . For hypercubes , symmeteric log N-dimensional grid graphs , it is shown that our algorithm leads to a surprising $\\Omega \\left( N\\, \\rm log\\,log \\,N \\over log\\,N \\right)$ degree of diagnosability . Next we show that the degree of diagnosability of an arbitrary interconnection graph by our algorithm is $\\Omega \\left( \\sqrt N \\over \\Delta \\right).$ This bound translates to an $\\Omega \\left( \\sqrt N \\right)$ degree of diagnosability for cube-connected cycles and an $\\Omega \\left( \\sqrt N \\over k \\right)$ degree of diagnosability for k-ary trees . Finally , we augment our algorithm with another algorithm to show that every topology is $\\Omega \\left( N^ 1 \\over 3 \\right)$-diagnosable . Introduction The problem of identifying faulty processors in a multiprocessor system , known as system-level diagnosis , has been extensively studied in the literature 1 , 2 , 3 , 4 , 5 . The foundations of this area and the original diagnostic model were established in a classic paper by Preparata, Metze and Chien 1 . This model , known as the PMC model , has been widely studied 1 , 6, 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 . It assumes a system to be composed of units or processors capable of testing each other along the available communication channels . Once a unit u 1 has tested another unit u 2 , it declares u 2 as fault-free or faulty . The outcome of the test is considered reliable iff unit u 1 is fault-free . Only permanent faults are considered in this model . In recent years , probabilistic fault models which allow intermittent faults have also been actively studied 16 , 17 , 18 . The process of interpreting the test results so as to correctly determine the status of various processors is known as syndrome-decoding . This can be done either by a central observer 1 , 6 , 8", "label": ["system-level diagnosis", "analysis of algorithms", "sequential diagnosis", "graph partitioning", "fault-tolerance", "degree of diagnosability", "multiprocessor systems"], "stemmed_label": ["system-level diagnosi", "analysi of algorithm", "sequenti diagnosi", "graph partit", "fault-toler", "degre of diagnos", "multiprocessor system"]}
{"doc": "AbstractIn this paper , we analyze several issues involved in developing low latency adaptive wormhole routing schemes for two-dimensional meshes . It is observed that along with adaptivity , balanced distribution of traffic has a significant impact on the system performance . Motivated by this observation , we develop a new fully adaptive routing algorithm called positive-first-negative-first for two-dimensional meshes . The algorithm uses only two virtual channels per physical channel creating two virtual networks . The messages are routed positive-first in one virtual network and negative-first in the other . Because of this combination , the algorithm distributes the system load uniformly throughout the network and is also fully adaptive . It is shown that the proposed algorithm results in providing better performance in terms of the average network latency and throughput when compared with the previously proposed routing algorithms . Introduction In distributed parallel computers , tasks are executed by a set of intercommunicating nodes or processors . The communication is usually carried out by means of passing messages from one node to another over the interconnection network . Since direct networks utilize the locality of the message references more efficiently , most of the existing systems use direct networks such as k-ary n-cube or n-dimensional mesh. The performance of the interprocessor communication scheme depends largely on the network dimension , the switching technique , and the routing algorithm . Most of the contemporary systems have used two or three dimensions . Store and forward , virtual cut-though and wormhole routing are the main switching techniques used for interprocessor communication . Due to lower latency and small buffer requirements , wormhole routing is preferred and is widely used in recent multicomputers 1 . Message passing in multicomputer systems is implemented based on a routing algorithm that determines the path a message follows to reach its destination . If the path between every pair of source and destination is fixed , the algorithm is called deterministic . For better system performance , it is preferable that the algorithm adapts itself to the traffic congestion by providing alternate paths . Adaptive routing algorithms are classified as partially adaptive or fully adaptive. Partially adaptive routing algorithms use only a subset of the available physical paths between the source and the destination . Turn model 2 , 3 , direction restriction model 4 , and planar- adaptive routing 5 are examples of partially adaptive algorithms . Examples of fully adaptive algorithms include the routing schemes proposed by Linder and Harden 6 , Duato 7 , Su and Shin 8 , Boura and Das 9 , and Schwiebert and Jayasimha 10 . The adaptive algorithms presented in 7 , 8 , 9 , 10 try to achieve more adaptivity by allowing more number of alternate paths for message routing . In order to achieve high adaptivity , these algorithms often favor some messages or some paths over the others , which in turn , cause an uneven traffic distribution in the network . As a result , a part of the network is heavily loaded", "label": ["two-dimensional mesh", "traffic distribution", "region of adaptivity", "adaptive wormhole routing", "positive-first-negative-first algorithm"], "stemmed_label": ["two-dimension mesh", "traffic distribut", "region of adapt", "adapt wormhol rout", "positive-first-negative-first algorithm"]}
{"doc": "AbstractWe consider the problem of communications over a wireless channel in support of data transmissions from the perspective of small portable devices that must rely on limited battery energy . We model the channel outages as statistically correlated errors . Classic ARQ strategies are found to lead to a considerable waste of energy , due to the large number of transmissions . The use of finite energy sources in the face of dependent channel errors leads to new protocol design criteria . As an example , a simple probing scheme , which slows down the transmission rate when the channel is impaired , is shown to be more energy efficient , with a slight loss in throughput . A modified scheme that yields slightly better performance but requires some additional complexity is also studied . Some references on the modeling of battery cells are discussed to highlight the fact that battery charge capacity is strongly influenced by the available \"relaxation time\" between current pulses . A formal approach that can track complex models for power sources , including dynamic charge recovery , is also developed . Introduction Small portable communication devices are an integral element of nomadic computing systems. These mobile devices must rely on limited battery energy to conduct communications over a wireless channel . Since low data rates and high error rates are endemic to the wireless environment, energy efficient error control over the wireless link is a significant part of the effort to develop nomadic computing systems. The first step is to understand the nature and impact of errors . Voice applications are traditionally supported with a \"thin\" protocol stack and so the impact of errors on the wireless links on voice transmissions is relatively easy to study . In contrast , control , data and other multi-media communications are implemented as applications at the upper layers of a protocol stack . Consequently the impact of physical layer impairments are harder to track , especially since errors on the physical channel are statistically correlated. To elaborate , note that errors that occur on the physical channel are a function of specific propagation phenomena such as multipath , fading and user mobility . The raw channel variations are by themselves not directly useful since processes such as coding , interleaving and power control alter the dynamics of the physical channel errors . Furthermore , for most non-voice applications, the more relevant quantities are related to block errors , since such applications run on top of a data-link layer that exchanges blocks of data . As we shift our attention to the higher layers , we find that the correlations that arise in bit errors will in principle lead to correlations in the block errors. It is worth noting that Markov models are useful in dealing with correlated errors . Once the structure of the error process is known , it is possible to study the performance of well known error control schemes such as FEC , ARQ or Hybrid ARQ . Although such studies have been performed recently 1 ,", "label": ["mobile communications", "wireless systems", "mobile computing", "energy consumption", "error control", "channel probing", "battery modeling"], "stemmed_label": ["mobil commun", "wireless system", "mobil comput", "energi consumpt", "error control", "channel probe", "batteri model"]}
{"doc": "AbstractNFS is a widely used remote file access protocol that has been tuned to perform well on traditional LANs which exhibit low error rates . Users migrating to mobile hosts would like continued remote file access via NFS . However , low bandwidth and high error rates degrade performance on mobile hosts using wireless links , hindering the use of NFS . We conducted experiments to study the behavior of NFS in a wireless testbed . Based on these experiments , we incorporated modifications into the mobile NFS client . This paper presents two mechanisms which improve NFS performance over wireless links: an aggressive NFS client and link-level retransmissions . Our experiments show that these mechanisms improve response time by up to 62% , which brings the performance to within 5% of that obtained in zero error conditions . Introduction Mobile computing is increasingly in demand and will be an important part of the computing infrastructure in the near future . The use of wireless links gives the mobile user new freedom and flexibility . Unfortunately , since most applications and reliable transport protocols have been optimized for wired networks and static hosts , they suffer from poor performance when used on wireless systems . The performance over wireless links is currently limited by low bandwidths , high error rates , temporary disconnections , and high latencies . Protocols and applications must be adapted to accommodate these characteristics in order to provide acceptable performance to mobile users. In addition to transmission limitations , mobile users are constrained by limited disk space. Unable to store all their data on their local disks , users often must fetch files from servers on the wired network via wireless links . The Network File System (NFS) protocol is widely used on wired LANs to provide a mechanism for remote and distributed file access SGK Users migrating to mobile hosts from stationary workstations want to continue to use NFS to access their files . However , the bursty errors and higher error rates prevalent over wireless media pose performance problems for mobile applications which use NFS-mounted files. This work is supported in part by NSF grant CCR 9318933 , by IBM equipment grants , and by Novell. NFS should be usable in in-building wireless networks even in the presence of interference or loss . We limit our scope to these wireless LAN networks , (which have bandwidths on the order of 1 Mbps) . NFS is designed for faster physical networks (on the order of 10 Mbps) which exhibit rare random errors . Therefore , packet losses are attributed to either network congestion or a server failure . NFS clients can back-off and retry a request after waiting for some predetermined time period . On wireless links , packet losses are usually due to burst errors rather than network congestion or server failures . These burst periods are on the order of a hundred milliseconds BBKT96 . In response to such losses , NFS clients back-off to unnecessarily long wait periods , leading to severe performance degradation.", "label": ["mobile computing", "link-level retransmission", "performance evaluation", "wireless lan", "nfs", "file systems"], "stemmed_label": ["mobil comput", "link-level retransmiss", "perform evalu", "wireless lan", "nf", "file system"]}
{"doc": "AbstractRecently , DQDB (IEEE 802.6) MAN has been proposed as a component of Personal Communication Networks , in which base stations of wireless infrastructures are connected by a number of DQDBs which in turn are connected via bridges . We propose a protocol for call setup and path migration in a cluster of DQDBs . The protocol uses a link-state-like routing method for path selection and a source-routing-based scheme for path establishment . In addition , we propose a labeling scheme that makes it possible to carry the path information needed by the source routing protocol in a single 53-octet DQDB slot . Without such a labeling scheme , source routing would be inefficient for our purpose . Introduction Personal Communication Networks (PCN) provide ubiquitous communication coverage , enabling people to call people , regardless of physical locations 7 , 9 . The coverage area of PCN is divided into radio cells , each having a Base Station (BS) to exchange radio signals with mobile hosts. Base stations are connected by wired networks to exchange control information. Recently , the IEEE 802.6 Distributed Queue Dual Bus (DQDB) MAN has been proposed as a component of PCN 9 , 10 , 14 . A typical DQDB-based PCN infrastructure is illustrated in Fig . 1 , where BS's are connected by DQDBs , and DQDBs are connected by MAN bridges to form a cluster . Clusters of DQDBs are connected to ATM networks via gateways . It is believed that the compatibility between the IEEE 802.6 DQDB MAN and ATM cell structures will simplify the interworking between DQDBs with ATM networks 14 . In an IEEE 802.6 DQDB MAN 11 , the basic unit of data transfer is 53-octet slot . There are two kinds of slots: Queued Arbitrated (QA) slots and Pre-Arbitrated (PA) slots . PA slots are used to transfer isochronous service octets . A PA slot consists of a 20-bit virtual Channel isochronous service octets . An isochronous service octet is specified by (vci,loc) , where vci is the VCI of the PA slot and loc is the location of the isochronous service octet in the PA slot . As PA slots are periodically generated , an isochronous channel can be supported by a sequence of isochronous service octets specified by (vci , loc) . Each DQDB has a bandwidth manager (BMN) in charge of reservation and release of isochronous channels. We assume that each voice call is supported by a \"path.\" Depending on the caller's and callee's locations in the PCN , a path may be in one of three forms: ffl If the caller and the callee are in the same DQDB , the path consists of only that DQDB. An isochronous channel in that DQDB suffices to support the call. ffl If the caller and the callee are in different DQDBs of the same cluster , a path will be a sequence of adjacent DQDBs (two DQDBs are adjacent if they are connected by a bridge). In this case , setting up the path entails reservation of an", "label": ["routing", "dqdb", "path migration", "isochronous channels", "call setup"], "stemmed_label": ["rout", "dqdb", "path migrat", "isochron channel", "call setup"]}
{"doc": "In this paper we extend our earlier work on supervisory control of nondeterministic systems using prioritized synchronization as the mechanism of control and trajectory model as the modeling formalism by considering design of supervisors under partial observation . We introduce the notion of observation-compatible systems and show that prioritized synchronous composition (PSC) of observation-compatible systems can be used as a mechanism of control of nondeterministic systems under partial observation in presence of driven events . Necessary and sufficient conditions that depend on the trajectory model as opposed to the language model of the plant are obtained for the existence of centralized as well as decentralized supervision . Our work on centralized control shows that the results of the traditional supervisory control can be ``extended\" to the above setting , provided that the supervisor is deterministic and the observation mask is projection type . On the other hand , our work on decentralized control is based on a new relation between controllability , observability , co-observability , and PSC that we derive in this paper . Introduction Supervisory control of discrete event systems (DES's) has been studied using prioritized synchronous composition (PSC) 4 in 5 , 15 , 10 , 11 , 12 , 1 , 3 . In PSC , each system component possesses an event priority set specifying the set of events whose execution in the environment requires its participation . Thus , when many systems are interacting , an event can occur if and only if all the systems having priority over the event can actively participate . In this case , the event occurs synchronously in all such systems; otherwise the event is \\blocked\" from occurring . The systems which do not have priority over the event will also participate in the event execution if they can , which is known as broadcast synchronization; otherwise the event takes place without the participation of such systems . Thus the systems with no priority over an event cannot block its execution . The event control function of Inan 7 assigns state dependent event priority sets , thereby generalizing the notion of PSC . However, when applied to supervisory control , the event control functions are taken to be constant, thus becoming equivalent to PSC . It should be noted that in the PSC formalism each system is associated with an event priority set , and the events that belong to that set is determined by the application . For example in the context of supervisory control this is determined by the controllability/drivability property of the events as explained below. The formalism of PSC , models the interaction between discrete event plants and supervisors quite eectively when all the events are completely observable at their interface , and the need to ensure that interacting systems are control compatible 16 , 17 is eliminated . In this setting the priority set of the plant includes the events that are uncontrollable (such as sensor and failure events) and controllable (such as actuator events) , whereas that of the supervisor includes the events that are", "label": ["observability", "controllability", "discrete event systems", "driven events", "trajectory models", "co-observability", "partial observation", "prioritized synchronization", "supervisory control", "nondeterministic automata"], "stemmed_label": ["observ", "control", "discret event system", "driven event", "trajectori model", "co-observ", "partial observ", "priorit synchron", "supervisori control", "nondeterminist automata"]}
{"doc": "An interior path-following algorithm is proposed for solving the nonlinear saddle point problem $$ \\rm minimax \\ c^Tx+\\ph(x)+b^Ty-\\psi(y)-y^TAx $$ \\vspace* -18pt $$ \\rm subject\\ to\\ (x,y)\\in \\X\\ti \\Y\\su R^n\\ti R^m , $$ \\noindent where $\\ph(x)$ and $\\ps(y)$ are smooth convex functions and $\\X$ and $\\Y$ are boxes (hyperrectangles) . This problem is closely related to the models in stochastic programming and optimal control studied by Rockafellar and Wets (Math . Programming Studies , 28 (1986) , pp . 63--93; SIAM J . Control Optim. , 28 (1990) , pp . 810--822) . Existence and error-bound results on a central path are derived . Starting from an initial solution near the central path with duality gap $O(\\mu)$ , the algorithm finds an $\\ep$-optimal solution of the problem in $O(\\sqrt m+n \\,|\\log\\mu/\\ep|)$ iterations if both $\\ph(x)$ and $\\ps(y)$ satisfy a scaled Lipschitz condition . Introduction This paper discusses an interior path-following method for solving a class of nonlinear saddle point problems in the following form: Find a saddle point for subject to x 2 X ae R n where OE(x) and /(y) are C 2 -convex functions , c 2 R n , b and the superscript T represents transpose . The sets of X and Y are boxes (hyper-rectangles). According to convex analysis 15 , problem (1.1) has a pair of associated optimization problems - the primal problem and the dual problem maximize Note that the function f(x) (called the primal objective function) is convex , the function g(y) (called the dual objective function) is concave , and both are nondifferentiable in general (for a detailed analysis for the case that both OE(x) and /(y) are quadratic, see 16 , where f(x) and g(y) turn out to be \"piecewise quadratic\" convex functions). Therefore , problems (1.1) - (1.3) can be categorized as nonsmooth convex programming problems . Some fundamental duality relationships among (1.1) , (1.2) and (1.3) have been established in 15 , which include existence results on the saddle points of (1.1) and the saddle point value - the common optimal value of (1.2) and (1.3). Problems stem from a development beyond the conventional formulation of optimization problems . These models provide a framework that allows penalty representations of constraints as well as accommodates other sources of nonsmoothness such as objectives produced by multistage optimization problems . For instance , linearly constrained convex optimization problems are usually posed in the form minimize OE(x) subject to Ax - b; x - 0: The corresponding Lagrangian saddle point problem is which is a special case of (1.1) . Now let /(y) be a convex function such that and /(y) - 0 and add \\Gamma/(y) to the lagrangian function . Then the corresponding primal program becomes fy subject to x - 0; where the function sup y-0 fy T (b is equal to zero for x satisfying Ax - b and is greater or equal to zero for all x: Thus in this formulation the exact constraint is replaced by a penalty representation that allows the modeler to deal with more flexibly by selecting suitable", "label": ["optimal control", "nonlinear complementarity problem", "interior point methods", "saddle point problem", "stochastic programming"], "stemmed_label": ["optim control", "nonlinear complementar problem", "interior point method", "saddl point problem", "stochast program"]}
{"doc": "We survey recent developments in high level synthesis technology for VLSI design . The need for higher-level design automation tools are discussed first . We then describe some basic techniques for various subtasks of high-level synthesis . Techniques that have been proposed in the past few years (since 1994) for various subtasks of high-level synthesis are surveyed . We also survey some new synthesis objectives including testability , power efficiency , and reliability . Introduction Very Large Scale Integrated Circuits (VLSI) technology provides densities of multiple- million gates of random logic per chip . Chips of such complexity are very difficult , if not impossible, to design using the traditional capture-and-simulate design methodology . Furthermore , VLSI technology has also reached such a maturity level that it is well understood and no longer provides a competitive edge by itself . Instead , time to market is usually equally , if not more, important than area or speed . The industry has started looking at the product development cycle comprehensively to reduce the design time and to gain a competitive edge in the time- to-market race . Automation of the entire design process from conceptualization to silicon or a describe-and-synthesize design methodology has become necessary 20 . As the complexities of chips increase , so will the need for design automation on higher levels of abstraction where functionality is easier to understand and tradeoff is more influ- ential . There are several advantages to automating part or all of the design process and moving automation to higher levels . First , automation assures a much shorter design cycle. Second , it allows for more exploration of different design styles since different designs can be generated and evaluated quickly . Finally , if synthesis algorithms are well understood, design automation tools may out-perform average human designers in meeting most design constraints and requirements. Synthesis is a translation process from a behavioral description into a structural descrip- tion , similar to the compilation of a high level language program in C or Pascal into an assembly program . Each component in the structural description is in turn defined by its own (lower level) behavioral description . Synthesis , sometimes called design refinement , adds an additional level of detail that provides information needed for the next level of synthesis or for manufacturing of the design . This more detailed design must satisfy design constraints supplied along with the original behavioral description or generated by a previous synthesis step. We define high level synthesis (HLS) as a translation process from a behavioral description into a register-transfer level (RTL) structural description . High level synthesis has been a very hot research topic over the past fifteen years . Comprehensive discussions of specific re-search approaches to HLS can be found in 6 , 20 , 63 , 96 . We concentrate on its development over the past three years. The rest of this paper is organized as follows . Section 2 describes the design flow of VLSI when HLS is used . Section 3 outlines the tasks and", "label": ["vlsi design", "high level synthesis", "design methodology", "design automation"], "stemmed_label": ["vlsi design", "high level synthesi", "design methodolog", "design autom"]}
{"doc": "This paper proposes a complete orthogonal decomposition (COD) algorithm for solving weighted least-squares problems . In applications , the weight matrix can be highly ill conditioned , and this can cause standard methods like QR factorization to return inaccurate answers in floating-point arithmetic . Stewart and Todd independently established a norm bound for the weighted least-squares problem that is independent of the weight matrix . Vavasis proposed a definition of a \"stable\" solution of weighted least squares based on this norm bound: The solution computed by a stable algorithm must satisfy an accuracy bound that is not affected by ill conditioning in the weight matrix . A forward error analysis shows that the COD algorithm is stable in this sense , but it is simpler and more efficient than the algorithm proposed by Vavasis . Our forward error bound is contrasted to the backward error analysis of other previous works on weighted least squares . Introduction We consider solving the problem min for y , where D is a symmetric positive definite m \\Theta m matrix , A is an m \\Theta n matrix , y is an n-vector , and b is an m-vector . An equivalent way to write this problem is \" x y b# which is a special case of an equilibrium system 9 . Applications include optimization involving a barrier function , finite elements , structural analysis , and electrical networks . The following assumptions are made throughout the paper. This work supported by an NSF Presidential Young Investigator grant , with matching funds received from AT&T and Xerox Corp. y Center for Applied Mathematics , Cornell University , Ithaca , New York 14853 z Department of Computer Science , Cornell University , Ithaca , New York 14853. A1 . A has rank n , i.e . full column rank. A2 . D is diagonal. and A2 imply that (1) is a full-rank weighted least-squares problem with a unique solution , and they allow us to use the norm bound obtained by Stewart. That bound is given in the following theorem. Theorem 1 8 Let D denote the set of all positive definite m \\Theta m real diagonal matrices . Let A be an m\\Thetan real matrix of rank n: Then there exist finite constants -A and - -A such that a) A A A A A similar result was obtained independently by Todd 10 . In this theorem , the norm can be any matrix norm induced by a vector norm . In this paper, Similarly , the condition number of a matrix M is the condition number of M in the 2-norm , i.e . We make one more assumption. A3 . D is very ill-conditioned. The ill-conditioning of D arises in certain classes of finite element problems 11 , electrical networks , and it always occurs in the barrier method for optimization 14 . It also indicates that the coefficient matrix of the least-squares problem is ill-conditioned . For this reason , the methods typically used to solve least-squares problems can give highly inaccurate", "label": ["numerical stability", "interior-point methods", "weighted least squares", "equilibrium systems", "qr factorization", "forward error analysis"], "stemmed_label": ["numer stabil", "interior-point method", "weight least squar", "equilibrium system", "qr factor", "forward error analysi"]}
{"doc": "We consider the construction of absorbing boundary layers using asymptotic expansions , the small parameter being the width of the layer . This allows us to define the order of the layer . We compute layers of various orders and analyze their stability properties . Finally , we perform some numerical tests to evaluate the practical utility of our layers . Introduction Classically when one wants to simulate numerically the propagation of waves in an unbounded domain in space , there are (at least) two methods for limiting the computational domain . One is to use absorbing boundary conditions which consist in prescribing boundary conditions specifically derived in order to minimize the artificial reflections inside the computational domain . Such conditions are now very well known and have been studied intensively from the physical , mathematical and numerical point of view in the last 15 years; see for instance 1 , 3 , 4 , 7 , 15 and references therein . A technically simpler and older approach is to use absorbing layers . This is equivalent to surrounding the domain of interest by some geometrical layer where one adds physical attenuation terms to the propagation equations in order to absorb the waves penetrating this region . Of course to get good absorption the thickness of the absorbing layer must be sufficiently large and to avoid increasing too much the size of the computational domain and therefore the computational cost it must be sufficiently small . Moreover , the transition between the propagation medium and the absorbing region should not be too abrupt in order to allow the waves to penetrate the absorbing layer. The design of such absorbing layers being essentially based on physical or engineering considerations , it is not surprising that most of the articles concerning this subject can be found in the physical literature , see for instance 2 , 8 , 9 , 10 and 13 . On the other hand , this domain has not retained too much the attention of the applied mathematicians (perhaps because of the development of the more attractive 1991 Mathematics Subject Classification . primary 65M99 , 35C20 secondary 65M06 , 35L05. Key words and phrases . absorbing layers , absorbing boundary conditions , wave equation. absorbing boundary conditions) . As far as we know , the only paper of a mathematical nature treating the problem is by Israeli and Orszag , 8 , where one can find a complete presentation of absorbing layers in the one dimensional case . However, their article does not really contain a theoretical analysis and in particular it does not address the following question: is it possible to establish a mathematical link between absorbing layers and absorbing boundary conditions? In this paper we intend to develop a tentative answer (or at least an embryo of an answer) for the one dimensional case to begin with . Our objective is to interpret the absorbing boundary condition as a limit case of some absorbing layer when the thickness \" of this layer tends to zero . In fact", "label": ["wave equation", "absorbing layers", "absorbing boundary conditions"], "stemmed_label": ["wave equat", "absorb layer", "absorb boundari condit"]}
{"doc": "We discuss the integration of autonomous Hamiltonian systems via dynamical rescaling of the vector field (reparameterization of time) . Appropriate rescalings (e.g. , based on normalization of the vector field or on minimum particle separation in an N-body problem) do not alter the time-reversal symmetry of the flow , and it is desirable to maintain this symmetry under discretization . For standard form mechanical systems without rescaling , this can be achieved by using the explicit leapfrog--Verlet method; we show that explicit time-reversible integration of the reparameterized equations is also possible if the parameterization depends on positions or velocities only . For general rescalings , a scalar nonlinear equation must be solved at each step , but only one force evaluation is needed . The new method also conserves the angular momentum for an N-body problem . The use of reversible schemes , together with a step control based on normalization of the vector field (arclength reparameterization) , is demonstrated in several numerical experiments , including a double pendulum , the Kepler problem , and a three-body problem . Introduction . In this article we consider the numerical integration of autonomous differential equations in R N d dt such as arise in celestial mechanics 22 , (classical) atomic and molecular dynamics 12 , and in many other important theoretical and practical situations . Direct integration (or simulation) is the principal tool for the study of such problems . Fixed stepsize numerical integration of nonlinear systems (1.1) leads to difficulties , particularly in the neighborhood of singularities of the vector field . This article describes a family of efficient adaptive methods for the numerical solution of initial value problems for equation (1.1) based on normalization of (or other dynamical scaling of) the vector field. Recent research 17 , 14 , 10 has focused on the development of time-stepping schemes that preserve the underlying geometrical structure of the flow of the system (e.g . symplecticness in the case of Hamiltonian systems) . Regardless of whether a scheme faithfully preserves available underlying structure , accurate and stable fixed stepsize numerical integration often requires excessively small timesteps . This is particularly true when integrating in the vicinity of fixed points and singularities . In principle , it is possible to incorporate stepsize variation mechanisms based on local error estimates , but many of the advantages of the structure-preserving schemes appear to be lost if the stepsize is varied using traditional approaches 4 , 3 , 7 . We consider an approach based on introduction of a time reparameterization. Given an appropriate smooth , scalar-valued function for some m;M , we integrate the differential equations d ds ds y Department of Mathematics , the University of Kansas , Lawrence , KS 66045 , U.S.A. (whuang@math.ukans.edu) . Supported in part by NSF EPSCoR grant no . OSR-9255223. z Department of Mathematics , the University of Kansas , Lawrence , KS 66045 , U.S.A. (leimkuhl@math.ukans.edu) . Supported by NSF grant no . NSF-9303223. The behavior of trajectories in extended phase space will be highly sensitive to such reparameterizations ,", "label": ["n-body problems", "variable stepsize methods", "hamiltonian systems", "leapfrog", "verlet", "time-reversible methods", "symplectic methods"], "stemmed_label": ["n-bodi problem", "variabl stepsiz method", "hamiltonian system", "leapfrog", "verlet", "time-revers method", "symplect method"]}
{"doc": "We describe the spectra and pseudospectra of continuous time and discrete time waveform relaxation operators . Since the spectrum of the finite-interval waveform relaxation operator is only a singleton , the spectrum of the infinite-interval operator is typically used to describe the behavior of waveform relaxation algorithms . Here , we show that the pseudospectrum is a more useful tool for analyzing convergence of waveform iterations on finite intervals and prove that the pseudospectrum of the infinite-interval operator is in fact the limit of the pseudospectra of the finite-interval operators . Introduction . The waveform relaxation algorithm is a dynamic iteration method for solving initial boundary-valueproblems , typically in ordinary differential equations or differential-algebraic equations 11 , 23 . Although the method has been widely used for some time, very few rigorous results regarding the convergence of waveform relaxation methods have appeared . This is due , in part , to the fact that practical initial value problems are solved on finite time intervals , where the waveform relaxation operator has a spectrum consisting only of a singleton , f0g . The most detailed analysis of waveform relaxation 14 instead analyzed waveform relaxation applied to initial value problems on the infinite interval , 0; 1) , in which case the spectrum is meaningful for analyzing convergence. The infinite-interval results are typically used with some justification about \"sufficiently long intervals.\" However , the spectrum of the finite interval operator is always a singleton, regardless of the length of the interval so that the limit of the spectrum of the finite-interval operator is not the spectrum of the infinite-interval operator . Yet , in practice , the infinite-interval results often are in fact good predictors of finite-interval behavior. That the spectrum of the finite-interval operator is not a good predictor of the convergence of WR iterations is due to the fact that the waveform relaxation operator on a finite interval is highly non-normal . For non-normal operators , the so-called pseudospectrum has been shown to be a more useful tool than the spectrum for determining the behavior of iterative methods applied to non-normal operators 18 , 19 , 21 . Roughly speaking (and we will be more precise below) , the spectrum of an operator is the region in the complex plane where the norm of the resolvent of an operator is infinite , whereas the pseudospectrum is the region in the complex plane where the norm of the resolvent is large , but not necessarily infinite. In this paper , we use the pseudospectrum to relate the finite-interval behavior of wave-form relaxation to the behavior predicted by the infinite-interval theory . In fact , we show that, although the limit of the spectrum of the finite-interval operator is not the same as the spectrum of the infinite-interval operator , the limit of the pseudospectrum of the finite-interval operators is the same as the spectrum of the infinite-interval operator and that the spectrum and pseu- dospectrum of the infinite interval operator are closely related. The following definitions will be used in the sequel ,", "label": ["dynamic iteration", "pseudospectrum", "waveform relaxation", "spectrum"], "stemmed_label": ["dynam iter", "pseudospectrum", "waveform relax", "spectrum"]}
{"doc": "In this paper , we describe a general approach to scaling data mining applications that we have come to call meta-learning . Meta-Learning refers to a general strategy that seeks to learn how to combine a number of separate learning processes in an intelligent fashion . We desire a meta-learning architecture that exhibits two key behaviors . First , the meta-learning strategy must produce an accurate final classification system . This means that a meta-learning architecture must produce a final outcome that is at least as accurate as a conventional learning algorithm applied to all available data . Second , it must be fast , relative to an individual sequential learning algorithm when applied to massive databases of examples , and operate in a reasonable amount of time . This paper focussed primarily on issues related to the accuracy and efficacy of meta-learning as a general strategy . A number of empirical results are presented demonstrating that meta-learning is technically feasible in wide-area , network computing environments . Introduction Many believe that we are poised once again for a radical shift in the way we learn and work , and in the amount of new knowledge we will acquire . The coming age of high performance network computing , and widely available \"data highways\" will transform the \"information age\" into the \"knowledge age\" by providing new opportunities in defense , commerce , education and science for sharing and utilizing information . However , with this new technological capability comes along a number of hard technical problems , many centered on the issue of scale . It is perhaps obvious that having massive amounts of data and information available anywhere and anytime enables many new opportunities to acquire new knowledge . The field of data mining studies how precisely this will be achieved in an efficient and transparent fashion. One means of acquiring new knowledge from databases is to apply various machine learning algorithms that compute descriptive representations of the data as well as patterns that may be exhibited in the data . The field of machine learning has made substantial progress over the years and a number of algorithms have been popularized and applied to a host of applications in diverse fields . Thus , we may simply apply the current generation of learning algorithms to very large databases and wait for a response! However , the question is how long might we wait? Indeed, do the current generation of machine learning algorithms scale from tasks common today that include thousands of data items to new learning tasks encompassing as much as two orders of magnitude or more of data that is physically distributed? Furthermore , many existing learning algorithms require all the data to be resident in main memory , which is clearly untenable in many realistic databases . In certain cases , data is inherently distributed and cannot be localized on any one machine for a variety of practical reasons . In such situations it is infeasible to inspect all of the data at one processing site to compute one", "label": ["data mining", "scalability", "meta-learning", "machine learning", "classifiers"], "stemmed_label": ["data mine", "scalabl", "meta-learn", "machin learn", "classifi"]}
{"doc": "This paper deals with nondegeneracy of polyhedra and linear programming (LP) problems . We allow for the possibility that the polyhedra and the feasible polyhedra of the LP problems under consideration be non-pointed . polyhedron is pointed if it has a vertex.) With respect to a given polyhedron , we consider two notions of nondegeneracy and then provide several equivalent characterizations for each of them . With respect to LP problems , we study the notion of constant cost nondegeneracy first introduced by Tsuchiya 25 under a different name , namely dual nondegeneracy . (We do not follow this terminology since the term dual nondegeneracy is already used to refer to a related but different type of nondegeneracy.) We show two main results about constant cost nondegeneracy of an LP problem . The first one shows that constant cost nondegeneracy of an LP problem is equivalent to the condition that the union of all minimal faces of the feasible polyhedron be equal to the set of feasible points satisfying a certain generalized strict complementarity condition . When the feasible polyhedron of an LP is nondegenerate , the second result shows that constant cost nondegeneracy is equivalent to the condition that the set of feasible points satisfying the generalized condition be equal to the set of feasible points satisfying the same complementarity condition strictly . For the purpose of giving a preview of the paper , the above results specialized to the context of polyhedra and LP problems in standard form are described in the introduction . Introduction This paper deals with the subject of nondegeneracy of polyhedra and linear programming (LP) problems . Nondegeneracy is a subject worth of intensive investigation due to its application in several branches of mathematical programming and has already been studied in several papers in the literature . These include papers dealing with cycling and termination of the simplex method and with the study of sensitivity and parametric analysis (Adler and Monteiro 1 , Akg-ul 2 , Aucamp and Steinberg 3 , Beale 5 , Bland 6 , Charnes 7 , Dantzig 8 , Gal 10 , 11 , Greenberg 12 , Hoffman 15 , Magnanti and Orlin 16 , Megiddo 17 , Monteiro and Mehrotra 18 , Ward and Wendell 29 , Williams 30 , Wolfe 31 ) , with the convergence of the affine scaling interior point algorithm (Barnes 4 , Dikin 9 , Hall and Vanderbei 14 , Monteiro and Tsuchiya 19 , Monteiro, Tsuchiya and Wang 20 , Tsuchiya 24 , 25 , 26 , Vanderbei et al . 28 , Vanderbei and Lagarias 27 ), and etc . The paper by G-uler et al . 13 surveys the theoretical and practical issues related to degeneracy in the context of interior point methods for linear programming. Recall that the LP problem optimize fc T x A is an m \\Theta n-matrix , is said to be primal nondegenerate if every feasible point x has at least m positive components , and strongly primal nondegenerate if every x 2 IR n satisfying b has", "label": ["linear programming", "nondegeneracy", "polyhedron", "constant cost face", "complementary slackness"], "stemmed_label": ["linear program", "nondegeneraci", "polyhedron", "constant cost face", "complementari slack"]}
{"doc": "We present a new method to represent variable bindings in the Warren Abstract Machine (WAM) , so that the ages of variable bindings can be easily found using this new representation in our intelligent backtracking schema . The age of a variable bound to a non-variable term is the youngest choice point such that backtracking to that choice point can make that variable an unbound variable again . The procedure backtracking point is the choice point of the procedure currently being executed or the choice point of its first ancestor having a choice point . Variable ages and procedure backtracking points are used in the process of figuring out backtracking points in our intelligent backtracking schema . Our intelligent backtracking schema performs much better than the results of other intelligent backtracking methods in the literature for deterministic programs , and its performance for non-deterministic programs are comparable with their results . Introduction The backtracking method used in a standard Prolog implementation is known as naive backtracking . In naive backtracking when a goal fails , backtracking is done to the most recent choice point during that failure (last alternative) , although this choice point may be nothing to do with that failure . In this approach , a lot of unnecessary backtrackings will be done even though the same failure occurs many times . An intelligent backtracking method analyzes the reasons of failures to choose proper choice points to avoid redundant backtrackings . The chosen choice point may not be the most recent choice point during that failure . In other words , the alternatives of choice points between the most recent one and the chosen one are discarded without retrying them . If they are retried , the system will reencounter with that same failure. The Warren Abstract Machine (WAM) is an abstract machine for Prolog execution which consists an instruction set and several data areas on which instructions operate . The WAM is recognized as a breakthrough in the design of Prolog systems and other computational logic systems by the logic programming community . Many commercial 2 , 15 and non-commercial 3 Prolog systems based on the WAM are implemented during the last decade . In this paper , we will assume that the reader is familiar with the WAM . The details of the WAM can be found in Warren's original paper 17 and Kaci's tutorial book on the WAM 1 . Many intelligent backtracking schemes 4 , 5 , 6 , 7 , 9 , 11 , 12 , 13 , 14 , 16 , 19 are presented to avoid unnecessary backtracking steps . Early works in intelligent backtracking 4 , 9 , 14 are implemented as Prolog interpreters . Implementations of later works 6 , 7 , 11 , 12 are WAM based systems. Our intelligent backtracking schema whose some parts are presented in this paper is implemented as an extension of the WAM , like the systems in 6 , 11 . Our mechanism is similar to the mechanisms used in those systems except in the", "label": ["logic proagramming", "prolog", "abstract machine", "intelligent backtracking"], "stemmed_label": ["logic proagram", "prolog", "abstract machin", "intellig backtrack"]}
{"doc": "AbstractWe present a technique for constructing random fields from a set of training samples . The learning paradigm builds increasingly complex fields by allowing potential functions , or features , that are supported by increasingly large subgraphs . Each feature has a weight that is trained by minimizing the Kullback-Leibler divergence between the model and the empirical distribution of the training data . A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights . The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated . Relations to other learning approaches , including decision trees , are given . As a demonstration of the method , we describe its application to the problem of automatic word classification in natural language processing . INTRODUCTION I this paper we present a method for incrementally constructing random fields . Our method builds increasingly complex fields to approximate the empirical distribution of a set of training examples by allowing potential functions , or features , that are supported by increasingly large subgraphs . Each feature is assigned a weight , and the weights are trained to minimize the Kullback-Leibler divergence between the field and the empirical distribution of the training data . Features are incrementally added to the field using a top-down greedy algorithm , with the intent of capturing the salient properties of the empirical sample while allowing generalization to new configurations . The general problem that the methods we propose address is that of discovering the structure inherent in a set of sample patterns . As one of the fundamental aims of statistical inference and learn- ing , this problem is central to a wide range of tasks including classification , compression , and prediction. To illustrate the nature of our approach , suppose we wish to automatically characterize spellings of words according to a statistical model; this is the application we develop in Section 5 . A field with no features is simply a uniform distribution on ASCII strings (where we take the distribution of string lengths as given) . The most conspicuous feature of English spellings is that they are most commonly comprised of lower-case letters . The induction algorithm makes this observation by first constructing the field e where - is an indicator function and the weight - a\\Gammaz associated with the feature that a character is lower-case is chosen to be approximately 1:944 . This means that a string with a lowercase letter in some position is about 7 - e 1:944 times more likely than Stephen and Vincent Della Pietra are with Renaissance Technologies , Stony Brook , NY , 11790 . E-mail: sdella,vdella @rentec.com John Lafferty is with the Computer Science Department of the School of Computer Science , Carnegie Mellon University , Pittsburgh , PA , 15213 . E-mail: lafferty@cs.cmu.edu the", "label": ["clustering", "word morphology", "iterative scaling", "kullback-leibler divergence", "statistical learning", "natural language processing", "em algorithm", "random field", "maximum entropy"], "stemmed_label": ["cluster", "word morpholog", "iter scale", "kullback-leibl diverg", "statist learn", "natur languag process", "em algorithm", "random field", "maximum entropi"]}
{"doc": "AbstractSimilarity measurements between 3D objects and 2D images are useful for the tasks of object recognition and classification . We distinguish between two types of similarity metrics: metrics computed in image-space (image metrics) and metrics computed in transformation-space (transformation metrics) . Existing methods typically use image metrics; namely , metrics that measure the difference in the image between the observed image and the nearest view of the object . Example for such a measure is the Euclidean distance between feature points in the image and their corresponding points in the nearest view . (This measure can be computed by solving the exterior orientation calibration problem.) In this paper we introduce a different type of metrics: transformation metrics . These metrics penalize for the deformations applied to the object to produce the observed image.In particular , we define a transformation metric that optimally penalizes for \"affine deformations\" under weak-perspective . A closed-form solution , together with the nearest view according to this metric , are derived . The metric is shown to be equivalent to the Euclidean image metric , in the sense that they bound each other from both above and below . It therefore provides an easy-to-use closed-form approximation for the commonly-used least-squares distance between models and images . We demonstrate an image understanding application , where the true dimensions of a photographed battery charger are estimated by minimizing the transformation metric . Introduction Object recognition is a process of selecting the object model that best matches the observed image . A common approach to recognition uses features (such as points or edges) to represent objects . An object is recognized in this approach if there exists a viewpoint from which the model features coincide with the corresponding image features , e.g . Roberts , 1965, Fischler and Bolles , 1981 , Lowe , 1985 , Huttenlocher and Ullman , 1987 , Basri and Ullman , 1988, Thompson and Mundy , 1987 , Ullman and Basri , 1991 . Since images often are noisy and models occasionally are imperfect , it is rarely the case that a model aligns perfectly with the image. Systems therefore look for a model that \"reasonably\" aligns with the image . Consequently, measures that assess the quality of a match become necessary. Similarity measures between 3D objects and 2D images are needed for a range of applications ffl The recognition of specific objects in noisy images , as described above. ffl The initial classification of novel objects . In this application a new object is associated to similar objects in the database . This way an image of , e.g. , a Victorian chair is associated with models of (different) familiar chairs. ffl The recognition of non-rigid objects whose geometry is not fully specified . An example is the recognition of 3D hand gestures . In this task only the generic shape of the gesture is known , and the particular instances differ according to the specific physiology of the hand. Existing recognition methods are usually tailored to solve the first of these application , namely,", "label": ["exterior orientation calibration", "object recognition", "affine deformations", "3d-to-2d metric"], "stemmed_label": ["exterior orient calibr", "object recognit", "affin deform", "3d-to-2d metric"]}
{"doc": "We describe efficient algorithms for finding even cycles in undirected graphs . Our main results are the following: (i) For every $k \\geq 2$ , there is an $O(V^2)$ time algorithm that decides whether an undirected graph $G=(V,E)$ contains a simple cycle of length $2k$ , and finds one if it does . (ii) There is an $O(V^2)$ time algorithm that finds a shortest even cycle in an undirected graph $G=(V,E)$ . Introduction Throughout this work , the term cycle refers to a simple closed walk and the term path refers to a simple non-closed walk . An even (odd) cycle is a cycle whose length is even (odd) . An even (odd) path is a path whose length is even (odd). The problem of finding cycles of a given length , and of finding a shortest , a shortest even , and a shortest odd cycle in undirected and directed graphs are among the most basic and natural algorithmic graph problems . These problems were considered by many researchers , see 10 for a survey. In this work we consider (almost exclusively) the undirected versions of these problems . The directed versions of some of them are believed to be much harder . The problem , \"does a given directed graph E) contain a directed cycle of an even length?\" , for example , is not known to be in P, nor is it known to be NP-complete (see 9 ) . Though we do not shed any new light on the directed versions of the problems , we obtain surprisingly fast algorithms for some of the undirected versions. Monien 7 presented an O(VE) algorithm for finding all pairs of vertices that are connected by paths of length is a fixed integer . (Note that if k is part of the input , the problem is NP-Hard) . A simple consequence of his algorithm is an O(VE) algorithm for finding a cycle of length k , if one exists . In 1 , an O(M(V ) log V ) algorithm is obtained for the same problem , where is the complexity of Boolean matrix multiplication . This algorithm is more efficient when G is dense . Both algorithms work on directed as well as undirected graphs . In this work we Work supported in part by THE BASIC RESEARCH FOUNDATION administrated by THE ISRAEL ACADEMY OF SCIENCES AND HUMANITIES . A preliminary version of this paper had appeared in the Proceedings of the 21st International Colloquium on Automata , Languages and Programming , Jerusalem , Israel , 1994 , pages 532-543. y Department of Computer Science , School of Mathematical Sciences , Tel Aviv University , Tel Aviv 69978 , ISRAEL. E-mail addresses of authors: fraphy,zwickg@math.tau.ac.il show that if k is even and if the graph is undirected , then both these bounds can be improved . We obtain an O(V 2 ) algorithm for finding cycles of a given even length in undirected graphs . An O(V 2 ) algorithm for finding quadrilaterals (cycles of length four) is part of", "label": ["graph algorithms", "cycles"], "stemmed_label": ["graph algorithm", "cycl"]}
{"doc": "We present a general theorem that can be used to identify the limiting distribution for a class of combinatorial schemata . For example , many parameters in random mappings can be covered in this way . In particular , we can derive the limiting distribution of those points with a given number of total predecessors . Introduction By a random mapping ' 2 Fn Fn we mean an arbitrary mapping ng ng such that every mapping has equal probability n n . The main purpose of this paper is to obtain limit theorems , when n tends to innity , for special parameters in random mappings , e.g . for the number of image points . Since every random mapping ' 2 Fn has equal probability it suces to count the number of radom mappings ' 2 Fn satisfying a special property , e.g. that the number of image points equals k . By dividing this number by n n we get the probability of interest . In order to get the limit distribution for n !1 it is not necessary to know the exact value . We just have to evaluate these numbers asymptotically . We shalll show that this can be done by a singularity analysis of a proper bivariate generating function. It should be noted that some of our limit distributions on random mappings are well known (compare with 4 , 16 ) . But our main goal is to provide a general method to derive such limit theorems . In particular , we use bivariate generating functions and singuarity analysis . Especially we are able to characterize the (up to now unknown) limit distribution of the number of those points with a xed number of total predecessors . It is a Gaussian distribution. Our basic combinatorial concept is that of labelled combinatorial constructions and the relation to exponential generating functions . A big advantage in such combinatorial constructions is that we can mark a parameter in the constructions which directly leads to bivariate generating function for the number of objects according to their size , and the value of the parameter of interest. Marking in Random Mappings Every mapping ' 2 Fn can be identied with its functional graph G' where ng and E(G' ng . It is obvious that each component of G' consists of a cycle (at least of a loop) and every cyclic point is the root of (labelled) tree . (see Figure 1) Hence we can interprete a mapping ' 2 F as a set of cycles of trees . Further- more , since there is no restriction on their structure , the trees (usually known as Cayley trees) can be recursively described as a root followed by a set of trees: Both structures , F and T , t into the concept of (labelled) combinatorial structures synthetized by Ph . Flajolet 11 (see also 17 ) . Let us give a short description of such structures. Let C be a combinatorial stucture of (labelled) elements , let jcj denote the size of c", "label": ["combinatorial constructions", "random mappings", "limiting distributions"], "stemmed_label": ["combinatori construct", "random map", "limit distribut"]}
{"doc": "AbstractWe define two measures on views: view likelihood and view stability . View likelihood measures the probability that a certain view of a given 3D object is observed; it may be used to identify typical , or \"characteristic,\" views . View stability measures how little the image changes as the viewpoint is slightly perturbed; it may be used to identify \"generic\" views . Both definitions are shown to be identical up to the prior probability of camera orientations , and determined by the 2D metric used to compare images . We analytically derive the stability and likelihood measures for two feature-based 2D metrics , where the most stable and most likely view is shown to be the flattest view of the 3D shape.Incorporating view likelihood or stability in 3D object recognition and 3D reconstruction increases the chance of robust performance . In particular , we propose to use these measures to enhance 3D object recognition and 3D reconstruction algorithms , by adding a second step where the most likely solution is selected among all feasible solutions . These applications are demonstrated using simulated and real images . Introduction In this paper we address in a systematic way the loose notions of \"characteristic\" views and \"generic\" views , by precisely defining and computing view likelihood and view stability . Incorporating these measures in object recognition and 3D reconstruction , we argue , increases the chance of robust and predictable performance . To illustrate this point , we start with an intuitive example: Consider the three images shown in the top row of Fig . 1 . Given three objects in the database (illustrated in the bottom row of Fig . 1): a cube , a flat box and an elongated box , a recognition This research was sponsored by ARPA through the U.S . Office of Naval Research under Grant N00014-93-1-1202, R&T Project Code 4424341-01. system is asked to match an object to each image . The images were produced in such a way that the left image is actually a picture of the cube , the middle image is a picture of the flat box , and the right image is the elongated box . A typical (good) computer vision recognition system would correctly produce this output , shown in Fig . 1 with white arrows . However , a human looking at those images would prefer the following interpretation: left image ) flat box , middle image ) elongated box , and right image ) cube , as shown in Fig . 1 with thin black arrows . Why would humans make this \"mistake\"? The answer seems to be: for a good computational reason! (a) (b) (c) Figure 1: Three polyhedral objects: (a) a cube of dimensions 1 \\Theta 1 \\Theta 1 cm. , (b) a flat box of dimensions 5 \\Theta 5 \\Theta 1 cm. , (c) an elongated box of dimensions 5 \\Theta 1 \\Theta 1 cm . Top: three images of these objects , obtained from special viewpoints; the extracted features are shown with dark circles . Bottom:", "label": ["bayesian vision", "object recognition", "generic views", "characteristic views", "canonical views", "view likelihood", "3d reconstruction", "view stability"], "stemmed_label": ["bayesian vision", "object recognit", "gener view", "characterist view", "canon view", "view likelihood", "3d reconstruct", "view stabil"]}
{"doc": "AbstractThis paper attacks the problem of generalized multisensor mixture estimation . A distribution mixture is said to be generalized when the exact nature of components is not known , but each of them belongs to a finite known set of families of distributions . Estimating such a mixture entails a supplementary difficulty: One must label , for each class and each sensor , the exact nature of the corresponding distribution . Such generalized mixtures have been studied assuming that the components lie in the Pearson system . Adaptations of classical algorithms , such as Expectation-Maximization , Stochastic Expectation-Maximization , or Iterative Conditional Estimation , can then be used to estimate such mixtures in the context of independent identically distributed data and hidden Markov random fields . We propose a more general procedure with applications to estimating generalized multisensor hidden Markov chains . Our proposed method is applied to the problem of unsupervised image segmentation . The method proposed allows one to: (i) identify the conditional distribution for each class and each sensor , (ii) estimate the unknown parameters in this distribution , (iii) estimate priors , and (iv) estimate the \"true\" class image . Introduction Hidden Markov chains are a useful tool for tackling numerous concrete problems , for instance in speech processing 27 , communications 15 , and image processing 1 , 8 , 25 . These all fall in the framework of estimating some discrete phenomenon from observed noisy data . The noise is often modelled as Gaussian , but in many applications, such as radar , sonar , ultrasound , infrared or magnetic resonance images , the noise is not necessarily Gaussian 15 , 18 . Furthermore , for a given sensor and a given class, the nature of the noise distribution can vary with time. For example , the form of the grey level of the sea surface in radar images can vary with the weather 6 . Thus , it may be desirable to determine automatically the correct noise distribution for each class and each sensor at a given time . Early algorithms treating this problem were proposed in 6 and 26 and applied to unsupervised image segmentation . They combine mixture estimation algorithms such as Expectation-Maximization (EM) 7 , 28 , Stochastic Expectation-Maximization (SEM) 20 , 22 , or Iterative Conditional Estimation (ICE) 23 , 24 , with the recognition of the form of a distribution in the Pearson system , assuming that a given sample is generated from a unique distribution. The present paper lies within the scope of this general prob- lem . We first propose a multisensor generalized mixture estimation method based on ICE and valid in a general hidden data context . We then tailor our method to generalized multisensor hidden Markov chain estimation . The effectiveness of the proposed method is validated by simulations The algorithms are then applied to the problem of unsupervised image segmentation . In image segmentation , statistical methods are based on random field models: for the set of pixels S , we consider two sets of", "label": ["mixture estimation", "unsupervised segmentation", "hidden markov chain", "multisensor data", "bayesian segmentation", "generalized mixture estimation"], "stemmed_label": ["mixtur estim", "unsupervis segment", "hidden markov chain", "multisensor data", "bayesian segment", "gener mixtur estim"]}
{"doc": "Computational methods based on the use of adaptively constructed nonuniform meshes reduce the amount of computation and storage necessary to perform many scientific calculations . The adaptive construction of such nonuniform meshes is an important part of these methods . In this paper , we present a parallel algorithm for adaptive mesh refinement that is suitable for implementation on distributed-memory parallel computers . Experimental results obtained on the Intel are presented to demonstrate that for scientific computations involving the finite element method , the algorithm exhibits scalable performance and has a small run time in comparison with other aspects of the scientific computations examined . It is also shown that the algorithm has a fast expected running time under the parallel random access machine (PRAM) computation model . Introduction . Adaptive mesh refinement techniques have been shown to be very successful in reducing the computational and storage requirements for solving many partial differential equations 10 . Rather than use a uniform mesh with grid points evenly spaced on a domain , adaptive mesh refinement techniques place more grid points in areas where the local error in the solution is large . The mesh is adaptively refined and/or unrefined during the computation according to local error estimates on the domain . This technique is much more efficient than the use of uniform meshes when the solution is changing much more rapidly in some areas than in others. The adaptive construction of these nonuniform meshes is a crucial part of adaptive mesh solution methods and has been examined by many researchers , for example , 3 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , and 18 . Typically , one begins with an initial mesh conforming to a particular geometry . This mesh is selectively refined , based on local error estimates , to construct a mesh that satisfies a certain error tolerance . Most research has focused on meshes composed of simplicial ele- ments: line segments in one dimension , triangles in two dimensions , or tetrahedra in three dimensions . This paper focuses primarily on two-dimensional simplicial meshes . However , the algorithms and analyses presented here are applicable to other dimensions and to nonsimplicial meshes. In this paper , we present a new parallel algorithm for the adaptive construction of nonuniform meshes . This algorithm is well suited for implementation on medium-grained distributed-memory parallel computers such as the Intel DELTA. The algorithm is based on the simplicial bisection algorithm given by Rivara 15 . Our algorithm is scalable in that it has an expected run time that is a very slowly growing function of the triangles in the mesh. This work was supported in part by the Office of Scientific Computing , U.S . Department of Energy , under Contract W-31-109-Eng-38. y The address of the first author is Computer Science Department , University of Tennessee, Knoxville , TN 37996 . The address of the second author is Mathematics and Computer Science Division , Argonne National Laboratory , 9700 South Cass Avenue , Argonne", "label": ["parallel algorithms", "distributed memory computers", "unstructured mesh computation", "sparse matrices", "adaptive mesh refinement"], "stemmed_label": ["parallel algorithm", "distribut memori comput", "unstructur mesh comput", "spars matric", "adapt mesh refin"]}
{"doc": "A second-order accurate interface tracking method for the solution of incompressible Stokes flow problems with moving interfaces on a uniform Cartesian grid is presented . The interface may consist of an elastic boundary immersed in the fluid or an interface between two different fluids . The interface is represented by a cubic spline along which the singularly supported elastic or surface tension force can be computed . The Stokes equations are then discretized using the second-order accurate finite difference methods for elliptic equations with singular sources developed in our previous paper SIAM J . Numer . Anal. , 31(1994) , pp . 1019--1044 . The resulting velocities are interpolated to the interface to determine the motion of the interface . An implicit quasi-Newton method is developed that allows reasonable time steps to be used . Introduction . In this paper we develop an interface tracking method for the solution of incompressible Stokes flow problems with moving interfaces on a uniform Cartesian grid . The interface may consist of an elastic boundary immersed in the fluid , as in the model problem of Tu and Peskin 49 , or an interface between two different fluids , as in the study of bubbles or free surfaces. The method we use is based on the Immersed Interface Method (IIM) for elliptic problems developed in our previous paper 22 and the second author's thesis 26 . This is a second order accurate Cartesian grid method for solving elliptic equations whose solutions are not smooth across some interface , due to discontinuous coefficients or singular source terms in the equation . The main idea is to incorporate the known jumps in the solution or its derivatives into the finite difference scheme , obtaining a modified scheme whose solution is second order accurate at all points on the uniform grid even for quite arbitrary interfaces. This approach has also been applied to parabolic equations 28 , 30 and hyperbolic wave equations with discontinuous coefficients 23 , 24 . Similar ideas have been used in the context of domain embedding , where an irregular region is embedded into a larger rectangular domain on which a Cartesian grid is used. Methods of this type include the method of fictitious domains 2 , 8 , 16 , 29 , capacitance matrix methods 9 , 43 , and Mayo's method 32 , 33 . A variety of Cartesian grid methods have been proposed for fluid dynamics problems with arbitrary boundaries and/or moving interfaces , e.g. , 1 , 4 , 11 , 12 , 17 , 21 , 31 , 37 , 44 , 45 , 51 , 50 , 52 and other references below . Such methods are becoming increasingly popular for problems with very complex geometries or moving interfaces where more standard \"body-fitted\" or unstructured grid approaches can run into difficulties. This work was supported in part by NSF Grants DMS-8657319 , DMS-9204329 , DMS-9303404 , DOE Grant DE-FG06-93ER25181 and URI Grant N00014092-J-1890. y Departments of Mathematics and Applied Mathematics , University of Washington , Seattle , WA 98195. (rjl@amath.washington.edu).", "label": ["bubbles", "stokes flow", "discontinuous coefficients", "cartesian grids", "creeping flow", "interface tracking", "immersed interface methods"], "stemmed_label": ["bubbl", "stoke flow", "discontinu coeffici", "cartesian grid", "creep flow", "interfac track", "immers interfac method"]}
{"doc": "A parallel preconditioner is presented for the solution of general sparse linear systems of equations . A sparse approximate inverse is computed explicitly and then applied as a preconditioner to an iterative method . The computation of the preconditioner is inherently parallel , and its application only requires a matrix-vector product . The sparsity pattern of the approximate inverse is not imposed a priori but captured automatically . This keeps the amount of work and the number of nonzero entries in the preconditioner to a minimum . Rigorous bounds on the clustering of the eigenvalues and the singular values are derived for the preconditioned system , and the proximity of the approximate to the true inverse is estimated . An extensive set of test problems from scientific and industrial applications provides convincing evidence of the effectiveness of this approach . Introduction We consider the linear system of equations The work of M . Grote was supported by an IBM fellowship . The work of T . Huckle was supported by a research grant of the Deutsche Forschungsgemeinschaft. y Scientific Computing and Computational Mathematics , Bldg . 460 , Stanford University, Stanford , CA 94305 (grote@sccm.stanford.edu). z Institut f?r Angewandte Mathematik und Statistik , Universit?t W-urzburg , D-97074 W-urzburg , Germany (huckle@vax.rz.uni-wuerzburg.d400.de). Here A is a large , sparse , and nonsymmetric matrix . Due to the size of A, direct solvers become prohibitively expensive because of the amount of work and storage required . As an alternative we consider iterative methods such as gmres , bcg , bi-cgstab , and cg applied to the normal equations 6 . Given the initial guess x 0 , these algorithms compute iteratively new approximations x k to the true solution b . The iterate xm is accepted as a solution if the residual r In general , the convergence is not guaranteed or may be extremely slow . Hence , the original problem (1) must be transformed into a more tractable form . To do so , we consider a preconditioning matrix M , and apply the iterative solver either to the right or to the left preconditioned system Therefore , M should be chosen such that AM (or MA) is a good approximation of the identity . As the ultimate goal is to reduce the total execution time , both the computation of M and the matrix-vector product My should be evaluated in parallel . Since the matrix-vector product must be performed at each iteration , the number of nonzero entries in M should not exceed that in A. The most successful preconditioning methods in terms of reducing the number of iterations , such as incomplete LU factorizations or SSOR , are notoriously difficult to implement on a parallel architecture , especially for unstructured matrices . Indeed , the application of the preconditioner in the iteration phase requires the solution of triangular systems at each step , which is difficult to parallelize because of the recursive nature of the computation (see 2 , section 4.4.4) . Our aim is to find an inherently parallel", "label": ["parallel algorithms", "approximate inverses", "sparse linear systems", "sparse matrices", "iterative methods", "preconditioning"], "stemmed_label": ["parallel algorithm", "approxim invers", "spars linear system", "spars matric", "iter method", "precondit"]}
{"doc": "A concept of generalized discrepancy , which involves pseudodifferential operators to give a criterion of equidistributed pointsets , is developed on the sphere . A simply structured formula in terms of elementary functions is established for the computation of the generalized discrepancy . With the help of this formula five kinds of point systems on the sphere , namely lattices in polar coordinates , transformed two-dimensional sequences , rotations on the sphere , triangulations , and \"sum of three squares sequence,\" are investigated . Quantitative tests are done , and the results are compared with one another . Our calculations exhibit different orders of convergence of the generalized discrepancy for different types of point systems . Introduction Of practical importance is the problem of generating equidistributed pointsets on the sphere . For that reason a concept of generalized discrepancy , which involves pseudodifferential operators to give a quantifying criterion of equidistributed pointsets , is of great interest . In this paper an explicit formula in terms of elementary functions is developed for the generalized discrepancy . Essential tools are Sobolev space structures and pseudodifferential operator techniques . It is mentioned that an optimal pointset may be obtained by minimizing the generalized discrepancy . But , in spite of the elementary representation of the generalized discrepancy , this is a non-linear optimization problem which will not be discussed here . Our investigations , however , show that there are many promising ways to generate point systems on the sphere such that the discrepancy becomes small . To be specific , we distinguish five kinds of point systems on the sphere: lattices in polar coordinates , transformed 2-dimensional sequences , rotations on the sphere , triangulations , and \"sum of three squares sequence\" . By use of our developed formulas , the five classes of point systems are described , and their discrepancies are explicitly calculated for increasing numbers of points . The results show different orders of convergence indicated by the generalized discrepancy . Furthermore , our computations enable us to give a quantitative comparison between the different point systems . It is somehow surprising that certain types of transformed sequences yield the best results. Nevertheless , there are special other pointsets which provide us with better results for comparable numbers of points . For instance , the soccer ball (C us to the best result in all our considered pointsets of about 60 points. The problem of generating a large number of \"equidistributed points\" on the sphere has many applications in various fields of computation , particularly in geoscience , medicine. The advantage of equidistributed point systems lies in the fact that relatively few sampling of the data is needed , and approximate integration can be simply performed by computation of a mean value , i.e. , the arithmetical mean. The outline of the paper is as follows: Section 2 begins with a discussion of Sobolev spaces and (invariant) pseudodifferential operators on the sphere . The generalized discrepancy is developed in Section 3 . The announced point systems are studied in Section", "label": ["low discrepancy quasi-monte-carlo method", "pointsets", "sphere", "approximate integration", "equidistribution", "pseudodifferential operators", "generalized discrepancy"], "stemmed_label": ["low discrep quasi-monte-carlo method", "pointset", "sphere", "approxim integr", "equidistribut", "pseudodifferenti oper", "gener discrep"]}
{"doc": "We consider the problem of ray shooting amidst spheres in 3-space: given n arbitrary (possibly intersecting) spheres in 3-space and any $\\epsilon$ 0 , we show how to preprocess the spheres in time $O(n^ 3+\\epsilon )$ into a data structure of size $O(n^ 3+\\epsilon )$ so that any ray-shooting query can be answered in time $O(n^\\epsilon)$ . Our result improves previous techniques (see P . K . Aggarwal , L . Guibas , M . Pellegrini , and M . Sharir , \"Ray shooting amidst spheres,\" unpublished note and P . K . Aggarwal and J . Matousek , Discrete Comput . Geom. , 11 (1994) , pp . 393-418 ) , where roughly $O(n^4)$ storage was required to support fast queries . Our result shows that ray shooting amidst spheres has complexity comparable with that of ray shooting amidst planes in 3-space . Our technique applies to more general (convex) objects in 3-space , and we also discuss those extensions . Introduction The ray shooting problem can be defined as follows: Given a collection S of n objects in IR d , preprocess S into a data structure , so that one can quickly determine the first object of S intersected by a query ray. The ray shooting problem has received considerable attention in the past few years because of its applications in computer graphics and other geometric problems 1 , 4 , 5 , 6 , 10 , 11 , 13, 16 , 21 . Most of the work to date has studied the planar case , where S is a collection of line segments in IR 2 . Chazelle and Guibas proposed an optimal algorithm for the special case where S is the boundary of a simple polygon 16 . Their algorithm answers a ray shooting query in O(log n) time using O(n) space; simpler algorithms , with the same asymptotic performance bounds , were recently developed in 13 , 24 . If S is a collection of arbitrary segments in the plane , the best known algorithm answers a ray shooting query in time Work on this paper has been supported by NSF Grant CCR-91-22103 , and by grants from the U.S.- Israeli Binational Science Foundation , and the G.I.F. , the German-Israeli Foundation for Scientific Research and Development , and the Fund for Basic Research administered by the Israeli Academy of Sciences . This paper is part of the first author's M.Sc . thesis , prepared under the supervision of the second author. y School of Mathematical Sciences , Tel Aviv University z School of Mathematical Sciences , Tel Aviv University , and Courant Institute of Mathematical Sciences, New York University s log O(1) n) using O(s 1+\" ) space and preprocessing 1 1 , 6 , 10 , where s is a parameter that can vary between n and n 2 . Although no lower bound is known for this case , it is conjectured that this bound is close to optimal. In spite of some recent developments , the three-dimensional ray shooting problem seems much", "label": ["ray shooting", "computational geometry"], "stemmed_label": ["ray shoot", "comput geometri"]}
{"doc": "Let G be an undirected graph with V vertices and E edges . Many algorithms have been developed for enumerating all spanning trees in G . Most of the early algorithms use a technique called \"backtracking.\" Recently , several algorithms using a different technique have been proposed by Kapoor and Ramesh (1992) , Matsui (1993) , and Shioura and Tamura (1993) . They find a new spanning tree by exchanging one edge of a current one . This technique has the merit of enabling us to compress the whole output of all spanning trees by outputting only relative changes of edges . Kapoor and Ramesh first proposed an O(N E)-time algorithm by adopting such a \"compact\" output , where N is the number of spanning trees . Another algorithm with the same time complexity was constructed by Shioura and Tamura . These are optimal in the sense of time complexity but not in terms of space complexity because they take O(VE) space . We refine Shioura and Tamura's algorithm and decrease the space complexity from O(VE) to O(V E) while preserving the time complexity . Therefore , our algorithm is optimal in the sense of both time and space complexities . Introduction . Let G be an undirected graph with V vertices and E edges . A spanning tree of G is defined as a connected subgraph of G which contains all vertices , but no cycle . In this paper we consider the enumeration of all spanning trees in an undirected graph . Many algorithms for solving this problem have been developed , e.g . 7 , 8 , 4 , 5 , 6 , 9 , and these may be divided into several types. 3 Department of Information Sciences , Tokyo Institute of Technology , 2-12-1 Oh-okayama , Meguro-ku, Tokyo 152 , Japan . shioura@is.titech.ac.jp y Department of Computer Science and Information Mathematics , The University of Electro- Communications , 1-5-1 Chofugaoka , Chofu-shi , Tokyo 182 , Japan . tamura@im.uec.ac.jp z Department of Information Sciences , Tokyo Institute of Technology , 2-12-1 Oh-okayama , Meguro-ku, Tokyo 152 , Japan . uno@is.titech.ac.jp The first type 7 , 8 , 4 , to which belong many of the early algorithms use a technique called 'backtracking' . This is a useful technique for listing the kinds of subgraphs , e.g . cycles, paths , and so on . Gabow and Myers 4 refined Minty's algorithm 7 and Read and Tarjan's 8 . Their algorithm uses O(NV +V +E) time and O(V +E) space , where N is the number of all spanning trees . If we enumerate all spanning trees by outputting all edges of each spanning tree , their algorithm is optimal in terms of time and space complexities. Recently , several algorithms 5 , 6 , 9 which use another technique have been developed. These algorithms find a new spanning tree by exchanging one pair of edges , instead of backtracking . Furthermore , if we enumerate all spanning trees by outputting only relative changes of edges between spanning trees", "label": ["spanning trees", "undirected graphs", "optimal algorithm"], "stemmed_label": ["span tree", "undirect graph", "optim algorithm"]}
{"doc": "AbstractIn this paper , we consider a model of lossless image compression in which each band of a multispectral image is coded using a prediction function involving values from a previously coded band of the compression , and examine how the ordering of the bands affects the achievable compression.We present an efficient algorithm for computing the optimal band ordering for a multispectral image . This algorithm has time complexity O(n2) for an n-band image , while the naive algorithm takes time (n!) . A slight variant of the optimal ordering problem that is motivated by some practical concerns is shown to be NP-hard , and hence , computationally infeasible , in all cases except for the most trivial possibility.In addition , we report on our experimental findings using the algorithms designed in this paper applied to real multispectral satellite data . The results show that the techniques described here hold great promise for application to real-world compression needs . Introduction Multispectral satellite images require enormous amounts of space , and with NASA's project EOS (the Earth Observing System) data will be generated at an unprecedented rate . The estimates are that over a terabyte (10 12 bytes) of data will be generated every day by the EOS satellites , most of it multispectral image data . Largely due to this fact , a lot of attention has recently been focussed on compression of multispectral images 1 , 2 , 3 , 4 , 5 . However , most of the compression methods that exploit spectral as well as spatial redundancy have been lossy compression algorithms , and for archival storage and for certain applications it is important to use lossless compression in order to preserve all of the data that is collected . One notable exception to this is the work of Roger and Cavenor 4 who extensively study various prediction and coding methods used for lossless compression of AVIRIS data . Table 1 lists some current , widely used multispectral sources , with their acronyms , full names , and basic properties - it is data from these sensors that we used in this study. In this paper , we study lossless compression of multispectral images . Spectral redundancy is extracted by coding each band of the multispectral image by making use of a second \"prediction band\" . In much the same way that standard single-image lossless compression is separated into the two separate components of prediction and coding , we divide the lossless compression of multispectral images into three components: band ordering , prediction , and coding . The new stage, band ordering , refers to selecting a permutation of the bands in which the bands that are coded first act as good predictors for the later bands in the ordering . The band ordering phase is independent of the other phases of the compressor , and the computational problems associated with this phase are identified and studied in this paper . In particular , given any particular predictor and coder (such as those in this paper or those studied", "label": ["image compression", "multispectral images", "np-completeness", "lossless compression", "compression", "satellite data"], "stemmed_label": ["imag compress", "multispectr imag", "np-complet", "lossless compress", "compress", "satellit data"]}
{"doc": "AbstractIn this paper , we consider a load-balancing process allocation method for fault-tolerant multicomputer systems that balances the load before as well as after faults start to degrade the performance of the system . In order to be able to tolerate a single fault , each process (primary process) is duplicated (i.e. , has a backup process) . The backup process executes on a different processor from the primary , checkpointing the primary process and recovering the process if the primary process fails . In this paper , we formalize the problem of load-balancing process allocation and propose a new process allocation method and analyze the performance of the proposed method . Simulations are used to compare the proposed method with a process allocation method that does not take into account the different load characteristics of the primary and backup processes . While both methods perform well before the occurrence of a fault , only the proposed method maintains a balanced load after the occurrence of such a fault . INTRODUCTION PROCESS allocation in fault-tolerant multicomputer systems has been studied by several researchers 1 , 2 , 3 . Nieuwenhuis 1 studied transformation rules which transform an allocation of non-duplicated processes into an allocation of duplicated processes. The transformed allocation is proven optimal in terms of reliabil- ity . Shatz and Wang 2 proposed a process allocation algorithm which maximizes the reliability of nonhomogeneous systems. Bannister and Trivedi 3 proposed a process allocation algorithm which evenly distributes the load of the system to all nodes . A common assumption of all of the above research works is that each duplicated process is not only a complete replica of the original process , but also has the same execution load as the original . This kind of fault-tolerant process is called an active process replica 4 . The fault-tolerant computing process model considered in this paper is the primary-backup process model , which is commonly used in distributed experimental and commercial systems such as Delta-4 and Tandem 5 , 6 , 7 . In this model , there is a backup copy for each process in the system . However , only one process in a pair is running actively at any one time . The active process is called the primary process and the nonactive process is called the backup (or secondary) process . The active process regularly checkpoints its running state to the backup process . During normal operation , the nonactive backup process is either waiting for a checkpointing message or saving a received checkpointing mes- sage . When the node in which the primary process is running becomes faulty , the backup process takes over the role of the primary process . Thus , in order to be able to tolerate faults , primary and backup processes should not be executed on the same node . This kind of fault-tolerant process is called a passive process replica 6 . The difference between the computing model considered here and the models considered in other research is in the role of", "label": ["fault-tolerant multicomputer", "checkpointing", "backup process", "load balancing", "process allocation"], "stemmed_label": ["fault-toler multicomput", "checkpoint", "backup process", "load balanc", "process alloc"]}
{"doc": "The 3-D motion of a camera within a static environment produces a sequence of time-varying images that can be used for reconstructing the relative motion between the scene and the viewer . The problem of reconstructing rigid motion from a sequence of perspective images may be characterized as the estimation of the state of a nonlinear dynamical system , which is defined by the rigidity constraint and the perspective measurement map . The time-derivative of the measured output of such a system , which is called the 2-D motion field and is approximated by the optical flow , is bilinear in the motion parameters , and may be used to specify a subspace constraint on the direction of heading independent of rotation and depth , and a pseudo-measurement for the rotational velocity as a function of the estimated heading . The subspace constraint may be viewed as an implicit dynamical model with parameters on a differentiable manifold , and the visual motion estimation problem may be cast in a system-theoretic framework as the identification of such an implicit model . We use techniques which pertain to nonlinear estimation and identification theory to recursively estimate 3-D rigid motion from a sequence of images independent of the structure of the scene . Such independence from scene-structure allows us to deal with a variable number of visible feature-points and occlusions in a principled way . The further decoupling of the direction of heading from the rotational velocity generates a filter with a state that belongs to a two-dimensional and highly constrained state-space . As a result , the filter exhibits robustness properties which are highlighted in a series of experiments on real and noisy synthetic image sequences . While the position of feature-points is not part of the state of the model , the innovation process of the filter describes how each feature is compatible with a rigid motion interpretation , which allows us to test for outliers and makes the filter robust with respect to errors in the feature tracking/optical flow , reflections , T-junctions . Once motion has been estimated , the 3-D structure of the scene follows easily . By releasing the constraint that the visible points lie in front of the viewer , one may explain some psychophysical effects on the nonrigid percept of rigidly moving objects . Introduction When a camera moves within a static environment , the stream of images coming out of the sensor contains enough information for reconstructing the relative motion between the camera and the scene . \"Visual motion estimation\" is one of the oldest 10 , 31 and at the same time one of the most crucial and challenging problems in computer vision . Even in the simplest cases , when the scene is represented as a rigid set of feature-points in 3-D space viewed under perspective projection , most of the early algorithms based upon the analysis of two frames at a time are not robust enough to be employed in real-world situations . Multi-frame analysis may be performed either in \"batch\" or recursively", "label": ["implicit extended kalman filter", "dynamic vision", "recursive rigid motion estimation", "nonlinear identification"], "stemmed_label": ["implicit extend kalman filter", "dynam vision", "recurs rigid motion estim", "nonlinear identif"]}
{"doc": "AbstractACL2 is a reimplemented extended version of Boyer and Moore's Nqthm and Kaufmann's Pc-Nqthm , intended for large scale verification projects . This paper deals primarily with how we scaled up Nqthm's logic to an \"industrial strength\" programming languagenamely , a large applicative subset of Common Lispwhile preserving the use of total functions within the logic . This makes it possible to run formal models efficiently while keeping the logic simple . We enumerate many other important features of ACL2 and we briefly summarize two industrial applications: a model of the Motorola CAP digital signal processing chip and the proof of the correctness of the kernel of the floating point division algorithm on the AMD5K86 microprocessor by Advanced Micro Devices , Inc . Introduction FORMAL VERIFICATION is the use of mathematical techniques to verify properties of a system description . A The work reported here was performed while the authors were employed at Computational Logic , Inc. y Matt Kaufmann is with Motorola @ Lakewood , P.O . Box 6000 , MD F52 , Austin, z J Moore is with the Department of Computer Sciences , University of Texas at Austin , Austin, received Oct . 25 , 1996; revised Mar . 31 , 1997 Recommended for acceptance by C . Heitmeyer and S.R . Faulk For information on obtaining reprints of this article , please send e-mail to: transse@computer.org , and reference IEEECS Log Number 104892.0 particular style of formal verification that has shown considerable promise in recent years is the use of general-purpose automated reasoning systems to model systems and prove properties of them . Every such reasoning system requires considerable assistance from the user , which makes it important that the system provide convenient ways for the user to interact with it. One state-of-the-art general-purpose automated reasoning system is ACL2: \"A Computational Logic for Applicative Common Lisp.\" A number of automated reasoning systems now exist , as we discuss below (Subsection 1.1) . In this paper we describe ACL2's offerings to the user for convenient \"industrial-strength\" use . We begin in Section 2 with a history of the ACL2 project . Next , Section 3 describes the logic supported by ACL2 , which has been designed for convenient specification and verification . Section 4 discusses guards , which connect ACL2 to efficient execution in Common Lisp and provide a powerful specification capability. We illustration the role of guards in Section 5 . In Section 6 we discuss other important features of ACL2 . In Section 7 we present two industrial applications . We conclude with Section 8. 1.1 . Brief Comparison with Other Theorem Provers As we mentioned above , there are many other automated reasoning systems besides ACL2 and its ancestors . Although it is beyond the scope of this paper to survey the field or provide descriptions of other systems , we say a few words here in order to provide some context for our work. Active research continues in automated reasoning in a number of areas . Here is an incomplete list . In each case", "label": ["automatic theorem proving", "formal verification", "partial functions", "computational logic", "total functions", "floating point division", "type checking", "digital signal processing", "microcode verification"], "stemmed_label": ["automat theorem prove", "formal verif", "partial function", "comput logic", "total function", "float point divis", "type check", "digit signal process", "microcod verif"]}
{"doc": "This paper addresses the problems of detecting Hopf bifurcations in systems of ordinary differential equations and following curves of Hopf points in two-parameter families of vector fields . The established approach to this problem relies upon augmenting the equilibrium condition so that a Hopf bifurcation occurs at an isolated , regular point of the extended system . We propose two new methods of this type based on classical algebraic results regarding the roots of polynomial equations and properties of Kronecker products for matrices . In addition to their utility as augmented systems for use with standard Newton-type continuation methods , they are also particularly well adapted for solution by computer algebra techniques for vector fields of small or moderate dimension . Introduction . Consider the n-dimensional system of ordinary differential equations defined by (1) is a C 2 \\Gammasmooth function , defined on a subset U ae IR n , which depends upon a vector of parameters , ff 2 IR k . An equilibrium of this system is a point x 2 IR n with the property that f(x; As the parameters ff are varied , equilibrium points can undergo bifurcation . There are two types of elementary bifurcations that occur in generic one-parameter families of systems: saddle nodes and Hopf bifurcations . At a saddle-node bifurcation , the Jacobian derivative evaluated at an equilibrium point possesses a simple zero eigenvalue . Similarly , a necessary condition for Hopf bifurcation is the presence of a pure imaginary eigenvalue pair in the spectrum of D x f . One would like robust algorithms for the calculation of parameter values where one of these bifurcations occurs in parametrized families of vector fields . In the case of saddle node bifurcations , one may obtain the bifurcation locus by augmenting the equation f(x; with a procedure to calculate equilibrium points where D x f has numerical rank (n \\Gamma 1) . An inflated system for the detection of saddle nodes has been previously proposed using det(D x f) as the augmenting equation 1 , 28 . To treat Hopf bifurcations in a similar manner , one requires explicit equations that determine whether the n-square matrix D x f has a pair of pure imaginary eigenvalues . This paper examines procedures for locating Hopf bifurcations based on the singularity of matrices obtained from algebraic transformations of the Jacobian matrix at an equilibrium. Previous investigators have proposed a variety of approaches to the determination of Hopf bifurcation points , which may be divided into two broad classes . A typical indirect method employs a numerical algorithm for computing the spectrum of the Jacobian at each point along a path of equilibria and then interpolating to locate parameter values at which a pair of eigenvalues cross the imaginary axis . For vector fields of small dimension , the unsymmetric QR factorization algorithm is widely ad- vocated , while for larger problems Krylov subspace techniques are fast and provide Mathematics Department and Center for Applied Mathematics , Cornell University y Center for Applied Mathematics , Cornell University z", "label": ["bialternate product", "hopf bifurcation", "resultant"], "stemmed_label": ["bialtern product", "hopf bifurc", "result"]}
{"doc": "The purpose of this paper is to develop a convergence theory for multigrid methods applied to nearly singular linear elliptic partial differential equations of the type produced from a positive definite system by a shift with the identity . One of the important aspects of this theory is that it allows such shifts to vary anywhere in the multigrid scheme , enabling its application to a wider class of eigenproblem solvers . The theory is first applied to a method for computing eigenvalues and eigenvectors that consists of multigrid iterations with zero right-hand side and updating the shift from the Rayleigh quotient before every cycle . It is then applied to the Rayleigh quotient multigrid (RQMG) method , which is a more direct multigrid procedure for solving eigenproblems . Local convergence of the multigrid V-cycle and global convergence for a full multigrid version of both methods is obtained . Introduction . In this paper , we consider the solution of the generalized eigenvalue problem based in an abstract finite-dimensional Hilbert space V with inner product (\\Delta; \\Delta): Find - 2 R and 0 6= such that Here , A and B are linear continuous symmetric operators defined on V , A is positive definite , and B is positive semidefinite. We will consider two multigrid approaches for finding the smallest eigenvalue for (1.1) based on a sequence of subspaces . One uses multigrid as an inner loop solver for an outer loop inverse iteration type process , which has been studied by many authors (cf . the early work in 1 and 7 ) . The other is the Rayleigh quotient multigrid method (RQMG 5 , 8 ) , which is a more direct approach based on minimizing the Rayleigh quotient at each stage of the multigrid processing . We will analyze convergence of these two multigrid methods by developing and applying a general convergence theory for singular or nearly singular linear problems: Given f 2 V and a scalar - 2 R , find such that Previous convergence results for multigrid algorithms applied to (1.2) were obtained by Bank 1 . In order to establish norm estimates for the rate of convergence, the shift - was assumed to be bounded away from the smallest eigenvalue of (1.1) in Department of Mathematics , University of Southern California , Los Angeles , CA 90089-1113. y Center for Computational Mathematics , University of Colorado at Denver , Denver , CO 80217- 3364 . Supported by the National Science Foundation under grant number ASC-9121431. z Program in Applied Mathematics , University of Colorado at Boulder , Boulder , CO 80309-0526. Supported by the Air Force Office of Scientific Research under grant number AFOSR-91-0156 and by the National Science Foundation under grant number DMS-8704169 1 . In contrast , our analysis is based on an error decomposition into the eigenspace associated with the smallest eigenvalue of (1.1) and its orthogonal complement . We will not attempt to solve (1.2) in the usual sense; instead , our aim is to preserve the approximate magnitude of the components", "label": ["singular equations", "rayleigh quotient", "multigrid", "eigenvalue problem"], "stemmed_label": ["singular equat", "rayleigh quotient", "multigrid", "eigenvalu problem"]}
{"doc": "We present algorithms for exactly learning unknown environments that can be described by deterministic finite automata . The learner performs a walk on the target automaton , where at each step it observes the output of the state it is at , and chooses a labeled edge to traverse to the next state . The learner has no means of a reset , and does not have access to a teacher that answers equivalence queries and gives the learner counterexamples to its hypotheses . We present two algorithms: The first is for the case in which the outputs observed by the learner are always correct , and the second is for the case in which the outputs might be corrupted by random noise . The running times of both algorithms are polynomial in the cover time of the underlying graph of the target automaton . Introduction In this paper we study the problem of actively learning an environment which is described by a deterministic finite state automaton (DFA) . The learner can be viewed as a robot performing a walk on the target automaton M , beginning at the start state of M . At each step it observes the output of the state it is at , and chooses a labeled edge to traverse to the next state . The learner does not have a means of a reset (returning to the start state of M ) . In particular , we investigate exact learning algorithms which do not have access to a teacher that can answer equivalence queries and give the learner counterexamples to its hypotheses . We also study the case in which the environment is noisy , in the sense that there is some fixed probability j that the learner observes an incorrect output of the state it is at. Angluin 2 has shown that the general problem of exactly learning finite automata by performing a walk on the target automaton , but without access to an equivalence oracle , is hard in the information theoretic sense (even when the learner has means of a reset) . This is due to the existence of a subclass of automata , which are often referred to as combination-lock automata 1 . The central property of combination lock automata which is used in Angluin's hardness result is that they have hard-to-reach states: In particular , there is a single accepting state which is reachable only when the learner performs a particular walk of length n (called the \"combination\") , where n is the number of states in the automaton . All other walks result in an all zero sequence of outputs. Therefore , for every exact learning algorithm , there will be some combination lock automaton on which the algorithm requires exponential time (if the algorithm is randomized then it will require exponential expected time). Thus , a natural question that arises is whether exact learning of automata remains hard when we assume the underlying graph of the target automaton has certain combinatorial properties such as small cover time . The", "label": ["learning automata", "learning with noise", "exact learning"], "stemmed_label": ["learn automata", "learn with nois", "exact learn"]}
{"doc": "Pre-pruning and Post-pruning are two standard techniques for handling noise in decision tree learning . Pre-pruning deals with noise during learning , while post-pruning addresses this problem after an overfitting theory has been learned . We first review several adaptations of pre- and post-pruning techniques for separate-and-conquer rule learning algorithms and discuss some fundamental problems . The primary goal of this paper is to show how to solve these problems with two new algorithms that combine and integrate pre- and post-pruning . Introduction Separate-and-conquer rule-learning systems have gained in popularity through the recent success of the Inductive Logic Programming algorithm Foil (Quinlan 1990) . We will analyze different pruning methods for this type of inductive rule learning algorithm and discuss some of their problems . The main contribution of this paper are two new algorithms: Top-Down Pruning (TDP) , an approach that combines pre- and post-pruning , and Incremental Reduced Pruning (I-REP) , a very efficient integration of pre-and post-pruning. . Pre-Pruning Decisions Combining Pre- and Post-Pruning Integrating Pre- and Post-Pruning Post-Pruning Pre-Pruning . Literals . Post-Pruning Decisions Figure 1: Pruning methods for separate-and-conquer rule learning algorithms. Pruning is the common framework for avoiding the problem of overfitting noisy data . The basic idea is to incorporate a bias towards more general and simpler theories in order to avoid overly specific theories that try to find explanations for noisy examples. Pre-pruning methods deal with noise during learning . Instead of trying to find a theory that is complete and consistent with the given training data , heuristics - so-called stopping criteria - are used to relax this constraint by stopping the learning process although some positive examples may not yet be explained and some of the negative examples may still be covered by the current theory . The final theory is learned in one pass (see figure 1) . Most separate-and-conquer rule learners , like CN2 (Clark and Niblett 1989) , Foil (Quinlan 1990), and Fossil (Furnkranz 1994) , use this form of noise handling. Another family of algorithms deals with noise after learning . These post-pruning algorithms typically first induce a theory that is complete and consistent with the training data. Then this theory is examined and those rules and conditions are discarded that seem to explain only characteristics of the particular training set and thus do not reflect true regularities of the domain . Figure 1 shows a schematic depiction of this process . The quality of the found rules and conditions is commonly evaluated on a separate set of training examples that have not been seen during learning . Post-pruning algorithms include Reduced Error Pruning (REP) (Brunk and Pazzani 1991) and Grow (Cohen 1993) . Both have been shown to be very effective in noise-handling . However , they are also inefficient , because they waste time by learning an overfitting concept description and subsequently pruning a significant portion of its rules and conditions. One remedy for this problem is to combine pre- and post-pruning . For this purpose pre-pruning heuristics are used to reduce (not entirely prevent) the", "label": ["inductive rule learning", "inductive logic programming", "noise handling", "pruning"], "stemmed_label": ["induct rule learn", "induct logic program", "nois handl", "prune"]}
{"doc": "AbstractThis paper describes algorithms for scheduling preemptive , imprecise , composite tasks in real-time . Each composite task consists of a chain of component tasks , and each component task is made up of a mandatory part and an optional part . Whenever a component task uses imprecise input , the processing times of its mandatory and optional parts may become larger . The composite tasks are scheduled by a two-level scheduler . At the high level , the composite tasks are scheduled preemptively on one processor , according to an existing algorithm for scheduling simple imprecise tasks . The low-level scheduler then distributes the time budgeted for each composite task across its component tasks so as to minimize the output error of the composite task INTRODUCTION HARD real-time system contains tasks which must produce logically correct results within certain timing constraints . In a system where the processing times of tasks transient overloads may be unavoidable . A hard real-time system must remain robust and maintain an acceptable level of performance under a transient overload . The imprecise-computation technique 1 , 2 , 3 , 4 , 5 was introduced as a way to deal with transient overloads . The technique is motivated by the fact that one can often trade off precision for timeliness . It prevents missed deadlines and provides graceful degradation during a transient overload by ensuring that an approximate result of acceptable quality is available whenever the exact result cannot be obtained in time. The imprecise-computation model used in previous studies 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 assumes that the quality of a task's result depends solely on the time spent by the task to produce the result. Specifically , the input of each task is free of error . If a task terminates prematurely , the result produced by it contains an error that is a nondecreasing function of the processing time of the unexecuted portion . While this model adequately characterizes many real-time applications , there are several others that it does not . Examples include video compression , speech recognition , and radar tracking . In these applications , the quality of a result produced by a task depends also on the quality of the input of the task. When the results produced by some tasks are used as inputs by other tasks , the decision on how much of each task to complete by what time in order for the set of dependent tasks to produce a good overall result should not be made by considering each task independently from the others. In addition , previous studies on imprecise computation focus on the case where the timing constraints of each task are given . However , the timing constraints that can be derived directly from high-level requirements are typically not that of individual tasks , but rather are timing constraints of sets of tasks . We call such timing constraints end- to-end timing constraints", "label": ["real-time systems and applications", "imprecise computation", "end-to-end timing constraints", "scheduling", "error"], "stemmed_label": ["real-tim system and applic", "imprecis comput", "end-to-end time constraint", "schedul", "error"]}
{"doc": "AbstractAtomic actions are an important dynamic structuring technique that aid the construction of fault-tolerant concurrent systems . Although they were developed some years ago , none of the well-known commercially-available programming languages directly support their use . This paper summarizes software fault tolerance techniques for concurrent systems , evaluates the Ada 95 programming language from the perspective of its support for software fault tolerance , and shows how Ada 95 can be used to implement software fault tolerance techniques . In particular , it shows how packages , protected objects , requeue , exceptions , asynchronous transfer of control , tagged types , and controlled types can be used as building blocks from which to construct atomic actions with forward and backward error recovery , which are resilient to deserter tasks and task abortion . Introduction Software fault tolerance is often classified according to whether it is static (mask- ing) or dynamic . With static redundancy , several versions of a software component are written and each version executes in response to all requests; voting is performed on the output to determine which result to use . It is static because each version of the software has a fixed relationship with every other version , and the voter; and because it operates whether or not faults have occurred . With dynamic redundancy , the redundant components only come into operation when an error has been detected. Dynamic fault tolerance has four constituent phases (Anderson and Lee, 1990). 1 . detection - Faults of significance will eventually manifest themselves in the form of an error; no fault tolerance scheme can be utilised until that error is detected. 2 . Damage confinement and assessment - When an error has been detected, a decision must be made on the extent to which the system has been corrupted; the delay between a fault occurring and the manifestation of the associated error means that erroneous information could have spread throughout the system. 3 . recovery - Error recovery techniques aim to transform the corrupted system into a state from which it can continue its normal operation (perhaps with degraded functionality). 4 . Fault treatment and continued service - An error is a symptom of a fault; although the damage may have been repaired , the fault may still exist and , therefore , the error may recur unless some form of maintenance is undertaken. This paper is primarily concerned with dynamic redundancy techniques and, in particular , damage confinement and error recovery . For sequential systems, damage confinement is well understood; techniques such as modular programming and object-oriented encapsulation (within the context of a strongly-typed programming language) enable faults to be confined . Judicious placement of acceptance tests or assertions allow errors to be detected before damage can be propagate . Similarly , techniques such as exception handling(Goodenough , 1975) (forward error recovery) and recovery blocks(Horning et al. , 1974) (backward error recover) allow error recovery to be performed according to whether the fault was anticipated or not. For concurrent systems , the position is not so", "label": ["exception handling", "atomic actions", "software fault tolerance", "conversations", "ada 95", "recovery blocks"], "stemmed_label": ["except handl", "atom action", "softwar fault toler", "convers", "ada 95", "recoveri block"]}
{"doc": "Combining different machine learning algorithms in the same system can produce benefits above and beyond what either method could achieve alone . This paper demonstrates that genetic algorithms can be used in conjunction with lazy learning to solve examples of a difficult class of delayed reinforcement learning problems better than either method alone . This class , the class of differential games , includes numerous important control problems that arise in robotics , planning , game playing , and other areas , and solutions for differential games suggest solution strategies for the general class of planning and control problems . We conducted a series of experiments applying three learning approaches lazy Q-learning , k-nearest neighbor (k-NN) , and a genetic algorithm to a particular differential game called a pursuit game . Our experiments demonstrate that k-NN had great difficulty solving the problem , while a lazy version of Q-learning performed moderately well and the genetic algorithm performed even better . These results motivated the next step in the experiments , where we hypothesized k-NN was having difficulty because it did not have good examples a common source of difficulty for lazy learning . Therefore , we used the genetic algorithm as a bootstrapping method for k-NN to create a system to provide these examples . Our experiments demonstrate that the resulting joint system learned to solve the pursuit games with a high degree of accuracy outperforming either method alone and with relatively small memory requirements . Introduction When two people learn a task together , they can both benefit from the different skills that each brings to the table . The result is that both will learn better than they would have on their own . Likewise , machine learning methods should be able to work together to learn how to solve difficult problems . This paper describes how a lazy learning algorithm and a genetic algorithm can work together to produce better solutions than either method could produce by itself. To explore our hypothesis that two learning algorithms can work together to outperform either individually , we focused on a particular problem in which an agent must perform a task , and the task requires several steps to accomplish . We limit feedback on how well the agent is performing to the end of the task . Several learning algorithms have been applied to this family of problems , called delayed reinforcement problems (Widrow , 1987; Atkeson, 1990; Watkins , 1989; Barto , Sutton , & Watkins , 1990; Millan & Torras , 1992; Moore & Atkeson , 1993) , but little has been done to evaluate the power of combining different types of learning algorithms to these problems. One way of characterizing these delayed reinforcement problems is as learning to solve a Markov decision problem (van der Wal , 1981) . Markov decision problems are those in which an agent develops a mapping from a set of states to a set of actions , possibly different ones for each state , and the optimal strategy from a given state depends", "label": ["reinforcement learning", "differential games", "lazy learning", "pursuit games", "nearest neighbor", "genetic algorithms", "teaching"], "stemmed_label": ["reinforc learn", "differenti game", "lazi learn", "pursuit game", "nearest neighbor", "genet algorithm", "teach"]}
{"doc": "Generalizing the two-commodity flow theorem of Rothschild and Whinston Oper . Res. , 14 (1966) , pp . 377--387 and the multiflow theorem of Lovsz Acta Mat . Akad . Sci . Hungaricae , 28 (1976) , pp . 129--138 and Cherkasky Ekonom.-Mat . Metody , 13 (1977) , pp . 143--151 , Karzanov and Lomonosov Mathematical Programming , O . I . Larichev , ed. , Institute for System Studies , 1978 , pp . 59--66 in 1978 proved a min-max theorem on maximum multiflows . Their original proof is quite long and technical and relies on earlier investigations into metrics . The main purpose of the present paper is to provide a relatively simple proof of this theorem . Our proof relies on the locking theorem , which is another result of Karzanov and Lomonosov , and the polymatroid intersection theorem of Edmonds Combinatorial Structures and Their Applications , R . Guy , H . Hanani , N . Sauer , and J . Schnheim , eds. , Gordon and Breach , 1970 , pp . 69--87 . For completeness , we also provide a simplified proof of the locking theorem . Finally , we introduce the notion of a node demand problem and , as another application of the locking theorem , we derive a feasibility theorem concerning it.The presented approach gives rise to (combinatorial) polynomial-time algorithms . INTRODUCTION E) and be two undirected graphs so that T ' V . We call a path of G H- admissible if it connects two nodes x; y of T so that xy 2 F . G will be called a supply graph , H a demand graph and the elements of T terminals while the other elements of V are called inner nodes. The maximization problem consists of finding a maximum number of edge-disjoint H-admissible paths. If H consists of one edge , then Menger's theorem gives an answer. In general , the problem is NP-complete even in the special case when G is Eulerian . graph is called Eulerian if the degree of every node is even.) There are , however , important special cases when the problem is tractable . Rothschild and Whinston 1966 proved a max-flow min-cut type theorem when (G; T ) is inner Eulerian and H consists of two edges . (We say that the pair (G; T ) is inner Eulerian if the degree d(v) is even for every inner node v) . Another result is due , independently , to L . Lov'asz 1976 and B.V . Cherkasskij 1977 . They solve the maximization problem when H is a complete graph and G is inner Eulerian . In 1978 A.V . Karzanov and M.V . Lomonosov found a common generalization of these two theorems . Their original proof is rather lengthy and technical and it is certainly much more difficult than those of the two special cases mentioned above . Details of these proofs were described in Karzanov , 1979 and Lomonosov , 1985 . Later Karzanov ( 1985 and 1987 ) exhibited", "label": ["multiflow", "locking", "network flows", "node demands", "polymatroid"], "stemmed_label": ["multiflow", "lock", "network flow", "node demand", "polymatroid"]}
{"doc": "An explicit finite element method is used to solve the linear convection--diffusion-reaction equations governing contaminant transport in ground water flowing through an adsorbing porous medium . The use of discontinuous finite elements for the convective part of the equations combined with mixed finite elements for the diffusive part renders the method for the concentration solution , which displays strong gradients , trivially conservative and fully parallelizable . We carry out a stability and convergence analysis . In particular , the method is proven to satisfy a maximum principle , to be total variation bounded , and to converge to the unique weak solution of the equations . Special attention is paid to the convective part of the equations . Numerical simulations are presented and discussed . Introduction . In this paper we propose and analyze a finite element method for solving the linear convection-diffusion-reaction equation: @t which describes the transport of a solute in a fluid phase flowing through a porous medium 1 , 16 . In this case , is the concentration of the solute in the fluid phase for which we solve (1.1) , is the Darcy velocity of fluid , \\Phi is the volume fraction-dependent constant , D is the diffusion constant , and is the first-order chemical reaction rate . This equation , while formally parabolic , is more nearly hyperbolic in practice 4 . In recent years many finite element methods have been proposed to solve this important partial differential equation . The classes of optimal spatial methods and characteristic methods have been extensively studied 2 , 9 , 15 , 17 , 18 , for example . However , all these finite element methods are defined by taking advantage of the parabolicity of the equation for the concentration u . As a result , the solution of the differential equation is required very smooth in the derivation of error estimates , and the constants for the error estimates blow up as the coefficient of the diffusion term goes to zero. In this paper we propose and analyze a finite element method for numerically solving (1.1) . It is similar to a finite element method introduced in 5 , 3 , 6 , 10 , 11 in that we approximate the convective part of the equation using a upwinding discontinuous finite element method or a upwinding finite volume method 20 , 19 . We use , however , a mixed finite element method for the diffusive part of (1.1) 8 . The main advantages of this method are that it is trivially conservative and fully parallelizable , and that it can capture discontinuities within a couple of elements without producing spurious oscillations. * Department of Mathematics and the Institute for Scientific Computation , Texas A&M Univer- sity , College Station , Current address of Z . Chen: Department of Mathematics , Box 156, Dedman College , Southern Methodist University , Dallas , Texas 75275-0156 . Partly supported by the Department of Energy under contract DE-ACOS-840R21400 . email: zchen@golem.math.smu.edu, ewing@ewing.tamu.edu. A stability and convergence analysis is carried out", "label": ["conservation law", "finite element and volume method", "convergence", "mixed method", "convection-diffusion-reaction equation", "stability"], "stemmed_label": ["conserv law", "finit element and volum method", "converg", "mix method", "convection-diffusion-react equat", "stabil"]}
{"doc": "The role of the interval subdivision-selection rule is investigated in branch-and-bound algorithms for global optimization . The class of rules that allows convergence for the model algorithm is characterized , and it is shown that the four rules investigated satisfy the conditions of convergence . A numerical study with a wide spectrum of test problems indicates that there are substantial differences between the rules in terms of the required CPU time , the number of function and derivative evaluations , and space complexity , and two rules can provide substantial improvements in efficiency . Introduction . Interval subdivision methods for global optimization 7 , 21 aim at providing reliable solutions to global optimization problems min (1) where the objective function f : continuously differentiable , and X ' IR n is an n-dimensional interval . In many cases , only the globally optimal solutions are acceptable 4 , 22 , and the local minima are less important . No special problem structure is required: only inclusion functions of the objective function and its gradient are utilised 1 . Denote the set of compact intervals by II := f a; b j a b; a; b 2 IRg and the set of n-dimensional intervals (also called simply intervals or boxes) by II n . We call a function F : II n ! II to be an inclusion function of f : for each interval Y in X . In other words , f(X) ' F (X), where f(X) is the range of f(x) on X . The inclusion function of the gradient of f(x) is denoted by F 0 (X). There are several ways to build an inclusion function for a given optimization problem (e.g . by using the Lipschitz constant) . Interval arithmetic 1 , 6 , 7 , 21 is a convenient tool for constructing the inclusion functions , and one can get those for almost all functions that can be calculated by a finite algorithm (i.e . not only for given expressions). It is assumed in the following that the inclusion functions have the isotonicity property , i.e . X ' Y implies F (X) ' F (Y ) , and that for all the inclusion functions (2) holds , where w(X) is the width of the interval X and The generality of the problem class and the modest requirement of the existence of the inclusion functions stress the importance of each improvement in the efficiency y Department of Applied Informatics , J'ozsef Attila University , Szeged , ' Arp'ad t'er 2. , Hungary (E- mail: csendes@inf.u-szeged.hu) . The work has been supported by the Grants CIPA3510CT926141 of the COST Project of the EC , OTKA 2879/1991 , and MKM 414/1994. z Institut fur Angewandte Mathematik , Universitat Karlsruhe , Kaiserstrae 12 , D-76128 Karlsruhe, Germany (E-mail: ae07@rz.uni-karlsruhe.de). of the interval global optimization methods . After studying the effects of some accelerating tools 5 , the present paper investigates the role of the selection of the interval subdivision direction. 2 . Model algorithm and subdivision direction selection rules .", "label": ["interval arithmetic", "interval subdivision", "global optimization"], "stemmed_label": ["interv arithmet", "interv subdivis", "global optim"]}
{"doc": "In this paper , we consider the so-called \"inexact Uzawa\" algorithm for iteratively solving linear block saddle point problems . Such saddle point problems arise , for example , in finite element and finite difference discretizations of Stokes equations , the equations of elasticity , and mixed finite element discretization of second-order problems . We consider both the linear and nonlinear variants of the inexact Uzawa iteration . We show that the linear method always converges as long as the preconditioners defining the algorithm are properly scaled . Bounds for the rate of convergence are provided in terms of the rate of convergence for the preconditioned Uzawa algorithm and the reduction factor corresponding to the preconditioner for the upper left-hand block . In the case of nonlinear iteration , the inexact Uzawa algorithm is shown to converge provided that the nonlinear process approximating the inverse of the upper left-hand block is of sufficient accuracy . Bounds for the nonlinear iteration are given in terms of this accuracy parameter and the rate of convergence of the preconditioned linear Uzawa algorithm . Applications to the Stokes equations and mixed finite element discretization of second-order elliptic problems are discussed and , finally , the results of numerical experiments involving the algorithms are presented . Introduction . This paper provides a new analysis for the inexact Uzawa method applied to the solution of saddle point systems which arise in the discretization of various systems of partial differential equations . Such systems typically are obtained when \"multiplier\" or mixed discretization techniques are employed . Examples of these include the discrete equations which result from approximation of elasticity problems, Stokes equations and sometimes linearizations of Navier-Stokes equations 4 , 14 , 15 , 16 . In addition , these systems result from Lagrange multiplier 2 , 3 , 24 and mixed formulations of second order elliptic problems 8 , 21 , 24 . We shall consider iterative solution of an abstract saddle point problem . Let H 1 and H 2 be finite dimensional Hilbert spaces with inner products which we shall denote by (\\Delta; \\Delta) . There is no ambiguity even though we use the same notation for the inner products on both of these spaces since the particular inner product will be identified by This manuscript has been authored under contract number DE-AC02-76CH00016 with the U.S. Department of Energy . Accordingly , the U.S . Government retains a non-exclusive , royalty-free license to publish or reproduce the published form of this contribution , or allow others to do so , for U.S. Government purposes . This work was also supported in part under the National Science Foundation Grant No . DMS-9007185 and by the U.S . Army Research Office through the Mathematical Sciences Institute , Cornell University. y Department of Mathematics , Cornell University , Ithaca , New York 14853 and Department of Math- ematics , Texas A&M University , College Station, z Brookhaven National Laboratory , Upton , NY 11973. x Department of Mathematics , Texas A&M University , College Station, the type of functions", "label": ["uzawa algorithm", "indefinite systems", "stokes equations", "saddle point problems", "iterative methods", "preconditioners"], "stemmed_label": ["uzawa algorithm", "indefinit system", "stoke equat", "saddl point problem", "iter method", "precondition"]}
{"doc": "Transversal homoclinic orbits of maps are known to generate shift dynamics on a set with Cantor-like structure . In this paper a numerical method is developed for computation of the corresponding homoclinic orbits . They are approximated by finite-orbit segments subject to asymptotic boundary conditions . We provide a detailed error analysis including a shadowing-type result by which one can infer the existence of a transversal homoclinic orbit from a finite segment . This approach is applied to several examples . In some of them parameters appear and closed loops of homoclinic orbits are found by a path-following algorithm . Introduction One of the fundamental results on chaotic behavior in discrete dynamical systems is Smale's Homoclinic Theorem , see 23 , 21 , 22 . For a more recent overview of homoclinic orbits, their bifurcations and the history of their discovery we refer to 19 . Consider a (time-)discrete system with a C l -diffeomorphism f assume that - 2 R k is a hyperbolic fixed point of f , i.e . the Jacobian f 0 (-) has no eigenvalues on the unit circle . Further assume that x 0 is a transversal homoclinic point , which means that the orbit generated by (1.1) satisfies lim and the stable and unstable manifolds of - intersect transversally at x 0 . Then the theorem states that there exists a compact set M and an integer such that the p-th iterate of f , denoted by f , leaves M invariant and is topologically conjugate on M to the Bernoulli shift on two symbols . It is remarkable that this chaotic behavior on a certain subset is created by a homoclinic point that is transversal , a property that persists under the perturbation of system (1.1). The perturbation stability of transversal homoclinic points suggests that we should be able to compute these points numerically in a robust and stable way . This is the topic of the Supported by Sonderforschungsbereich 343 \"Diskrete Strukturen in der Mathematik\" , Fakult?t f?r Mathematik , Universit?t Bielefeld. y Parts of this paper are based on the diploma thesis 17 of the second author. present paper . Instead of homoclinic points our approach aims at computing the complete homoclinic orbit by solving the 'boundary value problem' (1.1) , (1.2) . Any direct method for the single homoclinic point x 0 implicitly tries to solve this boundary value problem and hence is prone to the usual difficulties of shooting-type methods which are caused by exponential divergence of trajectories. Therefore , we propose to approximate the infinite orbit by a finite orbit segment x which satisfies a 'finite boundary value problem' Here (1.4) is a general set of boundary conditions defined by a smooth mapping b R k . Together , (1.3) and (1.4) comprise a set of (n+ equations for the same number of unknowns . We solve this system by Newton's method and take advantage of the sparsity pattern of the corresponding Jacobian. The most important examples for (1.4) are periodic boundary conditions and projection boundary conditions where the", "label": ["numerical methods", "shadowing", "homoclinic points for maps", "dynamical systems"], "stemmed_label": ["numer method", "shadow", "homoclin point for map", "dynam system"]}
{"doc": "An identity-based non-interactive public key distribution system is presented that is based on a novel trapdoor one-way function allowing a trusted authority to compute the discrete logarithms modulo a publicly known composite number m while this is infeasible for an adversary not knowing the factorization of m . Without interaction with a key distribution center or with the recipient of a given message , a user can generate a mutual secure cipher key based solely on the recipient's identity and his own secret key , and subsequently send the message , encrypted with the generated cipher used in a conventional cipher , over an insecure channel to the recipient . In contrast to previously proposed identity-based systems , no public keys , certificates for public keys or other information need to be exchanged and thus the system is suitable for certain applications that do not allow for interaction . The paper solves an open problem proposed by Shamir in 1984 . Introduction In their seminal 1976 paper , Diffie and Hellman 4 introduced the ingenious concept of public key cryptography and proposed the first public key distribution system , which is based on exponentiation in a finite field . The basic idea of a public key distribution system is briefly summarized in the following in order to point out the novelty in our scheme that allows it to be non-interactive . In an insecure communication network where all messages sent over a communication channel can be intercepted by an adversary , two 1 The results of this paper have appeared in part in the proceedings of EUROCRYPT '91 , Lecture Notes in Computer Science , Vol . 547 , Springer Verlag , pp . 498-507 , 1991. parties not sharing any secret information initially can generate a secure cipher key (to be subsequently used together with a conventional symmetric cryptosystem) by each choosing a secret number , applying a one-way transformation to this number and exchanging the results of this transformation (the public keys) over an insecure channel . The one-way transformation has the property that given the result , it is infeasible to compute the argument . The one-way transformation proposed by Diffie and Hellman has the crucial additional property , which is due to the commutativity of multiplication , that each party can generate the same mutual secure cipher key from his own secret number and the other party's public key . Without knowing at least one of the secret numbers it is infeasible to generate the secure cipher key using present technology and algorithmic knowledge. Public-key distribution systems and public-key cryptosystems suffer from the following well-known authentication problem . In order to prevent an adversary from fraudulently impersonating another user , it must be possible to verify that a received public key belongs to the user it is claimed to belong to . A commonly used solution to this authentication problem is the certification of public keys by a trusted authority which , after checking a user's identity , signs the concatenation of his name and public key using", "label": ["key management", "public-key cryptography", "trapdoor functions", "discrete logarithms"], "stemmed_label": ["key manag", "public-key cryptographi", "trapdoor function", "discret logarithm"]}
{"doc": "With the profusion of text databases on the Internet , it is becoming increasingly hard to find the most useful databases for a given query . To attack this problem , several existing and proposed systems employ brokers to direct user queries , using a local database of summary information about the available databases . This summary information must effectively distinguish relevant databases and must be compact while allowing efficient access . We offer evidence that one broker , GlOSS , can be effective at locating databases of interest even in a system of hundreds of databased and can examine the performance of accessing the GlOSS summeries for two promising storage methods: the grid file and partitioned hashing . We show that both methods can be tuned to provide good performance for a particular workload (within a broad range of workloads) , and we discuss the tradeoffs between the two data structures . As a side effect of our work , we show that grid files are more broadly applicable than previously thought; inparticular , we show that by varying the policies used to construct the grid file we can provide good performance for a wide range of workloads even when storing highly skewed data . Introduction The last few years have seen an explosion in the amount of information that is available online. The falling costs of storage , processing , and communications have all contributed to this explosion, as has the emergence of the infrastructure provided by the World-Wide Web and its associated applications . Increasingly , the key issue is not whether some piece of information is available online, but where . As a result , an emerging area of research concerns brokers , systems that help users locate the text databases that are most likely to contain answers to their queries . To perform this service, brokers use summary information about the available databases . Brokers must be able both to query and to update this summary information . A central problem in broker design is to find a representation for summary information that is both effective in its ability to select appropriate information resources , and efficient to query and maintain. GlOSS (Glossary-Of-Servers Server) 17 , 18 is one broker that keeps database summaries to choose the most promising databases for a given query . Initial studies of GlOSS are encouraging. This work was partially supported by ARPA Contract F33615-93-1-1339. y INRIA Rocquencourt , 78153 Le Chesnay , France . E-mail: Anthony.Tomasic@inria.fr z Computer Science Department , Stanford University , Stanford , CA 94305-2140 , USA . E-mail: x Current address: Trident Systems , Sunnyvale , CA , USA . E-mail: clue@tridmicr.com Department K55/801 , IBM Almaden Research Center , 650 Harry Road , San Jose , CA 95120-6099 , USA . E-mail: schwarz@almaden.ibm.com , laura@almaden.ibm.com Experiments with a small number of databases indicate that although the GlOSS summaries are orders of magnitude smaller than the information that they summarize , they contain enough information to select the best databases for a query . In this paper", "label": ["broker architecture", "distributed information", "gloss", "partitioned hashing", "grid files", "broker performance"], "stemmed_label": ["broker architectur", "distribut inform", "gloss", "partit hash", "grid file", "broker perform"]}
{"doc": "We introduce Kleene algebra with tests , an equational system for manipulating programs . We give a purely equational proof , using Kleene algebra with tests and commutativity conditions , of the following classical result: every while program can be simulated by a while program can be simulated by a while program with at most one while loop . The proof illustrates the use of Kleene algebra with tests and commutativity conditions in program equivalence proofs . INTRODUCTION Kleene algebras are algebraic structures with operators + , \\Delta , , 0 , and 1 satisfying certain axioms . They arise in various guises in many contexts: relational algebra Ng 1984; Tarski 1941 , semantics and logics of programs Kozen 1981; Pratt 1988 , automata and formal language theory Kuich 1987; Kuich and Salomaa 1986 , and the design and analysis of algorithms Aho et al . 1975; Iwano and Steiglitz 1990; Kozen 1991 . Many authors have contributed to the development of Kleene algebra Anderaa 1965; Archangelsky 1992; Backhouse 1975; Bloom and ' Esik 1993; Boffa 1990; Cohen 1994a; Conway 1971; Gorshkov 1989; Kleene 1956; Kozen 1981; 1990; Author's address: Computer Science Department , Cornell University , Ithaca , NY 14853-7501; email: kozen@cs.cornell.edu. The support of the National Science Foundation under grant CCR-9317320 is gratefully acknowledged Permission to make digital/hard copy of all or part of this material without fee is granted provided that the copies are not made or distributed for profit or commercial advantage , the ACM copyright/server notice , the title of the publication , and its date appear , and notice is given that copying is by permission of the Association for Computing Machinery , Inc . (ACM) . To copy otherwise , to republish , to post on servers , or to redistribute to lists requires prior specific permission and/or a fee. c 1994; Krob 1991; Kuich and Salomaa 1986; Pratt 1990; Redko 1964; Sakarovitch 1987; Salomaa 1966 . In semantics and logics of programs , Kleene algebra forms an essential component of Propositional Dynamic Logic (PDL) Fischer and Ladner 1979 , in which it is mixed with Boolean algebra and modal logic to give a theoretically appealing and practical system for reasoning about computation at the propositional level. Syntactically , PDL is a two-sorted logic consisting of programs and propositions , defined by mutual induction . A test '? can be formed from any proposition '; intuitively , '? acts as a guard that succeeds with no side effects in states satisfying ' and fails or aborts in states not satisfying ' . Semantically , programs are modeled as binary relations on a set of states , and '? is interpreted as the subset of the identity relation consisting of all pairs (s; s) such that ' is true in state s. From a practical point of view , many simple program manipulations , such as loop unwinding and basic safety analysis , do not require the full power of PDL , but can be carried out in a purely equational subsystem using the axioms of", "label": ["kleene algebra", "dynamic logic", "specification"], "stemmed_label": ["kleen algebra", "dynam logic", "specif"]}
{"doc": "We establish a general connection between fixpoint logic and complexity . On one side , we have fixpoint logic , parameterized by the choices of 1st-order operators (inflationary or noninflationary) and iteration constructs (deterministic , nondeterministic , or alternating) . On the other side , we have the complexity classes between P and EXPTIME . Our parameterized fixpoint logics capture the complexity classes P , NP , PSPACE , and EXPTIME , but equally is achieved only over ordered structures . There is , however , an inherent mismatch between complexity and logicwhile computational devices work on encodings of problems , logic is applied directly to the underlying mathematical structures . To overcome this mismatch , we use a theory of relational complexity , which bridges the gap between standard complexity and fixpoint logic . On one hand , we show that questions about containments among standard complexity classes can be translated to questions about containments among relational complexity classes . On the other hand , the expressive power of fixpoint logic can be precisely characterized in terms of relational complexity classes . This tight , three-way relationship among fixpoint logics , relational complexity and standard complexity yields in a uniform way logical analogs to all containments among the complexity classes P , NP , PSPACE , and EXPTIME . The logical formulation shows that some of the most tantalizing questions in complexity theory boil down to a single question: the relative power of inflationary vs . noninflationary 1st-order operators . Introduction The computational complexity of a problem is the amount of resources , such as time or space , required by a machine that solves the problem . Complexity theory traditionally has focused on the computational complexity of problems . A more recent branch of complexity theory , started by Fagin in Fag74 , Fag75 and developed during the 1980s , focuses on the descriptive complexity of problems , which is the complexity of describing problems in some logical formalism Imm87a . One of the exciting developments in complexity theory is the discovery of a very intimate connection between computational and descriptive complexity. This intimate connection was first discovered by Fagin , who showed that the complexity class NP coincides with the class of properties expressible in existential 2nd-order logic Fag74 (cf . JS74 ) . Another demonstration of this connection was shown by Immerman and Vardi , who discovered tight relationships between the complexity class P and inflationary fixpoint logic Imm86 , Var82 and between the class PSPACE and noninflationary fixpoint logic Var82 ; see also Imm82 . 1 The tight connection between descriptive and computational complexity , typically referred to as the connection between \"logic and complexity\" , was then proclaimed by Immerman Imm87b , and studied by many researchers Com88 , Goe89 , Gra84, Gra85 , Gur83 , Gur84 , Gur88 , HP84 , Imm89 , Lei89a , Liv82 , Liv83 , Lyn82 , Saz80b, Although the relationship between descriptive and computational complexity is intimate , it is not without its problems , and the \"partners\" do have", "label": ["fixpoint logic", "complexity classes", "computational complexity", "relational complexity"], "stemmed_label": ["fixpoint logic", "complex class", "comput complex", "relat complex"]}
{"doc": "AbstractQuery processing is a crucial component of various application domains including information retrieval , database design and management , pattern recognition , robotics , and VLSI . Many of these applications involve data stored in a matrix satisfying a number of properties . One property that occurs time and again specifies that the rows and the columns of the matrix are independently sorted . It is customary to refer to such a matrix as sorted . An instance of the Batched Searching and Ranking problem , (BSR , for short) involves a sorted matrix A of items from a totally ordered universe , along with a collection Q of queries . Q is an arbitrary mix of the following query types: For a search query qj , one is interested in an item of A that is closest to qj; for a rank query qj one is interested in the number of items of A that are strictly smaller than qj . The BSR problem asks for solving all queries in Q . In this work , we consider the BSR problem in the following context: The matrix A is pretiled , one item per processor , onto an enhanced mesh of size $\\sqrt n\\times \\sqrt n$; the m queries are stored , one per processor , in the first $ m \\over \\sqrt n $ columns of the platform . Our main contribution is twofold . First , we show that any algorithm that solves the BSR problem must take at least $\\Omega ( \\rm max\\ log n,\\sqrt m\\ )$ time in the worst case . Second , we show that this time lower bound is tight on meshes of size $\\sqrt n\\times \\sqrt n$ enhanced with multiple broadcasting , by exhibiting an algorithm solving the BSR problem in $\\Theta ( \\rm max\\ log \\!\\!n,\\sqrt m\\ )$ time on such a platform . Introduction Due to its simple and intuitive topology , the mesh has established itself as one of the massively parallel architectures suitable for solving problems in image processing , robot vi- sion , computer graphics , path planning , and VLSI design, among many others . At the same time , the mesh is notoriously inefficient when it comes to handling non-spatially organized data . To address this problem , mesh-connected computers have been enhanced with various types of bus systems 1 , 22 , 25 , 28 . Recently , a powerful and elegant architecture , referred to as mesh with multiple broadcasting , has been obtained by endowing each row and column of the mesh with its own dedicated high speed bus 22 , 35 . The mesh with multiple broadcasting has proven to be feasible for implementation in VLSI and was adopted , among others , by the DAP family of computers 35 . Being of theoretical interest as well as commercially available , the mesh with multiple broadcasting has attracted a great deal of well deserved attention . Applications ranging from image processing 23 , 35 , to computer graphics and robotics 6 ,", "label": ["parallel algorithms", "time-optimal algorithms", "searching", "vlsi", "ranking", "enhanced meshes", "pattern recognition", "robotics", "database design"], "stemmed_label": ["parallel algorithm", "time-optim algorithm", "search", "vlsi", "rank", "enhanc mesh", "pattern recognit", "robot", "databas design"]}
{"doc": "AbstractUsing runtime information of load distributions and processor affinity , we propose an adaptive scheduling algorithm and its variations from different control mechanisms . The proposed algorithm applies different degrees of aggressiveness to adjust loop scheduling granularities , aiming at improving the execution performance of parallel loops by making scheduling decisions that match the real workload distributions at runtime . We experimentally compared the performance of our algorithm and its variations with several existing scheduling algorithms on two parallel machines: the KSR-1 and the Convex Exemplar . The kernel application programs we used for performance evaluation were carefully selected for different classes of parallel loops . Our results show that using runtime information to adaptively adjust scheduling granularity is an effective way to handle loops with a wide range of load distributions when no prior knowledge of the execution can be used . The overhead caused by collecting runtime information is insignificant in comparison with the performance improvement . Our experiments show that the adaptive algorithm and its five variations outperformed the existing scheduling algorithms . INTRODUCTION OOPS are the richest sources of parallelism and are widely used in scientific application programs . In many scientific applications , a set of independent tasks typically exists in a parallel loop , called a DoAll loop , where the processing of each element in each iteration is independent of the others. The performance of a loop scheduling algorithm is mainly affected by three overhead sources: synchronization and loop allocation , load imbalance , and data communication. Although it is desirable for an efficient algorithm to minimize the above three sources of overhead , it is usually impossible because conflicts can arise among them . Exploiting processor affinity (processor affinity refers to certain data access dependence of a task to a specific processor; a more precise definition is given in Section 3.1) favors the allocation of loop iterations close to their data , which tends to cause load imbalance . Load balance favors the \"fine grain\" allocation of loop iterations (where a small number of iterations are allocated) in order to minimize the effects of uneven assignment . However , the \"fine grain\" allocation tends to increase synchronization overhead and loop allocation overhead . In different applications , each overhead source affects performance differently . Hence , an efficient loop scheduling algorithm should optimize its performance by adaptively trading off synchronization overhead , loop allocation overhead , load imbalance overhead , and data- communication overhead . Moreover , a dynamic scheduling algorithm should not assume any prior knowledge of the execution times of the loop iterations because the execution of the loop usually is unpredictable in practice. So far , many novel dynamic scheduling algorithms have been proposed , e.g. , 2 , 4 , 5 , 6 , 8 , 9 , 11 , 10 . These algorithms fall into two distinct classes: central queue based and distributed queue based . In central queue based algorithms 2 , 8 , 11 , 10 , iterations of a parallel loop are all stored in a", "label": ["shared-memory systems", "parallel loops", "adaptive scheduling algorithms", "dynamic information", "load balancing", "processor affinity"], "stemmed_label": ["shared-memori system", "parallel loop", "adapt schedul algorithm", "dynam inform", "load balanc", "processor affin"]}
{"doc": "AbstractA Multistage Bus Network (MBN) is proposed in this paper to overcome some of the shortcomings of the conventional multistage interconnection networks (MINs) , single bus , and hierarchical bus interconnection networks . The MBN consists of multiple stages of buses connected in a manner similar to the MINs and has the same bandwidth at each stage . A switch in an MBN is similar to that in a MIN switch except that there is a single bus connection instead of a crossbar . MBNs support bidirectional routing and there exists a number of paths between any source and destination pair . In this paper , we develop self routing techniques for the various paths , present an algorithm to route a request along the path with minimum distance , and analyze the probabilities of a packet taking different routes . Further , we derive a performance analysis of a synchronous packet-switched MBN in a distributed shared memory environment and compare the results with those of an equivalent bidirectional MIN (BMIN) . Finally , we present the execution time of various applications on the MBN and the BMIN through an execution-driven simulation . We show that the MBN provides similar performance to a BMIN while offering simplicity in hardware and more fault-tolerance than a conventional MIN . Introduction In order to achieve significant performance in parallel computing it is necessary to keep the communication overhead as low as possible . The communication overheads of a multiprocessor system depend to a great extent on the underlying interconnection network . An interconnection network (IN) can be either static or dynamic . Dynamic networks can connect any input to any output by enabling some switches . They are applicable to both shared memory and message passing multiprocessors . Among such dynamic INs , the hierarchical buses or rings 1 , 2 and Multistage Interconnection Networks (MINs) 3 , 4 have been commercially employed. In a strictly hierarchical bus architecture 1 , there are a number of buses connected in the form of a tree between the processors and the memories . The use of multiple buses makes the hierarchical bus-based systems more scalable compared to the popular single bus multiprocessors . However , the bandwidth of this interconnection decreases as one moves toward the top of the tree . Thus , the scalability of a hierarchical bus system becomes limited by the bandwidth of the topmost level bus. The bandwidth problem can be alleviated through the fat tree design 5 . The simplicity of the bus based designs and the availability of a fast broadcasting mechanism are factors that make bus-based systems very attractive. The MINs , on the other hand , offer a uniform bandwidth across all stages of the network . The bandwidth of the network increases in proportion to the increase in system size , making the MIN a highly scalable interconnection . The switches in a MIN are made up of small crossbar switches. When the system size grows , bigger switches can be used to keep the number of stages", "label": ["routing", "performance analysis", "interconnection network", "packet-switching", "execution-driven simulation", "queuing model"], "stemmed_label": ["rout", "perform analysi", "interconnect network", "packet-switch", "execution-driven simul", "queu model"]}
{"doc": "In this paper we present a new probabilistic clock synchronization algorithm , its prototype implementation and experimental results . The algorithm follows the client-server programming paradigm and is designed to work in a departmental environment with few servers and a number of clients connected through an arbitrary network topology . At the core of the algorithm is a remote clock reading method that mitigates the negative effects of message delay uncertainty . The implementation proves the effectiveness of this approach and corroborates the theoretical speculations . Introduction In a distributed system there are strong reasons to keep the clocks of the units as synchronized as possible since sharply synchronized clocks can ease the development of several distributed applications such as real time control , performance evaluation tools , distributed simulations , transaction processing , data recovery, atomic broadcast , group membership and many others 9 . However , the task of keeping the clocks synchronized is a hard one , since: ffl variable clock drift A hardware clock doesn't measure the time at the desired speed of 1sec=sec but , even if fault-free and initially synchronized with a standard time reference , it tends to drift away from it . The drift rate itself varies during the lifetime of the clock , and according with external conditions in an unpredictable ffl message delay uncertainty The messages that convey timing information are exposed to unforseeble delays . This delay uncertainty is due to a number of different factors such as network load , queuing delays , I/O throughput , protocol stack implementation and others. Therefore even perfectly synchronized clocks tend to diverge and cannot be exactly resynchronized. The primary goal of a distributed synchronization service is to keep all non-faulty clocks synchronized within is called the synchronization precision , and is a key parameter to evaluate the performance of a synchronization service 9 . In the literature , we can identify two different approaches to implement a distributed clock synchroniza- tion . An internal clock synchronization algorithm keeps each node's clock synchronized within while an external synchronization algorithm keeps each node's clock synchronized within time units from an external time reference such as UTC (Universal Time Coordinates) or GPS (Global Positioning System). A number of deterministic clock synchronization algorithms has been published 4 , 8 , 10 , 14 . Most of them are structured around periodic rounds of broadcast communication and address fault tolerance aspects; for a survey see 13 . An important result 11 fixes the upper bound Universit'e Catholique de Louvain y Universit'a degli Studi di Pisa the synchronization precision for deterministic algorithms executing in a distributed system with N nodes. Here min and max are the minimum and maximum network delay and the quantity (max \\Gamma min) gives an indication of the network delay uncertainty. According with these results , in networks with unbounded message delay , even if we assume that all system nodes are fault-free , it is impossible to achieve clock synchronization through a deterministic algorithm. In order to overcome this limitation , probabilistic clock synchronization", "label": ["tcp/ip", "clock synchronization", "distributed systems", "distributed algorithms", "probabilistic algorithms", "local area networks"], "stemmed_label": ["tcp/ip", "clock synchron", "distribut system", "distribut algorithm", "probabilist algorithm", "local area network"]}
{"doc": "A new method is investigated to reduce the roundoff error in computing derivatives using Chebyshev collocation methods . By using a grid mapping derived by Kosloff and Tal-Ezer , and the proper choice of the parameter $\\alpha$ , the roundoff error of the $k$th derivative can be reduced from $O(N^ 2k )$ to $O((N \\lge)^k)$ , where $\\epsilon$ is the machine precision and $N$ is the number of collocation points . This drastic reduction of roundoff error makes mapped Chebyshev methods competitive with any other algorithm in computing second or higher derivatives with large $N$ . Several other aspects of the mapped Chebyshev differentiation matrix are also studied , revealing that the mapped Chebyshev methods require much less than $\\pi$ points to resolve a wave; the eigenvalues are less sensitive to perturbation by roundoff error; and larger time steps can be used for solving PDEs . All these advantages of the mapped Chebyshev methods can be achieved while maintaining spectral accuracy . Introduction In 5 , we addressed the issue of roundoff error in computing the derivative using the Chebyshev collocation methods . For details on these methods , see Canuto , et . al . 1 , or Gottlieb and Orszag 2 . We showed how to construct the Chebyshev collocation derivative with only O(fflN 2 ) roundoff error , where ffl is the machine precision and N is the number of collocation points , by carefully constructing the entries of the derivative matrix. There are PDEs that involve higher derivatives than the first . For example , the viscosity term in the Navier-Stokes Equation and the fourth derivative term in the Kuramoto-Sivashinsky Equation. For these problems , the roundoff error in the k-th derivative will be O(fflN 2k ) . This can ruin the computed solution , even if k and N are not that large . This limits the applicability of Chebyshev collocation methods to certain types of PDEs and values of N . In this paper we investigate a way of modifying the Chebyshev collocation derivative which reduces the roundoff error , and also improves its accuracy . As stated in 5 , the roundoff error cannot be reduced further for basis functions based on polynomials , since the roundoff error of the Chebyshev collocation method already achieves the theoretical minimum . Therefore , to have any hope of reducing the roundoff error , the polynomial basis functions must be replaced with something else . One way to do this is to apply a coordinate transformation . More specifically, the Chebyshev collocation points - are mapped to a new set of points with a parameter ff . The transformation function g(-; ff) is one-to-one and onto . The mapping is also applied to the polynomial basis functions , and so they are changed as well. In this paper , we will concentrate on a mapping of the form In 4 , Kosloff and Tal-Ezer showed that this mapping increases the minimum spacing \\Deltax between collocation points from O(N \\Gamma2 ) to O(N \\Gamma1 ) , and argued that", "label": ["differentiation matrix", "tal-ezer mapping", "chebyshev collocation", "roundoff error"], "stemmed_label": ["differenti matrix", "tal-ez map", "chebyshev colloc", "roundoff error"]}
{"doc": "Analyses based on Symmetric Daubechies Wavelets (SDW) lead to complex-valued multiresolution representations of real signals . After a recall of the construction of the SDW , we present some specific properties of these new types of Daubechies wavelets . We then discuss two applications in image processing: enhancement and restoration . In both cases , the efficiency of this multiscale representation relies on the information encoded in the phase of the complex wavelet coefficients . INTRODUCTION Many current investigations in mathematical imaging consist in finding the optimal representation to perform specific enhancements by extracting the relevant information contained in an empirical signal . This question of representation , present in many fields of applied mathematics and physics , is indeed the cornerstone of the pionnering work of D . Marr in vision 1 . The \"primal sketch\" of an image he proposed was based on the multiscale edge representation obtained through the action of some operators of different sizes. More specifically , Marr and Hildreth 2 argued that the convolution of the image with the filter associated with the Laplacian of the two dimensional Gaussian at different scales constitutes the most satisfactory representation . Such a representation identifies edges with the zero-crossings of the filtered image . Physiological experiments 1 gave credit to this model of vision generally known as the \"Marr conjecture\" . In a more computational approach to edge detection proposed by Canny 3 , edges are located at the local extrema of the convolutions of the image with the directional first order derivatives of some smoothing function (e.g . a Gaussian kernel) . Unlike the zero-crossing technique , the Canny's edge detector characterizes the strength of the discontinuities in the image intensity . The synthesis of those two approaches is due to Mallat and Zhong 4;5 who demonstrated that zero-crossings and local extrema are unified in a single mathematical frame- work: the wavelet theory of frames . They further established an iterative algorithm to restore the original signal from these sparse representations . The aim of the present work is to show that similar ideas can be developped with orthogonal multiresolution bases with compact support provided we use the symmetric Daubechies wavelets 6;7 . Being complex-valued , the symmetric Daubechies multiresolution analyses did not receive much attention from the signal processing community since the resulting representation of a real field , such as an image , is a redundant expansion with complex-valued coefficients . Needless to say , this is also true with the Fourier transform; however , the reality condition is rather trivial and establishes a simple identity between the Fourier modes . The present work investigates the same kind of relationship between the complex wavelet coefficients: on the basis of comparison with the standard real Daubechies analyses , we show that the \"natural e-mail: lina@crm.umontreal.ca redundancy\" given by the complex Daubechies analyses of a real field provides a \"dual representation\" combining zero-crossings and local extrema . In fact , this result relies on the existence of \"hidden\" differential operators underlying the structure of some complex Symmetric Daubechies", "label": ["daubechies wavelets", "complex signals", "restoration", "image processing"], "stemmed_label": ["daubechi wavelet", "complex signal", "restor", "imag process"]}
{"doc": "In this paper , we develop a framework for computing upper and lower bounds of an exponential form for a large class of single resource systems with Markov additive inputs . Specifically , the bounds are on quantities such as backlog , queue length , and response time . Explicit or computable expressions for our bounds are given in the context of queuing theory and numerical comparisons with other bounds and exact results are presented . The paper concludes with two applications to admission control in multimedia systems . Introduction We are witnessing a phenomenal growth in the deployment and usage of networked multimedia applications . Numerous networked teleconferencing applications have recently been introduced, 40 , 58 , 30 , 41 . In addition , there are plans to deploy large-scale multimedia servers in the not too distant future , 55 . All of these applications share the need for a minimal quality of service (QoS) guarantee in the form of either an end-to-end delay constraint or a maximum tolerable fraction of loss . Providing QoS guarantees to these applications poses one of the most challenging problems facing designers of multimedia systems and applications. In this paper we focus on a single resource and develop a framework within which to obtain computable upper and lower bounds on the tail of the distributions of quantities such as backlog , delay and queue length at that resource . These bounds are exponential in nature when the combined arrival and service processes (to be made precise) can be described by a Markov chain and the system is stable . In addition to obtaining distributional bounds , we also apply these results to the problem of call admission in a network and in a multimedia server setting. More precisely , we consider the behavior of a single server as described by the recursion with a.s , where the real-valued increments (U n ) n are modulated by a Markov chain (Y n such that (Y n+1 ; Additive (MA) process 39 . In our context , one application is when X n represents the waiting time of the n-th customer in a First-In-First-Out (FIFO) G/G/1 single server queue , U are the service requirement and interarrival time sequences , respectively. Our primary objective is to compute exponential upper and lower bounds for the tail distribution of X n , both for every n - 0 and for the stationary regime X of X n (when it exists) , namely , to -nd strictly positive constants a , a n , b , b n and ' such that a a e \\Gamma'x - for all x - 0 , n - 0. In the particular case where (oe n ) n and (- n ) n are two mutually independent renewal sequences (GI/GI/1 queue) , Kingman 44 , 45 showed that a exp(\\Gammajx) - and x - 0 , where j is the unique solution in (0; 1) of the equation E exp(' (oe the stability condition E oe re-nement of Kingman's upper bound was proposed", "label": ["markov additive process", "call admission control", "queues", "markov chain", "exponential bound", "ergodicity", "large deviation principle", "matrix analysis", "effective bandwidth", "tail distribution"], "stemmed_label": ["markov addit process", "call admiss control", "queue", "markov chain", "exponenti bound", "ergod", "larg deviat principl", "matrix analysi", "effect bandwidth", "tail distribut"]}
{"doc": "In this paper we study the problem of on-line allocation of routes to virtual circuits (both point-to-point and multicast) where the goal is to route all requests while minimizing the required bandwidth . We concentrate on the case of Permanent virtual circuits (i.e. , once a circuit is established it exists forever) , and describe an algorithm that achieves on O (log n) competitive ratio with respect to maximum congestin , where nis the number of nodes in the network . Informally , our results show that instead of knowing all of the future requests , it is sufficient to increase the bandwidth of the communication links by an O (log n) factor . We also show that this result is tight , that is , for any on-line algorithm there exists a scenario in which ***(log n) increase in bandwidth is necessary in directed networks . We view virtual circuit routing as a generalization of an on-line load balancing problem , defined as follows: jobs arrive on line and each job must be assigned to one of the machines immediately upon arrival . Assigning a job to a machine increases the machine's load by an amount that depends both on the job and on the machine . The goal is to minimize the maximum load . For the related machines case , we describe the first algorithm that achieves constant competitive ratio . for the unrelated case (with nmachines) , we describe a new method that yields O(logn)-competitive algorithm . This stands in contrast to the natural greed approach , whose competitive ratio is exactly n . show that this result is tight , that is , for any on-line algorithm there exists a scenario in which ***(log n) increase in bandwidth is necessary in directed networks . Introduction Virtual Circuit Routing High-speed integrated communication networks are going to become a reality in the near future . Implementation of these networks raises numerous new issues that either did not exist or could be easily addressed in the context of the existing slow-speed networks . In particular , the increase in the network speed by several orders of magnitude leads to a situation where the bandwidth-delay product far exceeds the available buffer space , making it necessary to use bandwidth-reservation techniques. The main abstraction through which the customer can use the network is by a virtual circuit . In order to use the network , the customer requests it to reserve the required bandwidth between the two communicating points . The network guarantees that the reserved bandwidth will indeed be available as long as needed, creating an illusion of a real circuit dedicated to the customer . One of the basic services that appears in the proposals for future high-speed networks (e.g . ATM 1 ) is the permanent virtual circuit (PVC) service . As far as the user is concerned , such virtual circuit is supposed to behave like a physical line connecting the corresponding points , and hence it is desirable that once such a circuit is created , it", "label": ["routing", "high-speed networks", "optimization", "on-line algorithms"], "stemmed_label": ["rout", "high-spe network", "optim", "on-lin algorithm"]}
{"doc": "Strictness analysis is an important technique for optimization of lazy functional languages . It is well known that all strictness analysis methods are incomplete , i.e. , fail to report some strictness properties . In this paper , we provide a precise and formal characterization of the loss of information that leads to this incompletenss . Specifically , we establish the following characterization theorem for Mycroft's strictness analysis method and a generalization of this method , called ee-analysis , that reasons about exhaustive evaluation in nonflat domains: Mycroft's method will deduce a strictness property for program P iff the property is independent of any constant appearing in any evaluation of P . To prove this , we specify a small set of equations , called E-axioms , that capture the information loss in Mycroft's method and develop a new proof technique called E-rewriting . E-rewriting extends the standard notion of rewriting to permit the use of reductions using E-axioms interspersed with standard reduction steps . E-axioms are a syntactic characterization of information loss and E-rewriting provides and algorithm-independent proof technique for characterizing the power of analysis methods . It can be used to answer questions on completeness and incompleteness of Mycroft's method on certain natural classes of programs . Finally , the techniques developed in this paper provide a general principle for establishing similar results for other analysis methods such as those based on abstract interpretation . As a demonstration of the generality of our technique , we give a characterization theorem for another variation of Mycroft's method called dd-analysis . INTRODUCTION Mycroft 1980 pioneered the concept of strictness analysis as a technique for optimizing lazy functional languages by transforming call-by-need to call-by-value . His results have had major impact on techniques for compilation , optimization and parallel evaluation of lazy functional languages.Mycroft's work was based on abstract interpretation of first-order functions defined over flat domains . Subsequently , there has been much research into developing strictness analysis techniques for higher-order functions Burn et al . 1985; Hudak and Young 1986; Kuo and Mishra 1989 Work partially supported by NSF grants CCR-8706973 , CCR- 8805734 and CCR-9102159 . A preliminary version of this paper was presented in POPL '91. Authors' addresses: R . Sekar , Bellcore , Room 1J-226R , 445 South Street , Morristown , NJ 07960; email: sekar@bellcore.com; P . Mishra and I.V . Ramakrishnan , Department of Computer Science, SUNY at Stony Brook , NY 11794; email: fmishra,ramg@cs.sunysb.edu. and non-flat domains Hughes and Wadler 1987; Hall and Wise 1987; Sekar et al. 1990; Wadler 1987 . It is well-known that no strictness analysis method can deduce all the strictness properties of a function . For example , consider the function where P (x) is always true for all values of x . Observe that F is strict in y , but this fact is impossible to detect uniformly . Therefore , any strictness analysis method must be incomplete , i.e. , fail to report some strictness properties . This incompleteness may arise from a variety of sources such as", "label": ["program analysis", "strictness analysis", "completeness", "abstract interpretation"], "stemmed_label": ["program analysi", "strict analysi", "complet", "abstract interpret"]}
{"doc": "LAPACK and LINPACK both solve symmetric indefinite linear systems using the diagonal pivoting method with the partial pivoting strategy of Bunch and Kaufman Math . Comp. , 31 (1977) , pp . 163--179 . No proof of the stability of this method has appeared in the literature . It is tempting to argue that the diagonal pivoting method is stable for a given pivoting strategy if the growth factor is small . We show that this argument is false in general and give a sufficient condition for stability . This condition is not satisfied by the partial pivoting strategy because the multipliers are unbounded . Nevertheless , using a more specific approach we are able to prove the stability of partial pivoting , thereby filling a gap in the body of theory supporting LAPACK and LINPACK . Introduction . LAPACK is renowned for the numerical reliability of the algorithms it employs . The LAPACK Users' Guide 1 states that \"almost all the algorithms in LAPACK (as well as LINPACK and EISPACK) are normwise back- ward stable\" 1 , . 74 , and the algorithms not covered by this statement are known to be stable in appropriately weakened senses . The analyses to back up these claims of stability are spread throughout the research literature of the last 35 years . While writing the book Accuracy and Stability of Numerical Algorithms 14 we realised that there is no proof in the literature of the stability of the method used in LAPACK and LINPACK for solving symmetric indefinite linear systems . Furthermore , the stability is not a direct consequence of existing results . The purpose of this paper is to prove the stability of the method and thereby to fill a gap in the body of theory supporting LAPACK and LINPACK. In the remainder of the introduction we briefly describe the method to be anal- ysed: the diagonal pivoting method with the partial pivoting strategy of Bunch and Kaufman 5 . Let A 2 IR n\\Thetan be symmetric . If A is nonzero , we can find a permutation \\Pi and an integer so that with E nonsingular . Then we can compute the factorization I n\\Gammas This process can be repeated recursively on the (n \\Gamma s) \\Theta (n \\Gamma s) Schur complement Department of Mathematics , University of Manchester , Manchester , M13 9PL , England (na.nhigham@na-net.ornl.gov) . This work was supported by Engineering and Physical Sciences Research Council grants GR/H/52139 and GR/H/94528. N . J . HIGHAM The result is a factorization where L is unit lower triangular and D is block diagonal with each diagonal block having dimension 1 or 2 . This factorization is essentially a symmetric block form of Gaussian elimination , with pivoting , and it costs n 3 =3 flops 1 (the same cost as Cholesky factorization of a positive definite matrix) plus the cost of determining the permutations \\Pi . This method for computing a block LDL T factorization is called the diagonal pivoting method . Given the factorization (1.2) of a nonsingular A", "label": ["numerical stability", "rounding error analysis", "diagonal pivoting method", "lapack", "partial pivoting", "growth factor", "linpack", "symmetric indefinite matrix", "ldlt factorization"], "stemmed_label": ["numer stabil", "round error analysi", "diagon pivot method", "lapack", "partial pivot", "growth factor", "linpack", "symmetr indefinit matrix", "ldlt factor"]}
{"doc": "This paper provides an error analysis of the generalized Schur algorithm of Kailath and Chun SIAM J . Matrix Anal . Appl. , 15 (1994) , pp . 114--128 ---a class of algorithms which can be used to factorize Toeplitz-like matrices , including block-Toeplitz matrices , and matrices of the form $T^ T T$ , where $T$ is Toeplitz . The conclusion drawn is that if this algorithm is implemented with hyperbolic transformations in the factored form which is well known to provide numerical stability in the context of Cholesky downdating , then the generalized Schur algorithm will be stable . If a more direct implementation of the hyperbolic transformations is used , then it will be unstable . In this respect , the algorithm is analogous to Cholesky downdating; the details of implementation of the hyperbolic transformations are essential for stability . An example which illustrates this instability is given . This result is in contrast to the ordinary Schur algorithm for which an analysis by Bojanczyk , Brent , De Hoog , and Sweet SIAM J . Matrix Anal . Appl. , 16 (1995) , pp . 40--57 shows that the sta- bility of the algorithm is not dependent on the implementation of the hyperbolic transformations . Introduction . The Schur algorithm is a popular and fast method for the Cholesky factorization of a square , positive definite Toeplitz matrix , T . It performs reliably and in 3 it was shown to be stable in the sense that if the algorithm runs to completion and - C is the computed Cholesky factor, Ck is guaranteed to be small . This paper will perform a similar stability analysis which applies to several special cases of the generalized Schur algorithm , 10 . In its full generality, the generalized Schur algorithm can be adapted to the factorization of a wide variety of structured matrices . The analysis given here is primarily of interest for block- Toeplitz and Toeplitz-block matrices , as well as for matrices of the form T T T , where T is rectangular and Toeplitz . The key notion behind the general algorithm is the concept of displacement rank , 10 . One of the most significant examples is the Cholesky factorization of T T T . This factor is also the factor R in the QR factorization of the rectangular Toeplitz matrix T and the obvious application of this fact to the solution of Toeplitz least squares problems is explored in 1 . However , the analysis given there assumes the use of the algorithm presented in 2 rather than the generalized Schur algorithm . The basic idea is to obtain R without bothering about finding Q , thus avoiding any problems associated with the loss of orthogonality which are common to all fast Toeplitz QR algorithms . The method of semi-normal equations , possibly with iterative refinement, can then be used to find the least squares solution . The resulting equations are and a weak stability result can be given concerning their solution provided that for", "label": ["toeplitz matrices", "structured matrices", "stability", "schur algorithm"], "stemmed_label": ["toeplitz matric", "structur matric", "stabil", "schur algorithm"]}
{"doc": "Sparse matrix factorization algorithms for general problems are typically characterized by irregular memory access patterns that limit their performance on parallel-vector supercomputers . For symmetric problems , methods such as the multifrontal method avoid indirect addressing in the innermost loops by using dense matrix kernels . However , no efficient LU factorization algorithm based primarily on dense matrix kernels exists for matrices whose pattern is very unsymmetric . We address this deficiency and present a new unsymmetric-pattern multifrontal method based on dense matrix kernels . As in the classical multifrontal method , advantage is taken of repetitive structure in the matrix by factorizing more than one pivot in each frontal matrix , thus enabling the use of Level 2 and Level 3 BLAS . The performance is compared with the classical multifrontal method and other unsymmetric solvers on a CRAY C-98 . Introduction .Conventional sparse matrix factorization algorithms for general problems rely heavily on indirect addressing . This gives them an irregular memory access pattern that limits their performance on typical parallel-vector supercomputers and on cache-based RISC architectures . In contrast , the multifrontal method of Duff and Reid 9 , 10 , 14 , 15 is designed with regular memory access in the innermost loops and has been modified by Amestoy and Duff to use standard kernels 1 . This multifrontal method assumes structural symmetry and bases the factorization on an assembly tree generated from the original matrix and an ordering such as minimumdegree . The computational kernel , executed at each node of the tree, is one or more steps of LU factorization within a square , dense frontal matrix defined by the nonzero pattern of a pivot row and column . These steps of LU factorization compute a contribution block (a Schur complement) that is later assembled (added) into the frontal matrix of its parent in the assembly tree . Henceforth we will call this approach the classical multifrontal method. Although structural asymmetry can be accommodated in the classical multifrontal method by holding the pattern of A+A T and storing explicit zeros , this can have poor performance on matrices whose patterns are very unsymmetric . If we assume from the outset that the matrix may be structurally asymmetric , the situation becomes more complicated . For example , the frontal matrices are rectangular instead of square , and some contribution blocks must be assembled into more than one subsequent frontal matrix . As a consequence , it is no longer possible to represent the factorization by Computer and Information Sciences Department , University of Florida , Gainesville , Florida, USA . phone: (904) 392-1481 , email: davis@cis.ufl.edu . Support for this project was provided by the National Science Foundation (ASC-9111263 and DMS-9223088) , and by Cray Research , Inc . and Florida State University through the allocation of supercomputer resources . Portions of this work were supported by a post-doctoral grant from CERFACS. y Rutherford Appleton Laboratory , Chilton , Didcot , Oxon . 0X11 0QX England , and European Center for Research and Advanced Training in Scientific", "label": ["lu factorization", "unsymmetric sparse matrices", "multifrontal methods"], "stemmed_label": ["lu factor", "unsymmetr spars matric", "multifront method"]}
{"doc": "Some implementations of interior-point algorithms obtain their search directions by solving symmetric indefinite systems of linear equations . The conditioning of the coefficient matrices in these so-called augmented systems deteriorates on later iterations , as some of the diagonal elements grow without bound . Despite this apparent difficulty , the steps produced by standard factorization procedures are often accurate enough to allow the interior-point method to converge to high accuracy . When the underlying linear program is nondegenerate , we show that convergence to arbitrarily high accuracy occurs , at a rate that closely approximates the theory . We also explain and demonstrate what happens when the linear program is degenerate , where convergence to acceptable accuracy (but not arbitrarily high accuracy) is usually obtained . Introduction . We focus on the core linear algebra operation in primal-dual interior-point methods for linear programming: solution of a system of linear equations whose coefficient matrix is large , sparse , and symmetric . In existing codes , the linear system is formulated in two different ways . One formulation , usually called the augmented system formulation , has a symmetric indefinite coefficient matrix . The other involves a more compact (but generally denser) symmetric positive-definite matrix. A diagonal matrix D is involved in both formulations , where D has the disconcerting property that some of its elements grow to 1 as the iterates approach the solution set. This blowup in D can produce ill conditioning in the coefficient matrix of the linear system . In this paper , we examine the augmented system and look at how various factorization algorithms for this system behave as this ill conditioning develops. We restrict our study to three standard factorization algorithms - the Bunch- Parlett , Bunch-Kaufman , and sparse Bunch-Parlett algorithms . The last of these has been used in at least one practical interior-point code for linear programming (see Fourer and Mehrotra 5 ) . We assume that no attempt is made to improve the conditioning of the underlying linear systems by guessing whether each component of the solution is at a bound . Preprocessing of this kind detracts from the intuitive appeal of interior-point algorithms , namely , that they avoid explicit guessing about the contents of the basis. In numerical experiments with feasible linear programs , we find that two distinct scenarios arise. 1 . Even when the iterates are very close to the solution set , the computed search directions are good enough to produce rapid convergence of the algorithm at nearly the rates predicted by the theory . This performance is a little sur- prising . Since the matrix is poorly conditioned , we might have expected the computed directions to be too inaccurate to allow the algorithm to make much progress . This scenario usually occurs when the underlying linear program has a unique primal-dual solution. 2 . Near the solution , calculation of the search direction fails because of break-down of the matrix factorization , or else the computed search direction is so inaccurate that the interior-point method can", "label": ["symmetric indefinite matrices", "interior-point methods"], "stemmed_label": ["symmetr indefinit matric", "interior-point method"]}
{"doc": "We extend type specialisation to a computational lambda calculus with first-class references . The resulting specialiser has been used to specialise a self-interpreter for this typed computational lambda calculus optimally . Furthermore , this specialiser can perform operations on references at specialisation time , when possible . Introduction By far the most important program specialisation technique is partial evaluation ? . Partial evaluation is a program transformation , in which a program and parts of its input (the static part) is transformed into a new program . The partial evaluator performs the operations for which enough data is available and reconstructs the rest . Where an interpreter only operates on values , a partial evaluator operates on both values and symbolic values (code or values or a combination of code and values) . Partial evaluators appear in two variants , online and offline . In online partial evaluators all specialisation decisions are taken by inspecting the symbolic values , whereas in the offline variants all specialisation decisions are taken before actually running the specialiser. The decisions are communicated to the specialiser by means of two-level annotated programs ? . These annotations can be introduced by hand or by means of a binding-time anal- ysis . The specialiser , in this case , is an interpreter for two-level programs. Type specialisation ? is an extension of offline partial evaluation , where the specialiser is expressed as a collection of non-standard typing rules . Each type inference rule specifies a transformation on an expression e and a type - via specialisation judgements: \\Gamma is the code part or dynamic part of the result of applying the transfor- mation , and - 0 plays the same r-ole as the symbolic values in partial evaluation , and may contain values . The static Supported by the Belgian National Fund for Scientific Research (N.F.W.O . This work was done while visiting Chalmers. y This work was done while visiting Chalmers To appear in the proceedings of ICFP'97. parts can be used in static computations and the dynamic parts are treated as black-boxes . In this setting , specialisation corresponds to building a proof of a specialisation judgement . The advantage over partial evaluation is that symbolic values , the residual types , are propagated via type unification 1 . The combination of a rich language of residual types and the superior value propagation strategy , type unification , has enabled Hughes to achieve optimal specialisation of a self-interpreter for a typed lambda calculus ? , a feat that has not been achieved with standard partial eval- uation . Optimal specialisation in this context means that specialising the interpreter with respect to some term yields the same term up to ff-conversion . The problem here is the presence of a universal type in the self-interpreter . Standard partial evaluation is not able to get rid of the tagging and untagging operations of the universal type ? . This work serves two purposes . First , we show that type specialisation is modular with respect to the addition of", "label": ["type systems", "specialisation", "monads", "program transformation"], "stemmed_label": ["type system", "specialis", "monad", "program transform"]}
{"doc": "We argue that runtime program transformation , partial evaluation , and dynamic compilation are essential tools for automated generation of flexible , highly interactive graphical interfaces . In particular , these techniques help bridge the gap between a high-level , functional description and an efficient implementation . To support our claim , we describe our application of these techniques to a functional implementation of n-Vision , a real-time visualization system that represents multivariate relations as nested 3D interactors , and to Auto Visual , a rule-based system that designs n-Vision visualizations from high-level task specifications . n-Vision visualizations are specified using a simple functional language . These programs are transformed into a cached dataflow graph . A partial evaluator is used on particular computation-intensive function applications , and the results are compiled to native code . The functional representation simplifies generation of correct code , and the program transformations ensure good performance . We demonstrate why these transformations improve performance and why they cannot be done at compile time . Introduction Modern programming language implementation techniques are extremely important , even essential , for implementing flexible and efficient interactive visualization tools . As a case in point , we describe our new version of n-Vision , a visualization tool that we originally developed to present multivariate functions as interactive , 3D virtual worlds 3 . To appear in ACM SIGPLAN Conference on Partial Evaluation and Semantics-Based Program Manipulation (PEPM'97). We have used functional programming , program transforma- tion , partial evaluation and dynamic compilation to improve both the functionality and efficiency of the original version of n-Vision with the added benefit of simplifying the production and maintenance of its code. The primary focus of our research is the improvement of graphics and visualization systems through knowledge-based automated design and generation . In general , we believe that capturing rules and techniques of graphic design, and applying them to specific application domains can both increase the quality of the visualizations presented to users and relieve users of the burden of creating these visualizations themselves . Experimental automated generation systems have been developed in a variety of fields , including information visualization 13 , 5 , 16 , 3 , 21 , pictorial explanations 17 , and multimedia explanations 6 , 1 . In our current work , we are continuing development of AutoVisual 3 , a rule-based component that designs n-Vision visualizations from high-level , user-specified visualization tasks . AutoVisual produces representations of real- time , interactive , graphical scenes , which are actually small functional programs that generate and render graphical objects in response to user input . These programs are compositions of small , known components that allow the user to interactively explore 3D visualizations of multivariate re- lations . The space of possible visualizations that can be produced is extremely large and diverse , so an automated tool should be very helpful in searching it . Thus , this is a promising domain for automated generation research. Unfortunately , straightforward evaluation of these visualization programs is very inefficient . Even", "label": ["dataflow", "multivariate data visualization", "partial evaluation", "program transformation", "virtual worlds"], "stemmed_label": ["dataflow", "multivari data visual", "partial evalu", "program transform", "virtual world"]}
{"doc": "In this paper we investigate how partial evaluation and program transformations can be used on a real problem , namely that of speeding up airline crew scheduling.Scheduling of crews is subject to many rules and restrictions . These restrictions are expressed in a rule language . However , in a given planning situation much is known to be fixed , so the rule set can be partially evaluated with respect to this known input.The approach is somewhat novel in that it uses truly static input data as well as static input data where the values are known only to belong to a set of values.The results of the partial evaluation is quite satisfactory: both compilation and running times have decreased by using it . The partial evaluator is now part of the crew scheduling system that Carmen Systems AB markets and which is in use at most of the major European airlines and in daily production . Introduction Next to fuel costs , crew costs are the largest direct operating cost of airlines. In 1991 American Airlines reported spending $1.3 billion on crew AGPT91 . Other major airlines have similar costs . Therefore much work has been devoted to the planning and scheduling of crews over the last thirty years. The planning of aircrafts and crews in large airlines is a very complex prob- lem , see AHKW97 for a good overview . To make the problem tractable it is normally divided into four parts. Construct timetable First , the time table is produced with the objective to match the expectations of the marketing department with the available fleets and other constraints . The output of this process is a number of legs (non-stop flights) which the airline decides to operate. Fleet assignment Second , aircrafts are allocated to the legs . Again there must be a match between expected number of passengers and goods and the available aircraft fleets . The output of this problem is the timetable augmented with aircraft information. Crew pairing Third , pairings are constructed . A pairing is a sequence of flight legs for an unspecified crew member starting and ending at the same crew base . Such a sequence is often called a CRew Rotation (CRR) . The crew member will normally be working on these legs , but a pairing may also contain legs where the crew member is just transported. Such a leg is called a deadhead . Legs are naturally grouped into duty periods (working days) called RoTation Days (RTD) . Each rotation day is separated by a lay-over (an overnight stop) . Legal pairings must satisfy a large number of governmental regulations and collective agreements which vary from airline to airline . The output of this phase is a set of pairings covering the legs in the timetable. Crew assignment The fourth planning problem is to assign pairings to named individuals . This is the crew assignment or rostering prob- lem . The objective is to cover the pairings from the previous stage as well as training requirements , vacations ,", "label": ["airline crew scheduling", "partial evaluation", "generalized constant propagation", "program transformation"], "stemmed_label": ["airlin crew schedul", "partial evalu", "gener constant propag", "program transform"]}
{"doc": "Let $\\lambda( \\cal N )$ denote the weight of a minimum cut in an edge-weighted undirected network $ \\cal N $ , and $n$ and $m$ denote the numbers of vertices and edges , respectively . It is known that $O(n^ 2k )$ is an upper bound on the number of cuts with weights less than $k\\lambda( \\cal N )$ , where $k\\geq 1$ is a given constant . This paper first shows that all cuts of weights less than $k\\lambda( \\cal N )$ can be enumerated in $O(m^2n+n^ 2k m)$ time without using the maximum flow algorithm . The paper then proves for $k \\four$ that $n\\choose 2$ is a tight upper bound on the number of cuts of weights less than $k\\lambda( \\cal N )$ , and that all those cuts can be enumerated in $O(m^2n+mn^2\\log n)$ time . Introduction Let N stand for an undirected network with its edges being weighted by non-negative real numbers . Counting the number of cuts with small weights , and deriving upper and lower bounds on their numbers play an important role in the reliability analysis of probabilistic networks whose edges are subject to failure 2 , the graph augmentation problem , i.e. , the problem of increasing the edge-connectivity by adding the smallest number of edges to a graph 15 , and other problems. Let -(N ) denote the weight of a minimum cut in N , and let n and m be the numbers of vertices and edges , respectively . It is known that an upper bound on the number of minimum cuts is n(n 1) , which is achievable when N is a ring consisting of n edges with weight -(N )=2 1 , 3 . Recently , Vazirani and Yannakakis 17 showed that cuts of weights no more than the r-th minimum weight can be enumerated by O(rn) maximum ow computations . Based on a probabilistic analysis , on the other hand, Karger 10 derived for arbitrary k 1 an upper bound O(n 2k ) on the number of cuts of weights no more than k-(N ). In this paper , for arbitrary k 1 , we enumerate all cuts with weights no more than k-(N ) without relying on the maximum ow algorithm . Our enumeration algorithm makes use of the edge splitting operation (see Section to reduce the number of vertices by one while preserving the edge- connectivity . We repeatedly apply the edge splitting operation until the net-work has only two vertices , and obtain a sequence of such networks N i with 2 . After enumerating all small cuts (of weights no more than k-(N)) in N 2 , the set of small cuts in N i+1 are then computed from the set of those cuts in N i in the order of can show that the entire running time of this algorithm is O(m Thus , if there are (n 2k ) such cuts , each cut is found in linear time . We then prove that the number of cuts with weights", "label": ["polynomial algorithm", "graphs", "minimum cuts", "edge-splitting"], "stemmed_label": ["polynomi algorithm", "graph", "minimum cut", "edge-split"]}
{"doc": "AbstractInability to identify weaknesses or to quantify advancements in software system robustness frequently hinders the development of robust software systems . Efforts have been made to develop benchmarks of software robustness to address this problem , but they all suffer from significant shortcomings . This paper presents the various features that are desirable in a benchmark of system robustness , and evaluates some existing benchmarks according to these features . A new hierarchically structured approach to building robustness benchmarks , which overcomes many deficiencies of past efforts , is also presented . This approach has been applied to building a hierarchically structured benchmark that tests part of the Unix file and virtual memory systems . The resultant benchmark has successfully been used to identify new response class structures that were not detected in a similar situation by other less organized techniques . Introduction Given the current scarcity of tools to measure the robustness of a software system , operating system developers lack the means to focus their attention on issues affecting system robustness. System developers have long used suites of performance tests to aid in the development of high performance machines and application programs; we believe that a suite of robustness tests would be similarly useful in gauging the development of robust systems , and in providing a means to compare robustness among various systems . Throughout this paper many examples are presented in the context of evaluating the robustness of an operating system . However , most of the issues examined arise in evaluating the robustness of any complex software system. A robustness benchmark is a suite of robustness tests , or stimuli . The benchmark should address issues that are general enough to apply to a wide range of systems yet specific enough to provide a basis for differentiation according to system robustness . Essentially , a robustness benchmark aims to stimulate the system in ways that are likely to trigger internal errors , and thereby to expose design errors in the error detection or recovery mechanisms . Differentiation amongst systems should reflect the number of such errors uncovered. In attempting to design a useful benchmark with the most general applicability , several issues must be considered . For example , if a benchmark simulates memory faults via fault injection into the supervisor code of an operating system (as in Kanawati92 or Kao93 ) , it is not likely to be easily portable between operating systems , perhaps not even between operating systems that are very similar from an application's point of view - similar operating system interfaces are often backed by very different bodies of code . This makes it very difficult to inject faults into supervisor code in such a way that the results can meaningfully be compared across systems . This paper documents several goals that a benchmark of robustness should strive to achieve . Those goals are considered in light of the constraints presented by Unix-like operating systems . We then present the choices we have made in our initial efforts to develop a suite of", "label": ["software validation", "robustness benchmarking", "extensible benchmarks", "system reliability", "test suite organization", "software dependability", "object-oriented benchmarks"], "stemmed_label": ["softwar valid", "robust benchmark", "extens benchmark", "system reliabl", "test suit organ", "softwar depend", "object-ori benchmark"]}
{"doc": "AbstractWe report on a formal requirements analysis experiment involving an avionics control system . We describe a method for specifying and verifying real-time systems with PVS . The experiment involves the formalization of the functional and safety requirements of the avionics system as well as its multilevel verification . First level verification demonstrates the consistency of the specifications whilst the second level shows that certain system safety properties are satisfied by the specification . We critically analyze methodological issues of large scale verification and propose some practical ways of structuring verification activities for optimizing the benefits . Introduction paper reports on an experiment in the use of formal methods for producing and analyzing software requirements for a safety-related system . This work was conducted as part of the SafeFM project 3 , 4 , a collaboration with GEC Marconi Avionics (Mission Avionics Di- vision) and AEA Technology (Consultancy Services) . The SafeFM project was intended to support the practical use of formal methods for high integrity systems not by producing new theories but by integrating formal methods into existing development and assessment practice . The project focused on a particular class of application - real-time control systems - and most of the work is based on an avionics case study; a digital system controlling the variable geometry surfaces of an aircraft. This paper describes the application of a formal approach to the specification and analysis of the SafeFM case study requirements . The case study is a realistic system inspired by an existing air data computer (ADC) . It is a real-time control system which consists of two independent control channels: A primary channel performs all ADC functions during normal operation and a backup channel takes over when the primary fails . The two channels perform complex control and failure detection functions and have to satisfy safety-critical properties. The work on the case study was supported by the PVS specification and verification system 5 , 6 . We specified the functional requirements of the case study in PVS using a data flow approach . The purely definitional style This work was partially funded under the UK Department of Trade and Industry SafeIT programme by EPSRC Grant No under DTI Project No IED/1/9013 The authors are with the Department of Computer Science, Queen Mary and Westfield College , University of London , Mile End Rd , London E1 4NS , UK . E-mail: bruno@dcs.qmw.ac.uk, victoria@dcs.qmw.ac.uk adopted and the strong typing mechanisms of PVS give us strong assurance concerning the internal consistency of the functional specifications . In addition we performed various verifications by proving so-called putative theorems. Type-checking and putative theorems correspond to a first level of validation . On a second level , we verified that the safety-critical requirements were satisfied . This requires a system-wide perspective; relevant aspects and properties of the system under control and of the physical environment have to be included . For this purpose , we used an approach based on explicit time which is easy to implement in PVS . All the assumptions and safety properties", "label": ["requirements analysis", "formal verification", "safety critical systems", "avionics systems", "formal specification"], "stemmed_label": ["requir analysi", "formal verif", "safeti critic system", "avion system", "formal specif"]}
{"doc": "AbstractDynamic verification is a new approach to formal verification , applicable to generic algorithms such as those found in the Standard Template Library (STL , part of the Draft ANSI/ISO C++ Standard Library) . Using behavioral abstraction and symbolic execution techniques , verifications are carried out at an abstract level such that the results can be used in a variety of instances of the generic algorithms without repeating the proofs . This is achieved by substituting for type parameters of generic algorithms special data types that model generic concepts by accepting symbolic inputs and deducing outputs using inference methods . By itself , this symbolic execution technique supports testing of programs with symbolic values at an abstract level . For formal verification we also need to generate multiple program execution paths and use assertions (to handle while loops , for example) , but we show how this can be achieved via directives to a conventional debugger program and an analysis database . The assertions must still be supplied , but they can be packaged separately and evaluated as needed by appropriate transfers of control orchestrated via the debugger . Unlike all previous verification methods , the dynamic verification method thus works without having to transform source code or process it with special interpreters . We include an example of the formal verification of an STL generic algorithm . Introduction We present a new approach to formal verification of programs , called dynamic verification, and its application to C++ template-based generic algorithms . Whereas all previous verification methods have had to transform the source code or process it with special interpreters, such as a verification condition generator , the dynamic verification method is able to work directly with the original source code compiled with a conventional compiler . The method depends on two key insights . First , rather than viewing type parameters of generic algorithms as a complication , we can turn them to advantage by substituting for them special data types called Run-time Analysis Oracles (RAOs) 28 , which work with symbolic inputs and compute outputs using inference methods . By itself , this technique is a form of symbolic execution that supports testing with symbolic values , thereby covering large or infinite sets of inputs in each individual test . The set of data types covered by a RAO can also be infinite and can include data types that are non-isomorphic (such as one type in which an operator is commutative and another type in which the same operator is noncommutative). Something more is needed , however , for formal verification-the ability to control program execution paths and use assertions (such as function pre- and post-conditions and loop invariants) . This brings us to the second key insight behind dynamic verification , that we can achieve the necessary control via directives to a conventional debugging system . The assertions must still be supplied , but they can be packaged separately and symbolically executed as needed by appropriate transfers of control (achieved by setting breakpoints) . And we can similarly use", "label": ["generic algorithms", "templates", "standard template library", "software libraries", "specification", "verification"], "stemmed_label": ["gener algorithm", "templat", "standard templat librari", "softwar librari", "specif", "verif"]}
{"doc": "A hardware self-managing heap memory (RCM) for languages like Lisp , Smalltalk , and Java has been designed , built , tested and benchmarked . On every pointer write from the processor , reference-counting transactions are performed in real time within this memory , and garbage cells are reused without processor cycles . A processor allocates new nodes simply by reading from a distinguished location in its address space . The memory hardware also incorporates support for off-line , multiprocessing , mark-sweep garbage collection.Performance statistics are presented from a partial implementation of Scheme over five different memory models and two garbage collection strategies , from main memory (no access to RCM) to a fully operational RCM installed on an external bus . The performance of the RCM memory is more than competitive with main memory . Introduction 1.1 Technological Maturity Scale In 1992 Stuart Feldman presented a series of hurdles by which to measure progress in computing 15 . Paralleling the accepted milestones before thermonuclear-fusion power , he specified five milestones for new computer technologies by comparisons with alternative tools: 1 . \"Idea/Concept . An idea has been conceived and , perhaps , published . It sounds good and original but , at most, only back-of-the-envelope calculations and trivial (usually paper) examples support it. 2 . \"Research Demonstration . The idea is embodied in a first serious example or running demonstration as proof- of-concept , and its originator still likes it , though it is not useful for actual problems. 3 . \"Scientific Breakeven . The technique is developed sufficiently to be used on some real problems , and is shown to be better than some common technique or tool . Experience is not wide , and is probably controversial. 4 . \"Engineering Breakeven . Not only does the technique or tool do something , but it is useful on full-scale problems in concert with other tools. 5 . \"Financial Breakeven . The concept is known to be the technique of choice in a significant domain , and that it is profitable to use it in general software practice and in concert with other techniques 14 .\" In that context , this paper reports a research demonstration of hardware support for reference-counting and garbage collection as part of computer memory . Related work 21 supports scientific breakeven , as well . The concept was published twelve years ago 36 . The path from idea/concept to scientific breakeven is usually a story and , indeed , parts of this paper read like a narrative . However , the writing of stories like this-even unsuccessful ones-is essential to advancing the complex symbiosis between hardware and software . Without it we are denied the ability to whipsaw at their interface , reaching beyond improvements to one whose support can be foreseen in the financial marketplace . Innovative steps must be taken without a timetable for financial breakeven. 1.2 Reference-Counting Memory We report the design , construction , and testing of a specialized memory that provides system-level heap management in real time , providing atomic transactions", "label": ["uniprocessor", "garbage collection", "performance"], "stemmed_label": ["uniprocessor", "garbag collect", "perform"]}
{"doc": "AbstractWe present a new class of interconnection topologies called the Linear Recursive Networks (LRNs) and examine their possible applications in distributed systems . Each LRN is characterized by a recursive pattern of interconnection which can be specified by simple parameters . Basic properties such as node degree , diameter , and the performance of routing algorithms for all LRNs are then collectively analyzed in terms of these parameters . By choosing appropriate values for the parameters , our results can assist a network designer in selecting a topology with required routing performance and cost of interconnection . A subclass of LRNs , called Congruent LRNs (CLRNs) , is also identified here and shown to possess desirable properties for more tightly coupled systems . It is shown that the CLRNs include existing networks such as hypercube and generalized Fibonacci cubes . These results suggest that the linear recursive networks potentially have applications in interconnecting distributed systems . INTRODUCTION HEN designing the network topology of a distributed system , one attempts to satisfy as much as possible certain basic requirements such as routing efficiency, minimal cost of links , maximal concurrency , fault tolerance, and scalability (see , e.g. , 1 , 4 , 14 , 10 ) . It often appears that some of these requirements dictate conflicting approaches which can only be resolved by ad hoc methods and exhaustive simulations 4 , 14 . The complexity of the network designer's task can be reduced if the network topology assumes a certain degree of regularity . 1 Among other benefits , the simplicity of the naming and addressing conventions of such network tends to facilitate efficient routing and reduce software cost . For example , various topologies such as meshes , rings , trees, and combinations of several topologies 14 have been proposed and useful results have been obtained . However, there are relatively few existing results that quantitatively relate these individual networks . As such , it is rather difficult to choose a network topology to fulfill the different requirements . One objective of this paper , therefore , is to alleviate the difficulty of choice by contributing a new family of network topologies that span from loosely connected to densely connected topologies . As will be seen , these network topologies satisfy many of the basic requirements mentioned earlier. We will present the Linear Recursive Networks which include the hypercube 11 and the Generalized Fibonacci cubes 7 , 8 as special cases . Each member of these networks will be parameterized by a generator (call it A) and a dimension n . Properties of the class of networks are then analyzed and performance of the algorithms is determined in terms of A and n . The main advantages of this approach include: . Since the cost , performance , and reliability of a fairly large class of networks are expressed in terms of the same parameters (viz . A and n) , one analysis economically applies to all the networks. . The parameters provide a quantitative link between individual networks; the", "label": ["hypercube", "self-similar networks", "fibonacci cube", "routing algorithms", "recursive networks", "design and analysis of interconnection topologies"], "stemmed_label": ["hypercub", "self-similar network", "fibonacci cube", "rout algorithm", "recurs network", "design and analysi of interconnect topolog"]}
